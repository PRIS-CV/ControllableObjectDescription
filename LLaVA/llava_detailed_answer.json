[{"question_id": 0, "height": 240, "width": 320, "image": "000000001503.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [125.66, 11.46, 111.64, 89.53], "segmentation": {"size": [240, 320], "counts": "`am0c0l69G;F?@9H:F8H4L2N1O00N2010O00000000000000000000000001O0001O001O00001O00000000000000000000O1000000000000000O1000000000000001O0000000000000000000O101O000000000000000001OO2O00000000000000001O00001O1O2M7J7I4M6H7J6J6J5K8H5J7AlH5mbc0"}}, "object_label": "tv", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "cleanliness, texture, pose, color, pattern, state, material", "answer": "The image features a small, white flat screen TV with a clear plastic case surrounding it. The TV is turned on and displaying a screen with a blue background. The plastic case provides protection and a clean appearance to the TV, making it an attractive and modern display."}, {"question_id": 1, "height": 480, "width": 640, "image": "000000008021.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [318.36, 198.43, 21.96, 100.58], "segmentation": {"size": [480, 640], "counts": "cjd42\\>0gAd0\\=AlBl0n<WOoBn0l<UOQCR1i<QOTCR1i<g0L5K2N3N4L4L1O101OXMmCa2S<\\MRDa2n;]MWD^2Z<I8D=Ca0]Ob0AX\\\\4"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plaid/tartan/checkered", "pose:vertical/upright/standing", "state:folded/bend", "texture:smooth/sleek"], "control_dims": "color, texture, pattern, pose, material, transparency", "answer": "The tie in the image is a blue and white striped tie, which is worn by a man."}, {"question_id": 2, "height": 480, "width": 640, "image": "000000009769.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [84.55, 187.85, 379.28, 185.65], "segmentation": {"size": [480, 640], "counts": "nmZ14l>4L2N2N2N1O2O2M6J4YB\\Og<HkBg1S=3O1nBVNn<n100000001O001O000O1000000000000000000O1000O2O001OO1O10000000000O10000000000O100O10O10O100O1O1CRNgCo1X<QNjCn1T<TNlCl1S<UNmCl1Q<jMmC70P2R<jMoCM31LX20kMj;0WDL31LX20mMh;NYDM3OLY2OPNg;7ZDU2e;lMZDU2e;d0K5NVMcDS2];lMdDT2\\;lMdDU2[;jMfDV2Z;jMfDV2Z;jMfDV2Y;lMeDU2[;kMeD:1h0Z;nNeD1O\\O2O2d1X;oNfD2N\\O2N3e1W;oNfD58l0R;oNfD60VO3e1V;POgDGN10E61J[1Z;XOhDFO46AJ]1Y;XOhD96b0Q;VOhD98?Q;XOgD98>Q;ZOgDI0K6EJ[1Y;\\OgDH2K4FKZ1X;]OgDJOK6DMY1W;^OgD97POIY1X;_OhD8;9m:@gD7<9m:@gD7;:n:_OgD7<9m:_OhD96oNJY1W;@iD8;7k:CiD56oNOY1R;CiD56oNOX1S;DhD92lN2W1S;EiD=4MT;FhD90lN3T1V;HgD72kN2S1X;m0fDPN7R1T;n0PEPOR;P1kDQNGm0^;S1jDPNHm0^;U1aDoM2O1k0^;a1aD]N`;f1^DZNa;g1_DYN`;^1`DlN^;S1hDjNW;W1jDiMJk0Z;^1oDbNQ;_1nDbNo:a1RE^Nm:d1oDaMLi0S;l1lD\\M2g0Q;n1nDZM0i0Q;n1TERNk:P2UEoMi:T2XEjMf:X2[ETMG>m:_2\\EeMd:\\2VEoL0f0i:\\2\\EdMb:`2\\E`Mc:b2\\E^Mc:c2\\E^Mb:d2^E\\Ma:e2_E[M`:i1\\EZN5M^:j1]EbM05b0?P:o1_EbMb0=o9R2_EaMb0=n9T2_E_Mc0=m9`2iEmLKd0[:Z2aEVM6MNc0Z:d2fEjL0b0Y:e2gEjLOa0Y:f2hEiLO`0Z:o1cERN5]OOb0X:P2dEPN7]OM3L9[:X2eEcM107GNd0U:R2fEaM12>;j9S2gE`M21=<j9S2fEaM7L1MMb0U:U2fE`M7L0NN2K9Z:e2fEPM323NOb0U:b2iEoL1MMO1c0W:d2iEmL<?k9_2gEPM04?=i9_2iETMOKa0OA007V:a2hEaM1Oa0KB3S:b2kE`MO0b0IB5S:a2jE`M11`0GC7R:\\2oE^MK05OL1i06\\9\\2nE_M1NQ16P9]2mE`M10P12S9^2lE`MO3Q1OT9^2lE`M01Q1NU9a2kE`M1NP11T9a2lE_MZ1Ok8c2jE_MZ1Nl8c2jEaM1Kn01X9c2hEbM1Jo02W9P3oFUMm8k2jEoL0OP17V9k2TGTMl8l2UGoLdNOX:R3TGoLo8Q3oFRMP9m2nFWMQ9i2RGTMn8k2TGUMk8n2QGSMn8W3kEcLN1?2A5W:V3hEiL4L1<S:X3lE]LO<U:^1hEK2POV:m300000001O0000000000001O000000001O000000001O00000000000000001O1O:F6J2N1O2N1O1O001O1O0000001O000000000000000000000000000000O100000001O000O1O001N2N2N2M3K5G9H8L5N1O1O10000O11O1O01O00000O1000000O101O0O100O1O1O10000N2O2N1000001O00000000001O00001O1002NO1O3L4M3M2N2N3N3N1N1N3M104M24I3M4L1N2N1O00000000001O00000000000000000000O10000000000O1N2O1N2N2M3J6J6DlCeM[<h1eCXNn<i1QCWNP=l100000O1O2N2N2N4L3L7I>jN]B4Z>MRfb2"}}, "object_label": "truck", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:covered", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern, cleanliness", "answer": "The image features a red pickup truck parked on a snowy street. The truck is equipped with a plow on the front, which is used for clearing snow from the road. The plow is currently covered in snow, indicating that the truck has been actively clearing the snow from the street."}, {"question_id": 3, "height": 282, "width": 425, "image": "000000022371.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.64, 130.84, 195.62, 142.9], "segmentation": {"size": [282, 425], "counts": "T4R4h40000000000000000001O00000000000000001O00000001O0001O00000000001O0000000000001O0000001O00001O00000000000000000000001O00000000010O0000000000001O000000001O00000000010O0001O1O2N4M5J5K5K4M4K5K6J6J4L5K5K5K4L5K5K5K6J5K5K5K2N2N1NN3O1O1000O10001O00001O0O100000000O100000000000001O0O10000000001O0000000000001O000000000O10000000001N100000000000000O2O000000001N1000000O1000001N1O100O1000000O1O2M2O2NnRo1"}}, "object_label": "laptop", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:open", "texture:smooth/sleek"], "control_dims": "pattern, transparency, state, texture, cleanliness, color, pose, material", "answer": "The image features a man wearing a white shirt and tie, sitting at a desk with a laptop computer. The laptop is placed on the desk, and the man is looking at it with a thoughtful expression. The man is also wearing glasses, which can be seen on the desk as well. The scene appears to be a professional setting, with the man possibly working or studying."}, {"question_id": 4, "height": 375, "width": 500, "image": "000000023272.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 0.08, 499.46, 370.98], "segmentation": {"size": [375, 500], "counts": "j7b25\\Nh7j1THYNX4WOQOe3n0[L\\LJP2l3g1ULZL0m1m3T51N3N1O2O0O1O1O2O000N2O2O0O1O1O01000O1O2N100O1O01000O2N1O100O10O01O1O1O10000O100O100TJRKn4o4QKRKn4o4RKQKg4OdJP5e0QKg4NdJR5f0oJl4R5SKnJl4S5TKmJl4S5TKmJk4S5WKlJh4U5XKkJh4U5XKkJh4V5k01O010O1O101O000O10O0100N20001O0O1O10000O1O10000O10000O1O1O10000O100O100O100O1000000O002N100O100000000O1O100O100O10000O100O100OO2001N2O0O1O100O1000O10O100O100O100O011O1N100O100O100O1000000O100O100O10TLUKl0j4UORKWM0d3n4UOQKXM1c3n4Q3O100O100O10000O1000000O1O01O10O100O100O011N3N0O100O010aLPIW2Q7V101000O1000O02`LmHnN0X3T7X1000O100O010dLkHU2V7kMjHU2W7U1O02eLhHU2X7jMiHV2W7U10O1O10000O1mLQIjNHY2MfM[7V1YIkN[OU21jM[7W1]IP1c6QOgHkN000Y2Y7nNdHb1^7[10O1PMaHi1^7WNbHi1^7WNbHi1^7Y1NnLeHj1\\7UNdHl1Q1VMPOL2MM1_5T1aJlN0l2Q1bMQOE]5Q1aJlN1l2S1^MnNH^5R1`Jm1S1YMPOF_5T1^Jl1R1\\MPODa5T1]Jj11RMo0;SOE_5T1^Jj10SMP1:TOE]5T1_JP2f0kLZO12;g5i0XJkNOS3<QMD4OM2Nh5R1XJkN0S3:mLI?LFh5P1XJlN1R3a0]M]OEh5Q1YJT2`0jLA:h5g0WJW22fL51K;g5g0WJW21eL80L;d5j0WJW20cLd0;AE\\5V1_JkN0[3?eLC4m5P1QJlN4W33hLM3M15La5U1ZJkN4V33jLL3M11MM2f5R1[JlN0[37dLL4M121c5o0[J\\25`LL=1Bi5U1UJ\\25`LL=o5h0oI[27_LL<o5\\4\\JcKd5^4\\JXKB7Q6a4^JWKA8Q6`4aJZK^O25Le5h4fJ\\K@05Le5`1WJf1>lLC2o5Z1SJg1<lLA4P6S1_Jg12XM_5a4eJ\\K[5d4_JYKj5g4VJYKj5g4VJYKj5f4WJYK[11`2f4TLZKT1OaN3U4e4TN[Kl1e4TN[Kl1e4UNYKl1g4b20O10000eIXKg5h4ZJWKf5i4d0000N22N000O10O10O2O00000000SKZKi2f4T200O2O00001NZK]KZ2c4fM]KZ2c4]200cLRIP2P2lLg2T1YKP2o1mLh2S1ZKo1m1PMh2Q1VKjN2U3Q2PMg2\\4\\KaKb13S3\\4[KaKb13S3\\4WMaKoMNj4a4Y2hLmH5O7S7DoH407Q7EnH3479^NT6g2dIjN8_NT6f2eIlNN^NL4W1MhNOT5c2[KiNGcNK2Z11fNMR5b2_KjNGeNU10cNOR5a2aKeNGjN[10]3`2fKaNCoNY11^3^2hKbMYO5256EZ10]3_2QLdMSO8e1FYNOn4]2SLfMQO8l1FP3Z2VLgMoN8g1KT3U2VLiMoN7h1KR3U2WLiMoN0I1o11R3S2ZLjMlN8_14[3i1\\LkMiN8X1=b3_1_LkMgN9X1=b3_1_LkMhN8W1>b3]1`LnMgN7W1>b3\\1aLoMfN7W1>b3\\1aLoMfN7W1=c3\\1bLoMdN8W1=c3Z1dLPNdN8U1>c3Y1eLQNcN8U1>c3Y1RMXN\\O=c3Z1RMYNZO>d3W1TM[NWO?e3U1UM\\NSOb0h3Q1WM\\NQOb0i3Q1WM]NQO`0i3Q1XM_NoN`0i3P1YM`NmNa0j3n0ZMaNlN`0k3m0[McNiNa0l3l0[McNbNKQOe0S5l0[MdNaNKQOe0S5j0iJ`Nb26cNJnNe0U5j0]MgN^Ng0T4a0_McNZM2S1NmNi0V5d0aMcNYM2S1j0S4`0bMdNXM2S1:POLMGW5[1bMfNWM2S1NmN760JHW5Z1cMlNYNJoN1>3i4U1bMmNPOL_3V1bMnN]4Q1dKoNSNLU5T1iLPOQNOT5P1lLQOQNJW5T1iLmNPM2Y7P1hKnNoL2Y7o0iKoNnL2X7o0kKTOU4k0lKUOU4i0lKWOT4h0mKXOS4g0nKYOR4f0oKZOQ4e0PL[OP4d0QL\\Od1J[Mi0R1]On3b0SL^Om3a0TL_Ol3`0UL[ObL1Y7d0VLBh3<YLDg3;ZLEf3:[LC^LLW7`0\\LGd38]LE\\LLW7>^LB\\L0O0W7>^LB\\L0O0W7=_LCZL10OW7<`LDYL10OW7;aLIXLLW7:bLJWLLW79cLKVLLW78dLLULLW77eLIULO01U77gLITLO01U76hLJRL010V75gLNSLMV74hLORLMZ41]N2X10QLMZ41]N2X14;J]N1Y11PLMY41_N0Y11PLNX41_N0Y11PLNX40`N1X11PLNU70lL2oKNW4OcN0X13nKNV40dNOX13nKNV40cN0Y12nKNV4OdN1X12nKOT4NgN1V13oKNQ40kNOV12nKOQ4OmNOT13nKOQ4OmNOT13oKNo31nNNT11QL0m30oNOS116OhN0R11Z30eL0RL0k30SO0P11QL0j30UOOP11QLOj31VOOP1011oNOP101OQO1n0000RO0o0OX31hLON0UO1m0OPL1d31_ONT12]O0_OOT10]O1_OOT10]O0@0j00SL0c3OA1i00SL0o6OoL1SLO`30E0i00RL0_31FOi01PL0`31GNi01oK1a30GOi0OoK2a3OH0g00PL1_30KOe03oK0^3NOOd03PL0\\3N0Nf00QL2KO[323Mf03nKO]300Ne03mK0^3O0N50iL4BO`3O1NlN0iN0XO4BOa3M10kN1hNOYO4BO_3M50iN2gNNYO:Q3G6OiN2gNNZO9P3H6OjN2VO6i1I8OiN2eNN[O9o2G90WN4^NNh0N[O4B0P1LV14`1LVN2aN1f0M[O4B0X3O?MUN0cN4c0L\\O3C0X30>MiN1bNO\\O4BOY3O?OhN0aNO]O4CNW30a0OKOjL3DOT31d0NJOjL3DOS31f0N_MON0F0@3DOS31f0N_L0b01;OFOA2n21?NiN0YNOA2FNS32d0OiN1WN0B0F0S3Of01fN1YNOB0F0R3Oh01eN1YNOB0FOR30i01bN4ZNLC0FNR31j01`N5[NJE0j21f00]N8^NGEOj23f0O\\N9_NFEOj23f0NZN=aNCE0i22g0NXN?cNAE0h22i0NUNa0fN^OYO042m21l0NTNc0kN^OPO011T3Om0OnMh0POWORO200S30n0NhMn0UORORO30MT32m0NdMR1XOoNRO4W3Nj0NdMS1XOmNWO0S31k0ObMT1ZOkNVO2R3Om00^MW1EjNV60QJZ1_OeNYO2l2OU1OUM]1AcNYO2l2OU1OQMa1E_NYO2k20U1OoLc1H\\NYO3j2OV1OkLg1CWNB2L0N2o2OX1OhLi1DVNC2J001n20Z1LfLm1ETNC2J20Mo20Z1NeLm1MWNUON12m2M]1O^LR22RNUOM22l2O]1N]Ll1XOZNj0MWON135L]22g1N\\Lj1YOWN14`0KF3J66G]21h1OXLP2]OUN?LG2J66G\\22i1NULk1@YN20=MG2K55HY24m1LRLm1BXN1O>MG2K55HY23n1MQLn1AWN10<KD162J66GY23n1MQLU2DoM;NI2I57GY22o1NQL\\1AWO4A8OI=1@X23P2MQL\\1AXO3A8NJ=1@X21R2OoK]1@XO3@9NJ2J47GW22R2OPLZ1A[O2_O8MM>O@U24T2MoKS1ARO1`02_O6ON=0_OU24T2NnKZ1CSO0E126OO1J26HU23U2OmKZ1DROOGO28OM2K07HT23W2OlKZ1DC7WOJ=4^Om17`2JiKY1E@NXO93J=4_Oj17d2IhKZ1DD9TOJ?3_Oj17c2JiKY1DD8TOL`01_OKMj1;i2HiKX1EE6YOH<6]Oh1:f2H`KMMO1[11G2O0QO0OL;3GMM6379W4G`KNK02n0N[O3h0101PO69GLg06l3F`K1Mk0N[O3<ND0j04nN69GINMh0=m3E`KN0Z1NYO0m02aN6OE7U13a3I^KM12MQ11YOOD20M]14dN6OF6U12a3L[KN8R1HYOOC3b11_N78j0Nb3MZKO7Q1IZONB10Oc10\\N13;7j0Nb3I"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "state:off", "texture:smooth/sleek"], "control_dims": "cleanliness, transparency, pattern, material, state, texture, pose, color", "answer": "The image features a black Mercedes car parked in a driveway. A cat is sitting on the hood of the car, enjoying the warmth of the engine. The car is parked in front of a house, and there is a window visible in the background."}, {"question_id": 5, "height": 421, "width": 640, "image": "000000039477.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [341.18, 237.2, 252.01, 183.8], "segmentation": {"size": [421, 640], "counts": "Rl\\4d0^<<E7J7I6K6I7J5K4K6K7I4L7I6J3M4L6J4L6J3M6J4L5K5K2N1O0001O000000000001O00O10001O000000000000000000001O1O001O001O00000000000000000000000000O10jL`Gg1`8cMZHY2g7`M`H_2c7QMlHm2g8O1O1O1O1O001O001O0000000000O100O1O1O100N2O1O1O1N2O1N2N2N2N2N2M3M3L4L4M3K5L4I7H8J6[OWKeHR5Y7>1O1O1O1O001O1O1O1O1O1O1O1O1O1O001O1O1O1O1O1O1O1O1O001O1O1O1O1O1O001O1O1O1O1O1O1O1O1O1O002M101O1O1O100O1O001O1O1O1O1O1O1O001O1O1O1O1O1O1O1O1O001O1O1O1O1O1O1O1O1O001O1O1O1O1O1O1O1O1O1O1O001O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1N2N2N2M3M3N2L4M3M3N2M4L3L4M3L4L4M3L6HbVd0"}}, "object_label": "couch", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "material, pose, state", "answer": "The couch in the image is a small, brown, and black futon-style bed. It is placed in a corner of a room, with a window nearby. The couch is accompanied by a pillow, which is positioned on top of it."}, {"question_id": 6, "height": 421, "width": 640, "image": "000000039477.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "cleanliness, color, length, pose, size, state, texture, transparency", "region_anno": {"bbox": [310.2, 272.4, 20.15, 32.03], "segmentation": {"size": [421, 640], "counts": "cln31T=2UC1\\<ObC4]<MaCc0Q<^OlCe0R<80O6KO0000000O1OJkC^OT<j00O3TOiCf0^<[OkC3V<LlC2U<M]PP4"}}, "object_label": "potted plant", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:green", "length:short", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:rough"], "control_dims": "color, cleanliness, state, texture", "answer": "The image features a small potted plant with a red flower in a brown pot. The plant is placed on a table, and the pot is sitting on a blue tray. The plant appears to be a cactus, as it has a distinctive shape and is known for its ability to survive in arid conditions. The red flower adds a touch of color to the scene, making it an attractive and decorative piece."}, {"question_id": 7, "height": 375, "width": 500, "image": "000000050326.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [313.26, 0.0, 186.74, 260.04], "segmentation": {"size": [375, 500], "counts": "ZYb34b;2N100N3N1O1O1O1N2O1O100O2N10001N100000001N1000000000001O0000001O000000000O101O0000000000000000000O10000000000000O1000000000000000O00100O101N2O1O1O1N2O2M2O2N1O2M4M2M3N2M3N2M5LjN`F8]9GfF;U9EmF=o8DRG?j8@XGa0f8_O\\Gc0_8]OdGd0Y8\\OiGi0o7WOSHk0j7TOZHl0c7TO_Hm0]7TOeHm0X7ROkHP1Q7PORIo0l6POYIo0c6RO_IQ1\\6oNhIR1S6mNQJR1m5nNVJS1f5mN]JS1`5lNeJS1X5mNlJR1Q5nNRKQ1l4oNWKQ1f4oN]KP1a4oNeKn0Y4QOkKo0R4QOQLn0m3ROWLl0g3SO^Lj0a3VObLi0\\3WOgLg0X3XOmLf0Q3ZOQMe0n2ZOVMe0h2[O\\Mb0c2]ObM`0]2@fM>Y2BkM<S2CQN;n1ESN;l1EVN:i1EZN:e1F]N9b1GgM_OSMi0U5GcN9\\1GeN9Z1FiN9V1GlN8iL[Oh2<b07cLBi27d08aLDi24h07]LGj21[OBSNf0FIk2Om08WLIl2On08TLKm2MP18QLMn2JS19mK0n2GZOCeNf0QO2o2DZOFfNd0oN5P3@\\OGfNd0mN5Q3@[OGiNd0iN7R3^OHFSNe0QO8T3\\OIGSNe0oN8U3\\Oa1<XK:V3YOd1=TK;X3WOZOIXOe0UN;Y3WOYOJZOd0RN<[3UOYOLZOd0PN<]3TOi1?jJ=]3TOEKeNd0XN=^3TOEKfNd0VN=_3SOGJfNf0SN=`3SOn1`0`J>b3QODKoNh0fM?f3mNFLoNP2[1TNFLPOo1Z1UNXOL^M0P2n1[1UNWONMl1l0VNXOMMl1k0VNYONMk1j0WNY2h1gMWNC1ZOg1S1WNE0ZOh1X7OVM[NcKd1\\4]NdKc1\\4]NfKa1Z4^NhKa1V4`NlK_1T4`NnK_1R4`NPL_1P4aNQL^1o3bNQL^1o3aNSL^1T7O0000O10O0MiEhNh3"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:green", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness, pose, color, material, transparency, texture", "answer": "The chair in the image is a foldable lawn chair, which is green in color. It is placed on the sandy beach, facing the ocean."}, {"question_id": 8, "height": 480, "width": 640, "image": "000000056344.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 154.41, 282.87, 147.85], "segmentation": {"size": [480, 640], "counts": "P6;2]10[Nd<8[C^11[Nc<7\\C^10^Nb<V2O2O1O2N1O2M2O2N1O002N1N2O1O1O1O2N1N2O1O0000000000000O10O100000O1000000000O0100000000000O0100000O01000000000000000O10000000O1000O10000000000000O10O10000000O1000000000O10O1000000000000O10O1001OO100O100000O100000000O010000000000O100000O01O100000000000000O010O10000000O10000000O100000O100000000O01000000000O010000000000O1000O10000000O0100001O00O1000000000O10O1000000O100000000000O1000O100000000000N11000O1001O00O10O1000000000O10O10000000O10000000O10O100000000O10O1000000000O100000O1000000000O10O100000000000O100000000O0100000000000O1aNWD]NO11n0j;d0REiNo:W1]110OfBbNT=6lBR10dN101N10b<4hC1E11OO15J10XZ[5"}}, "object_label": "tv", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "cleanliness, material, pattern, pose, texture", "answer": "The image features two computer monitors sitting side by side on a desk. The monitors are turned on and displaying content, likely related to social media or other online activities. The monitors are placed on a desk, with one located towards the left side of the desk and the other towards the right side. The desk appears to be a workspace, with a keyboard and a mouse placed in front of the monitors."}, {"question_id": 9, "height": 612, "width": 612, "image": "000000057232.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [319.68, 421.92, 200.16, 138.24], "segmentation": {"size": [612, 612], "counts": "_db51Rc03ON]V10diN1ONjU42SjK3X]OK_U11]]O1N0O2EMe]O4Yb0Ne]O3Zb0Od]OMM0_b04b]OL1N]b0<6O01l]OG]a0;^^OHaa0;Z^OHea0l0O100O010O00010O0010O000010O010O01O01O01N1010O0001O10O1O01O010O01O01O010O0010O0010O0010O010O01O01Y^OmN\\a0R1e^OoN>OT`0R1]_OPO[a0P1e^OPO\\a0o0e^OPO[a0Q1e^OoNZa0Q1e^OoN]a0P1d^OPO[a0Q1d^OoN\\a0Q1d^OPO\\a0o0<1O0X^OnN`a0R1`^OoN^a0Q1b^OPO^a0o0b^ORO`0MT`0Q1]_OQO`0OQ`0Q1__OoNa0OQ`0Q1__OoN\\a0R1:0X^OoN_a0P1a^OQO^a0o0b^ORO^a0n0b^ORO]a0n0d^OQO\\a0o0=0O0W^OoN`a0R1`^OnN`a0Q1901O0010O00010O01O01O0100O000010O01O01O01O10O00010O01O01O01O001O010O1O010O001O0010O01O0010O010O0001O10O01O00100O000010O01O010O0010O01O00001O010O1O010O00010O1O0010O00010O000O11O01O0010O001O0001O0100O0010K41O100O100O2N100O1O2N2E;OYoe1"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:dilapidated/ruined/broken", "texture:rough"], "control_dims": "pattern, state, transparency, color, pose, material, texture", "answer": "The image features a wooden baseball bat, which is placed on a wooden rack or shelf. The bat is made of wood and appears to be old, possibly used for playing baseball. The wooden rack or shelf is filled with various baseball bats, creating a collection of these sports equipment. The wooden bats are arranged in a way that they are easily accessible and visible, showcasing the collection."}, {"question_id": 10, "height": 640, "width": 360, "image": "000000068078.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [140.0, 295.49, 171.08, 204.5], "segmentation": {"size": [640, 360], "counts": "Zfi2;bc07J5K3N3M3M3M2N2N2N3N2M4M1N3N1N2O1N2N2O1N2O1N101O0O2O1O0O2O001N2O1O000O2O1O000O2O001O001bA_MZ;b2cDeMY;[2cDjM\\;W2_DoM_;Q2]DTNa;n1ZDWNe;i1WD\\Nh;d1TD`Nl;a1mCfNR<\\1VBVM[1f1]<d1mBgNS=S401O00000O100000000O10000000O100O1O100VJZBY5g=eJ[BV1Lc2i=WL\\BT1Ld2i=WL\\BU1Kc2k=WL[BU1Jc2l=WL[BV1Ic2l=VL[BX1Ia2m=WLZBY1H_2o=WLZBZ1G^2P>VL[B]1C\\2g>Z14D<@?B?F9I8G8J7I7H7O101O001O00001O001O001O0O2O000000000O100000O1O001O1DlMl^OT2Ta0mMk^OR2Va0QNf^OP2Za0;1gMe^Oj1\\a0SNg^Om1Ya0VNe^Oi1\\a0YNa^Of1`a0=1N101lM_^Of1Yb0D2N101N1O2O0O1O2O0O1O1O2N1N3N1O1O1O0O1O1M3OO20O01O11O1O2N2M3N2L4K_UP1"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "pattern, color, cleanliness, texture, material", "answer": "The sink in the image is a white pedestal sink, which is a modern and sleek design. It is placed in a bathroom with a toilet nearby."}, {"question_id": 11, "height": 640, "width": 480, "image": "000000089761.jpg", "category": "description", "question": "Describe the toilet in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [138.38, 317.12, 253.69, 311.35], "segmentation": {"size": [640, 480], "counts": "[oe2b0Zc08J3M4M3M2M4M2N2N2N3M3M5K3M4L3N3L3M3M3M3N2M2O2M2O2M4L2O1N3N1N3N1O1N2O2M2O1N2N2O1O2M2O1O1N2O1N2O1N2O001N2O1N2O1O1O1O1hCiKd8Y4UGRLf8n3VGZLg8f3TGaLh8a3UGbLj8_3QGgLm8Y3QGkLm8V3oFoLo8R3nFQMQ9o2nFTMP9m2mFVMR9k2kFXMT9i2jFYMU9g2iF\\MU9f2iF\\MV9d2iF^MV9c2hF_MW9b2fFaMY9`2dFcMZ9_2aFeM_9\\2\\FiMc9X2VFoMi9R2SFRNl9o1mEWNS:j1jEYNU:h1cE_N]:c1\\EcNc:^5O00001O01O01O010O1O001N101O00001O0000001O00001O000O100000001O0000000000000000O100000000000000000000000000000000O10000O10000O10000O2O0O100O010O1O001N2O1O1O10000ULYE]Ng:a1eEVNZ:h1nERNR:l1TFPNl9o1XFmMi9R2[FkMe9T2_FiMa9V2eFeM[9Z2iFbMX9^2kF^MV9a2mF\\MT9d2nFYMS9f2oFoL\\9o2gFnLZ9R3gFlL[9R3hFlLX9T3jFjLV9U3lFiLU9W3lFhLT9W3PGeLQ9Z3RGdLn8\\3UG`Ll8_3XG[Lk8d3ZGSLk8l3YGnKk8P4XGgKo8X4]300O1O2N101N1N2O2N1O1O2N101N1O1O2M2O1O2M2O1O2N1O2M2N3N1N3N1N3N1O2M2O2M2N3M2N3M3L3N3M3M2N3L4L4K5M3N2N2N2M3N2N3M3L3M4K7IjTi1"}}, "object_label": "toilet", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color, cleanliness, pattern", "answer": "The image features a white toilet bowl sitting on the ground, surrounded by grass and leaves. The toilet appears to be old and dirty, possibly abandoned or discarded. It is situated next to a tree, which adds a natural element to the scene."}, {"question_id": 12, "height": 180, "width": 240, "image": "000000107339.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [3.5, 70.75, 137.0, 64.5], "segmentation": {"size": [180, 240], "counts": "on01161JS5g0F3N001O1O1O001O1O1O001O1O1O001O1EoNQLR1n3oNnKL0U1Q4SOoKm0Q4;0iNoKk0Q4UOoKj0R4VOnKj0R4VOnKj0R4<O10O10000000000O1O1SOnK8R4HoK7Q4IoK@Md0T4O[LEe3<\\LBd3>\\LBd3>\\LBd3>\\LAe3?[LAe3?[LAe3?g0010000O1O1K5M3N200O100O10000000000001O1O2M7J4L00O11WK\\O`4c0bK^O\\4b0gK[OY4e0gK\\OX4f0eK[O[4c0hK[OY4d0hK\\OX4d0_K\\O60[4d0^K]O7O[4d0_K\\O51\\4c0_K\\O51\\4c0^KFb4:^KEc4:_K^O10a4b0^KEa4<^KBd4=9100000O100001VK\\Ob4c080000O101O5KjJDZ55gU3L\\jL4`]c0"}}, "object_label": "couch", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "material, transparency", "answer": "The couch in the image is a large, white, and modern-looking piece of furniture. It is positioned in the center of the room, with a girl sitting on it."}, {"question_id": 13, "height": 500, "width": 375, "image": "000000214720.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [58.06, 142.83, 133.34, 77.42], "segmentation": {"size": [500, 375], "counts": "Q^n03`?2N1O2N1jAOh<3oB7n<KQC6l<LTC4k<MVC2j<NWCBVO:b=5XCAUO;b=JbBNg0MUO;a=IlC6S<JnC6Q<JPD6o;KUCJ6;d<LSD3m;MSD3l;NTD2k;OUD1j;1UDOk;1UDOj;3UDMj;4VDLj;5YDAm;`0RD@n;`0RDAl;?e100L4OeBE_;9YQ1HoaNOi_10WoN0000000000001OO1001iM1gDOZ;0fDO\\;0dD0`=1oM2ZDNg;2XDNi;1WDOk;OUD1l;1QDOP<0PD0P<1oCOP<5mCKS<6lCJT<9iCGW<:hCFX<;gCEY<=YCCZO0]==YCCZO0\\=?XCC[ON]=b0TCB^OK_=d0QCB@J_=d0PCBBJ^=d0PCBZ=b0bB\\OBLh=i0eBYODOg=d0VB]O=OE3g=g0dBUOg=h0jAB^>l0NDeA_O[>l01K5000O1O2O_OcAK]>5dAJ]>3gAJ[>4gAKY>5gAKY>5gAKY>4iAJX>6hAIY>7gAG[>9eAF\\>9`000000O1WAFW>:jAGU>9kAGU>9c000O100O100000001O0O101O1Oh`P3"}}, "object_label": "couch", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "material, transparency, texture, state, pattern", "answer": "The couch in the image is red and features a white fur throw on it. The fur throw is placed on the back of the couch, creating a cozy and comfortable seating area."}, {"question_id": 14, "height": 500, "width": 375, "image": "000000214720.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [20.34, 193.89, 289.08, 139.19], "segmentation": {"size": [500, 375], "counts": "na:6[?7J3N2M3N2N2M2O2N1O1O1N2O1N2O1O1O000010N100010O100O010O100O100O1O100O1O101N100O2O1N2N2O1N1O1O1O10000O10O01O100O010O100O1O1O10O0100O100O100O001O100O1000000O01000O100O100O1O01000O10000O010O100O100O10000O10O1000O101O0000POnB^OR=9[CCe<8`CHa<1fCNW<2lCN`;FbC>P1N\\;a0dD@U;WOkCZ1R1@Q;b0RE^Om:[OnCP1U1Ej:h0SD^Nk0k0o:P1PEPOo:V1kDkNT;Y1iDgNV;[1iDeNV;_1dDdMDn0g;a1cDbN[;d1_D]N`;l2O10O0100O100O10XO_D]Ma;b2bD\\M^;e2aD[M_;f2`DZM_;h2`DXM`;g2aDYM_;g2bDXM^;h2bDXM^;i2aDWM_;i2aDWM_;i2aDWM_;i2aDVM`;_300000O100ZO^D[Ma;\\31XO^D\\Mb;d2^D[Mc;e2]D[Md;\\3N01N2fN]DbNb;]1_DcNb;[1aDdN_;Z1fDbN[;]1eDcN\\;Z1fDfN[;X1gDgNZ;W1gDiNZ;U1gDkNY;U1ZDmM5o0b;k0VDXN`0m0[;j0VDXN?n0];h0SD[Na0l0_;l0bDUO_;EPD=<0g;_OUD;27g<0RC1m<2PCNP=\\10O001O00001O001O010O0010O01O001O1O1O1O0010O01O001O000001O000000000001O001O00001O1O001O1O1O1O0000O10000O11O001O1O001N2O1O1O001O0000000000001O001O001O1N101O1O1O1O1O1O1O1O001O1O1O1O1O1N2O001O1O1O001O1O1N2O001O2N1N2M4L4L5Gf@Om\\P1"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:curly/curled", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, pose, maturity, hair type", "answer": "The image features a man sitting at a dining table, smiling and posing for a picture. He is wearing a red sweater and glasses, and he is holding a plate with a piece of cake on it. The cake is placed in front of him, and there is a fork nearby. The man appears to be enjoying the moment and the delicious treat."}, {"question_id": 15, "height": 640, "width": 480, "image": "000000221708.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [373.0, 266.64, 93.39, 179.0], "segmentation": {"size": [640, 480], "counts": "X_Y73n05ha0MV^O8ca0MY^O6da0NT^O8ka0IR^O8na0Km]O3Xb0Nf]O2\\b00_]O0db0d0j]OiNga0V1Z^OkNda0U1]^OkNca0S1_^OmNaa0Q1g000NP^OoNVa0P1k^OQOUa0l0n^OUORa0i0n^OXOTa0f0l^OZOTa0e0m^O[OSa0e0m^O\\ORa0d0n^O\\ORa0d0n^O\\OQa0e0P_OZOPa0f0P_OZOPa0f0P_OZOQa0e0P_OZOPa0f0U10001O00000000000000010O00001O00001O002O0O0000O1N3M3N2K<F6J<b]OXN2Ofa0Y2J6J<e^OZMg`0Z3B5L3NjMo_Oa0o?@T@>j?C^@5a?Lb@\\O@[OR`0[1k@iN@Af?h1m14M2N3M2O1M\\O^^OeN2O_a0X1T_OdNl`0Y1m0N2N3L4I6L3O4M102M3O2M5Gi[:"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "transparency, texture", "answer": "The image features a wooden chair with a wooden seat and back, placed in a room. The chair is positioned near a wooden dining table, which is located in the corner of the room. The chair is situated in front of the table, making it a comfortable seating option for dining or other activities."}, {"question_id": 16, "height": 480, "width": 640, "image": "000000233033.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [343.62, 306.14, 119.2, 162.15], "segmentation": {"size": [480, 640], "counts": "bhP52i>7_<KdC3LO]AL^>OeA4c>1XBNa<1`BMd08YOH`=1aB3`09_ODf=1eB<JD`=0bB<2D[=d0kBZOT=e0a0ON]OnAb0V>03N21SC^O[;b0fD@W;a0jD_OT;c0mD]OQ;c0QE\\Om:e0TE[Oj:f0VE\\Oh:d0ZE[Od:f0]E\\O_:e0bE[O]:e0dE\\OZ:d0gE\\OX:d0iE[OV:MoCe0l1]OU:NoCe0T>YOmAg0W>O00000001O00000001O0000000000010O0000000000O1JYOSBg0m=ZORBg0l=ZOTBf0m=ZORBf0n=6001O000001N1O1L4M3M4M2M4K3gBaNQ=`1TC^Ng<e1ZC\\Nb<f1bCVN[<m1hCUNo;n1SDUNh;l1[DRNb;Q2^DPN];S2d05L4LMeCiMW<X2lCjMm;X2WDgMe;Y2_DhM[;X2jDgMT;Y2oDgMm:Z2VEgMf:V2aEjM[:T2lEjMQ:U2RFlMk9R2[FnMa9Q2cFoMZ9o1kFQNS9l1SGSNk8i1[GZNa8d1cG[N[8b1jG]NV8_1PH`Nn7\\1XHfNe7V1aHjN\\7T1iHkNV7Q1oHoNo6o0UIoNk6m0]InNe6n0h3L5M2M4L4M2N2O1O1O1O2N1O2NUga2"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:gray", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness, material, transparency, pattern, state, pose, texture, color", "answer": "The chair in the image is a folding lawn chair, which is placed on a wooden deck. It is positioned near a dining table and a railing, creating a comfortable outdoor seating area. The chair is currently empty, and it appears to be in a relaxed state."}, {"question_id": 17, "height": 459, "width": 640, "image": "000000242060.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [285.71, 17.53, 73.24, 127.91], "segmentation": {"size": [459, 640], "counts": "kho33V>7J6J5K<D?B8G;F7H6Ka0_O7H;F3M1O1O1N101O001O00001OXLcEb3]:_LdE_3[:bLhE[3X:gLhEW3X:jLiET3W:lLjET3U:lLnEQ3R:PMnEo2R:QMnEo2R:UMjEk2U:VMkEj2U:VMjEk2V:e02N2N1O2N2N1O1O1O2aLYEV3h:iLXEV3k:gLVEY3n:000]OhLSFW3n9kLPFU3P:jLQFV3P:hLQFX3a:O100O010O001OO01O0I3SMmDc2];G?H8C>E;E:I7B?MV\\n3"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:green", "material:glass", "transparency:transparent/translucent", "pattern:tiled", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency, color, state", "answer": "The image features a glass cup filled with water, placed on a wooden table. The cup is decorated with a blue and green design, giving it a unique and colorful appearance. The cup is positioned in the center of the table, and it appears to be the main focus of the scene."}, {"question_id": 18, "height": 424, "width": 640, "image": "000000245026.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [522.21, 343.08, 63.49, 77.92], "segmentation": {"size": [424, 640], "counts": "ilh66o<6K3O2M9\\C:U;R1K3L101O0O1000000O1000000000UOVEXOj:c0WEeN1g0h:h0XEXOh:a0WEkN1d0h:a0WEkN1d0h:a0XEjN0e0h:a0YEiNOf0h:a0XEjNOf0i:a0WEDj:a0UE[Ok:a10jM_Ee1b:XN`Eh1o:2M2M3M3K5O10000000000001O0000001N100M4I6J7H7K6I6K6J5J8L2O3M2L_Pf0"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:blue", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "cleanliness, pattern", "answer": "The image features a cup with a blue straw sticking out of it. The cup is placed on a table, and it appears to be a plastic cup. The straw is positioned in the middle of the cup, and it is quite long, extending out of the cup. The cup is sitting on a table, and there is a piece of paper nearby."}, {"question_id": 19, "height": 388, "width": 640, "image": "000000313454.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [262.37, 254.23, 49.97, 57.5], "segmentation": {"size": [388, 640], "counts": "RUS332Q1d::O1N2O1O1O100O1O1000000O10000000000000000001O001O0O101O001O001O1O001O1O1O1O1O1N110O1O2N1O2]Ob0L5K5J`\\l3"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:leather", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "texture, transparency, pose, state", "answer": "The chair in the image is a brown leather chair, likely a high-backed chair, placed on a table. It is positioned in front of a bottle, which is sitting on the table as well. The chair appears to be empty, and the overall setting suggests a comfortable and inviting atmosphere."}, {"question_id": 20, "height": 388, "width": 640, "image": "000000313454.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [88.44, 147.58, 21.04, 79.4], "segmentation": {"size": [388, 640], "counts": "kkQ119m0b:VOYEQ1c:9M2O1001NRFjNP9V1oFkNR9S1oFmNR9JaFk0<\\Oc9a0]F^Of9?ZFBk99TFGQ:4PFLV:NiE3S;000O24L4KeoX6"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:yellow", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:folded/bend", "texture:smooth/sleek"], "control_dims": "material, color, texture, length, cleanliness, transparency, pattern, pose", "answer": "The tie in the image is yellow and has a pattern on it. It is worn by a man who is standing in front of a podium, possibly giving a speech or presentation. The man is wearing a suit, which complements the tie and adds to the formal appearance of the scene."}, {"question_id": 21, "height": 640, "width": 480, "image": "000000313588.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [346.91, 189.61, 133.09, 99.8], "segmentation": {"size": [640, 480], "counts": "`[e6a0[c07L3M2XOXOU^OMCf0Wb0Hj]ODOc0Xb0Mg]O9Xb0Hi]O7Vb0Jh]O12[OWb0]15100O1O10000O101N10001N1O101O0000001O001N11O00O2O0010O0_OW^OkNia0S1b0N3O2M2O1O1O1O1O100O10000O01000O10001OO100000001O00001O0O2O001O2N2N1N4M2N5g]OdNda0^1W^OeNia0i1O10N1EU^O[N10ma0e1R^O]NNOPb0S1S^OSOO4la0n1G0O2O0O2O001O010O01O10O01O1O001O1O001O000O2O001O001O1O00001O001N101O00001O001O00001O00001O000O2O00001O0000001M[I"}}, "object_label": "umbrella", "attribute_label": ["cleanliness:clean/neat", "color:pink", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:horizontal/lying", "state:open", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The umbrella in the image is a large, polka dot umbrella with a purple and white pattern. It is being held by a woman who is smiling and posing for the camera. The umbrella is open, providing protection from the elements."}, {"question_id": 22, "height": 375, "width": 500, "image": "000000322352.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [148.88, 180.97, 100.51, 173.86], "segmentation": {"size": [375, 500], "counts": "dSg13c;2N3N4L3M4M7H6J9Gi0XO:E6J002[G_Mo7d2a0kMTG@Mo1l8`NbG[1\\8dNgG^1U8bNmGc1l7]NUHf1g7ZNYHP2]7PNcHZ2S7fMoH`3i5`LYJ_3f5aLWJA\\O`01j2\\6UMVJB]O?1j2\\6UMUJ6^O71_1\\6TNVJ5]O8`0P1m5cNWJ4\\O90TO>5B^1]6lNZJ1YO<a0YOOL_Oo0^6_OZJ1YO;b0ZO300Lh5>ZJ1YO<0UO=48Oa6;bI1YO`0;UO9Oa6;bI1XOd09QO<0`6:cI1WOk04jNc0O_6;cI1WOU1h0_N^6;cI1XOT1g0`N]6<dI0XOD0`030c0@^6<dIOYOEO`08N;Ba6;eI0YOC0a0:M5Dc6;eI0YOB1b0=J0Gd6;eI0YODO`0a0IMHe6;eI0XOEO`0b0GNId6;eI0YOD0?`0C4O^6;eI0YOB20K>c0F4O^6;eI0EO4G4O^6;eIOF03G4O^6;eIOF03G4O^6;bIAZO>?C@9d0K3O^6;aIB[O=b0L1K4N]6<aI3NG0L4N]6<aI4MF1L4N]6<aI4MG0K5N]6=`IA\\O>c0JOL5N]6=aI@[O>d0KNL5N]6=aI@[O>d0KNL5N]6>_I@]O>c0I0M3O_6<^IB\\O=d0JOL5N^6=^I3OG0K5N^6=_I2OG0K4O^6=_I2NH1J4O_6<^IA\\O?=06E30`6;aI0CBE>d0E30`6;^IA\\O?:AF?c0E30`6;^IA\\O?:BE>d0E30a6:]IC[O>;39C2Ob6:]I4G^OD?d0F2Ob6:\\I5KK5G2Ob6:[I6H]OE>d0E30a6;YI7E0>^O30a6:ZI8D0>^O21b69ZI8AZONf0b0_O3Oc6:ZI7_O5a0[O3O0Mj5=SJ7^O6c0YO20OOj5;UJ6^O6b0ZO20N0j5;VJ5@]OMc0b0B001Mk5=RJT118l5dNRJV1H?W6ZNQJf3o5ZLQJf3o5YLRJg3n5YLSJf3m5[LQJf3o5ZLlIj3U6XL`Im2d7F]HmL`03U7l2o0L4\\O]GVN`8j1bGUNKHNN2Mn7U2YHYNHNT8l0^HlNH;ENU8:nH@TOj0n7]OWI>fNDT8I\\I?aNIU8E\\Ia0]NJV:j03N<oNi0KcYk2"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "color, pattern, pose, cleanliness, transparency, state", "answer": "The chair in the image is a wooden chair with a seat and back, placed at a dining table. The chair is positioned in the middle of the table, and it appears to be empty. The table is covered with a tablecloth, and there is a bowl on the table, possibly containing food or decoration. The overall setting suggests a cozy and inviting atmosphere for dining or socializing."}, {"question_id": 23, "height": 414, "width": 640, "image": "000000353518.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [297.08, 135.45, 114.61, 55.88], "segmentation": {"size": [414, 640], "counts": "Qdh35i<0gCM\\<2M101O2N1O1O2N5I3O010O000O010000000O11O10O0001O00O10000O1E_OXDb0g;@WDa0i;:O1[OPO[EQ1e:oNZER1Y;000000[OXD4g;b000000000000O100000000000000000001O00000000001O001N3N\\OVO\\Eb0d:^O]Ea0b:@_E?b:_O_Ea0a:]OaEc0];01O00000O10000000O1N2O1O10O010O1O1001O0O2O0O0100O010001ON2N1O2M2O0011O03EdCKQ<1h0000\\^l2"}}, "object_label": "boat", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:green", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "pose, state, transparency, color, cleanliness, material", "answer": "The image features a small boat sitting on the beach, surrounded by a body of water. The boat is positioned on the sand, and it appears to be old and possibly abandoned. There are two paddles nearby, one closer to the boat and the other further away. The boat is the main focus of the scene, and it seems to be the only boat visible in the image."}, {"question_id": 24, "height": 478, "width": 640, "image": "000000363461.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [438.58, 163.31, 47.3, 239.49], "segmentation": {"size": [478, 640], "counts": "aR_6e0m=d0_O`0E>E9Ab0_O7_DiLl:o3E`0A?[Oe0]Ob0_O<D9UOVI\\IQ7b6QISIY7l6=00001O001O001O1O2L4J6J5M4I7I7F:L3SO]GiJ46d8m4XGnJ[9j4aFVK61Y9b4iFZKf9Q4o0H8A?D<F:J5AaCVNT1L]:i1c1EcCdNl;P1cCmNd00l;k0^1Hf0]O<0VmS2"}}, "object_label": "tv", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "pose, transparency", "answer": "The image features a flat screen TV mounted on a wall, with a person standing in front of it. The TV is positioned at the top of the wall, and the person is standing at a lower level, closer to the viewer. The TV appears to be turned off, as there is no visible content on the screen."}, {"question_id": 25, "height": 375, "width": 500, "image": "000000371749.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [31.45, 230.65, 250.81, 139.51], "segmentation": {"size": [375, 500], "counts": "ZT=Z1d9P1ROg0B>H8N2M3N2N2O1O1O100O10000000000000000O1KoKdHQ4Z77O100O1O1000000O100000000O100000000000000000000000000000000000000000000000000000000000000000000000HkHnKU7Z400001N10000000000000000000001O000000000O1O1O11O001O01O000001O000001O01O0000000001O00000000001O000000001O000000001O00001O000000001O001O001O001OO100N2000000000000000000000000000000001O001O00001O001O1O001O001O7I3M5K3M2N1O1O1O0000001O1O2N3M1O5K2N4LH]M_G`2a8dM`GW2`8nM\\GQ2d8PN]Gn1d8TNZGk1f8WNZGg1f8[NXGe1h8\\NYGa1i8_NWG`1k8^NUGb1m8]NSGb1n8^NRGm02QOm81QGj09ROg84PGf0=UOd85oFb0b0WO_87PG?d0YO\\89PG;g0[OZ8:nF9<[OK1k8<nF4;EKIm8?nF0:JKFm8b0nFI:3JBo8b0nFE8:L]OP9d0mF@9?W91PG1Q9OlF3U9KiF<U9_OlFd0T9WOoFk0P9POQGT1h92N100FhNVFW1h9mNUFU1f9QOXFP1e9RO[Fn0b9UO^Fl0a9TO_Fl0b9SO^Fm0c9RO]Fo0b9QO^Fo0c9jN]FI1[1e9hNdFV1^9gNdFV1P:M3L5L4J6M:FX`_2"}}, "object_label": "couch", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "state, color, texture", "answer": "The couch in the image is a large, white, and leather couch. It is positioned in a living room, and a person is sitting on it, holding a Wii remote in their hand."}, {"question_id": 26, "height": 375, "width": 500, "image": "000000371749.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [284.59, 164.28, 82.58, 67.33], "segmentation": {"size": [375, 500], "counts": "XPZ33c;3L4L2N3N1O1O2N100O1O2O0000100O1001O02N011N3M1O00000001O0O101N2N1O100O1O1O001O1O1O1O001O1O1O100O1003M00N101O1O1O1O1000eDIU;>O001N02N001O1O1O1O1O1O1O001O1O1N2O00BMmD242o:MnD112R;MlD4ONV;76KjY^1"}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "texture, pattern, transparency, color, material", "answer": "The remote in the image is white and appears to be a Wii remote, which is a type of video game controller. It is being held by a person, who is sitting down and looking at the camera. The remote is designed to be used with the Nintendo Wii gaming console, which is known for its motion-sensing capabilities."}, {"question_id": 27, "height": 640, "width": 426, "image": "000000378605.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [273.26, 126.12, 151.01, 245.93], "segmentation": {"size": [640, 426], "counts": "SZX5?]c0:H5K5K4M3L5L3M3L4M2N3M3M3M3M3N1N2O1N2O2M3M2O1O1N3NkM[_OP1d`0PO__On0``0ROd_Ok0Z`0UOj_Oj0T`0VOn_Oi0Q`0XOQ@g0m?YOT@g0k?YOX@e0g?[OZ@e0e?[O\\@e0c?[O_@e0_?[Oc@d0\\?]Od@c0[?]Og@b0X?_Oi@`0V?@n@=Q?Do@<P?DPA=o>DPA=o>CRA=m>DUA:j>HUA8j>HWA8h>IWA8h>IZA5e>L[A5c>L\\A5c>L\\A4d>M[A4d>M\\A2e>N\\A0^OTOYOG]>V1lBNUOHm=:oB2nNEi=UOnAU1[13iNGi=d0]CKcNBm=g0[CR1c<XOUBnMa0S3X=o2O2N1O2N1O100O2N101N1O10QJcB\\5[=cJkBY5U=gJmBX5R=bJfBI8e5Q=bJiBH7f5o<bJjBG9f5l<cJ]C[5c<eJ^C[5a<eJmBF<e5f<fJnBF<d5e<fJoBE>d5b<gJfCY5Y<gJgCY5Y<gJhCY5V<hJjCX5V<hJkCW5U<hJmCX5Q<fJRDZ5n;hJPDY5o;hJQDW5o;gJSDZ5k;fJWDY5i;fJXDZ5h;gJWDZ5g;gJZDX5f;hJZDY5e;fJ]DY5c;gJaCI=a5P<fJ_CFL34O9a5X<fJ_CIK140:a5W<dJaCIK42L<d5U<bJiCN9_5n;cJiCO8_5n;bJjCN:_5k;dJkCHD1f0d5j;bJlCO:_5j;bJlCN<`5g;bJhCKG4j0_5g;bJhC4IGa0d5m;aJhC<;R5m;bJhC<;S5k;bJiC7LA`0g5j;aJkC6`0Y5e;aJlCJG6j0_5b;aJnCHH7h0`5b;aJmCJH4j0b5`;`JjCNL0j0c5_;_JkC7MCc0h5d;]JmC9JD6M5i5n;]JmCJJb06_O5h5m;^JmCIK<0G6L7j5k;^JPD4KEc0j5a;]JRDJI2k0h5X;]JUDHG0Q1j5S;^JUDGH1P1k5R;]JQDGM7o0f5R;\\JRD6h0^5V;\\JQD<d0Y5Z;[JRD=d0X5Y;[JSD>2YO9o5a;[JSD=3YO9P6`;ZJSD:8\\O5Q6_;YJTD9j0^5R;YJTD9j0_5Q;XJVD8j0`5o:YJUD;6[O9R6[;VKVDkN=P6\\;VKVDjN>Q6[;[KeDe4[;[KeDf4Z;ZKfDg4Y;YKgDh4X;WKiDi4W;XKiDg4W;YKiDg4W;ZKhDf4X;ZKhDf4X;[KgDe4Y;[KgDe4Y;[KgDe4Y;hJ\\DSOh0T6P=QJZBK[="}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, texture, material, pattern, state", "answer": "The cup in the image is a white coffee mug, which is placed on a dining table. It is filled with a dark liquid, likely coffee, and is accompanied by a donut on a plate. The cup is positioned next to the plate, creating a cozy and inviting scene."}, {"question_id": 28, "height": 640, "width": 584, "image": "000000381639.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [221.2, 52.32, 12.18, 19.97], "segmentation": {"size": [640, 584], "counts": "diZ44>Nnb0c0O0100O1N2O1N2N3N4K3KQfj6"}}, "object_label": "backpack", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pose, texture, state, color, cleanliness", "answer": "The backpack in the image is black and features a white logo. It is worn by a person, possibly a young man, who is standing in front of a white wall. The backpack is positioned on the person's back, covering a significant portion of their upper body."}, {"question_id": 29, "height": 640, "width": 426, "image": "000000421923.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [178.03, 137.16, 50.65, 94.73], "segmentation": {"size": [640, 426], "counts": "o]_316P1n`0l1N1O1000000O0100\\Od0N2D<O10001O000000001O000O10001O000000001O000O1000001O00001O0000001N1000001O0O1]Oe0WOUPk3"}}, "object_label": "book", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:red", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "cleanliness", "answer": "The image features a red book with a white letter \"S\" on the cover, sitting on a wooden shelf. The book is placed next to a stack of other books, creating a visually appealing display. The shelf appears to be a part of a bookcase, and the books are neatly arranged, creating an organized and inviting atmosphere."}, {"question_id": 30, "height": 640, "width": 426, "image": "000000421923.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [183.49, 309.68, 112.21, 25.14], "segmentation": {"size": [640, 426], "counts": "Qbd34fc06O101O00000000000000000O2O000000000000001O000O1000001O00000000000O2O000001O000001O000000000001O01O000000000000010O00000000000000010O000000001O00000001O0O10000O1000000O2O0000000O1000000O2O000000000O100000000O2O0O2IVVb2"}}, "object_label": "book", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "length:long", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "length, color, pose, material, texture, state, pattern, cleanliness", "answer": "The image features a stack of books on a table, with one of the books being red. The stack consists of three books, with the red book being the largest and occupying the majority of the stack. The other two books are smaller and placed on top of the red book. The books are arranged in a way that they are easily accessible and visible, creating an organized and inviting reading environment."}, {"question_id": 31, "height": 480, "width": 640, "image": "000000444275.jpg", "category": "description", "question": "Describe the microwave in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [347.93, 171.94, 145.68, 77.31], "segmentation": {"size": [480, 640], "counts": "]ZS5i0Z=[1A101N100000000O101O00O1000000000000000000000000000000001O000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001O00000000000000000000000000000000000000000000000000000000001O000000000000000000000000000000000001N10001N2N5RNhC21HdQV2"}}, "object_label": "microwave", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:off", "texture:smooth/sleek"], "control_dims": "color, pattern", "answer": "The image features a broken white microwave sitting on the ground, possibly on a sidewalk or a street. The microwave appears to be old and possibly discarded, as it is not in working condition. The broken state of the microwave suggests that it has been abandoned or neglected for some time."}, {"question_id": 32, "height": 640, "width": 427, "image": "000000466125.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [281.79, 293.12, 85.4, 37.66], "segmentation": {"size": [640, 427], "counts": "XUa57hc02N2O1O001O1O1O1O1O1O100O1O1O1O1O1O1O1O100O1O001O2N0001O0000000O100O2O00000O1000000O10001O00001O00O11O000000001O001O1O1O1O10O01O1O1O10O01O1O1O100O1O010O1O1O1N1O2NP^V1"}}, "object_label": "book", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "material, pattern, cleanliness", "answer": "The image features a person holding a green book, which appears to be a book of recipes. The book is open, and the person is likely reading or looking through the recipes. The book is placed on a table, and there is a small apple nearby, possibly as a snack or ingredient for the recipes. The scene suggests that the person is engaged in cooking or baking, using the book as a reference for their culinary endeavors."}, {"question_id": 33, "height": 640, "width": 427, "image": "000000466125.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [264.67, 368.01, 134.13, 269.49], "segmentation": {"size": [640, 427], "counts": "mdS51QX10e?2UlN;F>C:F?^O]Nj]Ol1ja0`0@=H11^Mm^OT2Ua0dMR_O[2[a0M3M2N3L3M3N2O2N2M3M3L3O2M3L4K4O1NfBROg7h0`HXO_7d0Q6IkBGo66SIMk61WI0i6L[I3Y=O2NX\\OMec0333N002FKf\\O1^c0N3M92M3iMM_@3`?NT@0\\N4[a05Q@8P`0EQ@:R`0AR@<l?A\\@>e?B\\@<[?Gi^O2l15[?Jm@2T?Ok@3W?Ki@6Y?Gj@OnM1PVo0?niPOn04dN1No`0\\3\\O1O00000001O00001O1O1O2N1lLX_On2i`0oL[_Om2Wa0E3^Md^OV2VTg0"}}, "object_label": "chair", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "pattern, pose, state, transparency, color", "answer": "The chair in the image is a wooden chair with a green seat. It is placed in a room, and a person is sitting on it."}, {"question_id": 34, "height": 640, "width": 427, "image": "000000466125.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [282.52, 319.66, 144.48, 108.14], "segmentation": {"size": [640, 427], "counts": "[Vk53lc04L4M1O4L5K5K3M3N0O4L3N1N1O3M2N5K2N2N102M5K2N2N2O2M4i^OfM``0\\2^_OeMa`0]2]_ObMd`0a2<3M10O0N2O1N2N2N3L3M3N2K5N2L4O101N10000O1O1M4L3O1N2N2L4M4I6N2Lj[4^OldK0oi31oUL11NaW16VhNJ]\\O8fc0JWNNZk31eVL10NUW11aUN0db00\\]O0db00f000000a\\O0Zc01X\\O0hc0O6O^c51iTNOhWL100fU2"}}, "object_label": "dining table", "attribute_label": ["material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:covered", "texture:smooth/sleek"], "control_dims": "pattern, material, state, texture, size", "answer": "The dining table in the image is a small, wooden table with a laptop computer placed on it. The table is surrounded by chairs, with one chair on the left side and another on the right side. A person is sitting at the table, holding a book and using a green tool to interact with the laptop. The scene suggests that the person is engaged in a creative or educational activity, possibly working on a project or studying."}, {"question_id": 35, "height": 333, "width": 500, "image": "000000473821.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [3.0, 167.63, 78.0, 123.75], "segmentation": {"size": [333, 500], "counts": "c5e01a0`8@`G?`8]OaG@0R1_8^OaG@0R1_8]O`Gi0]8gNeG?Nj0]8gNeG?1ANS1`8\\OfGc0Z8]O_GB4Q1]8]OgGa0Z8_OhGBFj0b8DhG?X8A^GB5o0]8_OfGa0]8\\O^GD2n0]8@hGa0W8@gGb0V8PObG>9a0U8BfG^O11Kj0]8WOcG=4A1n0X8TOdG;2C22Kj0]8VOdG;>>n7VOeG<3C4j0T8WOdG=:a0U8@iGb0X8]OhGc0X8]OkG`0V8_OiGb0W8]OjGc0V8]OkGb0T8_OmG`0Q8BmG`0S8_OlGc0T8^OkGc0T8]OnGa0R8^OnGb0S8^OmGb0S8^OoG`0Q8_OPHa0o7AlGc0T8]OkGe0T8[OjGAJR1]8]OiGAJR1]8\\OiGh0W8UOmGEHQ1Z8TOcGNb0o0i7SOfGMa0X1a7nNaHZ1Y7cNcHf1Y7WNeHNCQ2d7PNfH[2Q7eMfHO9_2o6aMiH06c2Z7^M]Hf2`76DSMSIQ3Q7iNWIPOe6Q1cIkNW6Z1mIbNP6f1nIWNo5l1VJoMg5S2ZJlMd5Z2ZJcMe5a2ZJ]Mf5e2ZJXMg5j2m03M2NkNnHQOP7n0SIPOm6j0hIjNU6`0eJ]OZ5`0mJ^OQ5=WKAg4<bK_O^4>j2M3M3L5M\\]X4"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "color, pattern, pose, material, state", "answer": "The image features a black chair placed in front of a desk. The chair is positioned in the middle of the room, and it appears to be empty. The desk is located to the left of the chair, and there is a book placed on the desk, possibly indicating that someone was working or studying in the area."}, {"question_id": 36, "height": 333, "width": 500, "image": "000000473821.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [134.09, 169.18, 128.14, 143.78], "segmentation": {"size": [333, 500], "counts": "Qh[1`0f9k0ZOV1kN8VHnMk6k2O000000EVIRMk6n2UIPMm6T34M300001O0O102N001O2NcLTIZ3P702M3N3M003M1O2M4M1O2N1O5K44O4]NXMkJf2T5[MoJc2P5]MPKc2]600O2O1N_NaMVKX2c6K6J5N20001NPNVN_Kj1a4VN_Kj1a4VN_Kj1b4XN\\Kg1f6O1NPN[N[Kd1d4^N\\Ka1d4bNZK]1f4fNYKX1g4iNZKU1f4kN]KR1c4nNbKJlMk0c6\\OTL7l3IWL4i3LWL4i3LWL4i3LVL5j3LUL4k3LUL4k3LUL3l3MTL3l3NRL3n3MRL3n3MRL3n3MRL2o3OPL1P4OPL1P40oK0R4OnK1R40mK0U4NkK2Y4KfK4P6BeH>[7BeH>[7BeH>e8OgNCcH>]7BcH>]7BcH>]7BcH>\\7CbH?^7BaHOlN<c8EaH>_7B`H>a7B^H?a7B_H>b7@_H2mN8g8FZH0QO:c8H\\HNQO:c8JZHLSO:c8JZH;g7DYH<g7D^H7b7J^H5c7J]H6c7LYH5h76YGB1e0f8k01O0000001N100101N5L4K3M10O001O001N1ROP1VObk\\2"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:empty", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture, cleanliness, pose, transparency, size, pattern, material, length, color", "answer": "The image features a brown chair with a red blanket draped over the back of it. The chair is positioned in a corner of a room, and it appears to be a comfortable and inviting seating option."}, {"question_id": 37, "height": 640, "width": 480, "image": "000000491216.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [269.55, 180.58, 29.42, 62.6], "segmentation": {"size": [640, 480], "counts": "gaY53;0Uc01d\\O4\\c08e\\OAUc0f0N100R]O[Oab0e0_]O\\O_b0e0`]O_O^b0`0b]OB_b0:c]OJXb06^]O_O6f0Pb0Lj]O^O5h0oa0Kl]O]O22Nd0Sb02m]O[O0c0Sb0S11O1O001O0lNm]O:Tb0Eo]O@Kc0Ub0Mo]OBLa0Ub0Mo]OBLa0Yb0Jk]O;Xb0@c]OI49gb0LX]OI26lb0N]]OMjb00^n`3"}}, "object_label": "potted plant", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:green", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pattern, texture", "answer": "The image features a potted plant with a long stem, placed on a window sill. The plant is positioned in a black pot, which is sitting on a window ledge. The plant appears to be a small tree, and it is surrounded by a few other potted plants, creating a pleasant and lively atmosphere. The plants are placed in various positions, with some closer to the viewer and others further away, adding depth and dimension to the scene."}, {"question_id": 38, "height": 640, "width": 480, "image": "000000491216.jpg", "category": "description", "question": "Describe the refrigerator in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [4.3, 38.74, 104.76, 591.22], "segmentation": {"size": [640, 480], "counts": "R81kc06V\\Of03ZON2ON2O2M210M20T`0d6XF^I]I\\1g0cNZO28OF2:a0GC0OO11M3L30:T7c5WLRJcNJWN3N1M3m7T5_KjJkNNlM0O2a8a4ZMZKWJ3O1l8V4nLfKXJ2N2\\9f3^LVLYJ1L4g9[3jKaL^J0O1140O\\:g2oHVM]MO]O1:O@j02YO^:e2YHnM`MJGO2c03nN\\:g2VHTNZM>NK2POc:`2WG\\M[N000Kn00b10dMd:_2VG\\MPO3XO=OB2;MI1N2m0MTOe:]2fHaM\\MO]O0b0g0ZO\\Oh:Z2eHaMeM1F3ZO2MO0Nn:Z2`HcMcN4QN3MN1NP;X2bJiM_J4NN0MT;U2hJlMXJ0M1R;R2iJlMYJ1L2T;n1jIlMlK3ZO1L3U;m1]ImMcK2OO;3B;U;d1RHlMmL41W1LIU;U1YFhMcN4n08SOP1LkN0b0Z;`1gEcNBSOB=O4MDO<1D2d0Z;_1_EjNFnNC=O4NBO>OF2b0_;f1aDbMN01W1b0iN@:LF3h002OOa;[3PElKA4MM000h02o0d;l0YDeNj0kNXOLOo03TOOZ1j;P1UDkNh0kNYOMNQ12PO2?K9P<a1WDjNb0oNZOMNR11nN3a0L7P<f1QDfNg0oNYO[1OUO05R<e1nChNf0POZOP20cNS<n2bD_LZOQ21bNS<o2nC]L:1DQ21bNS<Z3WD[NF[NS<[3VDZNG\\NR<[3VDYNG]NS<Z3VDYNH\\NR<m0oCd063I\\NR<l0QDcN1GL91Q16T1I\\NR<m0UD[N27IP14mNIQ21cNR<m0dDZN[O21V14kNKR20dNQ<o0]DYNIOHY17iNJi046LHQ<o0ZD^NJW11eNJb00]O5P1KHQ<P1XD_NK5Ja08SOJc02[O3R1KHP<R1XD]NJX15_NJe00\\O5o0KJn;T1XD[NJY1<ROD^OOO1n00Ll;U1YDYNKZ1;QOE^OO0On00Mm;U1YDWNLZ1;QOE^ON`01o0j;c0ZDUNMZ16UOJO1^OOQ1h;P1ZDSNNHO^14[ONLOk0f;g0\\DQNNH1^1M^O3IOk0d;j0^DlMNK2\\2OYNLl0e;k0aDdM1OLO2Y21fNJ:d;W1QEaMFQ2MlNI:a;Z1ZEcMTOl1:lNG;`;]1UEFBfMIk00<_;_1TEENdMC5K220Og0];l1TEBc0fMPO2:>m:Z2UEgNAQO]1@VO8e:d2kDQM2c1KoN^1_OVO:c:e2jDVMO_10lN_1_OUO;a:h2kDTMOU27dMc00ZO3;O@9V;j2kDRM0I0o4S;YNlDoL6g4l:hNREX1m:jNSEU1k:nNTER1k:POTERN1i0i:X1TEXL8m0HoN5c2f:Y1\\EoK54Fh00XO3d2e:Z1kERL^Og00XOOh2f:X1nEQL]Og00XOONNg2f:X1\\ERLOOa05^Oe03VO5f2\\:Z1`EVL<l0CmN010f2`:\\1`EUL1K2R11mNJe2a:]1aE_L1c02lNKe2_:b1aE[LOd02iNOk2]:`1bEgK3`056JYONj2]:a1dEdK3b055IX2Z:b1hESL33OT2T:h1kESL002T2R:j1kEULON3S2Q:l1lERM2R1P:o1mEPM2QOLS1S:n2oEoL1POMS1R:Q3nEPL2J0R2o9U2oEfK1BO`04R2k9P3SFeJO095FI1R1l9\\4UFcJ6J86AN2R1i9_4VF`J6L49DK2Q1h9b4XF\\J6MKH3P1K>g9d4ZF[JOQ3d9g2^FnI0a3f3aLYLOW5S6jJfMY3oMeLUN57[3T:D`H7a7CgH9j6hL`Fn2h27e4SMYHOW1LSO6CH3U2U3l0T4TMhH8JI[1La03UNo0[3j1d=N4L5ZMh^OZ2`b0fMb]OP1Vc0mNk\\O5oVY7"}}, "object_label": "refrigerator", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "pose, cleanliness, transparency, pattern, state, size, material, color, texture", "answer": "The image features a refrigerator with a white door, located in a kitchen. The refrigerator is positioned between two other appliances, a microwave and a sink. The microwave is placed above the refrigerator, while the sink is situated below it. The refrigerator is situated in a corner of the kitchen, and the overall scene appears to be a view of the kitchen from the doorway."}, {"question_id": 39, "height": 427, "width": 640, "image": "000000540466.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [370.39, 93.08, 254.28, 187.11], "segmentation": {"size": [427, 640], "counts": "_dk43W=2O001O1N2O1O1oCNg:2SE4l:NoD6Q;KjD7X;JeD5^;L\\D3i;OSD0Q<a04L3J7N2001N2O1O1O1N2O1O1O2M2O2N2N1O1N2O1O1O001N101O1O001O1N101O001O1O001O001O1O1O0O2O1O001O1O00100O001SHoMgLNd7T2dKlMb4T2Z3010O1O010O100O00100O100O010O100O0oGgMQ5Y2nJgMR5Z2o210O0100O100O1O100O0010O0100O1O100O00100O100O1O00100O100O1O100O1O2O0O010O00100O01O010O0100O0010O010O01O10O010O010O0100O0010O010O0100O01O01O010O1O10O01O0100O010N2O1N20bEUM[:n2001O0O01000O1000000O10000O100O1000000O011N100000000O100O1000000O10000000001O00000O1O1O1O1N2O2L3L4O0KkDSNX;o11N2O100O101O00bDXNX;n10O1O1O100O1IdD]N];i10O10001N2O2M3N3L4M2M=D003L8I6H9GZb5"}}, "object_label": "umbrella", "attribute_label": ["cleanliness:clean/neat", "color:orange", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:open", "texture:smooth/sleek"], "control_dims": "material, transparency, pose", "answer": "The image features a woman holding an orange umbrella, which is open and providing protection from the elements. The umbrella is large and spans across the entire width of the scene. The woman is standing in front of a fence, and there are some plants nearby, adding a touch of greenery to the scene."}, {"question_id": 40, "height": 376, "width": 500, "image": "000000561335.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [209.92, 69.13, 115.5, 96.95], "segmentation": {"size": [376, 500], "counts": "Vo]21b;8fDJg:k0G7K7H4N1O1O1O1N2O0O2O1N2O2N1O1O1O101N1O2O0O1O100O100O1O1O100O1O100O100O1O1O100O1O100O1O1O1O100O010000O100O2O0O2O1O0O2O1O001N2O1O001N2O001O0O2O1O001N1010O01O10O0100O0010O01O100O1O1O2N1O2N100O1O1O2N1O3M3M3K7oN\\gR2"}}, "object_label": "boat", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:green", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "color, pattern", "answer": "The image features a small, old boat sitting in a forest clearing. The boat is made of wood and appears to be in a state of disrepair. It is surrounded by trees and foliage, giving the impression of being in a natural setting. The boat is positioned in the middle of the scene, with its hull facing the viewer."}, {"question_id": 41, "height": 391, "width": 640, "image": "000000046872.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 108.6, 490.6, 282.4], "segmentation": {"size": [391, 640], "counts": "W726e4R7[KnHe4X72mLXKiK1OOd2i4c43N2O1O1UMPKmK2W2n4l1PKnK0V2Q5e41O10000O1000000000000O1000000000O100001N100000O10O100000000000001O00000kMiJYMX5g2hJYMX5f2jJYMV5l40O100000000O10000000O1000000JTIQKk6V50000000000O100WMeJfN[5Z1fJeNZ5T4000000000O100000000O1000000000000O1001OO2O00000000000O100000000000000O100000000O1000O100000O2O000000000O10O1000000000000000000000O10000000001O00000O1000lMcI^N]6`1RJaLC[1[6S2[JlMe5S2\\JmMc5R2`JmM`5R2bJmM]5T2eJjM[5V2dJkM\\5U2\\JcL]OX1W6V2dJcLQOQ1[6_2lJ[MS5g2oJVMR5j2SKPMm4P3WKlLi4T3YKiLh4V3U200001O0O2O1O003M1N10000000[OhGYMZ8]2dG[M83T8a2iGXM54S8d2gGXM74R8d2gGWM93P8P3nGQMR8P3lGQMT8S3hGmLX8T3gGkLZ8U3gGhLZ8X3hGfLY8X3dGhL`8W3bGiL^8S3\\GoLl8Q3UGoLj8T3300O100O1O2G<K101N2O1N1000000003M4L1N2O0O1O10000K500O1000O13L2N2ZOgL]HW3d7jL\\HU3[8O2@oF\\M44o8KSG[23iMR9_1eFSO9^On8LkFc1NTO8\\OT9\\2iFdMX9\\2gFdMZ9[2fFeMZ9[2fFeMZ9Z2gFfMZ9V2=O10000001O1hNgM^GO01i0Z2h7kM^GKi0[2i7nMWHQ2S8fMlG[2o800010O0O3M2N20O3K06L5ROYMaG0;m2AWM^8LQHm2AVM0L31T80WHR3DnLO6Q8J\\HR3ISMk7K[HS3KQMi7M[HS3MnLj7NYHT3MmLk7OXHU3LlLl7OXHU3MjLl71UHW3b8002O1O1oGdLU7]2VH\\N6WOL1M0k7Z2YH^N1YOL7i7Q2\\H^N0XOL4m7V2XH\\N8]O`7V2YH]N]8b1fG\\Na0\\Oi6U2jH]N>_Oh6S2jH[Na0Af6T2iHTN^OMo8n1[GmML?k8a1YGTNH`0l8Z1]GWNEb0o0ZOk6m1aHVNFb0l8S1SGZN;1F>o8X1PG[N9NI`00]Oh8S2eGfNX8[1hGfNW8P1\\G[N>=B@f8g1]GZN:8AJn8e1XGWN9c0_6]OnJi1kNoNR6ZORKg1jNQOBUO40h54hKf1gNQOY6YOPKf1fNPO]6XOnJj1TNXN5l0g6QORKQ2SNYOf0gN_OOZ50^Ld3[N]LL1OO\\5O_L]3bNbLC;]5F^L\\3iNmLj4G\\L`3TNaL=8S5G\\LT4SNULa5GjK0ROc4S5]KkK0ROR2EKN\\Nb5FiK1QOR2IA4dNh6IZIR2J9h6gM\\In1Nc0_6_McIn1Nd0_6\\MdIP2Mc0`6]McIo1NBb7^N`HR2InMMb1W8g0hGZOW8f1jGiL0007U8e2hHSMW7h2j0WM\\Gg2_8ZMWG2:R2EZN4D3OP8OjG2:R2EYN3KMN1N3Kc72YH0;f2EbM1K1O3Ma71ZH0;l2FUM022M3O`70\\HO:`2DRN0D3L3OS8m1oGWNLe0NXO4OT8b1[H^N@i0LYO5N_72[H0;`1:_N_O?LE3Kl78[HZ1GbN2N1009ME132Mk76]H]1DaN3OO111NM5O0Oj70bHj1AcNND501N01i70cHi1AgN4_O_20T30lJh1ZOjNn8^OiGh1XOhNQ9@gG[2X8eMhG\\2@eM\\8OTH\\2[OlM1JV8N^H\\2\\OdMM34OU8O]H[2AfMM0MNn8Y2[GmMF11Jh8f1WG]N131K1h0NWO]8]1bGdN=5DL2n0X8>eGcN=3EO1NMO0e0\\8k0cGbN>0F11L17K0`8[1_GcN<MI2OM26K5Z8W1eGiN7EM120LNOg0X8m0gGlN3A1031Jj04TOl7d1PHmNa0A@NOg0X8m0iGcN00>JF6K6X8W1iG]N74OKI3O50c0U8i0kG^N<NH2M`1Q8MnGdN0Ob0f1^7LiH1X7OkHcNVON4e0k7k0UH[N9;CJ4f0j7`0PHPO2G7h0IWOOj0n7`0RHPO0G7n0JKl7`0THTO7;IWO1i0k7a0UHiNN29MJ4NLNM:?GGn7T1UHjNM28NL2MO7;HB0No7Z1THjNN161NMM30KMe0T8d0PHjNN152OLM3Od0R8?QHkNMM;5HMN4Md0T8>QHkNMM<6EL0>MG1JW8V1nGmNJM9OI>0e0S83RHSOIG42L>1f0Q80VHVOJGNi1P8YOYHPOKJ0b0M_O0X1o7MZHnN3;Ja0JTOP8Q1[HnNIM1>3FI4N01I22o7Q1ZHK7WO_O08Ji7T1ZHJ6VOA29M`7Q1aHH7VO@2:M`7R1aHVO@3S1F]ON`7S1_HECZOa00B1:Na7o0aH4AQO12NN2NM3Q8i0aH`0_OXOO^OR8j0aH1]OSO006b0L^OQ8l0`HVO^O73INL006OK0N<1FR8m0aHC_OCN0`06i7b0\\HC^OM>Nh7b0\\HC]ON?Mh7b0^HA[OGL1d01k7f0ZH^OYOF01l03d7h0YHNVOVO1033OMa8m0XH`0m7@UH>k7BZH4k7KZHTOgN12N12Z9k0j110HiD\\O[;h0000O10000M3O01O01O1O001000O1000000O01O010O1O1O100O1O0101N100000000L]OcDd0\\;]OdDb0];^OcDa0b;OoNB[F?d9B[F?d9A\\F?d9A\\F?d9A\\F?d9AeEL?d0l9@eEL?d0l9@[Fa0c9_O^Fa0VO[OW:5bFa0a9AhEL7OGd0Z:AgEN6OGc0\\:@hEM5h0U:YOgEN5g0U:\\OgEK5j0S:\\OgEK6NGh0Z:^OjEL9g0m9\\OjEN8e0o9\\OjEO7a0B^Ol:NcEc0C]O\\;?80O10000001OgDBi:?lDB];>cDC[;=fDB[;>7O1O1O2K5M3M\\lQ2"}}, "object_label": "truck", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:blue", "color:brown", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, pose, pattern, material, transparency, texture, length", "answer": "The truck in the image is a large flatbed truck, which is being used to transport a large pipe. The pipe is placed on the back of the truck, and it appears to be a long and heavy load. The truck is parked on a street, and a man is standing next to it, possibly supervising the transportation process."}, {"question_id": 42, "height": 427, "width": 640, "image": "000000189820.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [206.01, 177.09, 25.42, 39.95], "segmentation": {"size": [427, 640], "counts": "gZg22;O\\<7;5K9H3L:G2N0000001O0000000000O10001O0O2Oi0QOPnY5"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:white", "length:long", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture, color, pattern", "answer": "The image features a white coffee cup sitting on a wooden desk. The cup is placed on a coaster, which is designed to protect the desk from heat and potential damage. The cup is positioned in the center of the scene, and it appears to be a large mug."}, {"question_id": 43, "height": 427, "width": 640, "image": "000000296657.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [497.73, 137.72, 28.54, 44.18], "segmentation": {"size": [427, 640], "counts": "V\\_66T=8I2O1N1N3N2N1OZO_Cc0`<\\ObCe0c<O010OB]OSDc0l;]OUDd0Z<O01O001O10O0O2N2N1O1O2M3L4Kn[_1"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:green", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern, material", "answer": "The tie in the image is a light green, striped tie with a pattern of alternating stripes. It is being worn by a man who is wearing a blue shirt. The tie is positioned in the middle of the man's chest, and it appears to be a casual and comfortable choice for the occasion."}, {"question_id": 44, "height": 427, "width": 640, "image": "000000296657.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [195.46, 175.32, 19.86, 27.26], "segmentation": {"size": [427, 640], "counts": "U`a21X=7J100O1O1O10O000000HG_C9b<71O2N3M1O2N1N3L_Qa5"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:green", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern", "answer": "The tie in the image is white and has a patterned design. It is being worn by a man who is wearing a black shirt. The tie is positioned in the middle of the man's chest, and it appears to be a casual and comfortable choice for the occasion."}, {"question_id": 45, "height": 480, "width": 640, "image": "000000469246.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [114.08, 32.29, 525.92, 413.27], "segmentation": {"size": [480, 640], "counts": "abn11o>00002M3K5M1O2N100O1000N2I77I10ETo7NXQH1OO1Oom00RRO1O1O0O101N100O1O2N5L00L_AIa>7`AH`>8`AGa>9_AGa>84N0O22O1OO`AMW>0hA9T>ClAc04^O]=2]Bb0MEd=J^Bo0`=:O1O4J2M4N1O00100O2O0O2O00O100000O1O2O2M3N3L2O001O001N2O001O0O2N10001O0O1O2O00001N101O000O2O000O2N1O101O00001O1O0O2O000O101N10001O0O2O00001N1O1O2O001M2O101N100O101O0O2O001N1O101O0O101O00000O2N2N10001N101N101O0O100O101O1O0O2O000O2O0O101N10001N101O0O100O10001N100O10000O100O2O2M10001O1N10000O1O2O000O2O2M101O000O100O10000O10000O10001N100O101O0O10001N101N2O001N100O100O10001N10LUGUJi8i5[GUJd8k5^GTJb8l5^GTJb8l581000ORGTJi8n531000000O10O0101O1N5L4L0O3N3L2O001N101N100O2O1O001N10000O101O0O101N101N10001O0O2O0O2O000O101N10001O0O2O1O0O2O0O101O0O1001O00O100O1O01O02O0O2O2N001O0O101N10001O0O2N10001O0O1O2O000O101N100O101O0O100O2O1O0O2O000O10000O2O000O2N10001N10001N10000O01N11000N2M3O02N2E]GVJd8`5]G^J20c8_5gGaJZ8]5gGcJY8]5gGcJY8]5gGcJX8]5d02SGaJX8`5hG`JX8_5hGbJX8^5iGaJW8_5f0N100O100O100fJ]FV5d0iJZ81RGV5c0jJ[80RGV5c0jJ[8OSGV5g9O10kFkJ\\80QGU5b0lJ]80PGS5l9M3N5J7FfEbKe:S48M000OfEPLd9o3]FQLd9j3k000010O5\\EQLn9n3kERLL0X:o3gERLL33LZ:o3fEZLOG[:o3fEZLNH\\:n3fE^LY:c3hE\\LW:d3jE\\LS:f3nEYLQ:i3oEWLP:k3nEVLQ:m3mERLS:o3mEPLU:FjEW4OSL]:W4E_KWFa4h9aKWF_4i9`KVFa4j9^KWFc4m8]KeG0\\Oe4S:00ON3O0N3O10O103L10O10O01000O1000O100O10O1O00000N3M3O2M201N1O2O0O1O1O1N2TMVEb1k:X11O10001N101N10001N101N1O10001N101N10000nN"}}, "object_label": "train", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, pattern, cleanliness", "answer": "The image features a large silver train parked at a train station. The train is positioned on the tracks, occupying a significant portion of the scene. There are several people standing near the train, likely waiting to board or disembark. Some of these individuals are carrying handbags, with one person holding a handbag close to the center of the scene and another person holding a handbag towards the left side. The presence of the train and the people suggests that this is a busy station where passengers are either arriving or departing."}, {"question_id": 46, "height": 426, "width": 640, "image": "000000000139.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [613.24, 308.24, 12.88, 46.44], "segmentation": {"size": [426, 640], "counts": "igo77h0JZ;g0]DZOb;m0VDTOj;W1N11O0010OO3N=C7^O>LdR5"}}, "object_label": "book", "attribute_label": ["color:yellow", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, pose, pattern, state, texture", "answer": "The image features a book with a red cover, possibly a hardback book, placed on a table. The book is open, revealing its title and possibly some text or illustrations. The book is positioned in the center of the image, with the table occupying the majority of the background. The book's cover is the main focus of the image, drawing attention to its vibrant red color and design."}, {"question_id": 47, "height": 427, "width": 640, "image": "000000007818.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [8.11, 260.28, 106.92, 49.7], "segmentation": {"size": [427, 640], "counts": "\\c36U=:E=D4L1O00000000000O100000O1000000O01000001O000O1000000000000O1000001O00000O1000O100000O100000O10O1000O10000000O01000000O1000O1000O1000O01000000O10O1000O1000000O010000000O1000000O10000O01000000001N2O3M4K6K5K6IlQk6"}}, "object_label": "chair", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "pattern, color, pose", "answer": "The image features a black chair with a white tablecloth covering it. The chair is positioned in the center of the scene, and the tablecloth is neatly draped over the back of the chair. The chair appears to be empty, and the overall setting gives the impression of a well-organized and clean environment."}, {"question_id": 48, "height": 427, "width": 640, "image": "000000007818.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [446.99, 265.1, 107.57, 17.23], "segmentation": {"size": [427, 640], "counts": "fRk51Y=2O00001N1001O01O00000000000000000J5010000000O1O100O100O10000000000000000000001O00O1010O0000000KmB2S=NmB2S=300001OO1001N2O00O100O10002N000000000000000000O010000000O1000O100000O100000O010000000000O10O1000O100000O10O2O002NjUS1"}}, "object_label": "knife", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "state:dry", "texture:smooth/sleek"], "control_dims": "cleanliness, texture, transparency, state, pose, material, color", "answer": "The knife in the image is a large, long, and sharp blade. It is placed on a white surface, possibly a table or a piece of paper. The knife is positioned horizontally, with its blade facing upwards."}, {"question_id": 49, "height": 480, "width": 640, "image": "000000009891.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [198.58, 129.69, 40.83, 59.19], "segmentation": {"size": [480, 640], "counts": "dnl27g>`0A7I4M0O2OO100O010O1O100001O5K2N1O0LhN_BY1^=6O1O10O1N2O1O00003M2N3H8J4O2ClAJW>4kAIX>4;O3Mbhl5"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "state, transparency, color, material, pose", "answer": "The image features a white car parked in a parking lot. The car is positioned in the middle of the scene, and it appears to be a large vehicle."}, {"question_id": 50, "height": 480, "width": 640, "image": "000000009891.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [158.79, 134.21, 50.2, 35.24], "segmentation": {"size": [480, 640], "counts": "YeZ23l>2O2N1O2O001N2N100O1O1O1O2N000000000000001O0O1001O0O2O0010O1L_OhAf0Q>[OoAf0Q>4000M2N301N1DnAGU>7;O1O1O10001N2OdjZ6"}}, "object_label": "car", "attribute_label": ["color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:open", "texture:smooth/sleek"], "control_dims": "pose, transparency, texture, material", "answer": "The image features a car parked in a parking lot, with its hood up. The car is positioned in the middle of the scene, and its hood is open, revealing the engine and other components."}, {"question_id": 51, "height": 375, "width": 500, "image": "000000020553.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [391.28, 133.41, 16.68, 58.13], "segmentation": {"size": [375, 500], "counts": "^g_46l:f0L4N2L3J6K5I7O1O1000O100O3Kk0cNYEOKMYlQ1"}}, "object_label": "bottle", "attribute_label": ["color:green", "color:white", "material:glass", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "state, transparency, material, pattern, texture", "answer": "The image features a bottle of beer sitting on a table. The bottle is tall and made of glass, with a brown color and a blue label. The beer bottle is placed on a wooden table, and it appears to be the only object in the scene."}, {"question_id": 52, "height": 375, "width": 500, "image": "000000020553.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [364.89, 132.03, 17.59, 35.9], "segmentation": {"size": [375, 500], "counts": "_jU44`;3O1N2K5K5K5L5J5O10000000O2O6J?A9FPfZ1"}}, "object_label": "bottle", "attribute_label": ["color:green", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, material", "answer": "The image features a green bottle, possibly a vase, sitting on a table. The bottle is tall and has a unique shape, making it stand out. It is placed in a bowl, which adds an interesting visual element to the scene. The bottle appears to be made of glass, giving it a transparent and elegant appearance."}, {"question_id": 53, "height": 480, "width": 640, "image": "000000030785.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [256.14, 38.74, 361.62, 247.54], "segmentation": {"size": [480, 640], "counts": "Zna32o>OlZ25ndM2O003MN2O10nCJZ96ZF?]9\\OZD1U2k0]9ZO_Fm0]9UO^FR1]9oN`FV1^9kN_FY1_9gNmDD^1j1b9bN`Fb1^9\\NbFh1\\9WNdFl1Z9TNdFP2Z9RNcFQ2Z9PNeFS2Y9mMfFU2Y9kMfFW2Y9jM^EEQ1e2_9kM_FX2`9hM_FZ2`9]MfEHj0n2^9ZMiFi2U9VMlEHf0S3^9UMkEJe0T3^9nLgEN60d0V3^9lLhENS1X3T9jLiENR1Z3T9lLQFHa0^3]9jLPFK`0^3_9gLRFI?b3^9aLmEMn0d3T9_LoFb3o8_LPGc3o8]LRFKk0j3R9ZLTFLi0l3R9XLRGi3m8WLRGk3m8VLVFKh0R4P9SLWFM607R4[9QLXFL707X28kNQ9QOSGe1XOZNn0P1e8POUGf1a0YOY8QOVGe1c0\\OT8oNXGe1g0[OP8POXGe1k0[Ok7QOcFLb0h1Q1]Og7SOWGa1S1\\Oe7TOiFJ4f1a1[Oa7UOhFL6c1b1^O^7ROmFJ3e1f1^OY7SOoFG4f1g1AT7QO]G]1b1Bo6nNnFL`0d1e1Dj6kNRGM>b1i1He6jNSGM=^1P2K_6jNTGM=\\1T2LZ6kNUGN;\\1W2KX6POaGT1Y2LU6PObGT1Y2NS6nNcGU1[2MQ6mNeGV1\\2Ln5nNeGW1^2Kl5iN]GN9]1_2Mj5gN`GM7`1`2Lh5hN_GN8^1b2Lf5nNgGV1d2Ld5nNgGW1f2Jc5oNgGW1f2Kb5nNgGX1h2J`5nNhGX1i2K]5lNkGX1i2M[5kNkGY1k2KZ5hNeGL7a1j2LY5eNRH_1f2LW5jNnGZ1k2MV5jNmG[1n2IU5lNlG\\1o2IT5kNmG\\1P3IR5kNmG]1R3GQ5lNmG]1R3HP5jNoG^1S3Gm4kNPH^1T3Gk4jNQH`1T3Gj4fNUHc1Q3Hj4eNTHa1T3Jh4gNRH_1V3Kg4gNRH]1Y3Ke4hNQH^1Z3Kd4gNRH^1Z3Lc4eNTH_1Z3La4dNVH`1[3K^4dNWHb1[3J^4cNXHd1Z3I]4cNXHe1[3H]4cNXHf1[3G\\4cNYHf1[3G\\4dNXHe1\\3H[4bNZHe1\\3IZ4bNYHf1]3IY4aNZHg1\\3H[4_NZHi1\\3H`49_KGa49_KGa49`KGY4^NZHl1_3DW4`NZHl1_3EV4`NZHk1a3DU4aNZHk1a3ES4aN\\Hk1_3FU4^N[Hl1b3FR4]N]Hm1a3FV40ZHbN`3_1U4O\\HaN_3`1U4IYHeNm3b1j3IYHeNn3b1e3\\N\\Hb18^N_3c1m30dH^N`3a1k31bLO]31cLO^3^N]H[1Z48Z3]ORMc0m2[OUMe0k2ZOVMf0j2ZOVMg0i2XOXMh0h2XOXMh0h2WOYMi0g2WOYMj0f2UO[Mk0e2TO]Ml0b2SO`Ml0`2TO`Mm0_2ROcMm0\\2TOdMl0\\2TOeMk0[2UOeMl0Z2TOgMk0Y2UOfMl0Z2TOfMl0Z2TOfMl0Z2SOhMl0X2TOhMm0W2ROjMn0V2ROjMn0V2POlMP1T2nNnMR1R2lNQNS1o1lNRNU1m1kNTNT1l1kNUNU1k1kNUNV1j1jNWNU1i1jNXNV1h1iNYNW1g1iNYNW1g1jNXNV1h1jNXNW1g1jNXNV1g1kNYNU1h1iNZNV1f1jNZNV1f1jN[NU1e1kN[NU1e1kN[NU1e1kN[NU1e1lNZNT1f1mNZNS1e1mNZNT1f1lNZNT1f1lNZNT1f1lN[NS1e1nNZNR1f1nNZNR1f1nNZNR1f1nNZNR1f1nN[NQ1e1POZNP1g1nNYNS1g1mNYNS1g1mNYNS1g1mNYNS1g1mNZNR1f1nNYNS1g1nNXNR1h1nNZNP1f1QOZNn0g1ROXNn0h1ROWNo0i1QOWNo0i1ROVNn0j1TOSNm0m1SOSNm0m1SOSNm0m1SOTNl0l1TOTNl0m1TOSNk0m1UOSNk0m1UOSNk0m1VORNj0n1VORNj0n1VORNj0n1WOQNi0o1WOQNi0o1WOQNi0P2VOPNj0P2WOoMi0Q2XOnMg0S2YOmMg0T2YOkMg0U2ZOjMf0V2[OjMd0V2_OgMa0Y2^OhMb0X2^OhMa0Z2_OeMa0[2@dM`0\\2AcM?]2AcM?]2AcM?]2JYM7h2NRM2n2OQM0P30PM0Q3NPM2P3NQM1o20PMOQ32nLNR32nLNS31lL0T31kLNW32hLNX32gLOY31gLOY31fLO\\30dL0\\30cL1]3NdL2\\3NdL1^3NaL3_3MaL2`3NaL1`3N`L1a3O_L1a3N`LjNbKU1n71_L3b3M]L2d3N\\L2d3N[L2g3NXL2h3NXL2h3OXLOj30VL0j30VLOk31ULOk32TLMn32RLNn33QLLQ43oKMQ42oKOQ42nKMT42lKNU42iKNX42hKMY43fKN[41eKN\\43cKM^42aKN`42`KN`42`KMb43]KMc45[KJg45YKJh47WKHk47UKHl49SKGm49RKGP59nJHR58mJHT58kJHW58gJH[59cJG]5;`JEb5:^JEc5=[JBg5>WJCi5>UJBl5>SJBo5=QJBQ6=nICS6>lIBU6=jICW6=hICZ6=eIB\\6>dIA^6?_ICb6=]IBd6?ZIAg6?YIAh6>WICj6=TIDl6>RI@Q7`0mHAT7>kHBV7?hHBY7<gHEZ7:eHG[78dHI^75bHL^74aHLa72_HOb70XH5i7KUH6mMgNg9Q1\\H9n7FRH9PNgNd9o0ZH<S8ClG=U8CiG>Y8BdG`0]8_O`Gc0]NaNf9k0kGf0\\NbNj9g0QGUO@d1F_N`0O\\8i0kGYOA`1H`N6MF3P9f0jG[O@`1F[NM4g0M_8h0eG^OA_1F[NN1U:k0`FA]O\\18VN53Q9k0QGc1;hMa8f0QGb18aMXO8a9e0mFb1J_M5<Y9c0fFb1KaM59]9g0]F`10cMK:o9e0PFa15SNm9S3SFlLo9R3QFkLT:S3iEZLN?^:U3eE]LL:d:W3_EiLg:W3YE_L0Om:_3?N3M2N2N2N2N2N3M2N2N2N3L4L3N3M3M2M4L4L4L5L4I7J6K7F;EUf9"}}, "object_label": "bowl", "attribute_label": ["color:blue", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, texture, pose", "answer": "The bowl in the image is filled with a delicious and healthy meal consisting of broccoli and cheese. The broccoli is placed in various positions within the bowl, with some pieces closer to the center and others towards the edges. The cheese is spread throughout the bowl, adding a creamy and flavorful element to the dish. The bowl is placed on a dining table, ready to be enjoyed by someone who appreciates a nutritious and appetizing meal."}, {"question_id": 54, "height": 480, "width": 640, "image": "000000030785.jpg", "category": "description", "question": "Describe the broccoli in the following image in detail.", "dims": "color, size, state", "region_anno": {"bbox": [432.56, 169.41, 106.17, 63.25], "segmentation": {"size": [480, 640], "counts": "R\\X64e>:E9J5nNVOkCm0S<XOVCJ5W1c<j0O10001O00000OoNZCJf<2^CNb<0^C2b<IbC8^<GaC;`<D^C=e<@XCd0l<XOSCi0n<WOoBk0Q=a010000O10001O1O0O100001OUOmBIR=8mB\\ON1S=e0mB\\O0OR=T1nBmNP=T1oBnNP=Q1PCQOo<n0RCROn<n0QCSOn<n0RCROn<a1O000O02O2mNPC2P=NQC1Q=KQC5P=IQC7o<[OPCO2f0o<YORCM0k0o<WORCJ2o0e=100000O2O001O00001N3N2N3M001N2O]O@fB`0Y=BfB>X=C\\BM7`0[=LcB5[=MeB2[=OdB2]=KdB6^=GcB9`=CaB=`=^OdBb0n=O000O2OO100O100M31O004L2M101O002N3L3M2N10oic1"}}, "object_label": "broccoli", "attribute_label": ["color:green", "color:white", "size:small/little/tiny", "state:piece/cut"], "control_dims": "state", "answer": "The image features a close-up view of a plate filled with a variety of broccoli florets. The broccoli is cut into different sizes and shapes, with some florets being larger and others smaller. The plate is placed on a dining table, and the broccoli appears to be the main focus of the meal. The close-up view highlights the vibrant green color and texture of the broccoli, making it an appetizing and healthy choice for a meal."}, {"question_id": 55, "height": 640, "width": 458, "image": "000000032941.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [206.42, 127.04, 9.84, 30.62], "segmentation": {"size": [640, 458], "counts": "o_Q4m0Sc0001O0O100001O0O5UOd`f4"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "material, color", "answer": "The traffic light in the image is red, indicating that vehicles must stop at the intersection."}, {"question_id": 56, "height": 375, "width": 500, "image": "000000039785.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [165.99, 143.43, 56.15, 12.22], "segmentation": {"size": [375, 500], "counts": "Vbl11f;1N100000001O1O4L1OM3N2O1O1000O1000O10000000000000000000O10O1000000000000000000000000001O001O3M1O00K5O010O10001OZeU3"}}, "object_label": "bench", "attribute_label": ["color:gray", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "state, texture", "answer": "The image features a green bench situated on a concrete surface, likely in a park or a similar outdoor setting. The bench is positioned in the middle of the scene, with its back facing the viewer. The bench appears to be empty and ready for use, providing a comfortable spot for people to sit and relax."}, {"question_id": 57, "height": 320, "width": 480, "image": "000000050145.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [425.2, 143.25, 46.65, 23.14], "segmentation": {"size": [320, 480], "counts": "obU42k96L1OO[FId9:00O1O1O1O1OKaFHb98^FI`9>N00FbF2]9JiF3Y9MgF2Z9MhF3V9NjF2V9NjF1W90hFOY91gFOX93gFMY94gFJZ97eFI[98dFH\\9951O1O1O1O1O10O01O2N1O10O001HdFJ]94eFNZ90eF1f9N1MR[2"}}, "object_label": "umbrella", "attribute_label": ["color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "state:open", "texture:smooth/sleek"], "control_dims": "transparency, material, pose, state, texture, pattern", "answer": "The image features a black and white photo of an umbrella, which is open and positioned above a person. The umbrella is large and covers a significant portion of the scene. The person under the umbrella is standing in front of a building, possibly a store or a restaurant. The scene appears to be a black and white photograph, giving it a vintage or classic feel."}, {"question_id": 58, "height": 320, "width": 480, "image": "000000050145.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [176.9, 161.08, 43.14, 64.72], "segmentation": {"size": [320, 480], "counts": "TVg12k96XFNZ94hFHY9;34`FAY9e0M;E6J4L2O1O001O1O3NO1fNhGl0Y8POjGQ1b8000000001OOJ7N2J5L]NkGd1Z8O0M3O2O0000010N2[O_GIb86bGFa86dGE_88hGAZ8<g0G:LZ\\a2"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, pose, maturity", "answer": "The image features a woman sitting down, holding an umbrella over her shoulder. She is wearing a hat and has a handbag placed on her lap. The woman appears to be sitting on a bench, possibly waiting for someone or simply enjoying her time outdoors. The umbrella provides protection from the elements, and the handbag adds a sense of style and practicality to her outfit."}, {"question_id": 59, "height": 320, "width": 480, "image": "000000050145.jpg", "category": "description", "question": "Describe the bicycle in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [243.14, 196.46, 34.47, 34.23], "segmentation": {"size": [320, 480], "counts": "aT\\23l92N2N2O0O2aFFV9<fFFX9=fFDY9b0O100O1OO22M3M10001N11O102NO0000000001O0O10000O4Ldao1"}}, "object_label": "bicycle", "attribute_label": ["material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, transparency", "answer": "The image features a bicycle parked on a table, with its front wheel prominently visible. The bicycle is black and appears to be a mountain bike, as it is designed for off-road use. The front wheel is positioned towards the left side of the table, while the back wheel is located on the right side. The bicycle is parked on a surface that could be a table or a countertop, providing a unique and interesting perspective on the bike."}, {"question_id": 60, "height": 320, "width": 480, "image": "000000050145.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "material, pose, state, texture, transparency", "region_anno": {"bbox": [182.26, 186.53, 24.63, 42.68], "segmentation": {"size": [320, 480], "counts": "S\\i141`0T9;K2NOTGQOk8n031O100O2O100N100O20O001O9G`0UO^F8e900NYQf2"}}, "object_label": "backpack", "attribute_label": ["material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture", "answer": "The backpack in the image is large and has a patterned design. It is being carried by a person, who is wearing a dress. The backpack is positioned on the person's back, and it appears to be a comfortable and functional choice for carrying belongings."}, {"question_id": 61, "height": 478, "width": 640, "image": "000000079651.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [150.99, 0.0, 110.42, 390.27], "segmentation": {"size": [478, 640], "counts": "eeV23X>l0Ab0^Ol0ROd0@?^O?^Ol0XO>C7PGdJU8b5\\G`K5VOS7c7_O<F7J6G9dMUG[NQ9b1SGnLIh0[9W2oFjLOf0Y9^2_GWMi8i2f1O2O1O1O0O100000N2O1O1N2O1O1O1O1N2O1O1O100O1O100O10000O100000000O101O000000000000001O01O0001O1O102XEULW:m3fEWL7O[9W5H4K4L5K4M4K3N2M4L2N5L1N3M3N2N3L4L4M3L3N2M2O2M:F4L4L2N4L5K3M3L5K9G:YLaG<W9kNnFR1]9YNSG_O]Nm1U=[NXC5KC[na5"}}, "object_label": "bottle", "attribute_label": ["color:black", "color:red", "material:glass", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, pose", "answer": "The image features a bottle of Dragon Stout beer, which is a dark beer with a distinctive dragon logo on the label. The bottle is placed on a wooden surface, possibly a table or a counter. The bottle is positioned in the center of the image, and the dragon logo is clearly visible on the label."}, {"question_id": 62, "height": 640, "width": 480, "image": "000000085376.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [14.38, 413.18, 331.47, 212.28], "segmentation": {"size": [640, 480], "counts": "n^2213gc0MY\\O3lc0M_b8Oc]G1O1O2N1O001O1O1O10MZ\\OKec05\\\\OJdc06\\\\OJdc06[\\OKec05[\\OLdc081O0000000000000011N4\\\\OC]c0a0O001O10O10N2O2h\\OYOTc0f04N10000001O0h\\O[OUc0h0010O01O1O001O10O012Nc]O[O]a0f0b^O\\O\\a0d0d^O^Ok2Gk:l0YB]O[a0d0e^O[O[a0e0f^OZO[a0f0d^O[O[a0e0e^O\\O]a0b0b^O_O_a0`0`^OA`a0>`^OBCEea0i0g^OCCDfa0i0g^OC@Gla0d0c^OM^a02b^OO]a02\\^O[OHb0la03[^O\\OIa0la03Z^O]OK?U3]OiL1]>f0kA[OL=ma07b^OFaa09`^OFaa08`^OH`a08a^OFaa06W1L3Hj[`0?Zc_OCc]Oa0Rb0ZOj]O93=Ta0;f^O\\O39``0]Ol_Oo0@[O49l?^OX@;0c0G\\O58k?CT@83a0J]O28m?;P@oN0S10]O17o?e1P@POP`0P1o_OQOQ`0_201O0001O00O1000000000000O100K5O1O1O1O1O1O100O100O1O100O1O10000O100O100O1O100O10000O1000000O1O100000000O1000000000000O100000000001O00000000001O01O01O00001O000000001O00001O001O00001O010O00001O001O001O001O1O001O1O0000O100O1O1OiN]ARMd>l2Y1O0N30O010O100`_OPMo?Q3o_O^M_?^OY@Y4_?8L3M2K7L4LdKVAf3g>\\LXAe3f>m0N1N3N2M2N2N2O0O2O1O1O100O2OO100O2O0O101N2O1N4MO^LbAb1^>^NdAa1\\>]NiA_1]>[NdAe1\\>YNfAfNGc2c>gNfAfNFd2d>fNgAe1[>XNfAh1Z>XNfAh1[>VNfAj1[>TNfAl1\\>QNeAo1\\>oMeAR2[>mMeAS2[>mMeAS2\\>kMeAU2\\>jMeAU2]>iMcAW2^>hMcAW2^>hMbAX2`>eMaA[2`>dMaA[2`>dM`A\\2d>`M\\A`2f>^M[Aa2g>]MZAb2h>\\MXAd2k>XM\\Aa2h>ZM[Ae2h>WMYAi2P`0O0O2O2M101N2N2O1N2O2M1O3M3M2N2N3M3L5L2M4L5K5J6J8GYfe2"}}, "object_label": "motorcycle", "attribute_label": ["color:black", "color:green", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "material, color", "answer": "The image features a green motorcycle parked on the side of a street. The motorcycle is positioned next to a curb, and it appears to be parked in a parking lot. The motorcycle is the main focus of the scene, and it is surrounded by a few cars parked in the background. The cars are positioned at various distances from the motorcycle, with some closer to the foreground and others further in the background."}, {"question_id": 63, "height": 640, "width": 424, "image": "000000092939.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [351.13, 265.01, 19.35, 19.35], "segmentation": {"size": [640, 424], "counts": "ZXl62mc06K3M3M4L1O00Ei\\OLXc04:0000000000000001O00fkP1"}}, "object_label": "chair", "attribute_label": ["color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "color, material, texture, transparency, pattern, state, pose", "answer": "The image features a white chair with a white cushion, placed on a grassy field. The chair is empty and appears to be sitting on the grass."}, {"question_id": 64, "height": 640, "width": 427, "image": "000000125062.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [382.9, 2.03, 44.1, 363.87], "segmentation": {"size": [640, 427], "counts": "jba79bc07C;G:H7XOh0N2[Oe0B?C<PM`LPEP4n:SLjDT4o:dKSC:j1V4R;RL`D[4\\;iK[D_4b;eKSDe4e;hKnCjNBc5^<m1K4M3O2M3K4LoGXDS8W;oGnDZ8k:hGoDd8o:]GQEc8n:^GSEa8k::B6NO5N3LO2J62L9I9E;G9D<F:"}}, "object_label": "book", "attribute_label": ["color:black", "color:white", "material:paper/cardboard", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material, pattern, transparency, state, pose, color, texture", "answer": "The image features a close-up of a book cover, which is titled \"Life to the Full.\" The book appears to be a Christian self-help book, and it is placed on a table. The cover features a person, possibly a woman, with a smiling expression, indicating a positive and uplifting message. The book is positioned in the center of the image, with the title \"Life to the Full\" visible on the cover."}, {"question_id": 65, "height": 480, "width": 640, "image": "000000125778.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [1.03, 234.32, 301.42, 245.68], "segmentation": {"size": [480, 640], "counts": "R:n2n;5M8H8H8H=D6J8H8H6J7I3M2N1O1O1O1O100O100O1O100O10000O1O10000O1O100O1I7L4N2O1O1N2N2O1N2O1O1O1N2O1O1O1O1O1O1O1N2O1O1O1O1N2O1O1O1O1O1O100O1O1O100O100O100O1000000O1000000000000000000000000001O001O00001O1O1O2N1O1O1O1O2N1O1O1O1O2N1O2N2N1O1O2N1O2N2N2N2N2N2N2N2N1O1O1O3M002N2N3M2N2NCZJbGd5Q9L2N3jL]Fi0e9X24hKYFQOOO0f3a8ZLdG0e0o0UOS3a8QLbG3OJ>f0A_O0m3`8SL`G2ON200N2N;W4R8mK`G2O00?=c3T8hKcGZ10gN0W4]8hKdGY1OhN0W4]8kKaG8OC2141I0110M122X4]8kKbG6h0FVO11O3X4\\8lKaG7?EAO11N11N4T1Jo1a8QM_G;2A85FM11OO2N3U1Kn1`8hMhG_OINOJ3Y4]8cLaGTOO81b4^8eLaG[3_8c100000dIbGg10]OOl1_8PMbG]1OgN4n0Ln1_8PMbG]1OgN3o0Mm1_8cNaGaN2U4]8S2O100000bIbGZ6^84O1OlKdGf1]8^200O10000001OO1O10000O100000000O10000O10000O100000000O1000000O100000000O10000002N2N5K4L3M7I2N2N9G1O2N2N3M3M2N1O1O1O2N1O1O2N00M3NRKZFf4f9ZK[Fe4d9\\K]Fc4d9^KYFc4g9;00001O1O1O001O001mLRFR1n9nNRFR1P:lNPFT1S:iNmEW1T:hNlEX1V:@lEDW:8iEIZ:4fETNNY1_:6cEZN07NY1a:O`E[N45M8NY1d:1^E_NOP2h:o13M6J4L6J:F1O2N2N2N4L2N5K4L6J5K5K4L5K2N001O00001O00001O1O2N2N3M1O2N3M4L2N5K4Kj\\o4"}}, "object_label": "couch", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, material, transparency, texture, pattern, color, state", "answer": "The couch in the image is a brown leather couch with a striped pillow on it. It is placed in a living room, and there is a window nearby."}, {"question_id": 66, "height": 480, "width": 640, "image": "000000125778.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, pose, texture, transparency", "region_anno": {"bbox": [173.52, 197.92, 35.11, 35.71], "segmentation": {"size": [480, 640], "counts": "_Wb24j>`0[A@m=l0M1000000000O01000O101OO1O10O1000002M2O5K=^OW`^6"}}, "object_label": "bottle", "attribute_label": ["color:red", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, pose, texture", "answer": "The image features a vase made of three red bottles, which are stacked on top of each other. The bottles are placed on a counter, and they appear to be made of glass. The vase is tall and slender, with each bottle being slightly taller than the one below it. The arrangement of the bottles creates an interesting and unique design, making it an eye-catching decorative piece."}, {"question_id": 67, "height": 639, "width": 640, "image": "000000134882.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [85.84, 139.33, 60.39, 17.96], "segmentation": {"size": [639, 640], "counts": "iad16hc03N000000001O000000000001O01N10000001O01O00000000000001O01O0000000001O0001O000000000001O0001O01O00000I\\\\O3dc0M\\\\O3dc0401O00000000000001OQ`c9"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, transparency, state", "answer": "The image features a book with a red cover, placed on a table. The book is open, revealing its title and author. The book appears to be a paperback, and it is positioned in the center of the image. The table is a prominent element in the scene, occupying a significant portion of the image."}, {"question_id": 68, "height": 639, "width": 640, "image": "000000134882.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [78.68, 148.89, 85.86, 22.59], "segmentation": {"size": [639, 640], "counts": "URb1530_c08000J_\\ONac01`\\OO`c01`\\OO`c01`\\OO`c01`\\OOac00_\\O0ac00`\\OO`c01`\\OO`c01`\\OO`c01`\\OOac01^\\OObc01]\\O0cc0600010H]\\O2cc050000001O0001O00000000001O0001O00000000000001O01O0000000001O0001O00000L]\\OLcc04]\\OMbc03_\\OLac04^\\OMbc03^\\OMbc03^\\OMbc03_\\OM`c02a\\ON_c03`\\OM`c03_\\ONbc01_\\ONac02_\\ONac02_\\ONac03_\\OLac05_\\OJac05`\\OK`c04a\\OM^c03b\\OM^c03b\\OM_c03`\\OM`c03`\\OM`c02a\\ON_c03`\\OM`c03`\\OM`c090N2O101N2OTlX9"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, texture, pose, transparency, state, color, material", "answer": "The image features a large stack of books, with some of them placed on top of each other. The books are of various sizes and are arranged in a somewhat disorganized manner. The stack of books is located in the middle of the scene, with some books extending towards the edges of the image. The books are placed on a surface, possibly a table or a shelf, and they appear to be in a storage area or a room."}, {"question_id": 69, "height": 639, "width": 640, "image": "000000134882.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [208.63, 130.4, 16.59, 74.82], "segmentation": {"size": [639, 640], "counts": "dmQ4;1LYc0U1YOm0SO0001O0001O000000000001O001NmjR8"}}, "object_label": "book", "attribute_label": ["color:gray", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "state, transparency, color, material, pattern, pose", "answer": "The image features a book with a blue cover, placed on a shelf. The book is positioned in the middle of the shelf, and it appears to be a thick, hardcover book. The shelf is filled with various books, creating a visually appealing and organized display."}, {"question_id": 70, "height": 639, "width": 640, "image": "000000134882.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [76.2, 164.75, 101.61, 35.25], "segmentation": {"size": [639, 640], "counts": "]W`11[c03f\\O=Wc06O2O000000000000001O0001O001O0000010O0000000000001O01O000000000000000001O01O0000000000000000001O0O10WOl\\Og0Tc0YOm\\Of0Sc0ZOm\\Of0Vc001O00O10010O00000001O1]Og\\O>Yc041O01O0001O2N0000O11O0001H@n\\Oa0Qc0@o\\O`0Qc0Am\\O`0Sc0@n\\O?Rc0Cm\\O<Sc0Dm\\O<Tc071O1O00100O00O10000001O1N5HPhP9"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "state, color, texture, pose, pattern, material", "answer": "The image features a bookshelf with a variety of books, including a book titled \"Asian Cooking.\" The book is placed on the shelf, surrounded by other books. The bookshelf is filled with a diverse collection of books, showcasing a wide range of topics and interests. The books are arranged in a neat and organized manner, creating an inviting and visually appealing display."}, {"question_id": 71, "height": 639, "width": 640, "image": "000000134882.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [167.07, 121.5, 27.58, 79.57], "segmentation": {"size": [639, 640], "counts": "cnX32mc04K3N3M5K;E2N5K:F:E7P^OUN`a0X2M1O002N10O01O01Oa0_O<Dh0XO9G6JRhf8"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:closed", "texture:smooth/sleek"], "control_dims": "color, material, pattern, size, texture", "answer": "The image features a bookshelf with a variety of books on display. One of the books is a large, thin book that stands out among the others. The bookshelf is filled with books of different sizes and colors, creating a visually appealing arrangement. The books are placed in various positions, with some standing upright and others lying horizontally. The bookshelf appears to be well-organized and filled with a diverse collection of books, making it an inviting space for book lovers."}, {"question_id": 72, "height": 427, "width": 640, "image": "000000135604.jpg", "category": "description", "question": "Describe the sports ball in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [424.94, 283.84, 40.22, 36.15], "segmentation": {"size": [427, 640], "counts": "QSa5;m<6L3L3N3M2N2N1O100O100O010O1000000000001O00001O0001O00001O1O001O1N2N2N2N3M3L3L:DkeX2"}}, "object_label": "sports ball", "attribute_label": ["color:black", "color:white", "material:leather", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, texture, transparency, pose, state", "answer": "The sports ball in the image is a soccer ball, which is white and blue in color. It is sitting on a grassy field, possibly a soccer field. The ball is round and has a smooth surface, making it suitable for playing soccer."}, {"question_id": 73, "height": 640, "width": 470, "image": "000000151938.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [242.55, 177.02, 10.58, 48.13], "segmentation": {"size": [640, 470], "counts": "Tjf4:dc0e0\\O2N10ODTOb]OP1`b0PO]]OQ1db05;E1O1IQ]OZO]c0Oo]W4"}}, "object_label": "bottle", "attribute_label": ["color:green", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern, transparency, state, color", "answer": "The image features a bottle of wine, which is prominently displayed in the foreground. The bottle is tall and slender, with a greenish tint to it. The wine bottle is placed on a table, and there are several apples surrounding it. Some of the apples are placed near the bottle, while others are scattered around the table. The combination of the wine bottle and apples creates a visually appealing and inviting scene."}, {"question_id": 74, "height": 640, "width": 480, "image": "000000153529.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 146.32, 61.87, 131.9], "segmentation": {"size": [640, 480], "counts": "P6896\\c0M5N000Oe\\OKjb07j\\O8Qc0d0H0O01O10O00O10000OTMPOhBQ1W=oNiBQ1X=oNhBP1X=POhBP1Y=POfBP1[=TOaBj0a=UO_Bl0a=TO^Bl0d=SO[Bm0i=UOQBl0n=\\OjAd0Z>\\ObAd0`>^Ob_OFa1l0o>Fo@;T?Dj@<Y?Eb@<a?D[@<i?CU@=n?Bo_O?T`0Bh_O>[`0C`_O>c`0BX_O?m`0@o^Oa0Ua0@d^Oa0`a0n06J4K6_Nl]Ol0Vb0>3L3N2M4M2M101N2O1N3M3N2M5K5K4L3LTdU8"}}, "object_label": "handbag", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color, texture", "answer": "The handbag in the image is black and has a strap. It is being carried by a woman who is standing on a platform at a train station."}, {"question_id": 75, "height": 640, "width": 480, "image": "000000153529.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [1.08, 97.94, 55.15, 309.04], "segmentation": {"size": [640, 480], "counts": "V3_3<lN^=W1WB`L5[2a=\\1]BgN_=Z1`BjN\\=h1kBcMQ=R2cChMZ<X2nCdMo;\\2RDcMm;]2TDeMi;_2TDcMj;^2VDbMh;`2VDbMj;\\2WDdMm0\\Nd8Q4^FdMk0^Nh8l3^FfMi0_Nj8j3\\FiMg0^NP9a0_EP2j0XO?XN[94fE[2a0]O8UNe9IiEe29C3oMk:^2REKJhMT;]2QE0FdMZ;\\2oD6ROPM;>e;[2nD<[OZMi;P1VD]Of0Z2YOZMm;k0YD^Ob0^2VOYMR<c0_DnNZO?o0h2TOXMb<O_DOLj2QOYMi<EaD5Ec3`=\\LbBb3`=\\LfB]3]=`LgB]3[=_LoBY3n>N2M3N3L4M2N3L3M2O4L4K5L4L6I6K4L3L6K4K6K:E7J4K6IlcX8"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, pose, hair type", "answer": "The image features a woman standing in a train station, wearing a pink shirt. She is holding a black purse in her hand, and there is a backpack nearby. The woman appears to be waiting for a train or preparing to board one. The scene captures the essence of a typical day at a train station, with people waiting for their transportation."}, {"question_id": 76, "height": 640, "width": 480, "image": "000000153529.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [224.42, 186.93, 50.7, 72.62], "segmentation": {"size": [640, 480], "counts": "Wj\\4241N9Uc0X1SO7J3M2O1O00001N1000000O100000000O100000O1001OO100000000000000000000000000O101O00001O1O1O1N3N4K;F5I4M4ROnQn3"}}, "object_label": "suitcase", "attribute_label": ["color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, pose, material, transparency, texture", "answer": "The image features a large, gray suitcase sitting on the ground. It appears to be a rolling suitcase, which is a convenient and practical choice for travelers. The suitcase is positioned on a sidewalk, possibly near a train station or a transportation hub."}, {"question_id": 77, "height": 375, "width": 500, "image": "000000166166.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [15.32, 121.77, 134.68, 123.39], "segmentation": {"size": [375, 500], "counts": "RX5>Y;3N7H7I8I6I6K8G8H1N2_FlM]9X2O2N8H2M2O0000000O101N10000O1000000O101O0O10000000000O2O000000001O00000O2O0000000000000010O000000000001O00010O001O0001O000000010O00001O000001O01O00000000O1O2N1001O1O010O00O11O3M4L9H7H9G8I7H7J9G6J6I7I7HmgX4"}}, "object_label": "chair", "attribute_label": ["color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The chair in the image is a wooden chair with a brown seat. It is placed in front of a wooden dining table, which is located in a living room setting. The chair is positioned next to a fireplace, creating a cozy atmosphere in the room."}, {"question_id": 78, "height": 375, "width": 500, "image": "000000166166.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [401.35, 103.31, 45.68, 77.44], "segmentation": {"size": [375, 500], "counts": "]Ta48^;2O0000O10000001O00O100000O10001O00O101O00O1001O00000000000001iEHm89QFNLJ0n0g9n00O100000000F;jNeof0"}}, "object_label": "chair", "attribute_label": ["color:black", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "color, pose, state", "answer": "The image features a wooden chair with a black seat, placed in a room. The chair is positioned near a dining table, which is located in the background. The room appears to be a dining area, with a doorway visible in the background."}, {"question_id": 79, "height": 500, "width": 375, "image": "000000178028.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [89.91, 302.87, 19.35, 50.85], "segmentation": {"size": [500, 375], "counts": "VX\\1=V?d0SO<K4N2O01O00000000001O:E2O2Ma0^OTaR4"}}, "object_label": "bottle", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "state, texture, pose", "answer": "The image features a bottle of lotion or body wash, which is placed on a counter or table. The bottle is white in color and has a white cap. The bottle is positioned in the center of the image, and it appears to be the main focus of the scene."}, {"question_id": 80, "height": 640, "width": 480, "image": "000000179392.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 286.3, 140.94, 201.35], "segmentation": {"size": [640, 480], "counts": "P9?a1>GVO_OZ1m<ROfBBk0m02VO@Z1l<QO`BJn0k03QO@[1o<oN_BOi0h09oN_O\\1P=oN^B0g0d0>SO\\OY1R=DnB2e0QOZOY1U=DjB2f0TOYOW1W=nN[B6;d0l0oNUOZ1Z=lN[Bl1V1nMUOZ1[=kNZBl1W1oMRO[1^=kNXBj1Y1PNPO\\1_=jNXBH0P11QO5JO3T14oN]1a=hNWBI0Y15dNOOW16mN]1a=hNWBX10_N003NY16lN]1a=hNWBb1b1YNeN]1c=h0hClMcN]1f=mNUBU1W1YNSO7J^1h=fNTBJ1a1b1aN`N^1j=eNUBF5P1JWO0J02b14_N^1m=dN\\B2GL4J101O]1n1[<\\NZBNg2c1Q;_NYBLh2c1P;aNWBMT1I6g1`<cNVBNLHL1`0OE1K0a1d1d<dNTBOIN>JD2LOa1c1e<eNkAG38NMOO3N00d1`1`<fNSBOFOO02M2Oc1`1b<fNQB2EM1N2Mo1`1Y<fNkAHK<NK2M3Lo1b1Z<eNiA8KG0MY2^1U<gNbA93A^2_1o;\\OnCSOhMb1[>[OmCSOhMa1\\>\\OlCSOgMa1^>]OSDb0o;iN]A5OD]2]1Y<jN[AML03M3MP2_1d<jNZAKO02MX2_1^<jNXAH300OV2^1a<lNhA4Y1P1P=mNaA;[1h0U=oN_A5^1l0U=oNfAC]1\\1o<ROjCm0W<TOgCl0Z<TOeCk0^<UOaCj0`<VO_Cj0b<UO]Cl0d<UOZCk0g<UOXCj0j<VOUCi0m<WOQCj0P=VOoBj0R=WOlBh0V=XOhBi0Z=WOeBh0\\=XObBi0_=VOaBi0a=WO_Bh0b=WO]Bj0d=VO[Bj0f=VOYBj0h=UOXBj0k=VOSBj0n=WOoAj0R>YOjAe0Y>XOiAh0X>XOhAg0Y>YOfAg0[>[OaAf0a>ZO]Af0d>ZO[Af0f>[OXAf0h>ZOVAf0l>YOTAf0n>ZOQAf0P?XORAg0o>XOQAh0Q?YOk@h0V?ZOg@f0Z?[Oc@f0^?ZOa@e0a?[O^@d0d?\\O[@d0f?]OX@c0i?]OW@a0k?^OU@b0m?\\OS@c0o?]Oo_Od0R`0]Ol_Ob0V`0_Oh_Oa0Y`0_Oe_Oa0]`0VOf^OMm0m0^`0_O`_O`0b`0@]_O`0d`0AZ_O?g`0YOc^OHe0P1i`0WOe^OGa0Q1l`0XOc^OI>o0Qa0WO`^O09i0Xa0VO_^O;M`0fa0UO]^O`1da0`N\\^O4Lm0ia0oN[^O3Ok0ga0ROZ^OO2n0ga0ROX^ON2o0ga0SOW^ON0KLR1na0UOV^ON0KLP1Pb0WOT^OOOl0na0UOS^O1Lj0Rb0UOR^OU1Pb0jNP^OT1Rb0lNn]OR1Tb0nNl]OP1Vb0POj]Oo0Wb0QOi]On0Xb0ROi]Ok0Yb0TOh]Oj0[b0VOb]Ok0_b092N3N1O1O2N2N101N2O2M2N2N3M3M6Goef6"}}, "object_label": "book", "attribute_label": ["color:black", "color:white", "material:paper/cardboard", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "texture, pose", "answer": "The image features a book lying on a wooden table, with a cell phone placed on top of it. The book appears to be a large, thick paperback, possibly a novel or a reference book. The cell phone is positioned on the book, covering a significant portion of its surface. The table itself is quite large, providing ample space for the book and the cell phone."}, {"question_id": 81, "height": 640, "width": 480, "image": "000000179392.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [61.84, 1.8, 418.16, 260.31], "segmentation": {"size": [640, 480], "counts": "S\\f13jc0Q2W\\OSN4KXa0n2C5K1^@kLW>U3fA\\Ml=c2UBbMf=^2ZBdMd=]2[BeMc=j2ZAcLNO3LMe0g>g3YAYLg>g3YAYLg>a4O0000OdAiJQ>V5nAPKn=o4RBSKm=l4RBWKm=g4SB\\Kl=d4SB^Kl=a4TBdKh=\\4WBfKh=Y4XBiKg=W4YBRKJc0m=Z4YBkKg=T4YBnKf=Q4[BoKe=Q4ZBPLf=P4ZBPLf=o3[BRLd=n3[BSLe=R1hB5DiNc=l0WC3WOPOb=i0_C2QOTO`=i0fCKlN\\O^=f0oCGdNC]=e0TDC\\NmNFk0j=d0ZD]OXN3^=?_DXOPN>a=9jDkNhMn0]=7bEJ^:5dEJ\\:6eEI[:7iEEW:;UFYOk9g0_FoNa9R1`FlN`9T1hFdNX9\\1jFbNV9^1f41O001O00001O001O1O1O1O001O1O1O001O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O001O1O1O1O1O001O1O001O1O00001O001O1O001O1O001O1O1O1O001O00001O0000000000O1000000000000000000000000000000000000000000000000001O00cN\\_OVN5n0_`0k0h_OTOX`0l0h_OUOW`0l0i_OSOW`0m0i_OSOW`0l0k_OSOU`0m0l_OSOS`0m0i_OVNEm0b`0m0h_OWNFl0b`0n0g_OWNEm0c`0l0h_OWNEm0c`0m0g_OWOY`0i0g_OVNFm0c`0m0g_OVNFm0c`0m0k_OSOU`0l0l_OUOS`0k0m_OUOS`0l0l_OTOT`0l0i_OUNEo0b`0l0i_OWOW`0i0__OTN7T1Y`0h0`_OTN8S1X`0i0m_OUOS`0k0m_OUOS`0k0n_OSOS`0m0m_OSOS`0m0m_OROT`0n0^_OTN;n0W`0n0]_OVN2N11Ok0b`0]2100O10000O1gNY_OYOg`0f0\\_OXOd`0h0b_ORO^`0n0c_OPO^`0P1c_OoN]`0R1e_OjN\\`0W1c_OiN]`0W1c_OhN^`0W1c_OiN]`0W1d_OhN\\`0X1e_OfN\\`0Z1e_OeN[`0[1e_OdN\\`0\\1d_OdN\\`0\\1e_ObN\\`0^1d_OaN]`0_1d_O_N]`0a1c_O^N^`0c1a_O]N_`0c1a_O\\N``0d1a_OZN``0f1`_OYNa`0g1__OXNb`0h1^_OWNc`0i1^_OUNc`0k1]_OUNc`0k1^_OSNc`0m1]_ORNd`0n1g01O001O3M4L4[BfM\\9\\2`FhM^9X2aFnMZ9R2bFSN]9l1`FYN_9f1aF[N_9e1`F]N_9b1YFgNg9X1YFjNf9V1VFnNj9Q1nEXOR:f0kE_OU:a0hECW:<gEGY:7fELZ:3fENZ:1bE4^:L\\E:d:EWEb0h:^OTEf0l:ZOmDm0S;SOjDP1V;oNhDT1X;lNeDW1[;iNaD\\1^;cNaD_1_;`N`Db1`;]N]Dg1c;YN[Di1e;VNYDn1f;RNWDQ2i;oMTDT2l;kMTDV2l;jMTDV2l;jMTDV2l;jMoC[2Q<fMjC^2V<cMhC_2W<bMhC^2X<cMgC]2Y<dMfC\\2Z<dMfC\\2Z<eMdC\\2\\<eMcC[2]<fMbC[2]<fMbCZ2^<gMaCY2_<gMaCY2_<gMbCX2^<hMbCX2^<hMbCX2^<hMbCX2^<hMbCX2^<hMbCX2^<hMbCY2]<gMdCX2\\<hMdCX2\\<hMdCX2\\<hMdCX2\\<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCX2\\<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMcCW2]<iMdCW2[<iMeCW2[<iMeCW2[<jMbCX2^<hMXCb2h<[200000001O0000000000001O00000000000000001O000000000000000000000000000000O10000O1N2000000000000000000001O00000000000000001O00000000000000O1O10000001O2N00000000001O00000000jMZCVK0b1fP1"}}, "object_label": "tv", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:on", "texture:smooth/sleek"], "control_dims": "material", "answer": "The TV in the image is a flat screen monitor, which is turned on and displaying a webpage. The cat is sitting on the desk in front of the TV, looking at the camera. The cat appears to be curious and is staring at the camera, possibly capturing the viewer's attention. The desk is a workspace, with a cell phone placed on it, and a book nearby. The scene creates a cozy and relaxed atmosphere, with the cat enjoying its time on the desk while the monitor is turned on."}, {"question_id": 82, "height": 640, "width": 457, "image": "000000186980.jpg", "category": "description", "question": "Describe the microwave in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [406.54, 212.98, 50.46, 52.08], "segmentation": {"size": [640, 457], "counts": "Pdn73kc03fN>f]O1Xb0l00000000000O11O0000000000000001O000000000000000000000000000000001O0000000000000000O2O5fN_]ON5`0]b0^Oa]O14?db0CY]O?_c0\\O]\\O4i;"}}, "object_label": "microwave", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pose, state, transparency, material, pattern", "answer": "The image features a small white microwave sitting on a table. The microwave is open, revealing its interior. It appears to be an older model, possibly a toaster oven, and is placed on a countertop. The microwave is positioned in the center of the image, occupying a significant portion of the frame."}, {"question_id": 83, "height": 640, "width": 521, "image": "000000193717.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [291.1, 202.22, 63.19, 23.82], "segmentation": {"size": [640, 521], "counts": "iRf53lc02N1N5L2O0000O0101O0000000O1O1O10O010L40002N01O3J4O000O100O10000O1000000000001O01O0O2O5EQl18mSN4L00L4001O3M1OO101N2M3O2M4K]UX3"}}, "object_label": "car", "attribute_label": ["color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, texture, color, pose, state, transparency, material", "answer": "The car in the image is red and appears to be a sports car. It is parked on the side of the road, and there are people standing around it."}, {"question_id": 84, "height": 485, "width": 640, "image": "000000228436.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [29.51, 151.8, 64.01, 30.91], "segmentation": {"size": [485, 640], "counts": "Zl=2R?2N1000001O00001O01O01O00001O001O02L[n0NhQO;F1O001O001O001O001O010O001O0001O0O2J6N1O2O1N2O1O1OO10015L4SAEd>>001O010O000O2N2N101N3MVmR8"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a white car parked in a parking lot, surrounded by other cars. The white car is positioned in the middle of the scene, with a few other cars parked nearby. The parking lot is filled with various vehicles, including a truck and a motorcycle. The white car is parked next to a pole, and there is a parking meter nearby. The scene appears to be a busy parking area with multiple vehicles parked in close proximity."}, {"question_id": 85, "height": 640, "width": 481, "image": "000000231831.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [18.31, 141.56, 126.73, 49.26], "segmentation": {"size": [640, 481], "counts": "o\\;710_c090H80O1O01000O10000O100O101O0O100O1000001O00001O01O02N1O002N1O1O0O2O001O1m\\OXOkb0o00000O1000001O000000001O000000000O2O000O1O100O2O000O100001O100O1O0000001O01O000000O100O100O100O100O100O1O100O10O0L5O0100O100O100O101N100O100O100O1O101N100O100O100O2O000O100O1O2Laka6"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "state, transparency, pose", "answer": "The image features a book placed on a wooden table, with a pair of scissors sitting on top of it. The book appears to be a boxed set, possibly containing a collection of books or a special edition. The scissors are positioned in such a way that they are almost touching the book, creating an interesting visual contrast between the two objects."}, {"question_id": 86, "height": 400, "width": 500, "image": "000000316015.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [384.77, 144.69, 15.84, 27.99], "segmentation": {"size": [400, 500], "counts": "Raf44\\<6J4L0PDDl;<TDFj;:VDFj;;WDCj;b000O20O001N2N3N2Eg`V1"}}, "object_label": "book", "attribute_label": ["color:blue", "color:white", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, state, material, color, texture, pose", "answer": "The image features a bookshelf with a large book prominently displayed on it. The book is positioned in the center of the shelf, taking up a significant portion of the space. The bookshelf is filled with various books, some of which are placed closer to the edges of the shelf, while others are positioned more towards the center. The books vary in size and orientation, creating a diverse and visually interesting collection."}, {"question_id": 87, "height": 445, "width": 500, "image": "000000338718.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [66.0, 13.0, 434.0, 176.0], "segmentation": {"size": [445, 500], "counts": "WSn01Wc20[jM4cBL\\=7bBIX==hBCV=`012hB^OT=c0lB]OQ=f0oBZO;:m;=SDHk;8jCYO4e0o;3mC7o;JPD;l;o0L2M4M3L2O1O2M2O1O1N2O1O0O2O0O101O000O1000000O2O00000000O11J5O1IkLfEU3Z:lLeET3[:lLeET3[:lLeET3[:mLdER3]:nLcER3d:0000O2N1oLVEn2m:00OO02O1O1N2O0N3O1MM`MoD_2Q;cMnD]2R;cMnD\\2R;dMoD\\2R;cMnD]2R;cMnD]2R;cMnD]2R;cMnD\\2T;bMlD_2U;`MkD`2T;aMlD_2S;bMmD^2T;aMkD`2U;_MlDa2S;aMlD^2U;bMkD^2Z;0001O0000O11O00I7M4N1N2N200O2M201N100O2M3O2M2N2N2N2O1N2N3M100O2O0O2O0N2O2O000N2O10000O1O1O10O01O10O01O0010O1O01O01O0O1O200000O011O0O1000000O10001O000O10000000000O1000001O0000O11O0O1000000000000000001O00000000000O10001OO100001O000000000001O00O10001O000001OO100000000001O0000O100000000001OO100000000001O01OO0101O010O1O001O001O1O4L7I3M3M1O2N1O1O1O10O01O001O0000000000001O00000000000000000000000000000001O00000000000O100O100O2N1O1O1O1O100O1O1N2N2O0O2N2M3M3O1M3O1M3O1001O0000O11O001fFbKS9e4O1O4M0O1O2N001OQNVGmNh8S1XGnNg8R1YGoNf8Q1ZGoNf8P1[GQOd8P1[GPOf8T3O000000010O0000000001O000000001O000RMYGf0h8jNXGgN0^2i8jNYGgNN_2i8aNZGeNO0OW3h8SNdGl1^8SNbGm1^8SNbGl1_8RNaGTOD]2k8^NcGTOB]2m8^NbGTOA]2n8^NbGn1_8oMeGo1]8PNcGP2]8oMdGP2^8oMbGo1`8QNaGm1`8QNbGo1_8PNaGm1c8QN^Gn1c8RN^Gb1YOeM^9h0YGb1P9]NQGb1P9]NPGc1P9]NQGb1P9]NPGc1Q9\\NkFg1Z9UNeFl1\\9SNcFn1^9QNbFo1_9PN_FR2b9mMXFY2j9dMkEF5g2R:aMiEI4f2a:\\MZEMNg2g:_MXEd2i:gNWENi:c1001O0O1fMYE]OMk1j:UNUE>5@N6N\\1j:_NYE8;MLIFV1j:kNZE9:MOn0^:mNYE7:NHJKV1j:kNXE7<L0P1\\:lNYE8<G7Q1U:oNXE1K3V1LoNQ1o:oNmD4U1LoN1Km0Y;TOmENROm0S;VOTFi0l9WOTFi0l9VOUFj0j9XOXFd0i9]OWFb0i9]OXFc0h9]OYFa0h9_OPENi0a0Z:_OaD=U11g:HYE7i:GYE6o^5"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:smooth/sleek"], "control_dims": "pattern, transparency", "answer": "The image features a white SUV driving down a street, with a person visible in the passenger seat. The car is moving at a fast pace, and it appears to be a taxi. The street is lined with buildings, and there are other cars parked or driving nearby."}, {"question_id": 88, "height": 480, "width": 640, "image": "000000345356.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [155.91, 259.87, 48.29, 86.7], "segmentation": {"size": [480, 640], "counts": "]QX23m>02OO0[O0[BO_=9oAJ:Nc=a0_B^O_=c0aB]OV=l0jBTOn<T1SClNf<Z1ZCgNc<[1^CdN`<^1>4M2N2N3O0O1O2O0O1O2O0O100O101O00000O2O000000O1N2O1O1O1EPCeNR=Y1RCbNP=Y1>M4H8K6J4N4EmQ]6"}}, "object_label": "cell phone", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "pose, pattern, texture, state", "answer": "The image features a person holding a cell phone in their hand. The cell phone is an old-fashioned flip phone, which is a type of mobile phone that has a hinged design that allows it to fold in half when closed. The flip phone is black in color and appears to be in good condition. The person is holding the cell phone in their hand, possibly preparing to use it or simply admiring it."}, {"question_id": 89, "height": 480, "width": 640, "image": "000000346638.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [128.36, 304.18, 343.01, 130.52], "segmentation": {"size": [480, 640], "counts": "Vjl16f>7L3L3N2N2N102M1O2N101N2N101N101N1O101O0O2N2O0O101O000O2O001N10000O100N2O1000000O2O000000000000000001O010O1O00L[NlBf1T=[NkBe1X=11NK[NoBe1P=]NoBc1Q=]NoBd1P=\\NPCd1P=\\NQCc1n<^NRCc1m<]NQCe1n<\\NQCe1o<ZNRCOOc1n<]NVCNNd1l<^NUC0Nb1m<eNSC\\1l<eNTCZ1l<eNVCZ1j<cNYC]1g<dNSCK1b1k<gNUCY1k<gNUCY1k<fNVC[1i<dNYC[1f<bNVCL4b1e<bN`C_1_<aN`C`1`<`N]CKKf1h<^N]Ce1c<[N]Ce1b<]N`Ca1^<`NcC`1\\<`NdC`1[<aNfC_1Y<aNgC_1Y<aNaCHOh1`<`N`CON^1a<cNbCK0b1^<cNbCK0c1]<aNdCMNb1_<`NcCi1]<WNcCj1\\<VNdCj1]<UNcCk1]<UNcCl1^<RNbCNMO4d1]<_NbCO5a1Y<_NcC13`1Z<_NcC22`1Z<]NfCN4e1n<00010O000QO[NcDf1[;[NlC2`0c1e;ZNkC3a0b1d;[NkC3a0c1c;ZNlC3b0b1a;\\NnC2a0b1`;\\NoC2a0b1h;^NYDb1f;]N[Dd1d;\\N\\Dd1d;\\N\\De1_<0QOYNeDh1Y;YNgDg1Z;XNfDi1Y<OkNYNQEg1n:ZNREf1l:\\NTEe1l:YNUEh1Q<001002M010OaNYNfEf1k;O01^NYNiEh1U:[NiEe1V:\\N^DLZ1i1W:ZNmEf1R:[NmEe1S:]NkEd1S:^NlEc1S:]NmEd1R:WNdDO[1j1P:VNfD0Z1j1P:WNeDO[1k1P:ZNQFe1o9[NRFd1n9\\NQFe1o9[NQFe1P:ZNPFg1o9UNdD07Nm0m1X:TNeD1\\1k1P:SNUF8_N[1[;]NVF1bNOOb1Y;^N]F0ZNb1];^NYFc1f9^NZFc1a;01ON3TN[NZFg1d9ZNdE0Dg1h:ZNeEMCi1h:ZNZFg1e9YN[Fg1d9[NWFi1i9XNUFi1k9VNVFj1j9VNVFj1j9UNWFl1h9TNWFm1j9RNiDMX1R2o9QNUFo1k9QNTFNcNo1Y;SNTFP2l9PNSFQ2n9oMQFQ2o9oMbEN@S2n:oMbENAR2m:oMbE0AP2o:oM]E3En1n:nM^E3Eo1i;QNWDo1i;QNYDm1g;RN\\Dl1]<N2O000000000O101O1O00TOYN_Dg1^<NHZNXCf1h<[NWCe1i<\\NVCd1i<^NUCc1l<[NVCc1k<[NWCe1Q=1^O]NbCg1Z<WN_C45f0J3g<UOaCg0H4T=LlB4S=EmBB1i0^<SOgC10b0JA1h0_<UOeC1Na0OAOh0_<TOfC2M4N41H0j0g<UO\\C3M61E0n0g<SOZC5N51E1m0i<\\OVC2OH0i0l<]OTC3OH1h0l<WOSC019OH0i0m<UOTC119Mh0m<POTCO1:Ng0m<WOTC10g0W<mN[D=]ON2h0V<mN[Dk0^O8l<SOSC=2_ONl0l<YOTC=0?f<YO[C]1P<WNaD9D^1l;YNbD6D`1b<^N^Cb1b<^N^Cb1a<dNYC]1f<>2WNWCY1i<`NXCM1b1T<]NZD3@01`1T<aNXD6DY1T<aNXD6DX1U<aNYDMA51]1V<_NYDNA51^1U<_NXD:@X1X<^NXDP2h;PNWD?Bm0X<cNWDa0@l0Z<bNVDb0@l0c<cNdCP2\\<RNbCn1]<SNcCl1^<TNbCl1^<TNbCl1^<TNbCl1U<TNiC02l1U<UNgC03k1W<TNRD2Da1Z<\\NSD3D`1Y<]NSD3D_1Z<]NSD4C_1[<\\NSD4B`1[<]NRD3C`1[<]NRD3C`1[<]NRDk1o;VNfC10i1Z<VNfC10i1[<TNfC30g1\\<UNdC40g1\\<UNeC3Oh1\\<UNeC3Oh1\\<UNfC2Ni1e<WN[Ci1e<XNZCg1^<VNeC3Mg1^<VNdC6Ld1`<WNcCS2]<lMdCT2\\<lMeCS2[<nMdCR2\\<nMdC6M`1_<ZNdC6M_1`<[NdC5M_1i<aNWC_1i<aNWC_1j<`NTCb1m<^NQCc1o<\\NSCc1m<\\NWCa1h<_NUCe1j<\\NSCf1n<61O00000YNQC^1n<aNTC^1l<bNUC]1l<bNTC_1k<`NZC\\1g<_NcCZ1R=0000000O1O1000000BhNTCW1m<iNSCU1o<lNPCT1P=lNoBU1R=mNjBT1W=:1O6J2M100O00100O0OOO3N3N2M3N3SOoAh0R>WOoAg0S>21KlTb2"}}, "object_label": "keyboard", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:on", "texture:smooth/sleek"], "control_dims": "state, transparency, material, pose, pattern, texture, color", "answer": "The image features a black computer keyboard with a blue mousepad on top of it. The keyboard is placed on a wooden desk, and there is a mouse next to it. The keyboard is positioned in the center of the desk, with the mousepad slightly to the left. The desk appears to be a workspace, possibly in a home office or a similar setting."}, {"question_id": 90, "height": 480, "width": 640, "image": "000000406611.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [455.61, 352.35, 23.06, 26.81], "segmentation": {"size": [480, 640], "counts": "dSf62m>2O1O0@NPB5n=?01O0000010OO100000001^OgA;Y>DiA<X>BlA7Q^]2"}}, "object_label": "backpack", "attribute_label": ["color:black", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:tiled", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material, transparency, pose, color, pattern, texture, state", "answer": "The backpack in the image is red and black, with a red and white design. It is a large backpack, likely designed for carrying a significant amount of items. The backpack is worn by a person, who is standing in front of a snowy background."}, {"question_id": 91, "height": 480, "width": 640, "image": "000000406611.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "cleanliness, color, length, material, pose, texture, transparency", "region_anno": {"bbox": [407.56, 393.56, 41.74, 9.84], "segmentation": {"size": [480, 640], "counts": "[bP62n>001O1O001O1O00NWAMi>1Uh3OnWL3UAMg>7N11O0000000000O11O01O01O0000010OdRj2"}}, "object_label": "skis", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:blue", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, material", "answer": "The image features a pair of skis on a blue surface, likely a tennis court. The skis are positioned horizontally, with one ski on the left side and the other on the right side of the court. The skis are relatively small in size, and their positioning suggests that they are being used for a different purpose than their traditional use on snow."}, {"question_id": 92, "height": 427, "width": 640, "image": "000000422670.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [26.99, 64.3, 276.21, 356.68], "segmentation": {"size": [427, 640], "counts": "dh<c0e<8I6K8H4K:F5L1CXNVEj1g:YNUEm1_:k0H5I4JiLTF^3d99H7L7J3L6I5L4L5L2N4K3M4L6J3N4M1M5L3M2N3M2M3M4N2M3L5K4M4K2N4M2L3O4K4M2N2N3MmLgJYNU5g1mJYNQ5g1SKXNj4e1\\KYNc4g1_KRN^O]MQ5b1PKW1b0IC[Mh4g1QKn03^M`0c2_O[MQ5Y4TKiK<^2_OgMn4S4WKhK<^2i4i1mJhK<]2f4ROfJU19[M>\\2b4n1PKfKc0W2]4Q2fJgK:1h0S2W4X2QKdKn0n1P4XOjJm17mLf1Z1V3JSKe1I[M12Z2g0j26QKh1JZM0Oh2NWM9X5g0PKi1I[M1La8o0dGk1LXM0N`8m0dGo1MUMf8j0\\GS2o8T100PGmKi8R4VGQLNMg8`0WGm22iLNMh89[GR3NnLg80[GR3MnLi8LWGI3g3l8_LTG[3NaL3Li86WG]36^Ld84VG^36^Lc85VG^37]Lc84VG`36]Lk8f3mFYL32o8^3nFdL0L24o8\\3oFdL0L24o8\\3oFdL0M13o8]3PGcL2K04l8_3SGaL70e8_3UGaL50g8_3UG`L41f8`3UG`LOM13k8_3VGbLML23i8a3XG`LMM12i8b3WGaLOK04h8a3YG`LO5f8\\3[G^L06b8_3]G\\L2LM3b8g3`GYL1MM3^8k3QHPLA5\\8m3VHSLg7P4YHPLc7U4XHfKD6R8U4ZHeKD7n7V4^HoK`7S4`HnK^7S4bHnK[7m3YHhK<OC7g7S4[HeK<1B7e7S4QISLl6o3TIQLk6P4eH`K9`0P7Q4fHaK9>L@h6a4SIbK8?n6Q4jH`K8a0k6P4mH_K8b0i6P4oH^K8a0j6P4PI^K6a0j6R4QI[K6b0h6U4bI]K[O5R7_4cI[KCNj6h4cIZKk6f4VIYKh6j4WIUKi6l4fIVKi5i4XJXKf5i4ZJWKe5g4TIUKW14e5g4TIUKW14d5h4aJUK_5l4`10O00100O01XNeG`NZ8a1hG\\Nb1]NQ5W3_IZNV8h1jGWNV8i1kGVNU8j1lGTNT8l1nGSNMeNl7Y3XHQNLfNl7Z3YHnMJiNl7Z3[HlMIjNk7[3]HiMJjNj7]3^HgMHlNj7]3_HfMGmNi7_3`HcMFoN^1Og4_3WJaMDROh7^3eH_MBTOi7]3fH^MAUOh7^3hH\\M@VOh7^3iH[M_OWOg7_3lHXM]OYOg7_3mHXM\\OXOf7a3oHVM[OYOf7a3PIUMZOZOe7b3YH\\Le0h0\\OZOOO?0B3m3LeNe3\\M\\Le0g0\\O[O0O>8_3GeNe3]M[Le0h0ZO\\O1M?6a3IcNe3]M[Ld0P1[ORO1M=1h31]Ne3^MZLb0R1]OSO>Kj3OZNh3_MYL>S1DRO0J52P4NZNg3`MZL0O9S1ISO9Kl3OXNh3aMYL=S1EmN\\7g3cHXL<U1V7e2\\HWL=V1HjNc4OfMk3aMXL=^1N`Nn30VNo3mMcMN^No30UNQ4lMbM\\4]NhMh3dM]LOK3d1c4[NfMj3dM]LOL3j1j6X2SInK0o1j6S2WIRNi6n1WISNh6i1XIPL1V2g6k1\\IUNd6^1XIfL3l1d6]1\\IfL0m1d6\\1[IbLM03S2e6X1]IfLKO3S2e6Y1[InLNj1f6X4100hLYIRM0[2h6b0ZIQM1[2e6d0YIRM3FL`2h6V1`IiN`6T1cIkN^6T1ZI`L1\\2e6>WIfM4@0\\2d6>XIcM:AJ^2d6;ZIfM`0o1V6;ZI]MM0d0Y2T6:ZI^MONb0Z2V66XI\\M160Ma0[2V65YI\\M42007NGf08b0_6[1XI^Ml02TO7n0c0l5d1WIaMk01XONR1h0e5g1WIbMj0Nj0d0W5k1VIcMf2?U4m1YLnMh3R2\\LhMg3V2]LfMe3V2j3N2J6J6M3K5N2N2L4N2N2N2O1N102M2O0O2O1O1O1O1O1O1O1O2N1O010O2N1O1O100N200O1O2N1O1O101N1O2NlVe4"}}, "object_label": "bed", "attribute_label": ["color:brown", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:horizontal/lying", "state:covered", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, transparency, state, pattern, material, pose, color", "answer": "The bed in the image is a crib, which is designed for infants and young children. It is a small, cozy space with a white sheet and a pillow. The crib is positioned in a corner of the room, and a baby is lying on it."}, {"question_id": 93, "height": 427, "width": 640, "image": "000000506707.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 211.37, 31.75, 108.64], "segmentation": {"size": [427, 640], "counts": "e6X3S:00000000000000000000000000000001O000000001O0QNRFa0n9[OYFb0g9[O]Fd0_9]NRFm0b0e0a9YObFe0_9VOgFNH^Oe9;nFDS_n7"}}, "object_label": "chair", "attribute_label": ["color:gray", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "texture, pattern, color, pose, transparency, material", "answer": "The chair in the image is a red and white chair, likely used for seating during a baseball game. It is placed on a metal stand, which is situated on a baseball field. The chair is positioned in the middle of the field, and it appears to be empty at the moment."}, {"question_id": 94, "height": 427, "width": 640, "image": "000000506707.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [137.7, 153.31, 137.02, 117.93], "segmentation": {"size": [427, 640], "counts": "^dg1:Q=d0]O7H1O101nClNi;^1O6K`N\\DT1d;kN\\DV1c;jN]DW1b;iN^DW1b;iN]DY1b;80_N^DX1c;hN]DX1c;hN]DX1c;hN^DV1c;iN^Dk0NVOc;M_DN2V1^;nNgDR1U;WOfDi0V;iNgDa00g0V;^OlDa0Z;WOiD?KSOd;3]DNl03ROMo]74RoH8K1TCCh<=YCBg<>30000O1000000001O0000001O1O2N7I8H7I1O0000000000001O001O00001O1O1O1O0VEbNf9`1XFfNc9\\1[FjN`9U1`FlN_9V1_FkN`9U1`FjNa9W1^FhNc9Z1[FeNf9[1\\F_Nh9b1P11O001O1O1O1O100O1O1O2N6kDaNR:]2O001O001O1O1O01O100O0100O101O1O00O1O1N2O101N1O2N3M1O22ON3L3L1O2oN[E]N5;l:Q1IcNWE200f0R1Z:\\OQE@61K5M`0U<ZOoCj0[<M6[O]C:Q=Idbg4"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pattern, color, pose, transparency, size", "answer": "The car in the image is a white van, parked behind a chain-link fence. It is positioned in the background, with the fence separating it from the people sitting on the bench."}, {"question_id": 95, "height": 612, "width": 612, "image": "000000535253.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [29.07, 171.7, 85.13, 133.92], "segmentation": {"size": [612, 612], "counts": "Uh?3ob03N2M:G3M4M2N3L4M2N2M4M4K104L2N2c^OZNXa0i1O2O1O2N2N3M2N2N4L1O2NO1O1O0O2N1L5Mc_OSNi?k1V@YNh?f1X@\\Ng?a1Z@cNe?[1[@gNe?W1Z@kNf?T1Y@nNg?Q1W@_NE<S`0<m_OD>GF0T`0b0Q@]O82U`0`0]@Cb?=\\@Gc?7^@JlNBa`0c0e@0Z?Ng@3X?Ni@0W?0TAEl>6b_ODd10m>=P2O1L3O0O2O2O1MkUj9"}}, "object_label": "book", "attribute_label": ["color:blue", "color:red", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a red basket with a magazine inside, placed on a shelf. The magazine is a TV Guide, which is a popular publication that provides information about television shows, movies, and other entertainment options. The TV Guide is placed in the basket, making it easy for people to access and read. The basket is positioned on a rack, which is likely part of a store or a display."}, {"question_id": 96, "height": 427, "width": 640, "image": "000000541123.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [73.23, 178.96, 22.57, 25.09], "segmentation": {"size": [427, 640], "counts": "\\fP1252R=20OO0O1TCL`<6]CMb<>0N201O01OO0J503OUCK]<N]C66M]<M]C62KO0f<;5O3K7K1OgoP7"}}, "object_label": "chair", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, transparency", "answer": "The chair in the image is a black office chair with a black seat and a black backrest. It is positioned in a room, and a person is sitting on it."}, {"question_id": 97, "height": 480, "width": 640, "image": "000000555005.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [324.21, 103.4, 75.99, 26.2], "segmentation": {"size": [480, 640], "counts": "`og4<b>2O20N1000001O000001O00000000000000000000001O0000000001O0000O100000000O1O2N1M3O10000000000000000000000000001O0000000000000000000000000001O00000000000AiAOTk`3"}}, "object_label": "book", "attribute_label": ["color:gray", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "state, pose, color, transparency, pattern", "answer": "The image features a close-up view of a book, possibly a manual or a guide, with a focus on the upper part of the book. The book appears to be a thick, hardcover book, possibly a reference book or a textbook. The text on the book is blurry, making it difficult to read the content. The book is placed on a surface, possibly a table or a desk, and is the main subject of the image."}, {"question_id": 98, "height": 322, "width": 500, "image": "000000555050.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "color, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [386.17, 199.17, 72.82, 33.54], "segmentation": {"size": [322, 500], "counts": "abi31o94N001N2O;E4L001O0O1000000O10000O10000O1000001O00000000000000000001O3M1O001O000000001O00002N:DPb1>c]N11O01O00O11O00000000000000L5F9N3O1NUP="}}, "object_label": "couch", "attribute_label": ["color:brown", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "transparency, pose, pattern, color, material, texture", "answer": "The image features a large brown couch, which appears to be old and worn, sitting on a sidewalk. The couch is positioned next to a pole, and it is placed in front of a blue wall. The couch is quite large, occupying a significant portion of the sidewalk."}, {"question_id": 99, "height": 479, "width": 640, "image": "000000345252.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "length, material, pose, state, texture, transparency", "region_anno": {"bbox": [225.21, 321.72, 150.87, 26.24], "segmentation": {"size": [479, 640], "counts": "dlT36h>2N1O2N2O002N4L1O0000000000IiAFV>;7O010001O01OO10000O10000001O00000001O000000000000000001OO2O00001O01O001N10000000010O0000001O000001O0000001O00O100001O0O1000001OO1000001O00M301O00000000000001O0000000000000000000000000000001O001N100010O01O001N2O0O2N1O2O00010N1LZAOf>1ZAOg>402NO100001O0O10O11O000001O00001O0000001O1O10O01O1Ol_m3"}}, "object_label": "keyboard", "attribute_label": ["length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "state:on", "texture:smooth/sleek"], "control_dims": "pose, texture, material, state", "answer": "The image features a person's hand on a laptop keyboard, with the keyboard being the main focus of the scene. The keyboard is located in the center of the image, and the person's hand is positioned above it, likely typing or interacting with the laptop. The keyboard appears to be a standard laptop keyboard, with the keys arranged in a typical layout."}, {"question_id": 100, "height": 427, "width": 640, "image": "000000040036.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [161.97, 50.15, 427.0, 345.1], "segmentation": {"size": [427, 640], "counts": "aST26T=2M5L6I3N2N2N1LWOeCk0Z<3O1O1M3N2O1M3N2N2M3N3G]NdDg1W;8M30001N11OM12]OmDkN1CS;R2201IjDYNU;g1lDYNR;h1PEVNo:l174L1O1O10N1010N2mDkMP;k1oD\\N2Io:T2QElMo:6QEd1S;\\NnDc1S;^NkDc1U;XNjD01h1_;N1000EZNQEf1o:ZNQEf1o:ZNQEf1X;2N2N\\OeD\\O[;IfD;OK[;CeDO3W1o2dNU54lGN2Y1i2mNX54jGQ1k2oNZ5]1fJeNZ5a0nGEh2LZ5?kGGk2KY5c0oGYOh27X5R1gJnNZ5Q1eJQOZ5o0fJSOY5l0gJUOX5l0gJUOY5j0gJVOY5j0gJUO[5j0dJVO[MZOk7a1iJTO]M[Ok7`1hJSO_M^Oh7`1hJkNhME`7`1iJhNhMI^7b1jJbNjMK\\7b1jJcNiMM\\7`1lJbNaMHM6h7_1iJcNbMIL4k7_1iJbNaMJL3k7a1iJaNhMMB0f7a1ZH_N^26nMKENf7`1ZHdNY24QNKFNe7_1[HeNU26WNEE2d7]1YHjNS26_NFU7Y1WHoNQ25bNEU7h1WJcNcNGU7[1YHeNm1<bNFX7l0ZH@f0_O2b0DCZ7k0\\HF5SOKa0`08BXO26d7o0XHMNPOOc0>4FXO70a7\\2UH^N<NGXO70b7\\2SH_N;NIWO8Ob7]3[H]MKXOY8]3iGZMO[OW8]3gGXM2\\OV8]3gGVM6[OT8[4nGdK2Ma7_4^HcKQ8\\4PHcKQ8g0cGk2<^LQ8\\4oGdKR8[4mGeKT8\\4>mMUGEb0QNc7Y2kGG<PND222h7Y4fHeKB2h7Y4eHfKC1i7X4eHeKD2i7X4cHeKh7i3gGfLa0Ai7j1eG21cNa0Ai7i1gG20cN?Ck7f1fGAN[O1KP9c2PGbM0KQ9V1nFF1ZO0Ik0CX7P3mGdM0Jc0BA0P8f3lGhLc0Bh7W4g0SMmF`1T9^NPG_1P9`NQGa1o8eMlF:5Q2o8^NRGa1o8]MlFk04;K1U9gNnFm02;L0T9iNmFk03k1Q9YMkFk03n1S9UMkFm01n1U9UMjFl01o1[9oMeFR2V9TMjFj00Q2W9UMiFi00P2NWM^9i0dFP2_9PNaFP2_9PNaFP2_9oM`FT2_9kMbFV2]9jMbFW2_9hM`FX2h9aMXF_2h9^MZFe2e9XM]Fh2h9RMXFP3g9PMXFT3f9kLZFV3e9iL[FX3k91O110O1O001O001O001DaLiF`3W9aLgF`3Y9bLeF^3\\9aLcF`3]9`LcF`3]9`LcF`3^9_LbFb3c90O1N2004L2N2N001O00;E7I2N4M0ORO_MWG]2e8gM^GU2b8jM`GU2`8jMaGU2l902N00O01O3M1O1mMjD33c1S;`NmD0MW1V;iNmDOOW1a;gNdDU1j;O3M001O0M@POlDi0AVOe;1kDc0_O^Oj;OiD?]OCk;NhD?]OBl;OiD2g;MiC0R=100cc1O^\\N0000000\\E2[M20Nm<0SC7l<ITC7h<MXC4f;FXEd0g:]ORE2YOc0d;ZOUEj0a;WOhCi0W<600iMPOSHQ1l7oNSHR1m7nNQHT1R:1O0cNkNoE3LS1P:oNTFOJS1h9lNmE3a0NIT1h9lNoEOd01BU1l9iNnF3ROU1Q:gNnF4mNY1U:cNnF5oNU1S:gNmF5oNT1T:gNmF7mNQ1W:hNlFe1T9[NhENQ1g1W9[NmFd1S9]NlFc1T9\\NmFc1T9\\NmFd1S9[NnFd1]:000fN\\NmFc1T9^NkFb1U9^NkFb1U9]NmFb1^:O100O100001O012gN]NdFi1\\:2N2hNSNmFP2Q9^NaFh1X9]NUF]O:Z2^9YNWF_O6OI[2i9PNYFGOO6_2`9kMZFM5Z2a9TN_Fn1_9RN]FYOOg2c9oMbFQ2^9oMbFQ2^9UN\\Fk1d9o0N101O000O1000001O0000001O010O001O00aNcFQO\\9_210O01O01O010OkNeFZN[9k200100O01O01O10O0001O0001000O010O1O010SObFkM^9Q30XObFcM_9]2aFbM_9V30O001O00000]O_F\\Ma9_O`Fe3`9[L`Fe3d90000O1O1_OYF\\Mh9c2XF^Mh9R301O01O10G`LhFo2H]M_9DnFi2DdM]9CPGi2BdM_9BPGi2AeM_9BRGg2_OhM^9ESG_2CiM[9GhFN1n0L>0oNZ9GiFM2f0H@3X1OnN\\9FhFN57GO0O232e0L@Y:DeE72M312g0KA\\9EXG9ZOD12c00\\Oh03EY9EYG8ZOF2Oc01^Of01JV9B]G:5BXOi0OIX9B[G9>;oNMV9^O\\G;_OBl0g0SONV9_OoFNN1J55J101N7e0GOU9^OnF0JOO150O11O1O7d0HOK]OT90SG1M11OO1002M9e0FN^9_OaF191GOe0b0\\OMW9_ORG002GNf0d0ZONU9@eGOWON10:f0DOL[OR94lGMWOO10;h0ALN]O00m82QHM7i0lNLN[O20m84mGL<i0kNM0ZO43^8OVH1ZONh0i0VO14XO^80bGNN1N22N1N>l0BJI[OP91WG0LNM3234L1O0O5k0MMQ9ZOkF1N22N2M104k0MMQ9ZOkF1O11O<MLj0MNJZOg80bGNI3O01O`0i0C7a8POlGNB1K5NJb0]2Q8eM\\HNSO7MJc0g1]OlNd8]ObH8]OP1]OJn9UOfFP1\\OKn9VOeFn0^OLh8nNQH0[O85IMS1JXOOO2HP9MVGOO2M75KNP1KXOOKOK31n8O`GOD85J3k0D_O1INK43l8N`G0E75J=a0ZOI1IOJ36S9LZG6IK=a0ZOI1IOJ36Q9O]G1IL<c0YOH0K1H27R9N]G1JK`0X1UOhN0=P9G`G0KLa0W1TOiN1=o8G_G0m09cN91ZO2<e9HjG2bNc0LE]9AkF6JJ60a1b0WNM]9BiF7JJ7N;0e0Q1_8[ObHa0^7_OdH`0\\7_OiH=W7C[FE\\2i0X7DhH<X7DhH=Y7CeH=c7ZO`Hd0a7[OWF9;DG0e0g0T9YOVF<:EFOg0g0a9_O]Ga0f:02O1N10O01O1O001O1O1O2N6J5Kiig0"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:smooth/sleek"], "control_dims": "pattern, color", "answer": "The horse in the image is a brown horse, and it is jumping over a wooden fence during a competition. The horse is wearing a rider, who is skillfully guiding the horse through the jump."}, {"question_id": 101, "height": 517, "width": 640, "image": "000000092839.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [79.0, 23.24, 561.0, 487.95], "segmentation": {"size": [517, 640], "counts": "mZ\\14P`04L3M2N3M3M2N3M3M2N3M3M3N2M7H6K3M2M3N2N3N1N3L3N1O2N2N1O001O10O10O2O0N2O1O1O001O100O1O1O1O1O2N1O1O100O1O1O1O010O100N2O1O100O1O1KfL^C[3b<eL^C[3`<gL`CY3e<100O100O1O1O010N20O02N2N1O2I6N2N101N3N1N2O1O_OVDiLh;Y3XDgLh;Y3XDgLg;l3O1O1N3N1O1M3`E[K_9f4`F\\K^9e4aF\\KWOLQ:k4gF[KWOJQ:l4hFYKXOKo9m4iFXKXOKn9n4jFWKY9k4eFVKY9l4gFUKYOIj9T5hFmJ^O70Hg9W5jFkJ_O60Hf9X5kFkJ^O50Ie9Y5lFTK_OCd9Z5mFSK_OCc9[5nFRK_OCb9\\5oFPKAC^9_5QGnJAC\\9b5QGlJCBZ9d5SGkJBAZ9e5TGjJABY9f5UGiJBAY9f5TGmJk8U4hFTL=Gi8W4jFRL=Gf8Y5ZGdJC@Q9o5[GaJD@P9P6VGPJN5L12Ie26Y3l5VJPJL?O_Ob2?W3e5[JnIMb0`2NT3d5_JmIKb0_22T3_5cJmIJ?0_O^2j0P3]5gJ`JKYO\\2m0o2]5iJ`JW26m2[5lJ_JV2:j2X5PK^JU2?f2S5WKfIJ>2_OW2[1c2m3TKmK6mNL>Z2m0^2T5ZKcIL=\\2P1Y2Q5_KbIL=\\2Q1W2Q5aKUJV2n0SOfNV1X6bM`IK>1^OV2g1POmNX1g4aMmK5lNK>1^OV2h1jNXOV1\\4iMlK5lNK=2_OU2l1aN^OY1R4PNlK4lNK=2_OU2Q2YN_O\\1Y5YN[IK=2_OT2Y2PN\\Oa1W5^NXIK40OZ2Q4YOf2bNVIL3O0Z2V4ROc2iNTIL<Z2o3lNc2nNRIL<Z2Q4gNd2ROPIL<[2S4`Ne2YOlHL<2_OV2i4WNU1B_K4hNK<2_OV2P5hMV10XK5gNK<2_OV2h<mM]CK;3@V2g<lM^CL:]2X<gM]CM20N]2c<fM]CN1ON_2c<cM`CNO0O^2o:`M^F4eNNOO0_2n:`M^F4eNM9_2c:`M_F3fNM10N`2_<cMlCMF`2]<cMcCM10Mb2_<aMcCM7d2U<_MdCM10Ld2_<_MdCNO1Mb2h:\\MkF3aNNO1O_2g:_MjF3aNM10Mb2f:_MkF2RO^2U:_MiF3RO]2T:`MlF3QO[2T:bMjF4SOX2T:dMiF4QOY2V:dMiF3POX2Y:eMgF3`NL7Z2d:gMeF4_NL00OV2o:jMcF4YNL214O0R2Q;nM`F4_NL1OOP2T;QN]F3`NL8o1g<UNQCL9k1i<YNnBL9i1k<[NlBL:f1l<^NjBL9f1n<^NiBM6f1R=]NgBNLN7f1W=^NfBNLN014b1[=aNeBNLN014`1a;_NSF4\\NN1NO`1b;aNQF3^NM8^1Z;aNQF4]NL9^1Z;bNoE5^NK9]1[;cNnE5^NK9]1[;dNmE4_NK8\\1^;eNkE4_NLKO7]1d;dNkE4_NL7Z1`;fNjE4_NK10NZ1g;hNkE3_NK10NY1h;iNjE3_NK10NY1h;iNjE3POU1V;gNkE4POS1V;iNjE4POS1V;iNjE3ROS1T;jNjE3QOS1U;kNjE2POT1V;jNjE3oNS1W;jNjE3^NK10NV1j;lNiE4]NJ20OU1i;mNiE4]NJ20NV1j;lNiE4oNP1X;lNiE4POo0W;mNiE3QOP1V;mNiE3QOP1V;mNiE3POP1X;mNhE4nNP1Z;lNgE5POn0Y;lNhE6]NI20OT1i;nNiE5]NI20OT1i;nNiE5POm0W;nNiE5POm0W;nNiE4QOn0W;lNiE5QOo0V;lNiE4ROP1U;lNiE4QOQ1V;kNiE4POR1W;jNiE5oNQ1W;kNjE5]NJ01OT1j;lNjE5]NJ02NS1h=QOZBJ01OT1g=QOcBKET1i=POlBo0T=POnBo0S;mNnE4oNo0S;nNmE3oNP1S;nNnE2nNQ1T;mNnE3mNo0U;nNoE4ZNJ9S1^;oNoE4ZNJ9S1^;oNoE4lNm0U;oNoE4lNm0U;oNoE4lNm0U;nNPF4mNm0S;oNPF1POQ1o:nNQF3mNP1R;mNQF3lNQ1S;kNRF5kNo0R;mNSF5XNJ10OS1e;nNSF5XNJ10OS1e;nNSF4YNK9S1[;nNSF4lNn0S=QOnBo0R=POPCo0P=QOPCNROn0n=TOoBOSOn0i;POYF4iNOUOm0i;POYF4iNOUOm0i;POYF5iNo0n:lNYF5VNK00OU1a;kNZF5iNP1m:kNZF5hNQ1S=nNnBR1Q=nNoBS1d:kNiF2cNS1d:jNjF4`NT1Q=lNnBV1e:eNmF5^NW1d:eNnF4lMK11OZ1V;fNnF4lMK12NZ1V;eNoF4lMK11O\\1S;dNRG4kMK20M_1S;bNSG4]NZ1n<eNRC\\1m<dNTC\\1k<eNSC]1l<cNRC`1m<aNSC_1l<aNcBJ40Ne1[=`NcBK32Nd1[=_NdBK40Mi1Y=\\NPCKGj1X=[NYCe1g<ZNZCf1e<ZN[Cg1d<YN[Ci1e<WNYCk1e<VN[Ck1d<UNkBK50No1R=VNkBK50NP2R=TNkBL50NQ2Q=TNkBK>R2f<SN^Cn1a<QNaCo1^<QNbCP2]<QNbCP2]<PNaCS2^<QN^CP2a<QNWCFOX2j<RNWCFOY2i<QNXCFNZ2j<PN_CR2_<nMbCR2^<hMUCL>]2\\<gMiCX2W<hMhCZ2W<gMgC[2X<hMfCX2Y<iM^CGO`2c<iM]CH0`2b<hM^CH0`2b<iM^CF0b2a<hM_CF0c2`<fMiCZ2W<aM[CN>b2W<dMhC]2X<cMhC^2W<cM[CH3O2f2`<cM[CH204d2_<dM[CH204d2_<gM]CE4d2_<fMgCY2Z<dM`CI0c2`<dM\\CH014c2`<`MZCM3OO14b2a<dM\\CI7d2]<cMhC]2X<dM[CIO04b2c<eMYCJO13a2d<oM[C^ONa2g<QN]CP2c<PN]CP2c<fM]CJ1_2c<bMYCM?`2X<cMlC\\2U<dMjC]2V<cMiC^2W<cMWCL?`2Z<gM_CHMa2c<iM^CGO`2c<dMYCM6NNa2c<dMZCK=a2X<dM\\CK=`2X1cMR91lE\\2n0hMT9MnE[2m0iMU9KnE]2l0iMU9KoE\\2i0mMW9GiEKFa2Y1oMV9G_EJ40Ma2Y1PNV9F_EJ40Ma2W1QNX9DbEH31Mb2T1SNZ9@UF]2>VN\\9\\OWF^2;YN]9YOYF^28[N^9VO[F_25]N_9UO[F`23]Nb9SOZFb21^Nd9PO[Fc2M`Ng9oNkEI10Mh2>bNh9POhEH4NOi2:bNk9mNkEH20Mm25aNQ:jN\\F`4c9_K^Fa4a9[KiEMh0h4]9[KhFe4X9[KgFg4W9YKjFg4V9YKjFh4T9YKQFLf0k4X9YKRFLg0j4V9ZKTFLf0k4U9YKQGi4n8VKSGk4k8UKVGl4h8UKXGk4h8TKYGm4e8TKZGn4e8RK[Go4c8SK]Gl4c8VK_FHe0S5k8TK]Gm4b8RK_Go4`8PKaGR5\\8nJeGS5Z8lJgGU5X8jJhGW5X8iJhGX5V8iJiGZ5T8fJiFL60`0_5`8eJiFN6N;0B`5S9cJlFMo0a5S8bJTH_5j7aJVH`5h7`JYHa5e7`J[Ha5d7_J[Hc5c7^J\\Hc5d7]JYGKl0i5i7]JZGK=0F1Kg5g8_JZGJ4N0101Kh5f8]J]GIf02XOh5c8]J^HIPOk5a8[JgHe5X7[JhHf5W7YJjHh5U7WJkHj5T7WJkHk5T7UJfHLmNP6\\8VJhGI;0A1M21P6]8TJiGI:1B0M22o5[8VJ^HHXO6Om5Z8PJeGOP14QOl5Z8QJfGMR13oNP6W8PJQIMiNT6T8oITIMiNS6S8PJVHM=2XOS6S8oIWHM<^6\\7eIoGM20a0`6^7cInGNON01`0O@2N10V6T8lIoGMNO101OO150K1N10W6S8kIQHM1O=O@c6Q8aIRHNj0`6S7cISHLm04oNT6o7lIVHK20d00XOX6l7lIaHL`0Z6m6kIYHK02c00WOY6m7jIYHLJ6e0]6W7bIZHKJ60Ja05^OW6l7jIYHKL0001N01?1@Z6k7nIVHH0N011OO1?1AZ6h7nIYHH3Oe01XOY6g7nI[HHO1o0Z6f6lI]HHV1\\6]6kI^HIU1]6[6gIdHLQ1]6[6gIdHLP1^6\\6fIdHMH1>NMa6W7cI]HL61I10O=01a6T7bI^HN50KO2O:0F09b6V7cI_HNON210N10:0E1;a6T7cI`HN4N20k0a6^6bIcHN2O02m0`6]6`IeHN3OU1d6Q6`IgHM30T1d6Q6_IhHL32T1c6P6_IjHML1O61HQ1g6X6]IkH?0@0N12Mf6W7[IjHa0O\\ON02221Me6X7\\IiH7MK3IO110M1330b6V7_IjH6NF0O2O0001M2221b6V7^IkH7MG?3BN3b6T7_IkH8NE>3BN0NOe6X7^ImHOK1h0O[OO2d6R7^IoHNONe01Bf6j6^IPIMONf00\\O0Jh6U7]IPI6`0J]OOLe6V7]IPI6LH2O02LP7V7QIPI6KJ2M1>LX6V7bIjHI031KO11320O0Ob6T7dIkHG1O0O11O01ON13ON052Ke6T7jIlHC6MMO23O0Ld6T7jImHA5M0102M0Lh6U7aIkHH3M>OG2N0Ji6U7_InHH>N:2UOg6T7bIoHG>OFO10O2Ig6S7dIoHM6HI54KNo6P7jIQIOLY6S7iIPINMY6R7\\InHM3DO2N61O00Ob6R7\\InH31J046LJ500000a6P7^IoH02MO36LJ51T7o6iHRI0OO11<0EOL91Z6P7^IRI01Me02\\ONM6NK1d6o6^IUIN00f0NMf6W6_IVIM00f0N]O06e6a6aIUI0MM4O3NK61MN5O^6n6_IVI`0NAM<0`6n6VITI5OJ1OO100000`6m6cIRIM1L041JN2134NM12`6i6fISII5NL0O12M02O45LN20a6i6fISIK3LO34NK35LN11b6h6dIUIM0M023OL24L001c6g6dIVIL0M024MK4>LGc6f6fIUIJ2N201Nl0d6i5cIUIJ132N20V1a6a5dITIK041LO50K6OJ02O91Hc6i6bIUIn0OTO0J54M_6j6bITI5OG051M30NM0N151_6i6dISIJ052KO00Of0O\\O0<c6^6iITIF1N020N01e0O\\O0=b6]6oIYIA0Of0ODb6\\6iITIJ6MNOQ1OTOb6b6jIUII7Ka1b6R5cIWI02M4Na1b6R5bIXI20L5N10V1a6\\5eIWI10K6N10U1b6]5SJWIA2KN0\\1a6\\5TJXI\\O0O2OO11OU1b6a5dIYI1OK0O106O00l0a6e5dIZI1OL0N105000m0`6c5fI[I0OL5Nb1`6o4eI\\IOOOP2\\6e4eI]I0ONo1]6d4fI_IMO0m1^6e4dI`IMJ011P2^6d4eI`I2JLQ2^6e4dI\\IK0=NEk1`6k4cI\\IK0<0Dk1a6h4iI]IH401Nb1`6l4jI]IH5N10a1_6m4jI]II4Nl1_6c4iI^IJX2]6Y4iIaIHX2^6W4iIRLW6n3iITLU6l3kITLU6l3kIRLIZM[6c6mIbII101Ob11VNZ6d6mI]II114O2O00X11`NZ6d6nIaII2N10O1Y10`NZ6c6oIbIG=OF0Z1\\6Q5nIcIFZ2\\6S4mIdIGY2\\6R4nIeIFX2]6R4iI`IK7O00l1^6]4mIeIGK4R2Y6^4lI`IGO114P2Y6_4mI`ID21O5Q2X6^4nIeIEL56Ib1_6f4oIfIDL0O17Mb1_6f4oIfIDM45Jb1_6f4oIfIDM4P2Y6\\4PJhIAM6o1X6]4PJhIBL6o1X6]4kIbIH7OJ8o1V6]4QJcIC0O19m1T6_4ZJdICj1U6b4YJbIC3De1_6e4iJfIhNf1^6d4jJfIhN50W1^6n4jJfIhNf1^6d4jJfIhNf1^6d4jJaKV5^4kJbKV5]4kJeJgNRO2a0\\6h5kJdJhNRO3`0[6j5mJ`JfNVO2>]6l5lJ`JdNVO3`0\\6i5iJgIhNj0NXO4?\\6h5jJgIhNS1N^O`6h5jJgIhNg1^6b4jJgIiNf1^6a4jJiIhNf1^6a4iJkIiNb1_6b4iJlIiNY10fN_6T6b3lIoEc5]:[JgE000O2N1Oo3_3"}}, "object_label": "bear", "attribute_label": ["cleanliness:clean/neat", "color:tan", "maturity:adult/old/aged", "pattern:plain", "pose:sitting/sit", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, color", "answer": "The image features a large white polar bear sitting on a rock near a body of water. The bear appears to be relaxed and enjoying the sunshine. It is positioned in a way that it can easily look over the water, possibly observing its surroundings or searching for food. The bear's size and presence in the image emphasize its majestic and powerful nature."}, {"question_id": 102, "height": 426, "width": 640, "image": "000000346905.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [309.91, 256.66, 86.35, 155.43], "segmentation": {"size": [426, 640], "counts": "fRR4<i<7I8I7K4M5J5L3L5L4M2M5K3M6K4K4L5hF`M^7h2RH`Mm7P4O0O100O1O1O100O1000000000O10O1000XNgGhM5AT8d2PH]Mo8c2l02N3M1O3M2N0mEmLo9S3QFnLn9X3O;TF`LX9^4\\O0O01O1O001O1O00001O00002N0O2O2cNcGiM]8V2kGcMV8k2SGhLN?P9e31N2O1N3L3M4H7B?C=VOk0WOl0A=H8HVlV3"}}, "object_label": "elephant", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "maturity:young/baby", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:rough"], "control_dims": "pattern, cleanliness, size, maturity, pose, state", "answer": "The image features a large elephant walking down a dirt road, surrounded by trees. The elephant is the main focus of the scene, and it appears to be the only elephant in the image. The elephant is positioned in the middle of the scene, with its trunk raised, possibly interacting with its environment or exploring the area. The dirt road and the trees create a natural setting for the elephant, showcasing its size and presence in the environment."}, {"question_id": 103, "height": 480, "width": 640, "image": "000000368961.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [162.81, 199.8, 107.82, 165.94], "segmentation": {"size": [480, 640], "counts": "W^_22j0b00n0W:gN`Eb0AWO2R2i:]N[Ei2c:l0J5L5M2O1N2O10_OmEULR:g3UFQLC3W:i3ZFSLA2V:f3m0N2N3L4L4L4M3M2L5CPDgMS<Y2oCdMR<[2QDaMQ<^290SDcMD1X;Y2VEZNb:f1]E_N_:a1aEdNZ:\\1fEiNU:R1ZEkM;NGZ1^:k0cElM82D_19eN]9n1^FkM85CP2g90YFnM>Z2X9OfF2Z9NfF2Z9NfF2Z9NfF1[9OgFNZ92gFMZ93gFJZ97fFG[99fFE\\9:RGjNQOTOo9R2RHgMRNMN4o9X2b20jCeMh;Z2?010O01O00001O00nClM<Kk9Y2iEmM^OLg0OS:V2kESNo:m1SERNl:m1TEUNDGh:S2bEZN@Hn:3mD]1b0nN]OET;MRE^10[N4d0ICT;MQEa1N[N3e0J\\O[;1lDa16SOEZOh;b1cDTOE[Og;a1dDTOE]Of;2YDQ1<@E^Of;L`DS16BE^OJOV<o0\\D3d;L\\D4e;LjCQO1O8T1m;KjCRO1O8T1n;JhCSO3O7T1n;JhCSO3O7T1o;IhCSO206U1P<HhCSO206U1P<GiCTO106U1P<GnCTO3T1P<FmCWO3S1Q<DmCZOJN3T1W<BmC@Ln0X<@kCDMl0Y<_OjCEM:9_OR<`0hCF3NQ=:lBFo=2VYc5"}}, "object_label": "elephant", "attribute_label": ["cleanliness:clean/neat", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:rough"], "control_dims": "texture, color, size, pattern, cleanliness", "answer": "The image features a baby elephant standing next to a large elephant, both of them in an enclosure. The baby elephant is positioned on the left side of the scene, while the larger elephant is on the right side. The baby elephant is standing near a ball, which is located in the middle of the enclosure. The scene appears to be a zoo setting, with the elephants possibly playing or interacting with each other."}, {"question_id": 104, "height": 427, "width": 640, "image": "000000376278.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [40.85, 77.96, 572.83, 246.98], "segmentation": {"size": [427, 640], "counts": "[ia06P=9J3M4M2N2N2N1O2N3M1PLnNgKR1X82O0O100aNXO[Fh0a9_O[Fb0a9E\\F;a9J\\F7a9O\\F1b93\\FMb97\\FIb9:\\FGb9<\\FEb9>]FBf6lNeKe1bM@g6POcKb1eM^Oa6ZOeK[1hM\\Oa6]OcKj2\\4YMaKh2^4ZM`Kg2`4ZM_Kf2b4ZM\\Kg2d4[MYKf2g4[MWKf2i4]MPKf2R5ZMjJi2W5XMbJm2^5VM\\Jm2f5RMXJQ3g5oLUJV3k5iLQJ\\3Q6aLkId3T6\\LdIn3[6QLcIR4\\6nK^IY4b6fK[I\\4g6U1O0001N2N100O1O100O2N0000001O2N1O2M4M2M0100@UJVIN5n5c6WJVIL6m5e6VJ`Ii5X7H4L2NiNdJYJN[O\\5\\6iJWJKYO^5a6RKoIo4m5WKRJg4m5\\KSJb4m5`KRJ^4P6\\1101`IbIR6`6QJ^In5b6UJ\\Il5a6d0KKdI]I\\6a6fI`IY6`6gI_IZ6c6dI]I\\6c6dI\\I]6e65O05M0<D00O2N0020N1iIXIg5j6WJUIk5l6:1cITIW6P700000O1O1O1O1O1O100O0010O01ObJWI[4i6S110N110O001O2N1OVJ\\Io4c6PK`IP5_6mJ_IX5`6gJbIZ5]6eJdI[5]6bJeI^5b6XJaIi5P70000000000O100000000000001O00001N100000001O01O000000000000000001O000000000O1000000O10000O100O1O100000000000000O10001N10O010O11N100000O100000O10000O1N2O1O101O0000000O1001N010O10FXHPKi7P590O2O1OO_HRKh6m4UIWKj6h4UIZKj6g4VIYKj6f4RI_Kn6b4PI_KP7d4mH\\KR7`4SI_Kn6a4WIYKj6f4XIQKDMT7T5VIPKQ7m4`HPK>4Q7P5mHYKl6g4kHcKS7_4lHaKT7_4kHbKU7^4kHcKT7]4lHbKU7^4kHQKO03IT7V5jHPK2N[7P5eHRK0N[7n4gHTKNN\\7l4gHWKJ0^7h4iHhKQ7U4SIkKl6U4UIjKk6V4UIjKk6V4UIjKk6U4TImKl6S4SImKn6S4QInKo6R4oHPLQ7P4nHRLQ7o3lHSLT7m3lHSLT7m3lHbKNOV7^4lHcK0NT7_4lHTLU7l3kHTLT7m3lHRLV7m3jHSLV7m3jHRLV7o3jHQLV7o3jHRLU7n3kHRLU7n3kHSLT7m3lHSLT7m3lHRLU7n3kHQLV7n3kHRLU7o3jHQLV7o3jHQLV7P4iHoKW7S50000000O1QOgHlKY7n3fHYK2i0X7n3fHYK2i0Y7m3eHZK2i0Y7R4gHnKY7T4eHlK[7R500000ROeHlK[7S4fHmKZ7R4gHoKX7j3gH]K1i0X7i3iH]KOj0X7h3iH_KOi0X7g3iHbLW7]3jHcLV7]3jHcLV7\\3kHdLU7]3jHcLV7^3hHbKOh0Y7o3hHQLX7o3hHQLX7o3hHQLX7P4fHPL[7P5000000000000000000000000000000000000000O2O0000001N101O0O101M2M3N2O1O2O0O10001O001O00001N1gNoGfLc8Z3]GfLd8P4000017H10FfG^K]8`49O1L4N1O1012N0O01N2O1N1O2O1N101N2O1N1O2O1N1O2I^FbLd9a3101M3O1N2N2N1O2N2M3M2N3N1O1O2O0O3N1M3N2N2N2O1N2N2N2O1N3M3L4L3N2N4J5L5J6K8F]fV2"}}, "object_label": "zebra", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose, pattern, cleanliness, state, size", "answer": "The image features a zebra lying down on the ground, possibly in a dirt field or a rocky area. The zebra is resting on its side, with its head down and its body stretched out. The zebra's distinctive black and white stripes are visible, making it easily recognizable as a zebra."}, {"question_id": 105, "height": 451, "width": 500, "image": "000000392818.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [0.0, 10.55, 500.0, 436.45], "segmentation": {"size": [451, 500], "counts": "T236NL0i7l2`H_Ml1JkM02N]7j2dHeMP2<mMWOOL2OP41PL33L10O1N9R1e2lNeMT29kMYO0K2OP42nK62I3O10N9Q1f2lNeMW22hM\\O5NX46oMh2eMfMX25kMXOX46eKIY2m2gMgMX2=gMPO2OV14^13ZMK5N]16fNg2IgM[22dM\\O000O\\11^1OWMOj1:\\Nc2JgM]2\\OcM90H0O50T6a0kI\\2LgM`2E`MHO11N10U6f0mIV2MhM^2OaMC0K2Oh13YNO01i1MQO0VO55d0KS2NhM`2M`MDd5NbJk0Km1NjMd2A]MO2Md5N_JR1Lh1NkMd2I]MGk5o0WJe1MlMd21\\M[O10h21dNN@2YOU1Lb1NlMe2@[M1000Kd5Y1^J_1NlMQ3[OUM0a5[1\\J]1NlMo2]ORM0N10O`5^1bJY1OlMh2]OXM4O4_5W1cJX1OlMl2ASM10K\\5b1fJU1NmMm2@TM0\\5`1eJS1NmMj2[OVMa0X5V1iJR1OlMi2\\OWM`0W5W1jJQ1OlMm2@TM00KT5j1mJn0NmMb8V1aGm0MmMQ3[OUM0o4m1nJk0NlMo2^OQMOO1R5n1PKh0NmMQ3\\OPM0O0Q5P2SKe0MoMP3\\OPM0O0P5Q2TKc0MQNo2\\OPM4e36UMh1[O`0LRNo2\\OPM4k0Kj1`0oMf1A<MSNg6m2]IPOLSNf6n2^InNMTNl3\\OcNe3`MZLOa22TNj3BTLHX2i3iMYLN`23TNh3DVLFU2k3mMVL0_20VNe3GXLDT2l3nMUL2]2OWNc3L\\N\\3RNULN\\21WNc3LZN^3TNSLN\\21WNb3J\\Na3VNPLK^21WNa3J\\Nd1PNH4UNM02\\21YN^31eL\\OINZ1U2fNF3[NOV22YN\\33bLBW1i3kNSLNV21ZN\\33aLDV1h3mNjK22MZ21[NZ3g0dLdNm0T4UOkK21NY2O]NZ3T1XM\\2_OiKO7NS22]NY3T1YM\\2_OjKO6NS22]NX3n0^Md2ClKGT20^NW3P1\\Md2^OeK26LS21^NV3X1TM]2FhK05No12_NU3Y1RM]2KgKN5No12_NT3Z1kLSNOY44eK17Ln11`NS3S6oLXI18Ll12`NQ3U6PMXIM;Oh12aNR3T6XMbIDi13`NP3T6]MaIAk11`NP3T6_MaI@k11`No2U6`MjK@RNo2U6aMaI_Oh12aNn2U6cMaI_Og10cNm2V6SMSI<?Ce11cNm2U6TMTI:a0Db11dNl2T6gMeI]Ob10eNk2T6jMXIYO81g12dNi2V6kMeIYOa13dNh2W6WMSIa0e2@QNf2X6oMgKZORNf2W6QNdIXO^11gNe2W6SNeIWO\\11hNd2X6TNdIXO[11hNb2Z6TNeIXOY12hN`2[6_MPIc0e0\\OW12iN^2\\6bMnH`0i0_OT10iN]2^6cMmH`0j0_OR11iN[2e6XN^I[OT12iNZ2_6dMPIe0N^O?NY11kNX2h6VNbI@k02kNX2_6fMSI0T32ZMW2i6iMkH`0S2@YNW2d4hMhL2TNd0J[OW20_NV2a6hMQI^1g1cNgNV2b6iMlHk0MLk1ZOjNT2d6cNlH9`1POPOQ2g6dNkH\\OM1;1U1MQOo1i6^NbH0n0Ee0NROl1k6ZNaHL0;m0Fd0MSOi1m6\\NbHKN3O0`01@L22_1NSOh1n6ZNdHNLO141MO0L41M12_1MTOf1P7[NdHN23J1LL00O22O13]1MUOd1R7]NbHNI13O26IJ5161U1OUOc1R7^NfH6M1KG72T1NVOc1Q7`NgH6KO;Jl0OUOa1S7aNgH6IIH1e0Oj0OVOa1R7aNjHN_O47MJ0<NG3[1NVOa1R7`NQI2^OOJN>9Q1GVO`1R7bNQI1^OO<MA5\\1KVOa1R7bNRI0]ON;1E1Y1NUO_1T7cNQI1LN[OO72X1NUO_1T7bNRI4HN@M23R2[1c5bNRI4C3EI14Z1KVO_1U7bNRI4@5IF12KN^10VO^1V7cNRI3XOML;5DO3LM^10VO]1W7dNWI>@D_OM\\10WO]1V7dNZI0lN22O`01@MZ10XO\\1W7eNeI1cNN92V1NRO\\1V7fNfI0cNN82X1NQO[1T7jN^IOmNM1051OOg1Z1g5lNaIKmNN1033]1MoNZ1P7POdIFmN0:4V1LoNY1V7kN[I5jNH=60Ia1X1n2hNUK1^22SO:hN0HE2Oh1W1P3kNbMOWO7[NI75NJOOP2W1h2kNbM1mMNm00hN42K48f1HiNV1Q4kNPN2SO0cN4>In0U1X1lNcN1]NOX23LMXN2MN:1S1S1Z1lNbN1g01ONTN1Ha03@^1Q1\\1lN`N3g01bNLk01\\N33b01]O`1P1[5mNPJ0h06YNJ01b2Q1]4POoINi09o0f0X4ROQI1P1Nh04BL6n0Z5SOYION2o0Ng06ZNKT1O;n0`8SOPF7f2e0m3WOjL3XOd0m3XOPM3SOd0l3ZOTM0POe0m3[OTMOoNd0o3]OYLLjM3n1b0Q4_OWLLiM4V1LkNd0P6@nL0WNLkNd0c5BgIJ07c3McMOXOM8c0d5FgIMb3NcMOXOM8c0e5]OeI253^3NbM1ZOL7c0i5_OdI6]3ObML^OM6c0i5B`I9\\3KdMHC04b0k5_OdI9S3HgL3n0KE14`0Y6CQIKX32iL3j0NGO4`0Y6GXLIkL3g0OIN4`0Z6G^IIU2O`M5d0ML03?a6@XIOT20`MOL4g0ONO3`0Z4^ORM2R10QM1?1ON3`0`6AkHMm23VM0`00OO4`0_6HfKMTMMb0N204`0^6CiHKo21RM102b0M224?_6@WINR22aM0N2b0N216?g9^OcE1M2`0O237=n9AWE1`0N41:?l9@VE2?N619<ROBj:1VE2?N619?b9^OgE3I1>O7O:`0a9_OcE;OG40?0:<QOB_:1dE::G7O=<b9D`ENN8<K3MC1o0=`9DeE6MJN3?Lf0;]9FcE6LLM2`0Lg09h6EeJ1eM6JMM1b0Kf0;g6EeJ1eM6JMM2k15T6EdJ5dM1J80B54V17c6EdJ9`MLO>1CX15d6EdJ9_MM07OE05\\14b6EdJ2]M00O251M01OLO6^15U9G]EN55:L@1g1:k8FhE36L[1:h8FhE3T27T8F`EO25Z27R8LcEM[28Q8LcEK]28P8NcEJ]29o7FcE010^2:n7EdE011]2:n7DeE101]2:n7CfE2O1]2:n7CcE0O231]2;_5B\\J1eM0O140^2<^5B\\J1eM42N_2;n5B\\I0VN52M^2<P8FcEM^2>h7AiE41L_2?g7AjE3OMa2?Z5A[J0kM3NNb2>f7ARF1X2>S8DmG<S8DmG<d7ATF3X2=c7@TF4Y2<P8DQH<o7DQH<n7ERH;n7ERH;n7ERH:a7AUF5Z2:a7AUF4[2;`7AUF3\\2<m7CTH=l7CTH<]7CVF1^2<\\7CVF0_2=[7CUF1`2<[7CUF0a2=Z7BVF0a2>g7BYH>f7CZH=f7CZH=f7CZH<f7D[H<e7D[H;f7EZH;f7EZH;f7EZH;f7EZH:g7FYH:g7FYH:f7GZH9f7F[H:m6EjF1Y2:m6EiF1[2:c7E^H;a7F_H:a7F_H;_7FaH:_7FaH:_7DcH<]7DcH<b:001O00000iLChH=X7ChH=X7ChH>W7BiH>W7BiH>V7CjH=U7ClH>S7BmH>S7BmH>S7AmH`0S7@kHc0^4]ORK0?d0_4]OUNd0k1[OVNf0i1ZOWNf0b71kLYOmHi0R7WOoHh0Q7XOPIh0o6XOoHj0AVOj41eKi0AVOi42fKi0n6VOSIj0m6UOTIl0k6TOUIk0l6UOTIk0R:1N1O1O1UJQOaNP1^1RO^NQ1b1oN]NR1c1nN]KN:U1Y4mN[NT1e1kNYNX1g1hNXN2bJR1V7lNVN3eJQ1U7lNVN2eJS1P3jNR11_NO41^MV1m2iNR10`N022_M2Lm0Q3oNg30lK2`M2NLOn0o2RO^61gF2NMNn0]<TOgC11l0X<ROhC111Ig0]<XOhC120Ig0]<VOjC3No0_<TO^Cm0W<nNnC4Mn0T<oNoC2NP1Q<mNSD2MR1n;lNUD2NR1c5kNoM0cN1nM1NS1b5lNnMOcN2oM0NT1j4nNPKLc61dI20S1h4TOb1FcI1K29S1g4SOa1HeI0J26MJW1P5QOXOHhK2P20YN2ILO0OX1o4hNUK2R4O]N2`MNL01X1U5iN^K0k2OTO2bM1LU1V5gN_K3f2NhN0YN1I2KV1U5fNkJ0d01g20PM2V1OjN1J1KW1U5iNlNL[L4T1LlN5HOLY1S5hNmNK[L5T1LmN5GMNZ1S5gNlNL[L2g13RNLK01]1T5gNjNKdN4cM1JZ1U5fN]1O_Ih1U5YNZ1NdIi1R5YNX1NhIi1o4ZNW1NjIi1o4XNd0MeJ2Kh1l4XNc0OeJ2LMHOOb1W5aNlNL_M1mN40KBd1_4\\NTL2e53ZJ`1l3\\NUL0\\O1a50oJ23b1l3[NXL1j4OoJ35a1j3\\NYL0h40QK34b1i3[NZL1f40RK3JKOh1S4YN]L1b42TK6FH2g1U4XN_L0_42UK9EE5g1S4YN`LO^41VK4A03L2OKh1\\4XN]25XIO?g1X9VNkF1M2CO?h1h4UNPO1YL1L2E0=g1i4UNF2_K2F1KK=l1Z9TNjF3N1F53GHn1f9SNhF4O1BK2;3g1b9mMiF4O1G70f1S:oMWF4I7LFKl1k:WN_E8KCLo1S:SN]F2K:L`1l9TN\\F2M;FAOn1P:UN^F1N<D@0n1o9WN^FOO>F]1k9TNQFO=3DK:b0I]1j9SNSF0<42<D]1j9SNVFN:54=B^1h9QNgF42=^O_1h9oMiF33`0ZO^1^:SNZFb2n8ZMoF34f2h8WMUG44e2e8XMVG36e2c8XMWG46d2c8WMWG48f2U9YMRGd2l8[MWGd2h8]MWGd2i8\\MWGf2e6WMSJ3[Oe2b6XMSJ1\\Oh2a6WMbI0PO3e0o2W8nLTG2;]3_8bLRG19f3f8YLoF2:f3h8WLnF26l3U9SLkFo3P9RLQGP4P9nKPGS4^9WLTFK1]3X9^LTG[4j8eKUG\\4k8dKTG]4l8cKRG`4m8aKQGa4m8`KoFd4Q9\\KnFd4S9oKkFb3R9kKoFl1Ol0P9YMRGk1Nm0m8ZMUGf4i8[KXGk2MiNf8`NZGj11hN0o0b8:`GPN2NL^2b8E_GoM4LJ00a2\\8JfGhM5LJ2Oc2V8gMlGa10XN5j2e7dMVHW1NWN245k2`7gM[HW1NWN8LHj00X1a7XN`H11g18mMGk0O\\1X7XNjHNOR1:dN7M^Oh00g1f5aM^K;POGNl1:TN:S3U6lLVI;1EO0O1071U1:eN:W3R6VM[IAOO10O90U1:dN;]3m5aL^Ia07Q1J^NO043e0`3[5cLTJ9Ol0HjN2K54b0a3\\5bLTJNG11J4b10^NN4g0k0VOi1Q6cMTJGN5MI20OT11nN:OG3g0j0WOQ2j5]MWJG16O4N9d0[O?m0nNS2i5QMVJ53LO60NOK0>0Ci1l0VNS2n5SMVJOM51HN32MO?1Bh1m0VNT2e5nL_Jk0NTOO50MO>2Bh1m0VNY2_5mLbJh03N7WOW1Y4i3lKfJf03N1UON3_1Y4e3mKkJd0OSO0k02^O`1U4`3mKPKa0NTO02OO1843c1W4Q3nKYK:<XOBN96a1_4l2lK\\K8=YOK6_1_4k2]K\\KL08180F2I7208`1`4g2ZK`KL0m00[O1H83GO0;i1b4a2UKgKMNb02BN71F7e0b1Z4^2TKjKLNa04AN>42K_Oj1Q5Z2RKmKLO`03B24JI115a0LAh1S5R2mKYLPO2481AK4Of1X5o0fJWM21N11;U1IlN258O@K71b1[5Q1dJWM0O1<U1JkN2560NJ^1\\5S1cJUM0;W1IjN36312H\\1_5h0bJXNOWOg00C5F3:NN9HY1T1WNW3a2gK_Na0QO@O2b0d0j1;dMX3a2eK_Na0SO@O2`0d0j1j46^J[N0TOa03@11=g00WOV1b5QOkJ^1:kM[O138KHh0`0XOT1d5ZN\\Jd0`0d0BoNV1HUO1D4m0>TOR10[N^51aJa0b0f0AnNMJ50f01YO000L4d0K_Og0Mo00[N^50bJa0;AGU10nNMK2OO1d0O@2LN023OM4d0K_O3L`00S11[Ne59jJKCS13jNJO2OO1k02UO144LHf05ZOS21iMi53fJ4An09jNG0O1j04UOO58LDb05^OR21kMe5N[J3?`1N]NB2OO10<OG;LF2;ODb05^OT20hMf5O\\J1>>Ac0?PO_OO10<OE1N40N0N3:MFc04@R2NjM`6<kI<9XO50C?4G@:OQ12`Na66VJ7LBe0?WOGA9NQ13aN^6<SJ3A_Oe1?iNH^O90P1OaN01a6`0oI0C@NNW11jNO5>>I[O91W1b6lNkINFCi0LYO4576I@3OS2c6ZNkILFENM<OBa04_ON8a0L@0MU2c6ZNlIKEFL01MOO10Oe01ZO0143`00_O]2_6TNmIHDHLM0O101R1o0oNPOO0h0Om01ZN`6e0RJCBKK0<n0g0oNnNm0Oj0c6oNQJ\\O]OO40N1;h0BXOe00Ik0Ci0b6PORJ[O\\O0O063g01SONj0OC3Cb02m0b6ROQJ[O\\OO0180h0OO3[O3Ea02f0NhNe6c0kI^OBJ017>HHf0JD6La2^6QNjI^OEK4i07UOF25OF31i2_5TMcKh0\\O^OEK2P13QOJOMO;1GNO2O403070o0b5bNbKg0[O@DI4Q1LPOM50O;LJOM304O7OP1a5dNcKf0\\O_OEo0NQOM17HI1=OG6N6OT1^5bNeKh0]OZOCS10oNL27L6LH5M2NK2\\18aNj43TKMc0j0F[OBT11nNLJ13609ME4M:On0a5dNgJOb0l0FUODY1NmNMJ145OJM313OO4N:Mm0m6AjITOYOW12oN3104OF24K9Om0k5eNUKk0GTOZOX11PO202LJ14M33J:Om0c5eN^JO14ONg0j02=XO\\O6]OI23N33K9Om0b5QO^JFh0j00=YO\\O8BJLNNO6O72l0a5SO]JDk0m0KTOZOS13mNO5N09OKl0N8OgN^5?\\K>KTOZOT13kN041041L4MKO:1k00gNZ50fJ`0i0=LTOZOT12nNONOO41LO85M3LL1ON32R1OhN^54bJ0OLl0P1F:@hNONO2156O1NI2O63j0OjN]50aJ113o0k0_O>DeN0>0HNH3=L02g02lN[54aJ11Jl0P1B?CeN0:NC3677HO0g02mN[5<aJE0O2OO1b0m0MCA:1XO19OEO003:OF426Of02mN\\51`J1130Kn0R1^O=DdN1?O^O2380G317Oe0V71YIQOAn0OPO2a03@4OJ209Nc0Y72VIROAn00oNNO21O<6E50H02:Ld0S6POmI0n0R1@SOBONg06VOK00<6E6OH0LO2=Nb0U6QOoJT1YO6FhNMO1g0:YOG7NW1U6aNPKS1XO8DmN0=NA87IQ1m5bNUJ4N00Nh0Q1F8CkN2=O_O:7EU1k5cNUJ4N1004J<T104CmN20K54G:3B01;O=`7:oH1EmN02MO6012H?06`7:oH2FjNLOO34O3400I?24d6VOSJU1G3DjN102O1500I`004d6WOTJV1F0EkN2O101500I0O81<c6XOVJU1E0DkN21N242KI1P1MGg6ZOUJU1C2DjN1>0`0L_O06c6[O`I011b0U1J1CkN22L1OL4:LF15O10815`6^OhIO>T1LO@nN21M2OK63JN0013O30704i7d0jHM_OPOO10090GO1k0NDj7d0iHM_OPOMO5180E02j0NCl6@oIT1HO@nNLO8140F22NL4O<2Ok7d0iHN_OoN7010E33MM3N=3Ml7g0hHL[OTO5OJM6:2>HBQ8k0eHKZOTO6OIO6:1<JAS8k0cHL[OSO50JL71J4OK64I?1GS8k0eHJZOUO4NKO95FJ64I`01CW8l0bHLYOTO2NN541KJ2k0L[OX8m0bHJYOUO1N1422LI0m0NXOY8n0`HKYOUO=NG61OIOO81GZ8o0_HLXOTO>NG70NJ>2\\O[8S1[HMXOUO3641Hc0c85VHKYOUO30MN79Gd0d84WHKWOSO60:4^OL180;d8?VHKVOSO0O41>2_O9O8e8>VHKUOXO0O2O0O12M10f0e87WHKVOUONN10130000O101N?g8=cGoNG0=n0ESO2O10M300O1000>f8`0cGPO3l0DWO3ONO00N20b0l8:^GQO4U1DUO3f0h8O]GQO4l0BWO4OL15j0k82YGQO5l0CRON252L18g0i85WGRO7i0BXO30L14j0n83UGRO9f0A[O0<N71^OS9k0TGSO9f0BYO13L01k0U9NTGSOFNa0i0BZO2NK02OO11g0N^OX9i0QGTO;e0^O_ONN2R1W9HQGSOKN8i0CF2=N\\O[9f0oFTO;1[Ob00A1K5o0]8POXHn0@SO:2[Ob00A1J5d0NB]9h0kFROI1;m1CRNe9o0cFQOJ1<g0_O;m9K_FSOH1<l1]9hNSF_O=KH1<h0_O8o9JeFVOOi1^9POcFWOOg1a9PObFYOMR1^OROO4V:>`FZOMn0]OSO1203X:a0WF^OBL;`1n9VOSF_ODL=[1m9YOTF^OCN<[1n9XOTF^OBO<Z1o9[OSFZOB1=X1P:eN`Ej0<XOG1?V1o9hN_E`05_O72G1`0S1P:kNaE7LKc0OA0a0Q1o1"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:sitting/sit", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, cleanliness, maturity, texture", "answer": "The image features a small brown and white dog wearing a pink life jacket. The dog is sitting on a person's lap, likely enjoying the company and comfort. The person is wearing a black shirt, and the scene appears to be taking place on a boat. The dog's life jacket ensures its safety while on the water."}, {"question_id": 106, "height": 427, "width": 640, "image": "000000461405.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [353.39, 188.79, 93.39, 71.49], "segmentation": {"size": [427, 640], "counts": "gjc44T=3L4M3N2O1O1O1O1O1O2N100O1O0001O1O01O1001OO105J2O8hCkNk;[10O1O0001O001O1O010O1O2O1N2N100O000001O00000010O0O2O1M3N1M3N2OO10010O0LhDVNY;d19M3O2N1O1O2O100O1O1O1O1[OQDNo;f01N3K4N3N10000O1O10O[OfC:[<EhC9X<FjC9W<DlC;c<O1NaSa2"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state", "answer": "The image features a group of sheep standing together in a grassy field. There are three sheep in total, with one of them being a baby sheep. The sheep are standing close to each other, creating a sense of togetherness and companionship. The grassy field provides a natural and comfortable environment for the sheep to graze and interact with one another."}, {"question_id": 107, "height": 427, "width": 640, "image": "000000461405.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [416.46, 216.85, 45.09, 82.35], "segmentation": {"size": [427, 640], "counts": "kf]57P=a0cC\\OV;_1M2N2N2O1O1OL5L3O1O20O2O5F7L2O0kDPNP;P2PERNn:m1TESNl:l1TEUNk:m1SETNm:U2O2O0000O1N2O2O0M3N1014K4L4MjMVEk1j:QN\\Em1T;M5K3M3M2YOZDCl;5P1D`\\Z2"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "maturity:young/baby", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, state, cleanliness, pose", "answer": "The image features a group of sheep in a grassy field. One of the sheep is a baby lamb, standing in the middle of the group. The baby lamb is surrounded by several adult sheep, with some of them standing close to the baby lamb and others further away. The sheep are all standing on the grass, creating a peaceful and natural scene."}, {"question_id": 108, "height": 482, "width": 640, "image": "000000099024.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, pattern, size, texture, transparency", "region_anno": {"bbox": [51.25, 118.36, 458.82, 290.42], "segmentation": {"size": [482, 640], "counts": "bci01P?2O2M101O1N2O001O1N2O1O1N101O1O1O1O1N2O1N2O1O1O0O2O1O1O001O1N2O1O001O1N2O1O1O1O001O1O1O01000O15K0O3NO100O1O001O1O1O1O1N101O1N2O1O1N2O0O2DWN[Cl1a<=M3O0O2O1N2O001N2O1O0O2O1O0O2O1N2O1N2O_ORDcM15k;X2VDaM17h;X2WDaM18g;W2XDaM18f;V2[DbMO9e;T2]DcMN:c;T2_DbMN:c;T2fDmMX;T2gDnMX;R2hDoMW;P2gDaMG`0`;P2hDTNW;l1iDVNV;j1jDWNU;i1fDaMMh0\\;g1fD^NY;b1iD^NU;b1nD]NQ;b1PE^No:b1QE`Nn:`1REaNm:_1SEbNk:_1UEaNj:_1VEcNi:]1WEcNi:]1UEfNi:Z1YEfNf:Y1[EhNd:X1]EgNb:Z1^EgNa:Y1_EhN_:X1_EkNa:T1_EnN`:R1_EPO`:P1^ESOa:m0\\EVOd:j0_ETO`:k0bEUO]:j0dEVO[:k0dEWO[:g0gEZOX:f0gE\\OX:c0iE]OW:c0hE_OW:a0iE@V:`0iEAW:>jECU::mEHR:7oEIQ:7oEJP:6PFKn96hEjM5P2S:6hEjM6P2Q:6iElM4o1R:5jEmM3n1S:5jEmM1Q2T:2kEmMOT2U:0jEkM1X2S:3mEMS:3lEOS:`20\\MmE:R:FoE:o9FUF8j9HUF9k9GUF:j9FVF;i9EWF<h9DYF<e9FYF;g9@VFmM3d2f9_OWFmM2f2f9BXF`0g9_2O001OnL]Ff0a9ZOaFe0_9WO_FkM2o2^9ZObFg0]9SO_FQN4m2[9SOaFQN2m2]9RObFW1]9hNdFY1[9gNeFY1Z9hNfFY1Y9gNfFZ1Z9X2O1NaLhFV1X9hNjFY1U9fNmFZ1Q9cNlFoM3^3Q9bNmFPN2_3P9aNnFPN2`3o8`NoFoM3a3m8aNPGoM2a3m8`NQGoM1c3n8]NQGPN1d3m8\\NRGPN0e3n8[NRGPN0f3m8ZNRGm1n8QNRGP2n8oMRGS2n8P2100mKQGR2n8mMSGS2m8mMSGTNOl3n8oMSGUNOm3m8jMRG[N0P4o8dMQGb2n8^MRGc2m8]MSGc2m8]MTGc2k8]MUGd2j8\\MWGc2i8]MWGd2h8\\MYGd2f8\\MZGd2f8\\MZGe2e8[MZGg2f8XMZGi2e8WMYGk2g8i1OWKZGW3e8iL[GW3e8iL[GX3d8d1O1O1O010O1O001O1N2O001O1N2O1N101O1N1O^JnGgN1[5o7oKQHfNO\\5o7nKRHV4m7kKSHV4m7iKRHY4n7fKRHZ4o7]11O00XOPI]Io6c6RI_Il6`6WI`Ig6^6[IcId6[6^IfI`6Z6dIeIZ6Y6iIgIV6X6lIjIP6V6PJlIJTOg5o6`JnIGSOj5n6cJlIi5R6YJPJd5P6\\JUJ`5j5aJVJ_5h5cJWJ^5h5iJQJX5m5kJRJT5n5nJPJkN\\OQ6c6TK]IjN?1_OR6e6ZKkIl4S6UKmIgNAk5a6^KmIcNBN7l5Y6cKnIcNBN8k5W6eKmIhNMc5U6eKkIkN1`5S6eKiIoN5[5Q6gKgIPON^O8j5R6hKgIROM]O>f5l5lKiIdNM8>W5l5lKkIcNM9>W5i5mKlIbNN;>T5g5PLoI^NN`0:R5h5PLXJoN1o4g5RLXJRO0j4h5TLXJTOOg4i5ULRJ[O7\\4h5XLkI_N1o0<X4g5ZLlI`N1P1=R4g5^LlI_N0R1>n3g5bLjI]N2V1;i3i5eLQJC7e3i5gLRJE4b3k5iLQJG4^3k5lLPJG4\\3l5oLnIH7U3l5SMfIZN3`1;P3m5[MgIF=l2m5^MeIH`0g2j5bMfIJ>b2m5dMeIK>_2n5dMfIO;[2o5dMiI37X2P6eMiI48T2P6hMhI5ISN<n3T6jMgI87k1R6nMfI:6g1T6PNfI<6a1T6oM_I\\N6V28\\1T6QN`I\\N4W29Z1T6SN_I\\N4W2<V1R6SNjIj02S1S6TNiIn02l0W6TNgIR12h0X6VNfIT10e0[6XNZI_N6g26?[6ZNYI`N6i278]6^NUIbN6k282`6bNXI^1JSM;k2d6`NQIeN6P36Hf6bNWIf14Gf6aNVIj14Ch6bNTIl14@j6cNRIP21]On6bNQIR21ZOo6dNoHV2OVOT7cNlHY2NSOX7bNhHa2LmN_7`NdHW5^7hJcHV5_7eJ\\HWO5T6`7dJ[HWO6T6a7eJ`H[5b7dJ^H[5d7dJ\\H[5f7cJZH]5i7aJVH`5k7_JSHb5o7]JQHb5Q8\\JPHc5R8\\JnGc5T8XJhGF4R6V8VJgGH3R6W8UJmGj5U8UJdGK2o5]8TJaGM2n5`8SJ^GO1n5h8SJUGo5j842O1N3M2N100O1O2N3M2N1O2O1N2O0O2N2O2M2N2N2N2N2O1N2N2N2O1N3N1N1O3M2O1N2O1N2N2N2O1N2N2O2M2N2O1N2N2N2O1N2N2N3N1N2N2O0O3M2N2O1N2N2N3N0O3M1O2O2M1O3N1N2N2N2O1N2N2N2O1N3M2N2O1N2N2O0O3M2N2O1N2N2N3N0O2N2O1N2N2O1N2M3N2O1O1N2N2N3M2OkZn1"}}, "object_label": "kite", "attribute_label": ["color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:plain", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material, size", "answer": "The kite in the image is a small, square-shaped kite made of plastic. It is being assembled by a person who is holding the kite and attaching the string to it. The person is kneeling on the floor while working on the kite."}, {"question_id": 109, "height": 482, "width": 640, "image": "000000158548.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pattern, size, texture, transparency", "region_anno": {"bbox": [319.4, 160.0, 156.09, 44.1], "segmentation": {"size": [482, 640], "counts": "Yi^44P?Meb61]nH=X>:O000000001O001O4K2O2N1O0000O2O000001O000000001O00O10000O100001O001O002N1O001OO1M3O10000000000000000000000000001O01O00004L0000ZOWB3i=CWBK11Nb0j=FXB>h=BXB0N2j=OWBOO2j=OWB41Fh=6VBM0N2Oh=g0YBXOh=g0YBYOg=Q10001O00XOVB8j=`000000000000000000000000000000000001O0000000I7O1O10000000SBUOc=l0[BVOd=j0[BWOe=i0ZBXOf=h0]BUOc=j0;O1O1O1O100000000O100000000000000000001O00000000001JeAC\\>;fAC[>=60^AE\\>a0O0001HcAH^>3;O10jAJa=6VBJR>6mAKU>3bAL34b>M[A6i>Oil^2"}}, "object_label": "truck", "attribute_label": ["color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material", "answer": "The truck in the image is a large white tractor-trailer, which is parked in a grassy field. It is positioned near a white van and a car, and there are several people around the area. The truck is prominently featured in the scene, occupying a significant portion of the image."}, {"question_id": 110, "height": 482, "width": 640, "image": "000000158548.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [382.85, 171.56, 26.42, 25.72], "segmentation": {"size": [482, 640], "counts": "^oc53f>:M2aAIR>8lALR>c02M2OO01O0O010N2L4O2N2M2K5001O0O2O01O001N2N3Loa\\3"}}, "object_label": "motorcycle", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "texture, color", "answer": "The image features a motorcycle with a side view, showcasing the front wheel and the rider's legs. The motorcycle is positioned in the air, giving the impression of a jump or a stunt. The rider's legs are visible, and the motorcycle's front wheel is in the air, indicating that the rider is performing a trick or maneuver."}, {"question_id": 111, "height": 425, "width": 640, "image": "000000005193.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [369.48, 97.93, 19.76, 74.59], "segmentation": {"size": [425, 640], "counts": "\\Xi4i0]<b0fCgNd;k1C2O1N2J6O1000000001O1kMoDP2X;M2N2N3M1kNaD08_Oo;?gQX3"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, cleanliness, pattern, transparency, texture", "answer": "The image features a tall, thin bottle of water, which is almost entirely filled. The bottle is made of metal and has a blue top. It is placed on a table, and the top of the bottle is visible in the foreground. The bottle is positioned in the center of the image, with the top of the bottle being the main focus."}, {"question_id": 112, "height": 427, "width": 640, "image": "000000011197.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [204.28, 140.31, 13.72, 25.29], "segmentation": {"size": [427, 640], "counts": "b^f2b0i<9GO1O101O1O1O2N6HgW`5"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, texture, transparency, cleanliness", "answer": "The image features a black car parked on the side of the road. The car is positioned close to a pole, and its rear end is visible in the scene. The car's tail lights are illuminated, indicating that it is either parked or has recently been in motion."}, {"question_id": 113, "height": 449, "width": 640, "image": "000000029397.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [18.16, 147.14, 591.27, 266.38], "segmentation": {"size": [449, 640], "counts": "Wm52o=0KO61J0YBOf=43N[m02YQOOgD3X;LjD3b<0aNLRE3m:OQE2n:0QE0n:OUE0j:OXE1g:OZE1d:0]E0b:1^EOb:0`EO`:NcE3[:LhE4XNNk;OkE3YN1e;M\\D0e1b0e9^OgD0d1e0b9ZOkD1d1k0`9UO`Fo0]9oNdFV1l8mN\\GY1]8gNeG]1U8dNkGb1o7\\NTHOlMd1j9`NYHLlMl1d9YN_HJnMT2[9RNhHKlMW2Y9hMPI1gM[2S9dMXIe2a6\\M_Im2V6VMiIP3Q6oLPJU3l5hLWJ_3a5aL`Je3X5^LgJh3R5YLoJc2bMaNW7lNWKb2cMbNV7kNYKb2bMbNk9^1VFbNo6kN\\IOe1d2oMcNo6lNZI0f1d2nMaNR7jN\\I0d1o3k700VLTF_3n6[LkK5YM_3l6^LiK3[M`3j6\\LmK5WM`3m6YLnKQ4Q7000`MnKQKR4_70lLoKXLQ4g3PLRJOZ1Q4d4PLQJ0\\1o3b4RLQJ1\\1m3c4RL[Lo3j61001OgMnKcJS4e700O10kLnK\\LQ4d3oK\\LQ4d3oK\\LR4i600SLSFg3f6TL^L5lLh3e6TLhJO7T4Q5mK^LR4c3nK]LR4c3nK]LQ4d3oK\\LR4c3nK]LR4c3nK]LR4c3nK]LR4c3nK]LR4c3nK]LR4c3nK`I0d2R4l3nK]LR4c3nK]LR4c3nK]LR4c3nK]LR4c3nKfI0X2d3\\MgLf6FeIOY2d3]MfLe6G]Lb3nLgLe6H\\Lo3d3PL]LQ4b3oK^LQ4b3oK_Lo3b3PL_LP4a3PL_Ld3mLcLd6I_LP4a3QL^L3mLd3e6YL^L3mLd3e6YL^L3lLe3f6XL_Ln3a3RL_Ln3a3RLhINW2Q4P4PLaLP4_3PLaLo3`3QL`Ld3jL^L01f6M`LP4_3PL`LQ4`3oK`LQ4`3oK_Lb3mLjLd6D^Lb3PMiLb6E\\Lf3PMeLd6EZLh3RMcLe6DXLj3SMbLe6DVLj3_MYLX9d3]F[L=0U9j3jFXLS9j3fFRLO5Y9d3dF[L4LO5W9o0fFnN0Nd00@`1McN5OK2W9h0gF[OV1KnNU1OkN31M0T9U1eGiNXOa1MaN43LMU9W1oFiN74E]10_NOM37MLS9g1VG]NH]1O`N52LMP9i1ZGXNHa19[NH3k8S2TGmM2<K11A0114`0M\\8R3RGnM;nNI2h8\\4VGaK0320g8f3VG[L18NG050Ki8[3PHdL^O`0`8n2RHaL_Oa0^8\\3RHTLXO60Ke8T4kGkKBN51^8f4[G]K0M34`8m4`GSK^8Z5N1O2N2L2O2N2O1O1M3N2O4K2O1NTL[H`1c7_NkHgMB[3b7oNiHX1V7jNeHcMKc3`7kNcHcMLb3`7mNeHbMOZ3]7TOcHcM00NP3_7WO_HkM1a3`7eN`H[11[L`7[2_HZ1e7gN\\HeM2l0ML1[O2k0a7^1]HcM52J71FO15e0M]O4j0^7c1\\HaM5c0L@1f0M>g7Y1ZHaMOO0e01_O1j1j7c0UHaM3b0M@1f1l7i0SH_M30N=NA8c0M^OM=P8V2oG^M4O1OL40K0O52J1OO2O=<c7Z2oG\\M50ONN7NH;a03@A6T8a2nGZM40O0L;:5J@_8h2^GZMNc03]O2T1U8d1gGhMOD5J11KN07O;Y8Z2hGQN4TON4NK07O:Z8[2gGF[8:eG_Ob8`0dGZO]8e0ZH_NUOfNb8k2aHUNf7k1eHYMaN7l8`2V2001O0000000000000000000000001O000001O000000000000000000000000000000000001O000000000000000000000000000000000000000001O000001O00000000000000000000000000000000000000000000000001O000000000001O000000000000000000001O00000000000000000000000000000001O000000001O3M2N001O2N100O1O1O1O1O0000001O00001O0000000000001O2N1O2N1O3M2N001O1O1O001O1O010O001N1001O0001O00000000000001O000000000000000000000O11O00O10000O100O1O1O1L4O1O1YOg00000000000O2O000000000001O000000000000000000nFfMSNGN03IT7j2XJRMbNb2j6<cJH]58cJE`5;hIVMM1^ON5e1o6W1PITMK<c0d1_OQNS7k2nHbM<ACS23mM0Ni6o2UI_M9BF5N]13mN0GONi6l2WIYMc0M]O00N40M;10M2j6^2XIXMc0O]OO<NE:2e0e6n1VISM1Me15\\N74g0c6m1WIQMg10ZN50645KOi6`2WKVMPN75JLONN34g6g2eJUMbNL<1D`04DOOM042e6i2SJQMC80NA24L0OM132e6i2oIUMF6OLFN3OO1K033f6h2lIXMZOJ;;1JJM1O02J033f6h2kIUMJ2DO81KM10N2L<i6_2YIQM;214EO15OK00NO0=g6^2ZIRM92O7IL0a0OGN4h6]2ZIQM;2MNF54O4>LLM3h6]2XIRM>2JMH63N6=KNM2g6^2XIRM`0OM6FM8=JLN5h6[2UIVM?N03E09:MIL:g6Z2SIXMS1OSOOf11VN6P7OoHT2OhM`3O`L6^7R2bHjMOM]10oN0?0E1A6_7Q2aHoM=I=0A0F0d00F1D105a7P2aHoMZ1JkN1I1042J92F035K1c7o1_HoM1JT11lNOO7OO2K40I2122<`7e1aHkM]1ObN0000001b01]OO0O07N1c7n1iJjM[N0A0K1M214c7n1aHlMh2OdM2@5c7o1^HoMi2KgM0@7b7o1^HPN`31S4n1]HQNj1KH5Q6o1\\HSNV1HQO0K0O20N;0K0?0ZO3d7]2bI`MPO2JO11O01N6000:0A1M2e7[2cIdMiN0O11O00050K00050O11O0d7U2cHfMLNc03ZO400000d0OGe7j1fIdMhN1N02OO110N02O0000O11OO106O0e7S2\\HhMT1NmN00050K0d00A0K0O101N2e7V2]HfMV10PO000d00A0E107c7k1]HPNOMb10C0[O2@5e7l1\\HPNNNP11UO2OOe0M_O083A4f7k1\\HSNl0NVONL011OO110N114OL0O1;OE106e7k1]HSNj00TOMO0000O11OO115NL1N02O50J110M2g7o1\\HTNk00SOL0000000000001N02O50LON30N100O1g7P2[HSN0L?OBY1NA0\\OO2g7i1[HTN0LNO>1Dd0Nj00SOg7_1[HoMP10PO1OO2O0001N1000O20N1050O20N2f7j1aInMkN000:0F00000000001N020OO51K7e7k1YHTNS1I_O0@11O00000001M21320N2e7V2ZIfM[OLH0O7O0OU1f7R1[HcM6001JN17OL1X2c73\\HcM?2D3M10S2d7L]HnMa01_O2OKO114O1000K1>0KOIe7Q2]HnMO290Gh2d7@[HjM1J0X3c7_O]HYMOY3d7^O^HWM76I1N;1Y1c7d0]HhM=JC01140K00500000P1b7Y1^HgM=JC0123OL005000Z1b7n0_HcMN02O5`0IQ2b7D`HkM001OO10000OU3a7PO`HlMOO;0G_1NgN0U1a7j0`HPN8OGg00AOD21O000000b0OA00`7T2aHmM:]1E^N21N10k02]O\\7P2cHgMO07OJ2OO1e20eM\\7P2cHgM0O3NN210N01T3[7WOdHfM0O6062D91I101JO2Of02LW7P2gH\\Md00]O2O0042KN020OO1000O2O<76P7m1hHaM2O5O55D81J00Om01AU7n1kH^M1050KO5V3n6^OlH]M1050K00Y3R7[OmH]MO0<OGX3P7]OnH_M<KH7K\\21fMR7]2nH`M2b3P7nNnH`M0P10nN2T2o6?oH`MOn0>oNCOOg1Q7m0PI`MO;0O5m1m6c0PI[Mi0d0VO<P7e1TIRMMN?0AO1a2m6a0\\IoLF1NT10h0P7k0TIZM8NEY11c0m6m0VIXMMO4_3i6YOXI^MJf00g1n66UI_NL\\1o6?QITM0Y3m6YMSI_10nM20NP3m6cMSIZ11PNO122NP3m6cMSI[O1f13WNM14NN0N01d00]ONP2k6o0YIQMM2;MHe0M`1i6l0^ITM3LFO0l2h66YInL068LGN0l2h6<XInL9LJk2e6=WIkL4JO5O2O^2g6U1[I[LOj2f6n0YIZOg6f0YIZOg6m0ZIkNf6l0XI[L4KM`0Of1h6]1YIhL3EMi2g6`0XImL2KN1005j2c68XInL1N011OO1010N0l2g6<\\IkLOLN21O53Ib2h6c0\\IlLOL0O0000O2Od00A0[1g6g1\\IlLM4Ol2h64ZInLNZ3h6HZIiLN1050P3h60^IjLL5NQ3h60fIjLH0KO1`0Nk01hN0>g6g2fIhLGU3c68XIdL2O000U3g6<YI_L0001NP3i6?[I_LN1OW3g6LYIPM1L52JX3g6JYIl0g6W300000TLXI?h6]30O1gLWIZOi6n31O1L4SLRIPMOZ3W7CnHRMK`00T2Z7:iH;\\7EcH7b7I^HOj7b1THhLS8f1mG`N2GS8_45K5J6I7L4H8M4D;I7O1K4M4K5J6L4F:01O00001O1O2N3M1O2N3M2N2N3M2N2N3M3M1O3M1O4L2O1N3L2O3L4I7H7I7J8Gcm<"}}, "object_label": "bench", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, transparency", "answer": "The image features a wooden bench with a person standing on it. The bench is located on a brick sidewalk, and the person is wearing red pants. The bench is positioned in the middle of the scene, and the person appears to be standing on the back of the bench."}, {"question_id": 114, "height": 480, "width": 640, "image": "000000039769.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [41.88, 74.2, 133.15, 45.1], "segmentation": {"size": [480, 640], "counts": "oYc0;a>8J4M2N2N2N1O2O0O100O100000000O100000000000000O10O100000O1000O10000000O010000000000O10O100000000000O1000O100000O100000000O1000O10000000O10000000000O10000000O1000O100000000O1000000O100000000O100000000000000O10000000000O10000000000O10000O100000000O10001O000O2O0O3L3N6I^li6"}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, pattern", "answer": "The image features a close-up of a remote control, which is placed on a red surface. The remote control is a TV remote, and it has a few buttons on it. The buttons are arranged in a way that allows the user to control various functions of the television, such as changing channels, adjusting the volume, and navigating menus. The remote control is positioned in front of a cat, which is lying on the red surface, possibly resting or observing the remote."}, {"question_id": 115, "height": 480, "width": 640, "image": "000000039769.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [332.9, 73.8, 38.64, 112.08], "segmentation": {"size": [480, 640], "counts": "\\gl46e>6I8E9\\Oe0_Oa0I6F;H7J7L3O1O1O1O00O2H7A`0I7I7G8L5N2H9L3N2N2N3M2N3N1O2M3L5J7J\\_n3"}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "cleanliness, pattern", "answer": "The image features a remote control with a white body and a black face. The remote is placed on a red surface, possibly a couch or a bed. The remote has a total of 15 buttons, including a directional pad and a number pad. The buttons are arranged in a way that allows for easy navigation and control of various functions, such as volume, channel, and playback. The remote's design and layout make it suitable for use with a wide range of devices, including televisions, audio systems, and streaming devices."}, {"question_id": 116, "height": 359, "width": 640, "image": "000000047740.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [226.69, 0.0, 413.31, 237.18], "segmentation": {"size": [359, 640], "counts": "Zd`22U;001O1O001O02N01O100O0010O01000O01O10O010O010O01000O01O010000O10O10O010O010O1000O10O01O01000O10000O010UOJcF7\\9IdF7\\9JdF6[9KdF6[9KeF4[9LeF5Z9LeF4[9MeF3Z9NeF2]9McF3\\9MdF3]9LdF3]9McF3]9MbF3_9MaF3_9LbF3^9NaF3_9MaF2a9M_F3`9N`F2`9M`F3`9N`F2`9M`F3a9M`F2`9N_F2b9M_F3a9L_F4a9M^F4b9L^F4b9L^F3b9N]F3c9L]F4P9JnF224o8LnF033o8NmFO44n8NmFO52n80mFN42o80nFM34o80mFM23R90kFM34Q9OmFM14S9OkFM33R91kFK35Q91lFJ34Q93kFJ34Q93kFI53P9JaF79M52Q9JcF67M63o8IfF76L44o8JgF76K44n8KgF67K44n8KhF65L44o8IiF65L44n8KiF64J55n8LiF53J75m8KjF53K56n8JiF64I57o8JhF63J65P9LhF31M64Q9LiF30M63Q9NhF30L74Q9LhF5OL73R9MhF30L64S9MfF41K64S9LgF5OK74S9LhF5NK64U9LgF4NL64V9KhF4LM63V9MgF5LJ75U9MhF4KK83V9MhF5IL82W9NhF3JL73X9NgF3IM73Y9LhF4HL92X9NfF5IJ:3Z1LR63aH3JK83[1LR63aH3JL72\\1L^N0]73hH3HM:1d1Kb54iH:0HX9OgF:0GZ9NgF;OF[9NfF<OG[9MgF;NG[9OfF:0F[9OfF;NG[9OgF9NI[9MhF:MH]1LT63aH:MG^1LV62_H;MF^1LW64^H:MF]1LY63]H<LF]1LZ62]H<KF]1M[61^H;JG^1K\\63]H9MEZ1O\\63^H8ME]93eF9LE[1O^63[H8LGY1Oa62ZH:IFY10d61ZH8IIV10g6OYH9IIU11h6M[H9GJU10j6MZH8GKU11j6K[H9FJU1KgN2U80ZH7FKT1KhN2V80YH8DLX1Lk61XH7FKQ1LlN1V81VH8FKP1LnN0V81WH8DKY1Km63VH8@Li9LgFc0X9^OgFc0Y9]OgFb0Z9^OfFa0[9^OfFa0Z9@eF6DKg9OeF6BMi9MeF5BNj9LeFa0[9@dFa0Z9@fF?[9@eF`0[9AeF?[9@fF?[9AdF`0[9@eF`0\\9@dF?]9@cFa0]9_OcFa0]9^OeFa0Z9AeF>[9CdF=]9BdF>\\9BdF=]9CcF=]9CcF<^9CcF=\\9EbF<^9DbF<^9DaF=_9CaF<`9CaF<_9EaF;_9EaF:`9G_F8b9H]F9c9G]F9c9G\\F9e9F\\F:d9G[F8e9I[F7e9H\\F7e9IZF8f9HZF7g9JXF5i9KWF5i9KVF6j9JVF5k9JVF6j9KUF5j9LWF2j9NUF3k9LUF4m9KSF5m9KSF4n9MQF3n9MRF4o9KPF5Q:KPF4P:LPF4o9MPF4P:KQF5P:JoE6R:JnE6R:JnE6R:JnE6R:JmE6T:ImE7S:IlE8T:IlE6S:KnE3S:MlE4T:LlE4U:LiE5X:KhE4X:LhE4X:LhE4X:LgE4Z:MdE4]:KcE5\\:LcE5]::101N2O000O101N10O1000O2O0O01000O2O01N10O10O100000O0010O10O010O10O01000O0100O10O10O10O01000O010O10O010O1O10O0100O010000O10O10O010O010000O010O010O10O10O010O10000O00100O100O0010O010O01O0010O00010O010fNHcG8]8IcG7\\8IdG7\\8JdG5[8MdG3\\8NdG2[8OdG1\\81cGN]83bGN\\87`GI`89_GG`8;^GEb8a0XG_Oc8i0[GVOa88SG38D^8`0\\GK6DZ84VG7;05ES8:^G2<2O@V8>^G1=4`8c0SGlN4d0OYOW8i1gGoN0XOX86iGW2NcMX87jGN0Q2T8SNlGMNQ2V8SNjGg10aNQ8l1oGUNo7^ORH41d2j7XMVHN5m2a7VMZHM5o2^7VM\\HO2m2`7[M_Hh2_7XMbHh24TMh6LRI21P30ZMg6EXI11e3f6c0O00QLYI^3f6XL\\I01g3c6YL\\I2Nf3f6XL\\IQ4d6oK\\IQ4d6nK]I3Mf3f6WL^I1Mh3e6WL]IR4c6nK\\IS4c6nK\\IS4d6lK_IR4b6lK_IT4a6lK_IS4b6oK\\IQ4c6RLZIo3f6PL\\Io3d6nK_IQ4a6TLZIm3e6:100O1eK[IT4e6lK[IS4f67000gKXIR4i6mKXIS4h6500100O2O00XM"}}, "object_label": "kite", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, pose, color, texture", "answer": "The kite in the image is a large, colorful, and rainbow-colored kite. It is designed to resemble a butterfly and is being flown on the beach by a man and a child."}, {"question_id": 117, "height": 480, "width": 640, "image": "000000070048.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [286.49, 0.0, 111.35, 211.35], "segmentation": {"size": [480, 640], "counts": "jcV46P>R1lNW1^O=F9I5H9I5K5L4M2M4M3M2N3M2O2M2O1M3mEhK\\9Z4aFkK[9n4O5K2NSOlFoKS9P5O001O0000001O00001O00001O00001O0000001O0000001O00000000000000000000000000O10000O100O1N2N2YOg0N2O100O1O1O1M3N2O100O100O100O100N2O1O1O1O2N2N1O2N1O2N2L3N3M3L4L4L4K5C=I7K5G9G;E=^NcB0m\\a3"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, material, pose, texture, pattern", "answer": "The wine glass in the image is filled with red wine, and it is placed on a dining table. The glass is positioned near the center of the table, and it appears to be empty, with no wine left in it."}, {"question_id": 118, "height": 480, "width": 640, "image": "000000089556.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [235.6, 265.86, 76.36, 124.21], "segmentation": {"size": [480, 640], "counts": "Tk_33k>4K4M3O1N2O0000000O100O1O10O10O100O10O01RD]OdM2f;a0dFEZ9=dFEY9>eFCZ9?dFCZ9`0cFA\\9g0]FYOc9R3O2O0O100O100O100001O001O00001O001O001\\MkD[1V;aNZF2g9KbFM_93bFL^93dFK]95dFJ]94dFK^92eFL[93hFLX94iFJW97jFFX9;jFAW9?d21N20N2O10003M2N1N3K[jk4"}}, "object_label": "fire hydrant", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:tan", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "texture:rough"], "control_dims": "pose, texture, material, color, pattern", "answer": "The image features a yellow fire hydrant sitting on a concrete block, which is located on the side of a road. The fire hydrant is positioned next to a car, and there is a truck parked further away in the background. The scene appears to be set in a parking lot or a similar urban environment."}, {"question_id": 119, "height": 480, "width": 640, "image": "000000089556.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "material, pattern, pose, transparency", "region_anno": {"bbox": [587.25, 142.9, 43.33, 43.53], "segmentation": {"size": [480, 640], "counts": "`Yc82m>4L3O2M3M2N2N1O001O000000000001O0000000000001O001O001O1O00100O1O2N1O1O103M0d0\\OO1N2^OiA3Y^5"}}, "object_label": "car", "attribute_label": ["material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "pose, material, transparency, pattern", "answer": "The image features a white car parked next to a red car. The white car is positioned in the foreground, while the red car is parked behind it. The white car is a compact SUV, and it appears to be parked in a parking lot. The red car is also a compact vehicle, and it is parked in the same parking lot. The scene captures the contrast between the white and red cars, with the white car being more prominent in the foreground."}, {"question_id": 120, "height": 480, "width": 640, "image": "000000091779.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [406.44, 1.25, 93.51, 97.24], "segmentation": {"size": [480, 640], "counts": "PVP6?a>f0ZOb0^Oi0WO5K1O0000001O00001O00001O00001O0000001O00001O00001O00001O0000001O00001O0000001O00001O00001O000000000000O1000000O10000O100O1O1O1N2N2N2M3L4L4K5L4K5L4M3K5M3M3L4M3M3J6L4M3L4M3L4LTUQ2"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, pattern, pose, color, cleanliness, transparency, texture", "answer": "The cup in the image is made of plastic and is white in color. It is placed on a wooden table, and it appears to be empty."}, {"question_id": 121, "height": 480, "width": 640, "image": "000000091779.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [20.68, 0.74, 94.97, 97.14], "segmentation": {"size": [480, 640], "counts": "PZ:4l>3M3M4L4L2N2N2N1O4L3M3N5N00O0O2O2M3N1000ON0O100N1O0ASBIQ>7<O10000O10O01000000O1000O1000O01000O1000O010000O1M3O00oNOUC1k<6nBJR=7mBIS=:kBEU=?gB@Z=g0^BZOb=l0VBVOj=S1M2N4L2N3M2N4L7I6J5K5K2N4L22O2K6L3L4L3L4L6K4J5LUOcNWDY1l<K7I4M7H5L5J`Pf7"}}, "object_label": "chair", "attribute_label": ["color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency, pose, material", "answer": "The chair in the image is a black chair with a metal frame. It is placed in a room with a dining table."}, {"question_id": 122, "height": 480, "width": 640, "image": "000000091779.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "material, pattern, texture, transparency", "region_anno": {"bbox": [1.25, 275.0, 176.25, 198.75], "segmentation": {"size": [480, 640], "counts": "_8`6`801O1O1O1O1O1O1O1O2N001O1O2N1O1O002N1O1O1O1O1O1O1O1O1O2N1O1O001O2N1O1O1O2N1O1O1O001O2N1O1O1O2N1O001O1O1O1O1O2N1O1O1O1O1O1O1O1O1O1O2jM[EMf:V21O1O1O001O1O2N1O1O1O1O1O1O1O1O001O001O00000000000000000000000000O10000O1000000O10000O100O1O100O100O100O100O100O100O10000O_LYEi04>c:hNZEf09`0\\:jN\\Ee0:`0Z:kN\\Ed0<`0X:kN]Ec0>a0T:lN_Eb0?a0R:lNaEa0`0a0o9mNcE`0`0b0m9nNdE>a0c0k9nNfE=a0d0i9oNgE;c0d0f9POhE;c0e0d9POkE9c0f0b9QOlE8c0f0b9POmE8c0g0`9POoE7c0h0^9QOPF5e0h0[9SOQF3f0i0Y9TORF2f0i0X9ROVF3d0j0U9ROZF2c0k0S9SO[F0d0l0Q9SO]F0c0l0P9TO^FNc0n0o8TO[Hk0e7UO]Hi0c7WO^Hh0b7XO_Hg0a7XOaHg0m:O1O1O1O1O1O1O2N1O001O2N1O001O1O2N1O1O1O1O1O1O1O1ORWf6"}}, "object_label": "dining table", "attribute_label": ["material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:striped/lined/pinstriped", "texture:smooth/sleek"], "control_dims": "material", "answer": "The dining table in the image is wooden and features a silver serving tray with a knife on it. The tray is placed on the table, and there are two pieces of bread on it. The table also has a napkin on it, which is likely used to hold the bread. The overall setting suggests a casual dining experience, with the bread being served on a simple wooden table."}, {"question_id": 123, "height": 427, "width": 640, "image": "000000093717.jpg", "category": "description", "question": "Describe the bicycle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [485.09, 253.4, 153.72, 83.51], "segmentation": {"size": [427, 640], "counts": "QbZ66S=200N200O1O1O1O010O1O100O100O100O100O100O010O1000000O01000000O100000000000000O10000O1N2M4K4M\\`21e_M2O0003MPO0gDNno11Qn50V^H6O04L4LZO1PDOk;8RDIm;8mCIF2[<5oC2n;HjC088l;JlCM:8f;OPDI:8e;KVDL69c;IXDO86`;JYDO;4\\;NXDM<6];MVDM<7^;LjD5U<001mNKk0>NO2A>10O1O1000cC0];2iCNe01b;1iC0c0Oc;2jC0b0Nd;9bDGYO0k;;fD1V;0\\DB6>_;OlDNS;IXD2f04R;I[D0c09j:G`D1m0:c:L]E4c:L]E4c:K^E5c:K]E4c:1YEOf:4YEIi:4XELi:4WEKk:4UELk:7QEJP;8mDHS;7oDHR;6oDAZO6i;6REHP;6QEIQ;6nDIV;6hDLX;3hDMZ;4hDJY;3fDOZ;OfD1Z<O101N[O4b0OlQ3"}}, "object_label": "bicycle", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, cleanliness, color, pattern, transparency", "answer": "The bicycle in the image is a red and black bike, which is parked on a ramp. It is equipped with a skateboard attached to the back, indicating that the owner might be interested in both biking and skateboarding."}, {"question_id": 124, "height": 427, "width": 640, "image": "000000093717.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [208.33, 52.64, 260.58, 272.49], "segmentation": {"size": [427, 640], "counts": "[Uh2;n<5K2O10O0O11O1O2O0O1O10O000O1O2J5O1O2N100010O00010O1O0010O01O0010O01O1O001O010O1O0010O01O010O00010O10O010O010O01O00000O100000001N101O001N2O002N1O1N2O100O1O1O1O100O101N100O100O1O100O100O2O0O2N2N9G3M4L4L6K2M3N3ROjM`FX2U9SNgFP2V9WNbFn1\\9R1M2O2O0O2N100O1O10000O100000000RGlKf8T4WGPLg8^4M1N2O1N2O2N1O001O103L3N1nGhJm7[506K4MO:E00O2N4L4L5jIZJ]4h5^K\\Ja4f5ZK]Jf4?]JR4j0aKi4<cJT4<bKQ59fJU46cKT57iJU41eKV55lJU4IjK[50oJV4@nKa5JTKV4YOQLc5IWKS4UOULd5F`Ko3kN[Le5EdKW1fNlNJ\\15kNh5EfKU1gNgNMg1IhNm5DhKU1WOY1Q5bMiKU1VOX1Q5cMkKS1[OR1j4kMmKR1]Oo0f4oMoKP1]On0e4RNoKo0^Ol0d4UNoKn0^Ol0c4VNPLm0^Ok0b4YNPLm0_Oe0d4^NnKl0@b0d4bNnKj0A`0b4eNQLi0C_OZN2S6FRLg0E[OYN5R6IQLf0FPOTN18<n5MPLf0>[Oc3OPLe0>ZOc30PLf0`0VOa34oKg0S7ZOmHf0S7ZOmHf0S7YOnHg0R7YOoHg0P7YOPIg0P7XOQIh0P7WOPIi0P7WOQIg0P7YOPIg0P7XOQIh0o6XOQIh0o6XORIg0m6ZOSIf0m6ZOTIf0k6ZOUIh0i6XOXIk0d6UO\\IR1]6mNeIU1W6lNiIW1T6iNmIY1P6gNPJ\\1l5eNTJ^1i5bNXJ_1f5bNYJb1c5_N]Jd1_5\\NbJg1Z5YNfJl1V5SNkJP2R5oMoJU2m4iMUKZ2h4dMZK]2e4aM]K_2h70000O1O1O3M9F6K2OiDUNP;h1mD[NV;b1iD^N[;`1cDaNa;b14L3M5K3M3N2M2N2N2N4L2O2M1O3MO1000O10001O1O2N2M2O1JQCMQ=16O000000001OhkW2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression", "answer": "The image features a young man wearing a purple shirt and a hat, performing a trick on a skateboard. He is in the air, showcasing his skill and balance. The scene is set in a wooded area, with trees surrounding the skateboarder. There is another person in the background, possibly watching the skateboarder or waiting for their turn to perform a trick."}, {"question_id": 125, "height": 427, "width": 640, "image": "000000093717.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "material, pattern, pose, texture, transparency", "region_anno": {"bbox": [134.31, 361.88, 30.99, 18.32], "segmentation": {"size": [427, 640], "counts": "ajg11Y=2N100001N0100O00100O10000O00010O2N1OM40O010O1O1O1O010OO2O1O2M2OdYU6"}}, "object_label": "skateboard", "attribute_label": ["material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The skateboard in the image is a long, narrow, and wooden board. It is placed on a set of stairs, with the top of the skateboard resting on the first step. The skateboard is positioned in such a way that it appears to be ready for use, possibly for a skateboarder to perform a trick or simply ride down the stairs."}, {"question_id": 126, "height": 480, "width": 640, "image": "000000099039.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [156.6, 306.19, 67.09, 10.95], "segmentation": {"size": [480, 640], "counts": "ilY21n>2O0000000000001O00O100000000000O100O02O00000O1000000O1000Pj20PVM000nm00QRO101N10001O00010O001O1O1O000010O001O001O1O1O1O1OUUS6"}}, "object_label": "fork", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, cleanliness, color, texture, transparency, pattern, pose", "answer": "The fork in the image is made of metal and has a silver color. It is placed on top of a slice of pizza, which is also visible in the image. The fork is positioned horizontally, with its tines pointing towards the pizza. The pizza slice appears to be a pepperoni pizza, and the fork is the only utensil visible in the scene."}, {"question_id": 127, "height": 480, "width": 640, "image": "000000099039.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pose, state, texture, transparency", "region_anno": {"bbox": [420.15, 225.94, 66.03, 135.13], "segmentation": {"size": [480, 640], "counts": "ebU61g>m0WO8J5M2M4M2N3M1O2N2N1O1O1O2N1O1O1O2N001O1O1O1O1O1O1^CbN`;a2N00O100000000oNbD`N^;^1UEQNk:n1T1O1O1O1O1O1O1O1O1O1O1O1N2O1N2O1N2O1N2N2M3N2M5K8GgjY2"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, material, state, transparency", "answer": "The wine glass in the image is filled with red wine, and it is placed on a table. The glass is positioned in the center of the table, and it appears to be empty, with no wine left in it."}, {"question_id": 128, "height": 480, "width": 640, "image": "000000099039.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, material, pattern, state, texture, transparency", "region_anno": {"bbox": [427.4, 335.99, 138.5, 70.11], "segmentation": {"size": [480, 640], "counts": "laW6<c>1O2O0O1000000O1000000O1000000000000O100000CdA6\\>IeA7[>IeA6\\>IeA7[>IeA7[>IfA6Z>JfA6Z>JfA6Z>JfA6Z>JeA7Z>JgA5Y>KgA5Y>KgA5Y>900O10BgA5Y>9O10000000000O10_OgA;Y>EhA:X>FhA;V>800000^OiA<V>70000000000O2O0001OO10]OnA8R>GQB7o=IQB8o=GQB9o=HmAJ0>S>=O00_OmA5S>KmA5S>JnA6R>IPB6P>JPB7o=HRB8n=HRB8n=IQB8n=IQB8m=JQB7o=HSB7m=ISB7n=GTB9k=GVB8j=HWB7i=HXB8h=HYB7h=JVB7i=JUB7k=KSB6k=JVB7i=HXB8h=HYB7h=HUBGOb0l=FSBJ1`0l=JTB6l=JTB7k=JTB7l=HTB8l=HTB8l=HTB9k=FVB:k=EVB;j=@UBL1e0i=^O\\Bb0d=^O\\Bc0c=]O]Bd0c=\\O]Bd0b=\\OXBM3g0d=\\OYBM3h0c=[OZBN2h0OEQ=EmBO3Z1P=lNQCS1P=lNQCR1P=nNQCQ1o<oNPCQ1R=oNmBP1T=POkBQ1U=oNjBQ1W=nNiBR1X=nNhBQ1Y=oNgBQ1Y=nNhBQ1Z=nNfBP1\\=oNeBP1\\=QObBo0_=QOaBm0a=TO]Bk0f=62M2M3M3M3N2YOkAa0W>13O1O1K5H\\lQ1"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency, pattern", "answer": "The bowl in the image is filled with a white substance, possibly a creamy sauce or a mixture of ingredients. It is placed on a table, surrounded by other bowls containing different food items. The bowl is positioned in the center of the table, and it is the largest of the three bowls. The other two bowls are located on the left and right sides of the table, with one being smaller and the other being larger."}, {"question_id": 129, "height": 480, "width": 640, "image": "000000171740.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [515.55, 255.82, 31.52, 35.98], "segmentation": {"size": [480, 640], "counts": "QTb79f><E=C2N001O000000000000000000000000000000000001O000O10000O2SORB1ai[1"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:orange", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "cleanliness", "answer": "The image features a large, bright orange ceramic pot, which is placed on a table. The pot is quite tall and has a wide base, making it an eye-catching centerpiece. The vibrant color of the pot adds a pop of color to the scene."}, {"question_id": 130, "height": 480, "width": 640, "image": "000000171740.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 248.77, 434.58, 231.23], "segmentation": {"size": [480, 640], "counts": "\\8`1d3HP59nJIQ5<jJHQ5=jJDU5a0gJ_OY5h0_JYO`5l0\\JTOd5Q1WJoNi5U1SJkNm5Z1mIgNR6_1iI`NX6d1cI]N\\6k1]IUNc6P2XIoMi6V2RIjMn6\\2kHaMkNdNZ8Q4fHZM^7k2]HSMe7R3VHmLj7X3RHhLn7a3iG^LX8d3eG]L[8i3_GWLa8S501000O10000000OZO^GPKb8g5000O1ZO]GoJc8Q5]GoJc8Q5]GoJc8g5000PO]GhJ0O1b0b8g4]GgJ100b0b8g4^GfJ010c0a8f4`GkJN?a8g4`GbK`8^4_GVK0Fd8T5\\GUK1Fd8i5[GWJe8S6O00O100000000O1QOZGdKf8Z51000O2O01O0O1001O0000000O10001O005K5K2N4L1O00000000010O00000000000000000000000000000O1000000000000000000000000000000000000000000000000000000000000000000000000000000O10000000000000000000000000000000000000000000000000000000000000000000000000000O100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O11O00O100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O10000O100O1O002O0O1O1O011N1O10O01O1O2O0O1O1N200O100O1O2N100O3M2O2N2M3N7H3M4M2M3M8H6I3N4M2M4L4L4L4M3L4L4M3aLiDn2f;O0O001O100O100O1O1O1O1O100O100O1O1O1O100O100O1O100O1O1O1O101N1O100O10000O1O1O2N1O100O1O100O1O100O100O1O1O1O101N100O1O1O1O100O2O0OlBZNP=e1PC\\NP=d1oB^N0Nj<c1XC_NNOONg<d1[C`NN2g<]1ZCcNO0h<\\1YCmNf<S1[CmNe<S1\\C^NL403g<\\1^CaNK3g<\\1^C`NLO0Og<b1\\CaNm<_1QCbNP=^1PCbNP=X1nBgN11R=^1nBaNS=f11GnBaNS=W1?O1O1O]BlNMN\\=V1;00O101O0O100O101O0L5N2L7IXQS3"}}, "object_label": "couch", "attribute_label": ["color:black", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose, state, length, material, pattern, color", "answer": "The image features a black couch with a wooden frame, placed in a room. The couch is positioned in the middle of the room, and it appears to be a large, long bench."}, {"question_id": 131, "height": 392, "width": 640, "image": "000000197388.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 259.08, 106.63, 36.68], "segmentation": {"size": [392, 640], "counts": "W81h00f:0ZE0f:0ZE2d:N]E2b:N^E2];O1OUO0j010001O0000000000000fDN^:2aE0^:0cEN^:2l0001O0000000000001O0O1000000000000000001O0001O000000000000O2O01O0010O0001O00010O00001O01O01O0001O01O0010O01O10O00001O01O010O000010O0001O0001O01O01O01O000001O0000000O1O010O10O2MVP[6"}}, "object_label": "skis", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:yellow", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, pose, texture", "answer": "The image features a pair of skis on a snowy surface, with one ski on the left side and the other on the right side. The skis are long and narrow, designed for gliding on snow. They are positioned parallel to each other, with the tips pointing towards the viewer. The skis are likely used for skiing down a snow-covered slope, providing a thrilling and enjoyable experience for the skier."}, {"question_id": 132, "height": 480, "width": 640, "image": "000000210915.jpg", "category": "description", "question": "Describe the surfboard in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [286.92, 61.48, 180.14, 120.81], "segmentation": {"size": [480, 640], "counts": "bQX42l>3N3M2N3M2O1N3N2M3N2M2O2M2O1N2O1N1O2O0O101N101N2O1N2O001N2O1N2O3L4M1N3N3L3N1N2O1O1N2O2M2O2M2O1N101O1N2O1N2O001N2O1O1N010O10O010O001O001O10O01O100O010N2O001O100O00100O0010O0100O1O001O1O001O1O010O1O010O1O1O001O1O010O1O1O1O1O10O01O1O1O1O1O1O1O1O001O001O1O1O1O001O1O1O1O1O1O1O1N2O1O1O001O1N2O001O1O1O1O1O1O1O1O1N2O1O1O1O1N2O1N1O2O1O1O1O1O1O1N2N2O1N3N1O1N2O1N2N2OTd_2"}}, "object_label": "surfboard", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color", "answer": "The surfboard in the image is white and appears to be a longboard. It is being ridden by a man who is skillfully surfing on a wave in the ocean. The surfer is wearing a wetsuit, which is a common attire for surfers to keep warm and protected in the water. The surfboard is designed to provide stability and balance, allowing the surfer to ride the wave with ease."}, {"question_id": 133, "height": 425, "width": 640, "image": "000000288762.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [249.27, 27.4, 390.73, 147.08], "segmentation": {"size": [425, 640], "counts": "Sn[31W=11O01O002O0O00002O0O0SCLf<4ZCKf<58O001O0010XCNW<2bC0MMb<2_C3f<NYC2g<OWC37JV<?dCF[<:eCE]<1aCO5N[<3aCM50[<2`C2O0_<NaC=^<9N2N1O3M01KkCTOU<k05ChCHZ<d0O10OfCWOU<i0hC[OV<m0O0001O0L5O01fCSOV<P10MjCSOV<l04O11O02N3_O`C2m<MKLXC6g<67CTb4MU^K000Po92iPF6O10O0000001O0000PCJm<:O4M0O0001O00001O00001O1O1O1O2N1O2N1O1O1Oej05VUO1OMPCMP=26MnW12PhN3N1O01O000001O0001O0000001O000O10mBMP=61O01O01O01O001O0010O0001O00001O01O0001O01O01O001O01O0001O001O010O1O001O01O0001O01O01O010O0000010O1O000010O0000010O0001O00010O001O00010O01O0100O0O1001O01O010O00001O01O01O1O01O00000010O1O010O001O000001O01O0001O01O00100O0000010O00001O01O00010O0001O10O00010O00001O01O0001O0001O00010O000010O00010O01O0001O000001O010O0001O0001O01O0001O01O01O010O00001O01O01O00010O0001O01O0010O000010O00001O01O0001O01O01O0010O00010O0001O01O01O0001O01O01O00001N101L3K5LfK"}}, "object_label": "fork", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, cleanliness, transparency", "answer": "The fork in the image is silver and has a long handle. It is placed on a white plate, which is filled with a variety of vegetables, including carrots and broccoli. The fork is positioned near the center of the plate, ready to be used to enjoy the delicious and healthy meal."}, {"question_id": 134, "height": 374, "width": 500, "image": "000000300039.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [190.3, 127.67, 41.64, 131.24], "segmentation": {"size": [374, 500], "counts": "[aU25`;2N3\\EK_9;nEG08h98SFd0^9n0L6K4K5L4L3N1N5K4M2M4M10O104J102N1N4M1N4L4L3N1N2N2N1O2N2N:F5J9hNWF3l9F\\1G`hR3"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:red", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "cleanliness, transparency", "answer": "The image features a close-up of a bottle of beer, which is prominently displayed in the foreground. The bottle is brown and has a label on it, indicating that it is a beer bottle. The bottle is placed on a table, and the focus is on the bottle itself, showcasing its details and design."}, {"question_id": 135, "height": 374, "width": 500, "image": "000000300039.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, material, pose, state, texture, transparency", "region_anno": {"bbox": [222.85, 171.17, 42.63, 53.29], "segmentation": {"size": [374, 500], "counts": "`oa26_;5K3M;E7J4L4L4K3N2N00001O001O1O001O1O1O1O0000O10000O10O02O00000O2O000O100N3K5@?N3M3N=]OeD0Rmd2"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, texture, state, transparency", "answer": "The image features a close-up view of a glass cup filled with a dark liquid, likely beer. The cup is placed on a table, and the beer appears to be in the middle of being poured. The glass cup is positioned in the center of the image, and the beer is visible in the background, creating a sense of depth and focus on the drink."}, {"question_id": 136, "height": 588, "width": 640, "image": "000000365207.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [399.05, 306.02, 85.27, 184.74], "segmentation": {"size": [588, 640], "counts": "ifV7;5JQa0U1^O?UOk0F9L5G8J7K4N3M2N3L3005L0O00EVLUBh3k=YLUBa3Q>_LRBU3V>lLjAm2]>SMcAj2`>VM`Af2c>[M]A_2i>aMWAW2Q?iMo@T2T?lMm@P2U?QNk@l1V?VNj@h1W?YNi@c1Z?^Nf@`1[?aNf@]1Z?dNf@Z1Z?hNf@W1Y?kNg@Q1\\?POd@l0_?UOa@e0c?]O]@`0e?@]@=d?D\\@9e?I\\@3f?NZ@0g?1Y@Ng?4V@JA^OX`0j0V@Hm?a0h_OAX`0=j_OET`0;l_OGR`0Y10Mi_ORNW`0e1i_OaN2IT`0g1j_O`N2IS`0h1k_O`N1HS`0i1l_O^NV`0b1l_O]NT`0b1o_O[NS`0a1h_O`N_`0]1e_OcNZ`0^184NH\\_OgNd`0_1100N30O01O000YOa_OB``07g_OHZ`05j_OIV`04o_OJR`04Q@Ko?3T@Kl?5V1O100O103Kooj2"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, transparency, material, pose, cleanliness", "answer": "The image features a red car parked on the side of the road. The car is parked next to a building, and there is a dog sitting in the back window of the car. The dog appears to be looking out of the window, possibly enjoying the view or waiting for its owner."}, {"question_id": 137, "height": 588, "width": 640, "image": "000000365207.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [464.19, 273.52, 93.72, 82.24], "segmentation": {"size": [588, 640], "counts": "Vi^87na09F9L4N2O0O2N101N2N1H9M4N1N1O1O1O1N3N1O1N2O1O1O101M101O1O100O10000O10O10000000000001O002N001O0001O03M0000M3O1M3M3M3M2O2N2M3M3M3M3L4L4M3M3M3L4N2M3N1N3M3N2N3LXb0Ln]O001eT1NPX^1"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture, color", "answer": "The image features a large brown dog with its head sticking out of a car window, enjoying the breeze and the view outside. The dog appears to be looking at something, possibly observing its surroundings or watching other animals. The dog's head is positioned in the middle of the scene, with its body partially visible in the background. The car window is open, allowing the dog to have a clear view of the outside environment."}, {"question_id": 138, "height": 640, "width": 411, "image": "000000368335.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [251.57, 247.76, 47.13, 46.91], "segmentation": {"size": [640, 411], "counts": "oSm44kc04M1N2O1O1N2O2N1N5L2N3M2N^OQ]O9hb0Da]O=Yb0Bh]O?Wb0@k]O?Ub0@l]O`0Tb0@m]O?Sb0@n]O?Rb0Bo]O<Rb0Dn]O;Sb0Em]O:Tb0Fl]O8Vb0Hj]O7Vb0Jj]O5Wb0Ki]O4Xb0Lh]O3Yb0Mh]O1Yb0Nh]O1Yb0LS]OOe03Yb0Nj]O0Xb00h]ONZb02o\\ONgc07O00000000O1O1001O1O4L00O002J5O100OZXS2"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, pattern, transparency", "answer": "The car in the image is a silver sedan, parked in a parking lot. It is positioned next to a white car, and both vehicles are parked in front of a building."}, {"question_id": 139, "height": 640, "width": 411, "image": "000000368335.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [1.44, 95.86, 122.52, 420.9], "segmentation": {"size": [640, 411], "counts": "U3n<R70001O1O002M2O1N3N2N1VOcHoD^7l:fHTE[7g:jHXEW7d:kH]EW7_:kH`EW7]:kHcEW7Z:jHfEW7X:iHiEY7T:hHlEZ7R:eHnE]7P:bHRF`7j9bHVF`7f9aH[F`7c9`H]Fc7_9\\HdFf7Y9ZHhFh7U9RHPFGj0Z8S9oGUFFh0\\8Q9nGXGT8d8lG]GW8`8gGbG\\8[8dGfG]8X8dGgG`8T8`GnGb8o7^GQHd8l7\\GVHf8g7[GXHh8e7YG[Hj8a7VG_Hl8`7PGcHS9Z7kFgHY9U7gFlH\\9Q7eFmH`9o6`FPId9m6ZFUIi9f6ZFXIk9e6SF[IQ:b6PF]IS:`6kE^I\\:^6_E[HOX1f:Y6\\EkIg:S6YElIj:R6VEmIn:_74L3N4L2mIoDaM4P5Q;]M^E`2g:^MUEd2n:ZMoDh2V;TMVDkM>o4a;SMQDoMNO;`0Cl3V<dMmCVN:g4l;RMhCWN1L6i4U<aMkC]2[<`L^CC7l3^<_L[CiN2g06m3d<dLTC_O8m3h<`LPC\\O3A5b4j<`LnBXOd0V4`<cLlBZOa0P4f<eLiB\\O`0l3j<ZMVCe2l<ZMdB^N;W4MiKi<f1YC`2OmKg<b1ZC_22lKf<e1WC]2^=cM`B]29lKf<f1PC]2;oKe<c1oB^28TLk<\\1kBa2<mKA0Z=a1hBl1MVMa0]O@0[=c5gB\\J>2_O11OU=a5RCdJH<V=n4SC[Ko<b4QC_KQ=U4YCkKi<^4kBcKW=\\4eBgK\\=^51O2oN^BfJ0e0d=b52M2O2M3L6J3N6J2N1N3SMaAaMUa0d1R1B?_Oa0H7JWkk5"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:transparent/translucent", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "transparency, pose, pattern, cleanliness, color, size, texture, material", "answer": "The image features a black car parked in a parking lot, with its rear end visible. The car has a chrome bumper and a chrome exhaust pipe. The car is parked next to another car, and there is a person standing nearby."}, {"question_id": 140, "height": 375, "width": 500, "image": "000000402765.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [62.36, 0.0, 398.6, 374.86], "segmentation": {"size": [375, 500], "counts": "nPg09Y;<D;D9H8H8G8H8J6I6I8J5H7M3J6J6L4L4I8L3J6L3L5J6L4L5H7M3J5N3K5L4M3K6L3M3L3M4L4N2M3M4M2K4O2L4L40000I7DTHhLQ8\\33LlGdLU8P3kGTM]8d2dG[M4MX8T3cGlL]8P3dGoL`8d2bG\\Mi8^2TGcMT9]2lFcMT9Y2lFgMX9W25IeFPN]9Q2aFRN]9m17I]FVNg9g16O1L4HnEgNV:R1iEnN_:Q14D^E[Oj:<=J6M3O1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000nEM`83b100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002N3M4L6J6J7I6J5K6J5K8H5K8H4L4L5K7I5K5K5K7I4L5K6J6J6J5K6J8H:F4L7I5K6J6J7I7I6J3M8H7J:E:E9H7I5K7I8H8H6I9F:D=E8Emb="}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "cleanliness, color, transparency, material, pose, texture", "answer": "The image features a close-up of a Wii remote control, which is a white and black device. The remote has a few buttons on it, including a large \"1\" button and a smaller \"2\" button. The remote is being held by a person, with their hand visible in the foreground. The Wii remote is designed for use with the Nintendo Wii gaming console, allowing users to control various games and functions."}, {"question_id": 141, "height": 480, "width": 640, "image": "000000411530.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [523.26, 400.5, 40.16, 25.48], "segmentation": {"size": [480, 640], "counts": "mae71Y?0F0I0]A1e>400I8N2K7L2O00IjADV>:lADV>;jAEW>:jAFV>8lAHU>8jAHV>:gAFZ>`00O1N2M4N1O1N2O1O1O2N1OJ161O000100O]bU1"}}, "object_label": "skis", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:red", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, texture, color, pose", "answer": "The skis in the image are red and white, and they are attached to the person's feet. The person is standing on a snow-covered ground, possibly in a park or a skiing area."}, {"question_id": 142, "height": 427, "width": 640, "image": "000000437898.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [571.6, 269.53, 27.12, 29.47], "segmentation": {"size": [427, 640], "counts": "Vd_7;f<;L4O0O10001O0000000001O000000001O00001O0O2N:FdWa0"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern, cleanliness, pose", "answer": "The image features a white coffee cup sitting on a table or counter. The cup is placed on a white surface, which could be a table or a countertop. The cup is positioned in the center of the scene, and it appears to be a regular coffee mug."}, {"question_id": 143, "height": 427, "width": 640, "image": "000000437898.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [340.64, 197.67, 197.67, 224.53], "segmentation": {"size": [427, 640], "counts": "Qa^488NM1n:KPEZ1OoN0N7Ha9V3]FTMV9Q3kFoLc83WGe21SM[9^3fFaLZ9a3dF_L\\9a3cF`L]9h3O0dFZL2Jk8W4SGjK80Y8l3_GZL0J81X8k3`GZL0J91S8NdGm30ZL1I91R8Y4eGfK;OP8[4eGfKj8Y4VGgKk8X4VGgK12a8X4\\GiK03a8Z4_GgK2I10S8a4jGgK1H12S8_4kGiK3HR8Z4kGlK0M3NQ8b4nG_KZ8a4iG^KU8b4lG]K1Nj7e4TH`KOLm7j0oGm24_LNKo7d4RHaKOKP8OnGa40aK041KT8_4kGaK151JR8a4lGaK051HS8c4lG`K17S8Y4lG`K17S8Y4lG_K20N4T8]4lG_K2O04R8^4lG`K0O24P8^4nGdK2MQ8^4mGnKT8m3QHdKK:T8R4QHdKK;R8R4SHcKK<o7T4UH_KM>m7T4YHmKg7S4VHoKj7R4UHoKg7AYHZ41TLf7A[H[4NTLg7DXHX42SLf7X4YHdKMEj7h4YHbKMFj74VH]42iKNEk74WH]40mKi7FVH_40kKj7GUH^42gKNGj7l4WH\\KOHj7m4VH_Kj7a4VH_Kj7c4VH[Ke7D\\HS50TKOKe7T5_HnJLNe7U5_HlJLNf7W5^HjJLOf7X5]HhJN0e7Y5`HgJ`7Y5aHgJ^7Z5aHeJd7W5\\HiJe7V5[HjJf7V5YHjJg7P5THTK5Lf7X5YHhJg7Y542O001O1OTLUHX2k7d10XKWH40l2i7oLYH4Nj20^Lg7c0\\H5Mj2O_Lg7c0]H4Mi2OaLa72]H`064LP3_6ZLaIO00a04^O>47Ko2\\6dLdIEb04@<1:Mk2^6jLSJFA;1:Ni2^6jLbIA:<H6N:2h2\\6oLmI_OD42MN:4>Ni2\\6PMSJA@N088=Jn2X6oLVJ_O_O0268>Ie2NiLY6?WJCC26>Ie20gLW6a0WJAE4KF5i0Md20gLX6`0VJCD3LF3l0Mb23eLW6b0TJCF5NQ41fKW6`0TJDF4On0Lh14RMW6`0TJDF30IKT44lKW6`0TJDF22IIU44kKX6a0SJED25FIU47jKU6e0WJNI_3]6cLkIMHU3h6nL_INIj2R7XMUI1F[2b7cMhH3DR2m7kM_H2@\\OMU2g8WNZGBd0e0]O_OMh1T9aNnFCc0f0_O]OL71j0^9XOcFEc0e0@\\OK58=c9MmF3[O_OM3j:<nE1ZOAN1k:=mE1ZOAN0l:>lE2YO@O0l:>lE9YOWOl:`0lE8WOYOm:`0kE0XOFn:=hEK[OHm:9lE0VODQ;8mE4ROCR;8oE;Q:CVEEa0g0Y:AYEH>d0WO]OR;7oDH70a0d0XO\\OQ;8nDJ6Od0a0]:EiDK6Oe09UOL1JR;7mDK7NR18i9OnDKb16`93SEEX16e94TEFL0Z13g97QEGNO[12f99oDHZ1NeN1S;8lDLZ1LgN0S;`0WF_OfN0T;a0VF@eNOU;a0VFCj9>UFBl9=SFDm9;UFDk9<UFDk9<VFCk9=PE_Ok00Z:`0iDB[<=gCBY<>:M3O[CG[<7eCJ[<6eCJ2Mn;4SDO0Ml;4UDOX<2gCNY<2hCMX<3gCNY<2gCMJNZ<4mCL[<5=000PCMh<3WCO9LR<4fCLk<820000LPCLQ=43O1000000001kBLR=3mBO2Nn51j07XIHk<8UCHk<840001KnBOS=OnB1R=410O0nBJP=5PCKP=530lBLP=9O02N0O20O1oBHn<;1JPCM2Nk<4SCN2NR=140_T[1"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a white oven with a black door, placed in a kitchen. The oven is situated next to a stove, which has a black top. The kitchen also includes a sink and a microwave, both of which are located on the countertop. \n\nThere are several knives placed on the countertop, with some of them being closer to the sink and others near the stove. Additionally, there are two bottles on the countertop, one near the sink and the other closer to the stove. A bowl can also be seen on the countertop, positioned near the sink."}, {"question_id": 144, "height": 427, "width": 640, "image": "000000437898.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "cleanliness, color, pattern, transparency", "region_anno": {"bbox": [384.0, 188.84, 25.8, 36.56], "segmentation": {"size": [427, 640], "counts": "lTQ564Nc<a0M5L2O2N2001ON00000K500010O1O5@fCE[<9hCEZ<8iCF[<5gCH^<5=M3N10bfo2"}}, "object_label": "knife", "attribute_label": ["cleanliness:clean/neat", "color:tan", "transparency:opaque", "pattern:plain"], "control_dims": "cleanliness, color, transparency, pattern", "answer": "The knife in the image is a large, wooden-handled knife with a wooden handle. It is placed on a wooden table, and there are several wooden figurines or carvings surrounding it. The knife appears to be a part of a display or a decorative arrangement, with the wooden figurines adding a unique and artistic touch to the scene."}, {"question_id": 145, "height": 400, "width": 640, "image": "000000454978.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [91.22, 109.15, 52.15, 140.4], "segmentation": {"size": [400, 640], "counts": "eeS12]<2N2N2N2N2N2N2N2cD0W:2dE3Z:OeE2Z:OeE1Y:2fENY:3gEMX:6fEJY:8fEHZ:9eEGY:;gEFX:;gEEX:=hEBW:b0eE_OZ:\\1O1O1O1O101kEfNS9X3SO01oMkGEU8;_IPNd6n1P2UOeE_O\\:?fE@[:>fEB[:=eEC\\:;eEE[::eEG]:7cEI^:4eEK\\:2fEN[:1eEO\\:OeE1\\:MeE3\\:KeE5\\:JdE5^:JWEB?0f:b0e0J6N2L4L4MlcQ6"}}, "object_label": "stop sign", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, pose, pattern, color, material, texture, cleanliness", "answer": "The stop sign in the image is yellow and has a black arrow pointing to the right. It is located on a street corner, and there is a motorcycle parked nearby. The sign is positioned on a pole, and the motorcycle is parked close to the sign, possibly indicating that the rider is nearby or has just stopped at the intersection."}, {"question_id": 146, "height": 424, "width": 640, "image": "000000460147.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [302.33, 172.49, 17.08, 16.24], "segmentation": {"size": [424, 640], "counts": "SWm35R=6I2N2O01001O0O10O1000000O2L3O7IfgT4"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, pattern, pose, transparency, material, color, cleanliness", "answer": "The image features a black car driving down a road, with its brake lights on. The car is positioned in the middle of the scene, and its rear lights are clearly visible."}, {"question_id": 147, "height": 640, "width": 426, "image": "000000464144.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [5.52, 529.66, 299.68, 83.24], "segmentation": {"size": [640, 426], "counts": "c`52nc01O1O010O010O0100O010O10O01O0100O10O01O10O010O010O010O010O010O010O010O0010O01O01O01O01O010O10O1O01O010O010O1000O1O010O00000010O0O20O010O01O00010O0010O010O01O01O010O1OO2O0002OO001O000O2O11N1O1O10O00001O010O1O1O010O01O010O010O10O0lNJ_^O5fb01O000nNJ[^O6da0J\\^O6da0J\\^O6ea0KZ^O5ea0K[^O5ea0LZ^O5fa0J[^O5fa0KY^O5ha0KW^O6ha0JY^O5ga0KY^O6ga0IY^O7ib0OoNKW^O6ha0KX^O4ha0LX^O4ia0KW^O5ia0LW^O4ia0KW^O5ja0KU^O6ja0JV^O6ja0JV^O7jb0O010O0000010O00010O0001O001O001O0000001O000O2O000O2O00000O10000^OAc]O?]b0Bb]O>^b0Bb]O>^b0Ca]O=_b0Ca]O=`b0B`]O>`b0C_]O=ab0C_]O=bb0B^]O=cb0D]]O;db0E[]O;eb0E[]O:fb0F[]O9fb0F[]O8fb0HZ]O8fb0IZ]O4hb0LZ]O1hb0Ne01O100O001O010O01O01O01O010O01O010O010O01O010O01O010O10O00010O00010O0001O010O0001O01O10O01O010O0010O00100O001O01O00010O0010O01O00001O00001O0000001O001O0O101O00000O2O0000000000O100O10001O0O101N101N3MX]_2"}}, "object_label": "skis", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, color, transparency, cleanliness, pattern, material", "answer": "The image features a person skiing down a snow-covered slope, with their skis visible in the foreground. The skis are positioned in a way that they appear to be flying through the air, giving the impression of a dynamic and exciting skiing experience. The skis are long and narrow, designed for gliding smoothly over the snow. The person's feet are securely attached to the skis, allowing them to maintain balance and control while skiing down the hill."}, {"question_id": 148, "height": 480, "width": 640, "image": "000000489014.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [39.91, 2.16, 504.81, 380.76], "segmentation": {"size": [480, 640], "counts": "hgg03k>5M2M8I3M5K4L3M3I6M3TOdNnC_1P<cNmCa1c;^NUD35b1S<[NoCf1g<OO1O0AYNdCi1k<N1000N1O101O00000000010O0000010O000O100N2FTN_Cm1_<;G9M4L3_OZM]DQ3];oLcDW3];600001OLaLhD^3];01OHcLmD]3S;fLiD[3V;fLiD\\3W;cLiD]3W;aLjD`3V;50^LhD\\3W;7O1O1N2\\O\\MaEQO0d2a9VMnF0Gl0LWO3OKh2o8UMUGU2MPN5k2e8@VGdM7k2R82fGUM7JIl2R8<oGnL6ILk2]6m1dI_K3IL1Nf2`5P3bJcJ7GGf2k4e3VKPJ0D23Le2T4Z4PL]I1BLg2c3j4fLgHO_2Z3k4gLiHL\\2]3k4eLlHLZ2^3k4eLnHIY2b3i4eLkK[3T4eL^HJ02U3_3]4eL^HKO23Ml2a3e4dL\\H41Im2_3f4dL\\H41Im2_3f4cL]H50Im2_3f4^L^H101N22Ol2_3f4^L_H0O10130M1d2_3n4cLcHMKN0102d2_3m4eLdHJJ10O12d2_3m4fLQIKR2_3m4hLoHIT2_3m4iLoHFU2a3l4iLiKW3W4cL]H1Z3\\3Y4cL^H12Mn2`3a4aLaH;m2R3c4cLaH:l2S3c4cLbH9j2U3d4cLdH5h2X3d4cLdH5h2Y3c4bLbHKM;m2X3d4cL`H9l2T3d4cL`H9l2T3d4TMdHYOb2c3j4TMdHYOb2c3j4SMeHZOa2c3j4SM_Km2a4SM_Km2a4SM_Km2a4UM]Kk2c4VM\\Kj2d4VM\\Kj2d4YMYKg2g4[MWKe2i4[MWKe2i4ZMXKf2h4ZMYKe2g4[MjHTOP2a3V5[MiHVOP2_3W5[MhHVOR2_3V5ZMhHWOS2_3V5WMiHYOR2`3U5WMiHXOS2a3T5kL^HLm2Y3e4kL^HKn2Z3c4lL_HJn2Z3c4mL^HHP3[3b4WM]Ki2c4WM^Kh2b4XM^Kh2b4YM]Kg2c4ZM\\Kf2d4nL^HJo2X3c4mL_HJ:IW2`3P5nL^HIP3Y3b4WM_Ki2a4WM_Ki2b4VM^Kj2b4VM^Kj2b4VM^Kj2b4WM]Ki2b4XM^Kh2b4XM^Kh2c4VM^Kj2a4WM`Kh2`4XM`Kh2`4XM`Kh2`4XM`Kh2`4WMaKi2_4WMaKi2_4WMaKi2`4VM`Kj2`4VM`Kj2`4VM`Kj2_4WMaKi2_4VMbKj2^4VMbKj2^4WMaKi2_4WMaKi2_4WMaKi2_4VMbKj2^4VMbKj2^4VMbKj2^4WMaKi2_4WMaKi2_4WMaKi2_4VMbKj2^4WMaKi2^4XMbKh2^4XMbKh2^4XMbKh2^4XMbKh2^4XMbKh2^4XMgHYO`2_3i4XMbKh2^4XMbKh2^4XMbKh2^4XMbKh2^4XMbKh2^4XMaKi2_4WMaKi2_4WMaKi2_4WMaKi2_4WMaKi2_4WMbKh2^4WMcKi2]4WMcKi2]4WMcKi2]4WMbKj2^4VMbKj2^4WMaKi2_4WMaKi2_4WMaKi2^4XMbKh2_4VMcKi2]4WMcKi2]4VMdKj2\\4VMdKj2[4WMdKj2\\4VMdKj2\\4VMiH\\O]2^3j4VMhH^O]2\\3k4VMgH^O_2\\3i4VMiH]O`2\\3g4WMiH]O`2\\3g4WMgKi2Y4WMgKi2Y4WMgKi2Y4VMhKj2X4WMgKi2Y4WMiH[Ob2^3e4WMiH^O_2[3h4WMiH]O`2\\3g4WMjH\\O_2]3g4WMiH]O`2\\3g4WMiH]O`2\\3g4VMiH_O`2[3g4VMiH_O`2[3g4VMiH_O`2[3g4VMjH]O`2]3f4VMhKj2X4VMhKj2X4VMhKj2X4VMhKj2W4WMjKh2V4XMjKh2V4XMjKh2V4XMjKh2V4XMkKg2U4YMkKg2U4XMlKh2T4XMlKh2T4XMlKh2T4XMmKg2S4XMnKh2R4XMnKh2Q4YMoKg2Q4YMQLe2o3[MQLe2o3[MQLe2P4YMPLh2P4XMPLh2P4XMQLg2o3YMQLg2n3ZMRLf2n3ZMRLf2n3ZMSLe2m3[MSLe2m3[MSLe2m3[MSLe2l3\\MTLd2l3\\MSLe2m3ZMULe2k3[MULe2k3[MULe2j3\\MVLd2j3\\MVLd2j3[MWLe2i3[MWLe2i3[MWLe2i3[MWLe2i3[MWLe2i3\\MVLd2j3\\MVLd2j3]MULc2k3]MULc2j3^MVLb2j3]MWLc2i3\\MXLd2h3\\MWLe2i3[MWLe2i3[MWLe2i3ZMjH@S3V3S4YMjHBS3U3S4XMkHDLIR3[3W4QMRIKDJS3Z3W4lLVI4c2P3V4jLdILV2Z3V4iLeINT2Y3W4iLfILT2[3V4jLQILK5OJo2[3V4ZMhHDV3R3R4YMiHDV3S3Q4YMiHDV3S3Q4fLhH?1HV3S3Q4fLhH816V3l2Q4eLiH46;o2l2R4fLhH37;P3k2Q4nLoH8o2j2R4oLmH9P3h2R4SMkH5R3i2S4SMjH0NDU3Y3S4SMjH0NDU3Y3S4SMjH0X3l2n3TMjH1W3k2o3TMjH3T3j2R4SMjH3T3j2R4SMiH4V3h2Q4UMhH3W3h2Q4UMhH3W3h2P4VMiH3U3h2R4TMjH4T3h2R4TMkH3T3h2Q4UMkH2U3i2o3VMlH1U3i2o3VMkH2V3h2o3RMjHF1`0V3h2o3VMkH2V3h2o3VMkHHOK0OX3X3n3VMkHHOOX3S3m3SMkHE16OOX3S3m3SMkHF050OX3S3m3kMSLU2m3kMSLU2m3kMSLU2m3RMlH:W3d2l3SMnH8V3e2l3SMnH8V3e2l3SMnH8V3e2l3SMnHI14U3P3l3SMnHDO146S3R3k3SMTIEN5T3S3j3TMoHH40S3T3j3hLmH82JO011W3U3j3hLnH7031IW3U3j3hLoH6N61GX3U3j3gLPIONm0X3]2j3gLPIONm0Y3\\2h3jLPIm0X3Y2h3iLTIj0U3]2g3iLUIOJe0Z3d2g3hLVINIf0Z3d2g3hLUIOJe0[3c2f3iLSI1Lc0[3c2f3jLXIc0R3c2f3jLWId0S3b2e3kLXI0J:Y3k2e3lLWI=J_OZ3X3e3lLVI90CU3X3e3lLXI7NEU3X3d3mL[I9FC[3W3c3nL]I<P3f2c3oL[I<R3e2c3hLQI581INOO\\3U3c3hLSI3NO321NN0Z3V3c3gLVI1M:9HS3U3a3hLVI0N;9GR3V3a3iLUI3M45J_3V3Z3jLSI3O34L_3T3^3PMQIM34Y3o2c3QMPIL45X3n2d3RMPIH1OO1N4^3R3d3lLnH02N60H3_3S3c3jLQI1ON0O32L2^3T3`3iLRI031M080I1]3U3_3jL_I0K0K1\\3U3_3jLUI12O30K1\\3U3`3iLTI22O30L0[3W3e3kLPINNO120N]3Y3c3kLnHO1M022N\\3[3a3PMVIGMN\\3^3U3cL`I:2FNO[3a3R3_LeI:0FO0Z3c3P3]LgI91GN0Z3e3n2[LiI9:Go2i3j2WLlI:o3`3S2VLnI9P4c3P2TLPJ9P4f3m1QLnI108U4i3j1`LSJ^O70Y3T4[2eL[JWOZ3V4Y2dLTJVO50^3Y4V2aL_JVO[3\\4S2VL[JC5L]3]4P2nK]JH107L[3a4l1kKbJG2O6NZ3c4j1iKeJF?NS3d4g1\\KfJ80K4L51Z3g4d1YKiJ71L2N5OZ3k4b1UKlJ80K3O3O]3k4^1UKoJ70L101KN2c3n4[1RKRK?1D1LM1d3P5Y1PKTK?1D10a3P5V1mJXK6OL3O02`3R5T1kJ[K5NL5NOOL2c3Y5P1hJ_K3NLb0NR3]5n0eJ`K4OJb00Q3_5k0eJaK31Ib00Q3a5h0nJeKAb00Q3c5f0kJhKBa00Q3f5c0\\JjK52I`00Q3i5`0XJnK5g0Kk2j5>UJQL2MOf03n2j5;RJTL2MOd06o2j5?PJPLOb07o2m58mITL13N`09Q3m55oI[LK<<T3l53mI]LK;3C3b3T61kI_LK94G1`3W60hIoL0@2`3Z6OdIPM;Q3T6M`IRMN^O:c3[6K\\IYM9j2_6JWI]M:h2b6ITI`M9f2g6FQIdM8d2l6ElHgM8b2P7DhHkMOVO5[3V7CeHmMOVO6X3\\7c0cH\\O`7J[HXM006k2c7KWHZM006j2f7b0ZH\\Ol7`0TH^OP8`0oG@U8=kGAY8=fGC]8:dGE_88bGEc8:\\GEh89WGEm8KoFkM3Y2R9IkFnM3W2W97iFHZ97dFH`97_FGe97[FHi94XFJl92VFLR:NnE1T:NkE1X:OfE1^:jMcEd1O_N0R2j:mMWES12mNMQ2m:nMTET12mNMo1P;CQE<Q;CoD<S;oMlD<0i2V;jLnD9Nb03U1X;[NeDH0a04Z1X;cNfD04\\1V;eNjDJ1`1W;cNjDMHE2j1];cNjDIGJO23e1_;fNhDIF22^1`;gNaDD0a0OR1a;dN\\DK4OO`0OQ1d;cN]DMOO2`0NP1e;dN\\DNMN5?No0f;eN\\DKO03?MP1f;dNnD<ZOAN[1m;hNkD;[OBNY1m;gNTDOd0`0\\OBNX1T<fNbD5[O40S1T<eN_D6]O_1R<_NaD2\\O^1T<aN`D1\\O]1U<aN_D3]OY1U<eN]DK_O3O3Oo0X<PO[D3AJMQ1Y<RO[D0Gl0o;TOZDMJn0m;UOYDKLn0m;WOkDKiNh0]<^OnDa0S;_OmD`0S;AmD>S;ClD<V;EgD<Z;DeD<];BaCHk0f0d;B`CIg0OVOe0d<E]DFoNb0g<IYDEoNb0h<JWD;i;FUDLRO3j<0TDNSO0i<2UDNRO0i<0WD0PO0j<OVD1PO1i<NWD1PO1j<LWD3oN1j<KUCKP19POJ3Oh<1WCMn0?SOBi<1XD`0nN^Ok<1WDf0R=01ZOjA?]>N4M2N2M4LQW]1"}}, "object_label": "boat", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, transparency, pose, pattern, cleanliness, material, texture", "answer": "The image features a large white sailboat floating on a body of water, possibly a lake. The boat is equipped with a white sail, and there are two dogs on board, enjoying the ride. One dog is located near the middle of the boat, while the other dog is closer to the front. The boat appears to be a sailboat with a cabin, providing a comfortable space for the passengers and their canine companions."}, {"question_id": 149, "height": 457, "width": 640, "image": "000000532855.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [238.56, 187.0, 106.71, 56.8], "segmentation": {"size": [457, 640], "counts": "\\^Z31T>9H4M2O2O00000000000000000001N5I5K4N11O0d=O\\B1O1WB8Q=HkB=S=DlB=S=DmB=R=CmB>S=BmB>Q=DlB?T=AkB`0U=:O1O1O1O1O10O0M2020O2N100O100O^OQCLo<4XCEg<<YCCh<=XCCg<>YCBg<>XCCh<>WCBh<?WCBi<?VCAj<?VC@j<b0TC_Ol<a0RCAn<m000O10O1000O1000O100000OCUC^Ok<?YC_Oh<>\\CAc<?^CAb<?_C@`<>cCB]<>dC@\\<`0eC@[<`0fC_OZ<a0fC_OZ<a0gC]OZ<b0gC^OY<b0gC^OY<b0g000O10000O100000001O0O101O001O1O0O2OgBFd<9\\CHd<6i0O2Nj^S4"}}, "object_label": "skateboard", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, transparency, color, material, pose, cleanliness, texture", "answer": "The image features a skateboard with a worn-out bottom, sitting on a wooden surface. The skateboard has a pair of white shoes on top of it, and the wheels are visible beneath the shoes. The skateboard appears to be old and has been used extensively, as evidenced by its worn-out bottom."}, {"question_id": 150, "height": 427, "width": 640, "image": "000000551804.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [346.4, 60.16, 40.3, 140.09], "segmentation": {"size": [427, 640], "counts": "[[`4`0g<<E7J4M2N5K3M4L2O2N2M2O2N1O2N3M1O2NKQEoMn:Q2TEPNi:P2XEQNf:o1;01OZETNm9l1oEYNP:h1nEZNR:e1mE\\N6EX9P2_F]N8FX9l1]F`N<DX9b2iF^MW9]2nFcMS9S2X1L4L4M4J6K5L5K6H7J:DloX3"}}, "object_label": "tennis racket", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, cleanliness, pattern, transparency, material, texture, pose", "answer": "The tennis racket in the image is yellow and black, with a black handle. It is being held by a person who is playing tennis on a clay court. The racket is positioned in a way that it is almost entirely visible, with only a small portion of the handle not showing. The person is wearing a white shirt and is holding the racket in a ready position, preparing to hit the tennis ball."}, {"question_id": 151, "height": 427, "width": 640, "image": "000000570782.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [72.49, 282.75, 232.43, 119.81], "segmentation": {"size": [427, 640], "counts": "ohn01X=3O0H1SC0l<8O2O0O1LA\\C?d<A\\C?h<0O2N101N2O0O101N101O0cCXOV<j0iCVOV<l041OO1001O11OO01OJUOkCm0R<8N101O1N10001O0O101O1N3N1O1OO01O1O10001N2O1O0O2O0010O0001O1N101O1N100N2O2O0000001OkMnDQ2R;4100O01N101M3O001O1O000O2N2O1K^M^Ed2a:31O01O00001N2M2O2O0OQMgEo2W:31O01O00000N1010O10O001O010000O01O0100O1O010O1O1OO2O00010O0101N1O10O02O0O2N100O2O0O1O2N101O0O1O2O0O2O0O2O0O100O2O0O2N100O2O0O2O0O100O2N1O2O0O2O0O2O0O2N1O2O0O101N100O1O101N100O2O0O101N1O101O0O1O2O0O101N1O2N100O101N1O101N101N100O101N101N1O101N1O2O0O101N2N2N1NlV\\4"}}, "object_label": "keyboard", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:tiled", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, cleanliness, transparency, material, pose, color", "answer": "The keyboard in the image is a black laptop keyboard, which is placed on a white desk. It is positioned next to a silver laptop, creating a contrast between the two devices. The black keyboard is likely part of the black laptop, which is also placed on the desk. The desk appears to be a workspace, with the two laptops and the keyboard being the main focus of the scene."}, {"question_id": 152, "height": 640, "width": 512, "image": "000000021604.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [246.71, 245.56, 50.7, 322.54], "segmentation": {"size": [640, 512], "counts": "^`k4>Xc0<C<E;F:^Ob0A?D<\\Oe0E:L4]OgKQAf4j>:TNoJQC3_1Q5_;TK]DP5a;RK]Do4[9gJWGd0]Of4Z9gJXGe0]Oe4U9lJ]Ga0\\Od4S9nJaG`0YOd4S9nJdGa0TOe4U9lJfGc0lNg4]9iJcGd0jNf4c9fJ_FI2U1@c4n9^JaFNBe7m9[HbFZ8]9gGcFY8]9fGdFY8]9gGcFX8^9gGdFX8\\9gGfFW8\\9gGfFW8[9hGgFW8Y9cGjE1m0\\8Y9cGjE0n0\\8Y9dGjENn0^8W9eGjEMP1]8W9iGiFW8W9iGiFV8Y9hGiFV8X9iGkFU8V9iGoFR8b:PLlDoNY;`0dEoNa:d0UFnNP:g0aFoNg9c0mFnNa9:ZGTO[93[G[Oo89c5EmhT4"}}, "object_label": "tie", "attribute_label": ["color:black", "color:white", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "length, color", "answer": "The tie in the image is a unique and colorful design, featuring a combination of red, green, and yellow colors. It is being worn by a man, who is standing in front of a wall. The tie is positioned in the center of the image, with the man's body occupying the left side of the frame. The tie's vibrant colors and pattern make it stand out as a distinctive accessory."}, {"question_id": 153, "height": 480, "width": 640, "image": "000000184400.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [4.31, 206.29, 633.79, 110.02], "segmentation": {"size": [480, 640], "counts": "[7g2Y<1O0000000000000O10000000000O1000000000000000000000000000O10000hNQDdNMa0R<j0`DRO`;n0cDoN];Q1eDmN[;T1eDjN\\;V1eDhN\\;Y1QD_N95g;m1c02N1O1O5K1N2O1O1O1O3M2N00001N10000000000O1000000000000000O11O0000O1000O1000000000000000000000000000000000O10000000000000O010000000000000000000O10000000O100000000O100000O101O00000000000000000000000000O10O1000000000000000fNQDCo;<\\DZOd;f0]DYOc;f0eDSO[;l0gDROZ;n0hDPOX;P1\\10000002N5bBPOb<i1N3M4L001O1O001O00nNhC]OW<c0jC\\OU<e0kC[OU<h1000000000000000000000000000000O100000000000O1000000000000000000O1O100001O0000000000000000000O10hNjCFV<4lChN0R1T<3UDMk;5SDKm;<mCCS<<PDBP<=RDBn;>SDhNI?T<i0SDhNI?T<i0SD@n;a0QD_Oo;a0QD_Oo;b0PD^OP<i10XOlCdNT<\\1lCdNT<\\1lCdNT<\\1lCdNS<]1lCdNT<\\1jCfNV<m0jC@V<`0jC@V<e1000kNjC@V<`0jC@V<`0jC@V<`0jC_OW<a0iC@V<e100O10O10000000000000000000000000000000000VOjCjNV<V1jCjNV<U1lCjNT<g0\\DXOd;e0cDVO^;i0gDQO[;n0hDjN^;U1W10000001O001`BSOj<i1I1[CjM^<]2O2N4K2O1O1O00000O10000001N100000O1000000000O1000000000O10eNlCJT<6lCJT<5nChNMj0V<?kChNNj0W<?jCHV<8iCIW<`100000O10000O100000000000O1000000000O10O100000000000000000000OkNiCCW<c100000O10001O0000O10000000000000000000000000000000O10O100000000000000000000000001O000000000O10O101kNhCeN1a0V<b0_D[Oa;e0bDhNWO;X<l0jDgN_;Z1S101O01O000jBjNb<W1VCVOc<j0\\CYOc<g0]CZOb<e0_C@\\<`0gC^OX<f0fCZOX<j1L2O1O000O10000000ZMhCd2X<\\MhCd2X<\\MhCd2X<\\MhCd2X<20000O1000000000O2O000aNgC7Y<IgC7Y<IgC7Y<DhCQOO[1Y<CiCQOO2OT1Z<HjCQON10U1\\<[OVEDWS5KlWK`0jCBE5KO16]<7QD_OF5KLON1<^<6QD_OE;MCO=]<<cC[O3NNR1X<a1O0000000000O100000O10hNgCJX<^11000000000000000000O1000000iNfCIY<7gCIX<8hCHX<8hCHX<`100000000000O100001O001O000000O1000O10000000000000O10000000000000000000000000000O10O10000000cNkCOU<0XDjNCc0U<c0`D\\O`;c0aD]O_;c0fDWO[;i0mDmNU;S1[1011O4L4dBgNi<Y1WCkNe<U1XCRO3_OX<`1bCAY<c101O00kNhCBX<c10000000000O10000000000000000000000000000000000000O100TOhCPOX<l1O10000000O10000000000000000VOjCjNV<V1jCjNV<W1hCjNX<o100O100000O1VOhClNX<S1iCmNW<n1000SOiCQOV<P1jCPOV<P1jCPOV<P1jCPOV<P1jCPOV<P1kCnNV<R1mCkNS<U1nCXNJ>X<Z1nCWNL=W<]1mCUNL>W<[1oCWNJ340S<e1oCYNKOc<h1bCYNc<f1_CYNa<f1=00ZOiBVO0J33U=l0iBWO6LQ=m0iBVO7MP=n0hBUO8LQ=o0WCQOh<Q1c000O2O00iI"}}, "object_label": "train", "attribute_label": ["color:blue", "color:red", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "length, material, transparency, texture, color, pose, pattern", "answer": "The image features a blue and red train traveling on a bridge. The train is quite long, with its length extending across the entire width of the bridge. The train is moving along the tracks, providing a sense of motion and activity in the scene."}, {"question_id": 154, "height": 480, "width": 640, "image": "000000248631.jpg", "category": "description", "question": "Describe the mouse in the following image in detail.", "dims": "color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [460.5, 273.86, 158.19, 165.78], "segmentation": {"size": [480, 640], "counts": "i\\h6>^>8H8J4L4M3M2N3N1N2N2N2O1O1N2O1O1OYNoB`1m<cNTC]1h<?M4M]NZCQ1c<bN]CM6NLc1`<bN_CL50Kb1_<lNbCCNc1^<lNcCAOd1\\<_NjCNMNMe1[<_NlCNLMNg1Y<bNiCI5f1P<gNSDY1m;fNTD[1j;fNUD[1k;dNUD^1i;eNUD\\1j;iNQDW1o;iNQDX1n;dNnC@0P2P<_NSDe1m;[NTDe1k;^NSDa1m;_NSDb1l;]NTDe1k;YNVDh1j;YNTDi1k;XNTDi1k;WNUDi1k;WNUDj1k;UNUDk1k;SNUDP2j;oMWDQ2i;oMWDR2i;mMVDU2i;kMWDU2j;a0O100O01\\NWD0i;d1000O100RMVDe2j;ZMVDg2k;70oLVDk2o;0100000O100O100O1000000O100O010O1000000O100O1O1000O02O0O10O01000000O1000O10000O100O1O2OO02O002M010O102M010O100O1O011N101N1O1O1O2N101N1O2N1O2N2N1O2N2N1O2N2N2N2N2M3N3M2M3N2M4L4L4L4L5J6I]^9"}}, "object_label": "mouse", "attribute_label": ["color:gray", "color:red", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The image features a silver and red computer mouse sitting on a white surface, likely a desk. The mouse has a red ball on top, which is a common design element for computer mice. The mouse is positioned in the center of the image, with its body facing the viewer. The overall appearance of the mouse is sleek and modern, making it an attractive addition to any computer setup."}, {"question_id": 155, "height": 480, "width": 640, "image": "000000248631.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "color, material, state, texture, transparency", "region_anno": {"bbox": [3.24, 90.61, 426.06, 343.01], "segmentation": {"size": [480, 640], "counts": "YY23f>9L4L2N3M2M3O1O1O1N2N2N2N2O1N2O0O2O1N2N2O1N2O1N2N2N2O1N2N2O1N101O1N2O1O1L4N2O001N2O1N2N2O1N2O1N2O1N2N2O0O2O1N2N2O1O1N2N1O2N2O1O1N2N2O1M3O1O1UO[LYFf3f9]LWFe3i9[LUFg3k9YLTFh3k9YLSFi3l9XLRFj3l9XLSFh3m9YLoEl3m9WLRFj3Q:a05J10K\\KnEd4Q:65J1000N2N2O100O10O[KdKXNCgLi4m4XLhJoNf24YMN:h4l4oLiJQO1WOR1d0POT4S50lJ0S5o4O1000000O1001O00000000O101O0000`JnJQ1S5^4000000000000000000000O01000000000000000O10000000O1000O100000000000000O1000000000O010000000000000000O10000000O100000000000000000000000O10000000000000O100000O10000000000000000O10000000O10000000O10000000O1000000000O1000000000000000O1000O100000000000000O100000000000000O1000O1000000000O10000000000000000O1000O1000000000000000000000O100000O1000000000O100000000000000000O10O100000000000000000000O100000O100000000000O100O1000000000O1000000000O10000000000000O1000O1000001O001O2N2M4M5K:F8H9G7lGTIe7Z7J2N>B9G9G=C<D5K7I:F:F1O1O1O1O2N3L4M3M3M5K3M2N3M1O5K3M1N5L2N3M1O2N4L3M2N3M1N4M3M2N3M3M3M3M3L4M3M4L2N2N3M2N2M3N4L3L]NUOTEj0j:YOWEd0f:@_E:b:F^2M2O\\_T3"}}, "object_label": "laptop", "attribute_label": ["color:black", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "state:on", "texture:smooth/sleek"], "control_dims": "state, transparency, color", "answer": "The image features a silver laptop computer sitting on a white table. The laptop is open and turned on, with its screen displaying a blue background. The keyboard is located in front of the screen, and a mouse is placed to the right of the laptop. The laptop is connected to a power cord, which is plugged into an outlet. The scene appears to be a typical workspace setup, with the laptop and mouse ready for use."}, {"question_id": 156, "height": 640, "width": 424, "image": "000000352684.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [180.91, 288.21, 20.12, 88.43], "segmentation": {"size": [640, 424], "counts": "[Zc33ec0c0@i0WO7K5J7I5L4K4H8N11O1N2O1N3hMU@9l?B]@7e?H[2MRkY4"}}, "object_label": "tie", "attribute_label": ["color:blue", "color:white", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, transparency, material", "answer": "The tie in the image is a blue and white checkered pattern, which is worn by a man."}, {"question_id": 157, "height": 640, "width": 424, "image": "000000352684.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [152.01, 250.47, 28.21, 213.01], "segmentation": {"size": [640, 424], "counts": "ben21ic08D=J9H5L3N1M3T^OiN[OOYa0Z1h^OgNOi0o`0R2H7BoLd_O[3P`0a0L3LiN]@ZN]?a1_@YM8X1OVO^>U2kAAR><QBKi=L`B8]=@jBa0ZOcMW=i1bCW1^<gNdCX1b<nLVB^1[1c1f<YN[Cg1e<SN_Co1a<nMhCb1UNdMX>d0`D>R<gNZA`0a0@Q2i0`<EcDN`;Ki@N0Lf30e;3SALTbg4"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, pose", "answer": "The image features a woman standing in a room, wearing a blue shirt and black pants. She is smiling and appears to be enjoying herself. There are two other people in the room, one standing behind her and another person on the left side of the room. The woman in the blue shirt is the main focus of the scene, and she seems to be the center of attention."}, {"question_id": 158, "height": 480, "width": 640, "image": "000000561958.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "color, length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [491.13, 231.03, 9.81, 21.9], "segmentation": {"size": [480, 640], "counts": "h^U72m>3K3N3I6M3O1O11O1]OhA;a>Id\\Q2"}}, "object_label": "skis", "attribute_label": ["color:white", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "length, material, texture, transparency", "answer": "The image features a person wearing skis, standing on a snowy surface. The skis are positioned horizontally, with the person's feet strapped into them. The skis are white in color, and they are placed on the snow, indicating that the person is likely skiing or preparing to ski. The person's position and the skis' orientation suggest that they are actively engaged in the winter sport."}, {"question_id": 159, "height": 480, "width": 640, "image": "000000007511.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [386.16, 240.54, 122.96, 231.91], "segmentation": {"size": [480, 640], "counts": "dPa55i>4N001O00000O10O10O2O10000O01001N0SDMn83PG0n81PG8h8IUG;i8FSGa0c8E[G?c8BZGc0b8^O]Gj0Z8YOdGP1S8QOkGV1P8jNoG[1m7fNPH`1k7aNRHj1f7VNYHl1f7TNXHQ2d7PN[HQ2d7PN[HQ2e7oMZHR2e7nMZHT2f7kMZHV2e7kM[HU2d7kMiGTO_OV1E>R9XOjGWO\\OS107i8_OjGZO[OP164d8BjG^OYOk0?1^8FhGAYOh0i0JU8MTGYO3h1m0jNl74QGi1Y1mMf7U3^HhLa7X3bHfL^7Z3dHdL\\7[3gHcLY7]3jH`LV7_3mH^LS7b3V200O100OQOiLVFW3i9oLSFP3j9VMTFj2i9[MTFe2l9]MRFf2k9\\MRFi2j9Z1M4K5L4L7Io0QO7I2N4L1OO1HYHRIl7i6UHVIQ8i63O2N2O1YJgGb4]8[KfGb4]8[KfGc4\\8ZKgGc4\\8ZKfGf4[8VKiGh4]8oJgGQ5T9O1O1iNgFeL[9W3Z1J5L4M3M3_N`D@c;8lDYO[;b0PEPOX;l0`1K6M20I7000000KjN`BV1_=lN`BT1f=M4N2O2N100O100O2O1N100O101N1O010O1O2N2M4M2N1N4KZbm1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, gender, maturity", "answer": "The image features a man standing on a sandy beach, holding a kite in his hand. He appears to be preparing to fly the kite, possibly enjoying a day outdoors. The man is wearing a black shirt and jeans, and he is positioned towards the center of the scene.\n\nIn the background, there are several other people scattered across the beach, possibly enjoying the outdoor activities as well. The beach setting and the presence of multiple people suggest a lively and recreational atmosphere."}, {"question_id": 160, "height": 428, "width": 640, "image": "000000012120.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [3.85, 235.64, 57.71, 75.98], "segmentation": {"size": [428, 640], "counts": "iU32<4EO_<h0N3L3M3O0O?B2N0O1O1OXOdDB\\;b0`D^OW;@kDi1S;[OjDFU;n0mD\\NT;d1910ROeD[OL5_;a0dD[ON3^;c0aD\\O02_;^1O02O0XOaDC_;T12\\OaDYO`;N_D60^ON>d;M`D4O1b;J`D4O1b;EfD9H1c;EfD:G09G[;8[D28H^;5ZD16O_;0[DO54b;LXDh0h;XOWDi0j;VOVDj0k;VOUDh0m;XORDh0n;XOSDg0n;XORD;2Dm;1PD:5El;b0VD_Oi;?YDAg;<]DCd;9`DEb;8`DHa;5bDJ_;3dDLchc7"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "maturity, gender, hair type, pose", "answer": "The image features a man wearing a red vest and a blue shirt, kneeling down on a blue surface. He is holding a tennis racket in his hand, possibly preparing to play or practice the sport. The man appears to be focused and ready to engage in the activity."}, {"question_id": 161, "height": 438, "width": 640, "image": "000000052507.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [105.63, 107.14, 76.82, 183.91], "segmentation": {"size": [438, 640], "counts": "]c]18X=6M3N3M2M3M4I6M3O01O0N3N2M3M]M\\OZHa0d7IWH5i71RHOm75QHJn78RHGn7:QHGn79SHGm79RHHm78THFn7:RHDo7<RHCn7>QH@Q8`0PH^Oa7GgFl0h1\\O]70fFe0n1ZOZ7\\1fHcNZ7]1fHbNZ79cFc0S2SOZ7<bF`0U2ROZ7d1eH\\N\\7c1eH\\N[7e1dH]N[7c1eHaNV7`1iHeNS7[1mHjNn6U1oFXNP2h0m6P1SGYNo1h0m6o0TGZNm1h0n6T1RIlNn6W1oHiNR7Z1iHgNW7[1gHeNY74UG;Z1Bb70WG>V1Bd7NXG=V1Ec7KYG?InNS1i0m7FZGk0h0_Oo7B]GQ1a0]OS8^O`GU1;^OV8[OaGW17CT8TOiGY11Lo7fNUH]1K0X9JeF:\\9DbF>_9@_Fc0c9[O[Fg0g9VOXFk0i9VOSFk0P:TORFh0o9YOSFc0o9BVF2n9JXFROXOe0b:7`FHd94`FHc95aFGa96eFE]99kF^OY9>R2M3M3M3LdXS6"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, hair type, pose, maturity", "answer": "The image features a man walking into the ocean while holding a yellow surfboard. He is wearing black shorts and appears to be enjoying his time at the beach. The man is the main focus of the scene, and his surfboard is clearly visible as he makes his way into the water."}, {"question_id": 162, "height": 640, "width": 427, "image": "000000087476.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [232.9, 64.88, 31.96, 46.89], "segmentation": {"size": [640, 427], "counts": "X[b43fc07M3O1O1O2O0O1@A_]O2E7hb03Z]OE26ab0?]]OBcb0l0101O001O1O1IX]OVOhb0f0;N2N2O10001O1O1OP]OAcb0;\\]OGfb06Z]OIkb02RjU3"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, pose, gender", "answer": "The image features a group of people standing together, with one person in the foreground looking at the camera. The person in the foreground has long hair and is wearing a black shirt. There are several other people in the background, some of whom are also looking at the camera. The group appears to be engaged in a conversation or socializing."}, {"question_id": 163, "height": 640, "width": 427, "image": "000000087476.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [120.03, 566.75, 252.76, 72.22], "segmentation": {"size": [640, 427], "counts": "UZZ21lc07J4L4M2N3M2O0O2O1NAQ]O0nb0LZ]O0fb0Ng0O001O1O10jU=2QjB6L2[OMZ]O5cb0N\\]O2cb0O]]O2ab0O_]O1`b00`]O1^b00b]O0^b00a]O1_b0Oa]O1_b0Oa]O1^b00b]O0]b02b]ON]b03c]OL]b05c]OJ[b09e]OGVb0>j]O@Vb0c0i]O[OWb0g0j]OVOWb0k0i]OQOZb0P1:1000001O000000000000001O01O00000000000000010O00000001O000001O0001O00000000010O00001O0001O00010O00000000010O0000000001O01O00000001O000001O000001O00000001O01O0000000001O01O0001O1O103AW]O_Ogc0N001O010O001O0000S\\4OncK000O10001O0O1O2M2O10001N1O1O1O2O000O2O00000O101N1O1O101N1_OZOf]Oi0Yb0YOc]Oi0]b0=00001O000000001O0000001O0000001O0N200000000O1000000O10000O10000O101O0O100O100O2N10000O2N100O2N1O2N2N2N2M5KmhQ1"}}, "object_label": "skateboard", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:rough"], "control_dims": "pose, transparency, color", "answer": "The skateboard in the image is black and white, with a design on the bottom. It is being ridden by a person wearing blue jeans and a pair of shoes. The skateboarder is standing on the skateboard, which is positioned on a wooden floor."}, {"question_id": 164, "height": 480, "width": 640, "image": "000000098497.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [146.86, 219.43, 35.43, 152.57], "segmentation": {"size": [480, 640], "counts": "\\iT22m>1kM0ZE1d:0\\E0c:1RDMa03[;2oC0f0NZ;4iC5l0GY;6iC6m0DX;9gC:l0^O[;;gC9n0[Ol:M]Da1e0bNj:P2SEQNi94kEa20[MT:5kEh2ITMX:KbE::m2FQM\\::hEU3V:l0O001O0000bNhETNX:k1kESNV:k1mESNS:j1RFSNP:]OdEf1d0kNi9\\OfE`1k0QOb9\\OfE^1n0SOP:j0VFQOl9a0oDmNZ1>i9:WEVOT1<j93YE_OQ1<P;DRE9m<N2M2NiZf6"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, pose", "answer": "The image features a person standing on a street sign, which is designed to look like a person. The person appears to be a woman, and she is wearing a skirt. The street sign is positioned in the middle of the scene, with the woman standing on it, giving the impression that she is walking on the sign. The scene is likely meant to be humorous or artistic, as it is not a typical sight to see someone standing on a street sign."}, {"question_id": 165, "height": 425, "width": 640, "image": "000000114907.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [34.39, 258.09, 95.21, 110.66], "segmentation": {"size": [425, 640], "counts": "lg<4<M[<7aCJ_<4?MM201G9O0NL[CIX<4jC5X<`0M2O2O1O1O2N100O10O010O11O1O2N1O1N101O1O1O2N3M3M01O0O10001O00001O001O1O2GZDkNg;T1[DjNh;R1YDnNj;o0WDPOm;j0=G8H6Ib>0bA5N00100O2O0O1O1O1O3WCAc<c00O000100O010O0101N0L\\CCe<<[CDg<?1IXCIi<6YCIh<5YCKh<3XCNg<3XCOh<1YCLh<47O100O002OO03NO1OOb00_O1Rbd6"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, maturity, hair type, pose", "answer": "The image features a group of people sitting together, with a woman in the center of the scene wearing sunglasses. She is surrounded by several other people, some of whom are also wearing sunglasses. The group appears to be enjoying a casual gathering or event, possibly outdoors.\n\nThere is a car visible in the background, suggesting that the gathering might be taking place near a parking area or a road. The people in the group are sitting on a bench, with some of them sitting closer to the foreground and others further back. The atmosphere seems relaxed and social, with everyone engaged in conversation or simply enjoying each other's company."}, {"question_id": 166, "height": 400, "width": 500, "image": "000000121591.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [256.28, 122.25, 122.25, 163.1], "segmentation": {"size": [400, 500], "counts": "TcT38S<KVD0g;3WDOe;4UD3W:FVGh0e8XO\\G3dNa0m9@\\GNgNc0n9DSGJoNe0Z;\\OeDf0Y;XOgDl0V;:cNhN]GZ1k92]OdNdEO5a1U:`NfE02c1W:]NgE00f1V:]NhEj1W:9L3N3M2O1O1O1N2YO^M_Gd2^8cM]Gm0D8m8mN]Gl0F7l8PO\\Gi0H7j0eNR7<[HZ2;bMY7HUH75`2<cMY7GUH74`2=cMY7U3fHmLY7S3gHmLY7]1XHF=oN\\7Z1WHG<QO]7m2bHTM_7@WHR38`Ma7^OYHV1N:8SOa7]OZHU1L;8VO]7]OaHl0Ld05eNH0e7N`Hh0Oc04gNMM_74_Hb04f0OiN3F\\7:]H`05g0OiN6CY7>\\H?6h0LjNR80mG<6j0JkNS8NnG>4i0KjNT8OmG^2NcMU81mG[2NcMV83kGZ2OcMU85kGj2V8VMjGi2V8XMjGg2V8[MiGF1]2W8\\NkGb1X8]NfGc1[8h0eGlL[8U3eGiL\\8X3dGgL]8Y3cGdL\\8IdGm3]8SLcGl3^8TLbGk3_8ULbG>4d2]8oL^G;7d2KPMZ84mGNNb0Ik1[8eMnGM0b0Gm1[8cMnGM2b0En1[8dMgGN?>_Oo1\\8fMcG0c09^OP2]8gMbG0e0g2S8WMPHe2Q8[MQH8WOl1g8mMTH7TOj1j8oMTH[2m7eMUHX2l7fMWHY2i7fMYH7kNg1m8RN[H4hNi1n8SN[H5kNb1e8YNYG0X14kNb1b8]NiH0fN`1a8^NYGNP2`1h6aN]I]1j8ON4OOM`NZE:2d0_:ZO]E45=_:2^EMc:4\\EJd:9[EFe::\\EDe:0[EF18d:4ZEC7HI102i:m0d00O10O1O010O1O10000O2N1000000O2O0O101M2O2O001N2O4J6JPS_1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, maturity, pose", "answer": "The image features a young man skillfully riding a skateboard on a ramp, performing a trick. He is wearing a white shirt and appears to be in the middle of the trick. The skateboarder is holding onto a pipe, which is likely part of the ramp, to maintain balance and control during the trick. The scene captures the excitement and athleticism of skateboarding."}, {"question_id": 167, "height": 480, "width": 640, "image": "000000127092.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [24.3, 420.47, 24.38, 56.74], "segmentation": {"size": [480, 640], "counts": "if;4e>8M2@EXB>Y=CdB6L:`=B`Bf02WO]=P1gBoNW=R1jBnNU=Q18320`BkNW=T1jBlNU=T1lBlNT=V1jBjNV=c0jBGMKV=3gBK<e0j<^OlBJ=g0h=N3M?A00ZON_B0c=O]B1Y>OXQe8"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, hair type", "answer": "The image features a woman walking down a street, carrying a handbag. She is wearing a white shirt and appears to be walking confidently. The woman is also wearing a backpack, which is visible as she walks. The scene takes place on a street with a sidewalk, and the woman is the main focus of the image."}, {"question_id": 168, "height": 480, "width": 640, "image": "000000127092.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "cleanliness, color, length, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [32.39, 450.95, 11.48, 19.11], "segmentation": {"size": [480, 640], "counts": "^^?6g>5L2L4N200001O1N102Mj\\g8"}}, "object_label": "handbag", "attribute_label": ["cleanliness:clean/neat", "color:black", "length:short", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, pattern, cleanliness, texture, pose, length, state, size", "answer": "The handbag in the image is large and brown, with a black strap. It is being carried by a person walking down the street."}, {"question_id": 169, "height": 480, "width": 640, "image": "000000142324.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [0.0, 139.06, 76.57, 245.87], "segmentation": {"size": [480, 640], "counts": "d5P4P;0O100YEPL^:P4810O11N100O01000O2OO01O1O1N3AhKSFY4a9lKWFO4V4e9h00001N010000]KWFo3j9oKWFR4h9nKXFR4j9`KUF80Y4l9^KUFa0Oh3l9hKSF72Z4k9iKUFW4i9lKWFS4g9oKYFP4g9RLXFn3h9dKWF81U4g9cKYF70V4g9bK[F8MV4i9aK\\F0L51T4i9fKZFOO57l3c9RLRF:=c3`9dL_F[3f9\\L^Fe3b9RLRFN?o3\\:01O000UOUEoL09l:g2aEUM_:JoDm2i0SMX:0oDm2n;21O1O000000000O2O0100O02O0O13M03J7H=hNXCCS=k06N7hNodX8"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a man walking down a street, carrying a pink bag in his hand. He appears to be the main focus of the scene, and his presence is noticeable as he walks past other people. The man is wearing a white shirt, which stands out against the background.\n\nThere are several other people in the scene, some of whom are walking in the same direction as the man with the pink bag. The presence of multiple people in the image suggests that it might be a busy street or a public area."}, {"question_id": 170, "height": 427, "width": 640, "image": "000000144300.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [509.16, 68.4, 69.49, 111.45], "segmentation": {"size": [427, 640], "counts": "i[d62X=1K5NJPC020k<3YCLl;4cDO_;9f04fCAe;b0`04dCYO60V;h0dDXOl;j091O1hCUOP<k0PDUOP<3kCc03[OR<1lCd00Kf;@[D[1d;fN[D[1d;eN\\D^1a;bN_D^1a;aN`D\\1ObNa;2`D[1d;fN\\DX1e;iNZDQ1m;34K4VOkC;Y<DgC;\\<84L6K3H:GP[3OfXL0^<101OO1000O1[ONQD2o;OPD1Q<OnC1=Oe:0mD1>Of:OmD1;2[;NdD3\\;McD4_O0R;NlDNb02B;g:HSEKb02F<P;CZEOH>j:G[EMM;m:CVE1N<Y<000WOInCL023:n;h06ZOkCKb<FcC6m<L\\Sj0"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity, hair type", "answer": "The image features a man standing next to a boat, possibly a speed boat or a motorcycle. He is wearing a blue jacket and appears to be looking at the boat. The man is also wearing sunglasses, which adds to his overall appearance. The boat is positioned in the background, taking up a significant portion of the scene."}, {"question_id": 171, "height": 309, "width": 640, "image": "000000146825.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [55.74, 147.87, 9.75, 47.04], "segmentation": {"size": [309, 640], "counts": "PRa06W9MjF<e8D_Gi0\\8a0F2O0001UOmG@f8MXG=W9L3LYh\\5"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, maturity, gender", "answer": "The image features a person standing on a sidewalk, wearing a blue jacket and a red scarf. They are holding a cell phone in their hand, possibly checking messages or browsing the internet. The person appears to be engaged with their phone, possibly taking a break from their daily activities or waiting for someone."}, {"question_id": 172, "height": 480, "width": 640, "image": "000000153011.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [430.49, 208.79, 46.28, 140.99], "segmentation": {"size": [480, 640], "counts": "`RW61j>7I6L3M3M3N2PN@_Ea0\\:FZEa0e:ASEg0k:[ObDX1[;kN_D[1`;eN]D_1a;dNZD`1e;n0O01I\\DPMf;h2<LG:1N4M31O<E:E=D6I20O0000001O0O2N2N2M4J7Cc0XOb0B<H7K5N3M3L5L4VO]BOk=J^BMg=OPc]2"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type", "answer": "The image features two people standing in a parking lot, both of them wearing black clothing. One person is a woman, and the other is a man. They are engaged in a conversation, possibly discussing something important or sharing information. \n\nIn the background, there are two cars parked, one on the left side and the other on the right side of the parking lot. The woman is holding a cell phone, which she might be using to communicate with someone or to access information relevant to their conversation."}, {"question_id": 173, "height": 480, "width": 640, "image": "000000153011.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [364.22, 213.61, 57.18, 24.39], "segmentation": {"size": [480, 640], "counts": "j[Z53m>1N2N2O1O0O2N2N2O0000000O101O01O00:Dk>MXA>D1O001O00001O001N200O1O1O10O001O001O0O2N1O2N101O01O0000N3M2N2N3N1OSkW3"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "color, texture, transparency", "answer": "The image features a white car parked in a parking lot. The car is positioned between two other cars, with one car on the left side and another on the right side. The white car is parked in a parking space, and it appears to be a compact car."}, {"question_id": 174, "height": 480, "width": 640, "image": "000000153011.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [0.0, 113.0, 317.49, 164.67], "segmentation": {"size": [480, 640], "counts": "W4543Y>;J6\\B\\Ok<f0lBVOL53Li<d1TC\\Nl<m1O3[CQNS<Q2cCZNZ<X2N2N5K3M6J2N001O0000000000001O01O000001O001O1O3L106J1O2N1O3M2N0000_OUEmLi:S3\\EjLd:U3_EdLe:V3e0N3N20000O010O02O001N101O002N1N4M3M2N1N3N1O1O1O1O2M7J9G1O0000O2O001O01O0000O1000O10001O001O001N2O001O2N6JE;M4L3L4M3O1O1M3O100O100O1N3N1O1N2O1O1O1D<N2N2N3O0O2O2N0O10000000O1000001O0O101O001O1O3M2N0001O000O10000001O000010N1O1lNTDYN026Mh;h1RDYN11[<f1dCYN11[<f1eCXN2OZ<j1b001N101O01O0nBZNQ1Mc:i1]DXNj<g181nBWNl<i1RCZNl<m1OIVCYNk<f181mBYNk<o1O1OO1001O2NQOWCHi<7WCIi<7WCIj<6VCKj<4VCMi<3XCMh<2XCOg<1YC@OMf<c0[C]O3D11b<m0ZC]O`0DV<j0XCYO19b0CU<k0XCYO3L15Z=e0bBYO;2R=k0mBUO8KX<o0`CWO5MZ<m0`CVO5N\\<k0`CVO4O\\<k0`CUO50[<d0VC\\O<N42Z<d0VC\\O=L44=Lm:g0UD\\OR1Ol;h0V101O1O0000hBYOW<g0gC]OUOKo<h0fCG8AZO6HNZ;c0mD^OM?M\\Oi05XOa0o:?RE@M^Oh03XOa0Q;>RE@M]Oi03YOa0o:?SE_OL^Oi03YOb0n:`0QECf0]OZO`0o:a1UEhM5S1f:U1TEiM6R1f:DPEh04bN6R1f:CQE70Ba0b0_:W1cEjMI<d:j1VFTNj9c1PEVNW16k9c1^F\\Nb9d1aFYN`9e1cFXN_9g1n1O1J7I6O1O2O1N1001N010O001O2N2N3MM3O1001OO10000001mBkNGGM1Y<_1QDWOMB];V1fDXOGHc;P1eDYOHGc;o0fD\\ODGe;l0hD0X;0hD0X;OiD1W;OiD1W;OiD1W;0hD1W;OfDcNG^1c;OiD1W;0hD0X;0iDOCdNa;\\1mD3S;MnD2R;9dDG[;KaDSO2R1];=aDD_;;aDF^;;aDG];o100002RMaDW2_;XMaD9i0h1j:XNWEg1j:YNVEf1i:QNeDN`0R2k:PNfDNH0a0S2P;oMiD17P2P;oMaEQ2_:oMbEP2^:QN_DLm0U2c:TN[Em1e:SNXEQ2g:oMYEQ2g:oM[En1f:RNiDH5U2R;TN_D2>i1T;cN^DYO:T2X;fNhDY1Y;mM^D41MO6=b1CZNa;g0iDX1X;hNgDX1Z;hN]D_1e;`N]DVO3P2a;ZN[DH041J4g1L[Ne;8YD4OF6`1k;_OUD<n;DSD:n;FQD;o;lNkC<7h0n;DQD=o;CoC?R<@nC`0c=Ee0\\Oemj4"}}, "object_label": "truck", "attribute_label": ["color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "transparency, pattern, color, material", "answer": "The truck in the image is a food truck, which is parked on the side of the road. It is a large white truck with a distinctive fire design on the side, likely representing the food truck's brand or theme. The truck is parked next to a sidewalk where several people are gathered, likely waiting to order food or enjoying their meals."}, {"question_id": 175, "height": 480, "width": 640, "image": "000000159399.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [337.96, 278.98, 45.18, 118.52], "segmentation": {"size": [480, 640], "counts": "RWP54k>2M2M3M3ZNEcD?];AbD>_;NSD0Q<FWCNg0;V<CVD;f;IZD9e;IXD9f;JTD<j;FhCK@a0f<GiCc0W<_OXCB<m0\\<JXCYO5k0d<4ZCKe<7YCHi<V12N2N2N20010001EVN`Ch1]<YNeCi1V<VNlCi0E6Y<QOTD1D98j0i;jN\\D4?S1YOhNZ;4PE1?Z1_:hNoDOe0W1Z:nNnDLk0S1W:TOjDHW1n0o9HWF3h9L^FC\\NGW;1eD9m1A`:=U2Lmdh3"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, pose, gender, maturity", "answer": "The image features a woman standing in a grassy field, holding a frisbee in her hand. She appears to be enjoying her time outdoors, possibly playing a game of frisbee with friends or family. The woman is wearing a backpack, which suggests she might be on a hike or a day trip. The scene captures a moment of leisure and outdoor activity, with the woman being the main focus of the image."}, {"question_id": 176, "height": 426, "width": 640, "image": "000000163118.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [296.4, 113.44, 111.08, 312.56], "segmentation": {"size": [426, 640], "counts": "UQd31T=0Zj05bUO5K4M3L4L4K5M3N2M20O001O00N21ON3O0O1O21NKkNZDQ1i;nNXDn0U<LeLWO\\Jd0W9MoL\\ObIb0`6_O`I?f9NnNB]E;j;O\\LF[G0Y27U7IlH4V:Nnm18]eMH<ON<\\9NWFG8N?6Z9d0VFXOG054V:`0^F\\OZO1COm:;eFEe99XEE>6\\:2WEHo;6d000O1OYCMf2O]63mFNF1f9OjH0iM0D2000O2O01W2Nd44dKLlM?ICP9NkF6l27]MCi85mF5i20XMF`93_F9h2EYM5:Kj82kF<j2AXM10112S9`0UJ^Oj5d0UJZOS20[Nh0_OXOc0d0PMB]OJW3i0FWO47jLR1Z44YMdNQ2W2?UOX1j0jNTOW1k0jNTO\\NfN4V2c1POZNjN4U2d1oNnMmNlMOc2T2`MmMi3o0XNQOi0T2TMnMm3j0]1X1eJPNo3f0TNUOl0U2PMmMKOW4i0QNVOm0T2d1dNXMZOnM0V3l1P2eNkLCU1`1^2gN\\LFQNMV3_1i2iNoKL[1W1R5jNlGLg2=bMBT85cGNf27b6Fm?2jCN<2a<1QC0cFMc53j30jEOR72S3O1OnY_3"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity, gender, hair type", "answer": "The image features a man wearing a grey shirt and black shorts, standing on a basketball court and reaching up to catch a frisbee. He is focused on the frisbee, which is in the air above him, and appears to be in the process of making a catch. The man is the main subject of the scene, and his athletic stance and determination to catch the frisbee are evident."}, {"question_id": 177, "height": 612, "width": 612, "image": "000000169076.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [53.64, 75.64, 125.15, 130.65], "segmentation": {"size": [612, 612], "counts": "l]P1`0ga0BR_Ol0b`0TO]_OT1S?QOQBP1k=WOQBj0m=ZOoAg0Q>[O]A_O[OV1W?_O[A[O]OW1W?FdA;Z>GdA:[>IcA7]>JbA6]>M`A4`>N^A2b>O]A1b>1]AOc>1\\A0c>2\\ANc>3\\ANd>3ZANf>2XA0g>2UA1k>1RA0m>6l@LT?4i@OV?2i@0V?o1O1O10000O10000000000O10000001O0001OO2O01O000001O001O1O2N1O3M1O2N2N002N1O2mM[@c0g?QO[@TO1j1V`0ZNZ@d1d`0O1N2O1O002N1O2N1O1O1O0010O01O1O001O001O0O101O00001O001O1O1O00001O00001O001O002N1O1O2N1O3M2N2N2N2N5K3M2LlhV8"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity, gender", "answer": "The image features a young man and a young woman standing next to each other, engaged in a conversation. The young man is wearing a tie, which suggests a formal or semi-formal setting. The woman appears to be looking at the young man, possibly listening to what he has to say. The scene takes place in a public area, possibly a street or a park, as there are other people in the background."}, {"question_id": 178, "height": 612, "width": 612, "image": "000000169076.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, texture", "region_anno": {"bbox": [222.88, 293.25, 369.42, 301.69], "segmentation": {"size": [612, 612], "counts": "YPW45nb04K4M2M4M3Mb0^O4L3L3N2N1N2O1O1O1O2M2O1N2O1O1O1O1O1O1O2M2O1N200O1O1O1O1N2O1N2O1O1N2nNYMeAi2[>WMdAj2[>[M_Ag2X>eMVA\\O9Q3W>_1K5K5M3N2O1N2O1O1N2N2N2N2O1O1O1N2O1O1O1O1O1O1O1O1O1O10000O100O1O1O100O10000O1O1O1O100O100O1O1O1O1O1O1O1O100O1O100O100O1O1O100O100O1O100O1O1O1O100O100O100O100O100O1O100O1O10000N200O10000O1000000O100000000O100O100O1O1O10000O100O100O100O100O10000O1O1O100O1N2O1O100O1N200O100O1O100O1N2O1N2O1O1N2O1N20000O100O1O1O1N2M3O100O1O1O1O1O1M3N200O10000ORHQFi6o9WISFg6m9YIRFh6n9XIQFi6n9XIRFh6n9YIQFg6o9W100O1000SHTFmN4Y7g9lITFkN5Y7g9lITF`6l9\\10]HTFn5l9lI[FS6e9nIYFS6g9mIYFS6g9nIYFQ6g9PJYFo5f9SJYFaNLW7k9YJXFl5h9UJWFk5i9WJVFh5j9YJVFf5j9aJTFZ5m9cJVF\\5j9eJUF[5k9hJZFP5f9PK[Fo4e9UKYFi4g9\\KTFd4l9Z2000000001O0000000000001O0000000000000000001O000000O100000000000000000000000000000000000000000000O10000000O10000001O000001O00000000000000001O000000000000001O00001O0O1000000000001O0O1000001O001N100O100O1O1O101O0O1N2O100O1O1N2O1O1N2N2L5Mh2kI]BWN2OO1O10O1O10O002L;Xc<"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:black", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, pattern, color", "answer": "The image features a black dog lying on a bed, possibly a couch, in a room. The dog appears to be relaxed and comfortable, possibly sleeping or resting. The room has a TV in the background, and there are several books scattered around the area. The presence of the books suggests that the room might be a living space or a bedroom where the dog's owner spends time."}, {"question_id": 179, "height": 612, "width": 612, "image": "000000191614.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [347.77, 289.95, 33.8, 66.87], "segmentation": {"size": [612, 612], "counts": "bf_68lb00OO0101O2N2N1J6L5L4AYO]^Oi0ba0ZO[^Og0da0=01N1000010O01kN_^Oe0ba0VOe^Og0na0N3MQ^O[O`a0e0S^OJka0g01O1oNW^Oe0ia0[OW^Oe0ja0ZOW^Oe0ja0YOW^Og0ia0YOX^Of0ia0XOZ^Of0Tb0N2M`0_Of`X4"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose, gender", "answer": "The image features a woman riding a brown horse, wearing a helmet for safety. She is sitting on the horse's back, enjoying her time outdoors. The woman appears to be the main focus of the scene, and her riding posture suggests that she is comfortable and experienced in horseback riding."}, {"question_id": 180, "height": 612, "width": 612, "image": "000000191614.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [73.07, 310.37, 154.97, 169.85], "segmentation": {"size": [612, 612], "counts": "PU]1f0\\b0a0_O6J5Jb0@4K6Jf0W@QMU>V3`ASMZ>n3MTL_AX3_>gLdAX3[>gLgAY3X>gLjAX3U>gLnAW3S>iLmAW3S>gLoAV2B]N`>\\OPBR2DbN[>\\OSBW3m=hLTBX3l=gLVBX3i=gLZBW3g=fL\\BX3g=fL[BS3k=mLUBc2[>]MfAW2e>hM\\AT2g>nMXAo1k>QNVAm1k>RNVAl1R`0G9N3M2O1N2N2N2N2H\\@SOa=l0\\B[Oa=e0\\B@b=`0[BDe=;YBHf=8WBKi=5RB0n=1iA7W>IbA>^>B^Aa0b>@WA>Q?Cj@8_?JX@:k?]12N100001N02OXO[MRA`2U?aMj@X2S`0N1O2O0O21O1O2M3EdMl_O]2U`0dMi_O]2W`0cMd_Ob2\\`03fA]MT<a2gChMW<W2^CVN`<j1WC`Nh<e1eBjNZ=`300000O100BQBfKP>n3i0H8M4J5J6G:G9K4M4L3N3K5K5M3N3L4L3N102N1O2N001O003M100O1O1O2O0O100O1O17JO0O10Y^OfNda0X1\\^OhNea0\\1[^OcNba0`10fN_^Oo00nN[a01f^OZ1Ya0eNg^O\\1Ya0cNg^O`1Va0`Nj^Oa1Va0^Nj^Od1Ua08NO010O08I3L3NO001O2N1O1N2N102M3M5K5K3gNT_O4Wb0DUYV7"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "maturity, texture, pattern, color, cleanliness, pose", "answer": "The image features a brown horse standing in a grassy field. The horse is wearing a saddle, indicating that it is ready for riding. The saddle is positioned on the horse's back, and the horse appears to be calmly grazing on the grass. The scene is set in a fenced area, providing a safe and controlled environment for the horse."}, {"question_id": 181, "height": 640, "width": 426, "image": "000000193181.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [339.42, 70.66, 25.01, 32.52], "segmentation": {"size": [640, 426], "counts": "lRb66hc04L5K3M2O2N1N2N2OLo\\OZOQc0f03101k\\OYOPc0f0Q]O[Onb06R]O30Gob05T]O2MHob07V]OOKIPc07V]O0nb01Q]O0nb00Q]O1Pc00j\\O3Wc0:1O1N4M3M6IbYW1"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "maturity, hair type, gender, pose", "answer": "The image features a woman with long hair, possibly a young girl, who is looking at the camera. She is wearing a white shirt and appears to be smiling. The woman is standing in front of a wall, and there is a sports ball located in the upper left corner of the image."}, {"question_id": 182, "height": 640, "width": 426, "image": "000000240049.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [188.4, 174.02, 237.6, 457.35], "segmentation": {"size": [640, 426], "counts": "Ske36QZ6KhYJ:G9G7I7M2M2O1O100d_OlNl=T1RBQOk=P1SBTOi=m0UBWOi=k0SBXOl=g0SB\\Oj=f0TB]Oi=f0UB\\Oj=d0UB^Oi=d0TB_Ok=`0VB@j=`0UBBi=?WBCf=?YBBf=>PBaNgNS1V?=RBO5gNk;[1UClNET1>0X<1dClNGS15;\\<FeCZNE`09CE[14\\1Q<mNUD\\NG=;@G]4R<[MRDPO5XOH\\4P<^MPDPO7XOHZ4Q<`MmCTO1g3Q<T3N2O1O1O1N200O100O100O1000ULXD^Oj;a0UD_Ol;Z41OO1FSHaDm7P<I3SLlCHV<IhCjL4]3S<4nCLQ<5nCLR<Q40XHnCb7Y<OO1hIaHN`73]HOc7W601OK_HkCa7T<`HlC`7T<_HmCa7R<`HmCa7T<^HkCc7X<100N2E^HVDd7j;900000000O1O1M3kNmG[FU8`9RHiE4Ll7V:UHkEa8R:cGoE[8P:gGPF[ONh8o9T1M3N2N2O1N2N2N2O100N200O1O1O1O1O100mL`EeLa:Z3dEaL]:]3gEaLY:[3TF[Lm9b3[FSJQOP2e:l3gFlKZ9S4jFjKV9T4PGgKQ9W4\\G]Ke8b4_GZKb8e4`GYKa8f4aGXK`8g4bGXK^8h4dGTK^8k4dGRK^8n4cGPK^8o4eGnJ\\8R5eGlJ\\8S5fGjJ\\8V5dGhJ^8X5cGeJ_8Z5cGcJ_8\\5dGaJ]8_5R300O1000000O100000000O100000M3D<M3N3^Oa0I7C=C=L4M3M3iFSHX6P8hIPHV6R8k21L5M2M3O1M3N3[G\\Gk5e8UJ[Gh5i8VJXGh5j8XJVGf5m8YJSGe5P9[JoFb5T9a25I7RH`FX5c9gJ]FV5f9_24H8M3G9N2L4H8I8G8J6J6I7H:J7G8L5G8I7K4J7J5K3N3N1N3M2N3M3M2N7`KYA\\3W?TLj@j3[?PLh@n3f?O1N2O2L3N2O2N1N3M2N3M2N3M4M2O1O2N2N2N1O2N2N2Ng1[Mb]OOW8"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type", "answer": "The image features a woman holding a baby in her arms while standing near a fence. The woman is wearing a black jacket, and the baby is wearing a pink jacket. They are both looking at a giraffe that is visible in the background. The scene appears to be taking place at a zoo, as the woman and the baby are enjoying their time observing the animals."}, {"question_id": 183, "height": 640, "width": 426, "image": "000000240049.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, state, texture", "region_anno": {"bbox": [26.12, 139.54, 273.59, 258.64], "segmentation": {"size": [640, 426], "counts": "]Rm02nc01M3OLX\\OO^X16X[O2O0002N10O001_NLU_O3i`00Z_OLd`06]_OIa`09__OG]`0=c_OCX`0b0i_O]OU`0d0a13^^OZOh?h0X@ZOd?h0\\@YOa?i0_@XO_?i0a@WO\\?l0g@SOV?n0l@QOQ?Q1l@lNZN6f`0o0SAROk>P1UAoNj>R1ZAkNc>W1]AiNa>X1XAeN^N5X`0X1`AhN_>Y1aAcNTN0Y`0_1cA`NVN0U`0b1hA^NY>c1fA_NW>c1eA\\NUN3T`0b1eAcNZ>^1fAbNY>^1S22O1OO`_OZNi>f1WA\\Ng>c1XA`Nf>a1YAaNf>_1ZAbNe>^1WAgNg>Z1VAjNi>V1VAlNi>S1VAPOlNWOg?i1]AQOg>o0WAQOPOWOc?h1ZAaNPO44Ba?i1YAfNQOLQ`0^1n@hNoNJS`0^1o@SOR?m0PAQOP?P1PAWNmNc0U`0T1PAXNlNb0T`0W1[@[NOLB=W`0^1V@\\Nk`0]2O1N2N200N1O10N3M2M2O2Cg^OTNZa0l1f^ORN[a0o1d^OPNU3KP;]2QEdMo:e1kAjNba0U1`^OiNaa0W1_^OhNba0X1^^OhNg2HWMK7Om=d1PBjNe2Fk;^1bAlN^a0S1c^OlN^a0T1b^OlN^a0S1c^OmN^1ET>]1_@mN_1DS>^1^@nN^a0Q1b^OPO^a0o0c^OPOl`0EX_O[1LPOj`0GZ_OX1MPOi`0IZ_OW1MPOi`0IY_OW1NQOh`0IZ_OT10ROf`0KZ_OS10QOf`0MZ_OQ11ROd`0N[_OP10SOc`0O]_Om01TOa`00^_Ol01TOa`00^_Ok01VOHD_`0<h_Oj01VO_`01`_Oh02WO]`02a_Of02YO\\`02b_Oe02YO\\`02b_Oe02YO[`03c_Od01[O[`01d_Oe00[OZ`01f_Oi0JWO``00g_Oj0FVOc`01g_Ol0BTOg`00g_O^1AQNg`0b0h_O]1BPNf`0c0h_O]1BPNf`0c0h_O]1AQNg`0b0h_Oa1W`0_Ni_Oa1V`0`Nj_O`1V`0`Nj_O`1U`0aNk_O_1U`0aNk_OX1AXNd`0`0k_O_1U`0aNk_O_1T`0bNl_O^1T`0bNl_O^1T`0bNl_O^1T`0bNl_O^1T`0bNl_O^1FnMT`0f0U@\\1FoMU`0e0U@\\1FoMU`0e0U@\\1GmMU`0g0Y@W1BQNV`0h0a@n0e?SO]@k0c?UO]@k0c?UO^@j0b?VO^@j0b?VO]@k0c?UO]@k0c?UO]@k0b?VO^@j0b?VO^@a0ROkNa`0d0^@`0ROkN``0e0^@`0ROkN_`0f0_@>SOjN``0h0]@>SOjN``0h0]@?ROhNb`0i0[@`0SOgNa`0j0\\@b0f?^OZ@a0f?@[@?e?A[@?d?B\\@?c?A]@<QOgNb`0n0\\@;f?GY@9f?F\\@9d?H]@Ln?4Y@oNkN8Ua0j0X@QOh?o0[@nNf?R1c12N1O00101N1O1O100O100O100O1O3M3m^OaNiNMb`0k1o_OYNA8]`0`1R@XN_O<]`0\\1S@POk?R1T@nNk?S1U@mNk?S1U@lNl?T1S@kNo?U1Q@jNo?X1P@dNT`0\\1l_OTNc`0m1h000000O2O000O10O10000000000000001O0O2EZ^OYNga0d1<N3N1O2N1O2O1N101O0O2O001O001O001O001O001O10O01O1O10O0100O2O01O00011O4LO2M4Iafa2"}}, "object_label": "giraffe", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pattern, maturity", "answer": "The image features a giraffe standing in an enclosure, likely at a zoo. The giraffe is reaching its head over a fence, possibly to interact with visitors or to eat from a feeder. The giraffe's long neck and legs are visible, making it a striking sight.\n\nThere are several people in the scene, including a woman holding a baby and a child. The woman is standing close to the giraffe, while the child is positioned further away. Another person is also present in the scene, standing near the woman and the baby. The visitors seem to be enjoying their time observing the giraffe in its enclosure."}, {"question_id": 184, "height": 640, "width": 480, "image": "000000252559.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [0.33, 457.6, 17.84, 73.09], "segmentation": {"size": [640, 480], "counts": "f>k1Ub00OOJCV^OTOia0a101ON3N2J7L4`Nh]OR1eb0M4H7O2K5L6JXmP9"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, gender, hair type, pose", "answer": "The image features a man walking on a sidewalk, wearing a black shirt and jeans. He appears to be looking down, possibly at his shoes or the ground. The man is walking alone, and there are no other people visible in the scene."}, {"question_id": 185, "height": 480, "width": 640, "image": "000000259690.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [148.22, 136.34, 211.79, 212.63], "segmentation": {"size": [480, 640], "counts": "Vmf23k>5L2N2iDIb79ZHJf78lG4S8NjG4V8MdG8[8J`G9a8H[G<d8DWGa0i8@QGf0n8[OnFh0R9ZOiFi0Y9UOdFm0`9ROWFT1m9iNnEY1V:hNhEU1\\:kNaES1h:iNUEU1P;lNlDQ1Z;oNdDo0`;QO^Dm0g;ROWDl0m;TOQDj0S<XO_C^O6Y1^<]O`Ca0d<]O\\Cc0e<]OZCb0i<]OWC?m<AQC>S=BlB;X=DhB:[=FdB8^=HaB9_=c0hDbNQ9X1jFjNSN0Q;W1jFlNTNLR;X1iFnNTNKR;c0kD]O0>l1IVNJR;b0nD[OOd0^1ObN@R;c0RE1m06POUOP;e0PEZONl0<?HeNm:f0RES22VMi:i0VEQ2n:PNUEo1i:QNYEo1d:SN]Em1`:TNbEm1Z:UNgEj1W:WNjEi1U:YNgEj1X:WNhEi1V:ZNiEa1HZM`:W1bE^1f:X16I7M3L5M2_O`010100O100O0100O001N2O010O11N1000O^OUMQEk2l:YMREg2k:eMmD[2R;gMlDY2U;hMjDX2U;jMjDV2T;l0O1IXLUEi3Q;O100000000000O10O100000000bNREUNJ2T;e1XEVNG3R;e1YEVNF5Q;b1]EXNC5Q;a1^EXNCLI3W;g1`EXNIOh:h1bEUNI0g:i1`EXNJNg:i1_EYN[;e1fDZN\\;e1dDZN^;e1aD[Nh;\\1WDeN]<h0aCYOc<d0m0O1OXB[OU=f0b00000001O1O3NVOlAi0U>4K1O000001O0O4M1N2O2M2N2N2O1N101N2O1O001O1N4M^f_4"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose, gender, hair type", "answer": "The image features a young man in a wheelchair, who is being pushed by another person. The person pushing the wheelchair is wearing a baseball cap and appears to be a friend or family member. They are both standing on a dirt field, possibly at a baseball game.\n\nIn the background, there are several other people present, some of whom are sitting on benches. The scene suggests a social gathering or event where the young man in the wheelchair is enjoying the company of his friends or family."}, {"question_id": 186, "height": 480, "width": 640, "image": "000000259690.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, length, material, size, texture, transparency", "region_anno": {"bbox": [380.76, 167.19, 91.69, 44.23], "segmentation": {"size": [480, 640], "counts": "[Pg53m>1OO01lZ22ReM1O0000OO1001000O00100000O010O01O01000O010O10O0100O010O10O010O01000O01000O01O10O010O10O10O0100O010O010000O01O10O010O10O01000O010O10O010O100O10O02OhS^2"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:tan", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size", "answer": "The baseball bat in the image is black and made of wood. It is being held by a person, who is standing on a grassy field. The person is wearing a white shirt and appears to be preparing to swing the bat."}, {"question_id": 187, "height": 428, "width": 640, "image": "000000269316.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [204.86, 139.46, 178.9, 269.3], "segmentation": {"size": [428, 640], "counts": "RPe24V=2O2M8SCE]<=_CF^<g0M3M3M2bJlNbNV1\\1hNdN\\1e61N2N100O100O1]J^NlI9T5Y1n0mNPOT1a0[O_Oe0;AE`07CI=3GM9^KhNb3S1P15[KQO]3l0X14WKZOX3d0b11TK_OV3a0g10PKDT37U25dJGT34Z2e1bM\\Na2d1ZM^Nh2b1UM_Nn2b1mL^NW3b1fL_N[3b1bL^Na3b1\\L^Ng3b1VL^Nm3b1PL]NT4d1hK]N[4b1bK^Nb4a1YKbNk4]1PKdNV5Z1fJeNk5P1PJPOS6Q1iImN[6U1bIiNa6Y1[IfNh6[1TIbNQ7a1jH`NX7b1eH^N\\7c1aH^N`7c1^H\\Nd7e1ZH[Ng7g1UHZNl7f1THYNm7i1PHWNQ8j1mGVNT8_32O1O1O1O1O2N1O1O2O0O2O001O1O0010O0100O010O1O010O01O01O001M2O1O2WLPGT3P9lLPGT3Q9lLnFT3R9c0001O001O1O001O1N110O0110010O01O01N3M7I2O0O0fL]Fj2e9RM]Fo2c9oL^FP3R:N001O003_MfEi1\\:SNiEj1Y:SNmEGDm1e:SNVFe1Q;H:F00203K2O0O10O1O01O0001O0O101O000100O001O001O1O010O2N1O1O000103M1ON2O2M2N1O2N2N2N1O1O1O001O1O1O2N1N2O1O2NS^[3"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:curly/curled", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, pose, gender", "answer": "The image features a man running on a grassy field, possibly in a park or a field. He is wearing a white tank top and black shorts, and he appears to be in motion, possibly playing a game of frisbee. The man is the main focus of the scene, and his athletic attire suggests that he is actively engaged in physical activity."}, {"question_id": 188, "height": 428, "width": 640, "image": "000000269316.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [498.37, 180.26, 94.47, 210.15], "segmentation": {"size": [428, 640], "counts": "\\[a61Y=3N1M3NMPCMP=2SCMZ<f0fCZOU<i042O4M3L3gLlNYJT1d5QOXJR1f5PO^GJb2T1Q6QOaGK]2R1S6TO`GK\\2P1T6UObGJY2o0X6UOTJn0l5QO\\Jg0f5YO]Jb0e5]OaJ<b5DeGLo1>^6E^GN@4_26e6IcG1h11i6Nk3O01O0dFMa53`JL`53oGO`:1aE2\\:NeE0[:1eENhN2n:MYE4W11[90\\EOZ1L_N1h:8\\EMb18\\NFk98UFKe12XNG43f9l0`HSO_7P1`HPO_7OXFo0W2SO`7OZFm0V2TOPNNU91dFo0V2RO`7U1_HkNa7U1_HkNQNML8n8Q1TIjNRN;i8k0UIjNQN`0f8f0[GgNe13ZN<j8j0VGhNLOf12_N6P9Q1oFQO]1HdN1U9U1kFTOY1FhN1?Nk7V1fGVOW1EbNN52`00l73_Gi08_OU1JgNKb0Ol72_Gk07^OV1KfNLa0NNNZ75SHj08_OU1KfNLa0MOOZ7S1\\HZOT1KhNO;IS8R1gG[OU1IgN3n8;nFE73U1CcN575l88RGG14W1EbN2;6l82PGL23V1MlNHE:Y9MPGN8MP18dN7V9ARG0k18jM?e9YOaH9hM72Dk0Ji73lGNQ1e0]N]O66c0Gn74aHNBd0VO\\O79Y9KfGNCb0AFV9JdG0D`0BGV9HcG5BF\\Oa0;KU9JPGJL=6D_O>;MU9I_Gc0TO\\OKO09<0W9I]GS1ROSO91IDY95cGR1SOTO72IFk0N]74dHe0TO^OO481IGj0O\\72fH;@ED83CK=2Hi0O]77_H7On06bN^79[H;Ll0:`N`79XH=K@AS1k0gNc77UHc0G\\OLP1d0jNe77SHg0A[O7NKHKa0j0_Oh7:kGU1c0oNb81bF>O@P1Na83_F>1B`1Am7_1aFTOU;b14oMiDb1e;K5oNRD;g<G4M4K4LoUd0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, face expression, gender, maturity", "answer": "The image features a man wearing a white shirt and a blue hat, standing on a field. He appears to be a soccer player, as he is wearing a soccer uniform and is holding a soccer ball. The man is looking to his left, possibly observing the game or preparing for his next move. The field is surrounded by trees, creating a natural and serene environment for the soccer game."}, {"question_id": 189, "height": 451, "width": 640, "image": "000000272566.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [339.34, 125.74, 57.54, 138.81], "segmentation": {"size": [451, 640], "counts": "X^e44k=7H6M3N3M2N3M3M3N2M3N3L3N1O2N1O1O2N1O3M3N1iEXNo7i1lG\\NT8e1hG]NX8g1bG[N_8e1`GXNd8g1ZGYNi8f1VGYNm8f1SGXNP9g1PGXNR9g1PGUNT9c0`E<U<AmC?W<[OjCe0Y<WOiCh0i<1O1N2O1O1iCkN^;W1g01N4MM3LcDlNR:m0TFSOn9i0TFWOm99bFFoi02PTO0\\=OiB7T=NjB2V=OlBNV=Kbb\\3"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose, maturity, hair type", "answer": "The image features a young girl sitting on a chair, surrounded by a variety of bananas. She is positioned in the center of the scene, with the bananas spread out in front of her. The bananas are arranged in different clusters, with some closer to the girl and others further away. The girl appears to be enjoying her time with the bananas, possibly preparing to eat them or engage in some other activity involving the fruit."}, {"question_id": 190, "height": 451, "width": 640, "image": "000000272566.jpg", "category": "description", "question": "Describe the banana in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [312.49, 309.22, 45.86, 19.65], "segmentation": {"size": [451, 640], "counts": "RUZ44o=1N3N1O1O1O00000000001O01O01O010O00010O0000001O01O0001O01O0001O00000001O1O0000001N4Ldhl3"}}, "object_label": "banana", "attribute_label": ["color:yellow", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "size, texture", "answer": "The image features a large pile of bananas, with some of them appearing to be overripe. The bananas are arranged in a stack, with some of them overlapping each other. The bananas are yellow in color, indicating that they are ripe and ready to be eaten. The pile of bananas is quite large, occupying a significant portion of the image."}, {"question_id": 191, "height": 480, "width": 640, "image": "000000282298.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [363.08, 267.5, 68.9, 199.6], "segmentation": {"size": [480, 640], "counts": "Pj\\5<_>6I<lDVO]7Y1[HiNc7[1YHfNf7_1UHbNj7a1SH`Nk7T2`GPN_8b2nF^MT9c2jF]MW9d2gF\\MY9f2aF_M^9b2bF^M]9c2bF\\M`9e2^FYMd9h2[FWMf9k2XFVMg9k2VFWMc9R3ZFoLe9T3VFoMh8\\4I2O0O10000001O00000001O01O0000003aNaGWLd8a3gGWLk8[2\\FcMX1K^8^2ZH`Mg7_2YHaMh7V2VFfMT23h7T2WFfMR25R8j1VHVNm7g1SHYNn7f1RHZNP8d1PH\\NS8b1lG^NV8`1jG_Nj7JVFf1Q2_Nh7LXFc1Q2_Ni7N\\F9_Oa0NXOU=OhC`0b=NaAC\\>?1IdAH^>4;Mb_S3"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a man walking down a street, holding a white dog in his arms. The man appears to be wearing a black jacket, and the dog is positioned close to his chest. There are several other people in the scene, some of whom are walking in the same direction as the man with the dog. The overall atmosphere suggests a busy street with people going about their daily activities."}, {"question_id": 192, "height": 480, "width": 640, "image": "000000282298.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [451.08, 53.64, 9.6, 109.04], "segmentation": {"size": [480, 640], "counts": "T`c62X>n0kA<W<_1E6J3M33M>Al1TN\\Xd2"}}, "object_label": "clock", "attribute_label": ["color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The image features a clock with a white face and black hands. The clock is positioned on a wall, and it is located near the center of the scene. The clock's hands are pointing towards the top of the clock face, indicating the time. The clock's design and placement make it a functional and visually appealing addition to the space."}, {"question_id": 193, "height": 480, "width": 640, "image": "000000322163.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [491.49, 160.94, 47.69, 60.11], "segmentation": {"size": [480, 640], "counts": "meX78d>7M3kA@c=e0WB]Oi=m0O10000O101N1N4I6J5M201O1OCjBROV=\\1O100O100000O1N2N3M201SOdB4\\=KfB4[=IhB7X=FkB9W=CmB;m=02M0I7N3M3N2NjR`1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, hair type", "answer": "The image features a man sitting at a dining table, wearing a red shirt. He is eating food, possibly a sandwich, and appears to be enjoying his meal. The man is seated in a chair, and there is another chair visible in the scene. The dining table is surrounded by a few books, suggesting that the man might be reading or studying while eating."}, {"question_id": 194, "height": 480, "width": 640, "image": "000000322163.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, length, material, pose, texture, transparency", "region_anno": {"bbox": [507.4, 282.79, 46.26, 82.55], "segmentation": {"size": [480, 640], "counts": "lm^77g>3L4L4L3M4J6K5M2M4H7O1N3J5N2N3N1O100O1N201N010N2K4N200001N2L4M3M3M4L3M3N2L5L3M4RO[B=g=BaB6a=H`B2g=K\\B1gmX1"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a bottle of Gatorade, which is a sports drink, sitting on a table. The bottle is red and has a white cap. It is placed on a table, possibly a countertop, and is the main focus of the scene."}, {"question_id": 195, "height": 640, "width": 427, "image": "000000333745.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [54.5, 144.26, 137.76, 358.93], "segmentation": {"size": [640, 427], "counts": "UTR1126ac06HDh\\O`0Vc0Ci\\O;Xc0Fj\\O7Uc0>K4m\\OTOmb0P1M4ZKDcE?Z:I`E8^:5REcNPMY1n=b0bDgNdMDMJ05l=j1`DbNjMCO1f=Q2ZDTNlME92KOJ3k=V2WDSNoMEOO20M435i=R2SDYOl;k0lCZOR<j0aCA]<e0dBWMG54W2`=`0bB4]=OaBbNK\\OO^Oe=d2bBZNIhN61J00>2Jb=g2eBSN6ZOCE25`=j2iBoLD73I=NF7JM3N26^=k2eBmLI2O0O34M<OCOO?0D45`=k2aB`MIE5IMT10UOe=j2]B`MLV10aNh=j2ZBWMNK1`11cNf=k2ZBlL010N02OO11OO11OS14TOd=k2ZBlLO2400O2ON8J`04@j=f2[BSMk0OmN21h00]O]=IRCl2S1TM_N1O0O2O92J98P=[2`DXMWNb01DOe0S=UOlB1O_28`M0O000000K0O2OO16OM3U1W=GfBa03`N310N10O2JO11N1050M4W1V=fNhB33OM14W1JiN6N0OO1Of2[>XMbAU1OPO4O0ON20e0NU1b>TO^AQO6N0N02Ol2Z>UNbAoN6N0O02O0K0Ok2=`MP=e0eBQO5M100000J2Nj3a:ZLWHKZMe0N^Oa1MbN0N2O00T3^:QM`H<RM@b1LaN1O0O11U3Z:SMbH?aNXOiN2I01T3Y:TMbHETMb0O@8N:0E1K00140K50o20kLU:>gH8ZMYO10O2O0KO114:Li2OmLT:?fH7ZMZO;2C1N3O92h2Q:[MfH4[M\\O3MM4N1O2O93h2m9`MgHN_MYO<3A20c01a2j9dMhHHaM[O;0E2O5J65l2o8UMmFDOT1d2]OaN]ORO3I43N2U3l8hN`IRN`MOO2e1MbNOKO2Z3l8oN^IgMdM3N2f1LaN0KO2Z3i8UOcIdMbMN^1ORO2CW3g8]O_I\\MgMO6Od00[O2JO1141OV3g8@[I[MjMM7O:0F0O6KM31OU3h8DVI\\MhNLZOON<0F0i1OZOk8f1TIYM[NHM0K6O001N011O00S1b0HZ8m1TIXMkNLYO0O<M20`0o0Mm7S2RIPMUNOi00[O0O1KO1h0OOZ14a7W2XInLF2WN2O9W2:e6^2TIlL1OZN5Q2=`6d2RIlL3N[N3T2<\\6P2VGTNm1]O`034:Y6R2VGbMN>P2@XN0d00\\O000O114^2NZM3l8Z2VGWNj1ZO\\NO:0E2OO20N113a2KYM6k8V3mHgLRO1XO1O10KN210OO64c2OT6X3jHhL]NLNO60L5N1O10LOO11OO2OO5i2NS6Z3jHfLSO0YO1O101NL0O1005j2KR6]3jHcLaNN:1D4MMNO150K0=j;S3iEaL@0RON132OH5j;[3gEbLl02]9_3dE_Lo02]9`3eE[Lo05\\9`3eE[LQOO00F001OO17e;_3dE[LQOOF001OO1196\\;_3bE\\L_OOYO01OO11OO7e;_3bE]LWOMB101KOO020N11N11O0O6k;_3cE]LiNM:2D000100NK2O5k;_3WEZLYO1LO0001OOK1024M20J>h1GQ8`3fG]Lh0;_OLR8Z3gG`Lj04eMKf1:S8T3kGdLg01gML37LJP1<h8d0ZFV1c1iMg03gMMNa00@c0?S9?^FT1d1lMc04gMMMW10_Of98aFS1R4RNjKNLQ2f9nM[Fi0:U1]1TNf0_2W7_M]Ff0=R1AXNi12XNMY2f2X7[M`Fd0`0T1Y1[Na0e2X7iMRGV1X1ZNYNNh1m2e7bMUGW1V1[N=i2Y7[M[FMo0b1`3W1`6fNQG`N>j2d8aNaI`1^6hMQEOc4X2]6hMQEMd4\\2Z6gMSEIP2DnM0^2l2a8gMUEFn1HmM1^2j2c8gMTECP2LkMN_2l2b8hMSE^OLO^18mNIW2k2^8gMUE]Oi07VO67DW2k2`MVMf:a0^E^O?m0\\OSO9OY2m2]MXMg:=_E_O>`0@D0K6OY2o2\\MWMh:=^EA;6j0MR1P3\\8[M]EB87d0EXO7FK20P2T3h8]MZED;KV1N\\N?o1h2j8iMaG^OEa2PNXMj:h0TGRO\\N>GDh1l2XNWMk:h0^GKfMYO`1n2`NXMl:f0^G6fMPOR1V3l9fMhGNXN]2Q:dMjG0PN\\2W:cMoGMhM`2[:bMQHKbMc2`:_MWHFPM@J\\3P;]M[HEoLm2h:^M\\HAmLP3i:^M[HAkLJBP3Z;bM_HAcLLGb1<WOk:I`HC`LJKX1f0VOSOI^;9aHGVLJ><Q1L\\NN_;6dHJoKLg23WM1a;3cH5hNCUM5e;HgH<fNLT=2lBNU=1lBMW=MnB2S=LoB3R=LoB1S=0Zcg4"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, gender, pose", "answer": "The image features a woman walking down a street while holding an umbrella to protect herself from the rain. She is wearing a pink top and a white skirt, and she appears to be in a hurry as she navigates the wet street. The woman is also carrying a handbag, which she is holding close to her body. The scene captures the woman's determination to stay dry and continue her journey despite the unfavorable weather conditions."}, {"question_id": 196, "height": 640, "width": 427, "image": "000000333745.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 0.0, 427.0, 447.72], "segmentation": {"size": [640, 427], "counts": "0j1l3XN\\:j1[DUNZN1UO6h1IZN1O00Oj;l1bF]NoMm2=mNk7JhI^NiMT33bLHg2OYMV8l1WJ^NfMd6P8mJ[J^NfMn2O<n7XN]J^NfMm22;k7ZN]J^NfMm20=m7XN]J^NfMn2N<P8WN\\J`NfMe6n7SJoGSO6K\\2;_Md6Q8mInGTOV3=jLa6S8SJoGRO02NL\\2<dM\\6X8XJiGEY2FgM\\6X8YJhGDZ2HdM\\6Z8XJhGTO4LLN\\2>bM\\6Z8XJhGPOn2<PM\\6Z8XJhGROl2:RM\\6Z8YJgGQO9LX2=_M]6Y8YJgGnNP3=oL]6Y8XJlJ[OlL]6W8XJmJ[OlL]6W8XJ]HmNi1>cM`6T8UJlGmNa00l1>cMd6P8QJSK\\OmLf6m7nIVK\\OlLi6l7jIYK]OkLi6l7kIXK[OnLi6j7lIXK[OnLi6j7lIXK[OnLi6j7kIZK[OlLk6i7jI[KTOkLN1T7i7jI[KROnLNOV7h7kIYKQOXMT7_7jIZKPOYMV7]7mHUHf0U3VOVMOGc5O_J2X1k7hNSHi0b3UO_Lj4\\1WKfNe0h7<kKi3ZLUKa1e0Z6=kKl3lMfKY6>kKd3YL\\Ko1:m5f0lK]3YLcK\\2Nb5R1iKX3P7hLPIX3SOgKo4R1mKW3ROQLi4g0QLnN`LZ4g2PLi4g0PLPO^LY4j:fLhHQO^LY4\\3hKk3P1[LoN^LY4[3lKi3l0^LnN_LX4Z3XLa3b0fLoN^LV4`3UL\\3f0VJoNY11eMU4l:jLUFROY1o3eMVLl:j0VFROX1X4g1dKh2R1YJROX1X4]1dK`L6]6l0^JSOW1W4l1eK_2Q1^JTOV1U4f8fLTFVOU1T4f8gLUFVOT1S4g8gLUFWOT1P4h8iLTFWOT1HjMj20]M0c0R;6PFZOS1FlMa1OfN0IZ1a0gN^OR;Q1oE[OR1EnM`1f1fNXN1V;i0lE\\OQ1DoM`1j1aNVN4U;k0kE]OP1CPN`1k1_NWN5S;l0kE^On0CQN`1`=_OaC_Om0W1b;[O`C^On0V1c;\\O_C_Om0U1d;\\O_CAk0_OTN_1c=A^CAk0o0j;_O[CDi0m0m;_OZCEh0@WNS1h=IXCDi0@XNQ1h=KWCFg0]O[NP1i=MUCGf0c0W<FSCGg0b0^5gN_OP1\\JHf0>b5jN\\OP1\\JHf0>Z<FPBTOP1i0e0=[<FPBTOP1i0f0WO\\Nn0o=NoATOP1i0n0J\\<9gASOo0j0POVOl1b0_<;fASOo0j0POVOl1b0_<;eATOQ1h0POVOk1c0_<;eATOP1i0POVOk1b0a<;dATOo0m0d0QOcN?Z>?`ATOo0m0d0SO`N:ND`>n0_ATOo0m0d0ROaN:a>c0[ATOo0m0d0QObN;`>c0[ATOo0k0R1VOg<k0XATOo0j0P`02Q_OTOn0k0Q`01Q_OUO6M203l0e`02P_OUO402N5k0e`08Q_O\\O0A2m0m`0Q2O0R_OQMk`0o2U_OQMk`0n24000000O100O10000O10000000000O100000oHeMmEH4Jl5h2R4RNPFWOn5g2P4TNRFUOn5g2P4YNRLROnI^2o9aNTLoNPJh0Mj0o9_OTLoNoI_2m9aNULPOnI`2l9_NULi1k3WNULi1k3TNXLk1j3TNVLm1i3RNXLn1h3RNXLm1i3SNWLm1j3iMoEDX6c2j3gMPFAO0W6h2i3iMoEA0NX6h2h3RNXLn1m:000000000000000000000000000000000]@YMm=g2SBYMm=g2SBXMn=h2RBXMn=h2RBYMjN0E01O000O11N1P>f2bCZMdN6IJ101OO1051Ik=h2fCZMcNa0KDO10Jl=f2gCZMcNOJW1l=a1_DZMlMMM;g=^2SEdMj:\\2VEeMi:[2XEeMg:[2YEeMg:[2UDXMVO?c<Y2VD[MXO;`<Z2XD\\MWO:a<Z2XD\\MXO9`<[2XD\\MTOKTO108`=`2XD[M@O\\<f2TD[M[=e2eB[M[=e2dB\\Mo2Lb5h2_G\\M4Nh00d7f2`G]MTOK00j10c7h2_G]MoN7k1CcM2h:g2kF]M\\NL:<Q2EdM1]4Li1i2_K]M\\NK;=;Cg02bN1T4NjK3V6d2aK]M\\NK;=8Hi0KcN4d3g0_2m1bK]M\\NJN1Mh0i0]O4LCND50L]3k0f2m1bK]M`Ng0e1XO_N?Y3HZLJX6c2`K^MaNf0d1^O[N:k0]O`1O^M02OZ6i2[K^MaNf0c1@YN:n0[O_10_M01OZ6h2\\K^MaNg0i0ROUO16>D:R1ZOWOMj14lMO0O2NV6i2`K^M`Nh0Q1TOkNN32NOOf0o0\\OVOLk14lMO000OW6g2`K_M^NIKo0X1POnN2d02[O8n0ITOMm15mM0V6b2`K_M^Nm0Y1mN^ON]O:;FI5JNm13mM1V6b2`K_M^Nm0KkN[13_O1]O6=FI5FKO34Me18UNOW6b2`K_M^NIKk00WO1N7O?1_O1;NF6N50Eg05WOKO24Ob1b0`4V2_K_M^Ng0LSOT1NSO0Q1:JKPOKO43Lf18UNNX6c2_K`M\\N3M43Bg28ZNJRO1m1LnM113V6d2_K`M\\NLMM88j20iMF]O2O3l1LoMO11Y6h2[K`M[N17OLGg29dNLc0LoMO11Y6i2ZK_MZN31E480Gg29eNL`0MQNO01NOX6i2^K_MZN83I2F^20cM:[1L?LQN013V6d2_K`M[Ne03SO7Og11oM>^1Dc04oMOU6c2`K`M[N<NB5K6Nk00\\O0E2I>g0CNN_16nMOU6d2_K_M[Nf04UO3Md0O\\O00000Od0`0_ONN\\O0l1OTN71OU6d2_K_MZN`00\\O5LK17O1O00K00050O1000c0M\\O=25N\\O1k1:SNKX6d2^K_M\\N:1D5JKO00i00\\O0000000J?f0AO0^17lMOW6e2]K]M_N81@05N4[22[1KYLMX6n1fIhNd1_OcNOIL6MO5N4\\21lMFQ31eL110Y6j2YK\\MbN65HF6]2NlMHQ30eL011Z6i2YK\\MaN76FF:j0BO0G9HIQ30fL001Z6h2ZK\\MaN85DI8T1DQO0O160C:9HP36gLKZ6h2ZK\\McN0JK91]1N`NN104?MAJ0T39iLMX6g2[K[MeNOJL1M04d1O`NM104`0G@O110d21dM7EMX6g2[K[MeNNKL35j0ID4BM105?GAOO10e22cM7EMX6h2[KYMeNOKL36h0JTON0174ML10LO4`0KB5Na22bM`0n5\\2[KYMeNO6JC3o0NQO02O74GM106O4`0G@52^2OfM?m5^2ZKYMgNLMMY15UOK9=ZOCK2R37kLJ[6l2WKXMjNIL0X16SOK<<XOCK3T35jLK[6l2WKXMg0NZNM;;[OHl2:U3a2WKWMhNJa1OXN87JI2k08\\OIl2:U3a2WKWMhNJf10fN468WOC53m2=V3a2VKVMCMPOMb14cNK5`0DB1NY3:eLKY6m2VKVMB3g0G`NN00Ja0OA0OZ39fLKW6m2WKVMB3e0IbNL00Ja0NB1NZ39fLKW6n2WKSMkNJ80@:d1KaNL00Ke0]3DaLLX6m2WKSMD2f0K_NM00Je0^3E`LLX6m2WKSMKK^1<m0L[LLY6o2UKRMh26_OM[LKZ6P3TKRMh27]OM]LJZ6Q3SKQM2J;2lN<m22g2e2SKQM2JU1`0hN@g0a0V4f2RKoLOOW1`0hM[OM241K4KL1NY10lN:JKX6Z2iITNZ1BlNJi05]1KeMh05XON51m0l0QORO:LIX6[2hITN[1@M0g0K^N0Eh0<]OHm0m0POROb0S6n1hIRN[1AoNK84A1m1KSN050Jg0=^OGOJh02TOn01UOc0S6d2SKmLMOh0LbNf0M_OET1MhN2Oc01@a0S6g2RKkL]O1BO<M]OOe1`0YN@>f2JiMP6k2QKjL^O1B17O_OOg1;kNW2HhMo5m2PKiL_O1BNGM`05_ONP1MF?HADf2<]MB2Y6V3PKiL^O1DMGN?5_ONo0NG>[OA91H8OR2b0iMf5X3oJhL_O1?NkNOn0OG>HAD6=Y1APOR7m2VJhL_O1h1MVN=MD20A94DM3L<o6m2WJhL^O1j1MlMNF1O?2A929Mc01kN=n6o2VJgL_O1j1MlMNF2N>2B:09OB0K0001O50Jg0o6f2VJgL]OM\\O3`2NlMNF2N>0C=O4NA11OO2O00O11N11OOg0P7e2VJfLAOj1O`MO7OO?JB=170AOL1OO1292G9n6Q3UJeLVO3_2JWM1?<l0EZON74S6\\3SJcLXO3_2JWM2>;m0FZOL75S6]3RJbLXO4_2JXM0`0;b0CTO3?N74S6]3QJcLYO2`2KWM0`0;b0CTO39NA1n02Q6_3PJbLZOLF2k2OVMO7OO?j0CUO04OJOM3m02R6_3oIaL\\1KfN1ZO1K=MC9N02JO32OOf03R6_3PJ`LWOLf10UN2O0j0O_O3J<ND9L12JOM2N07O9NI6f6_3oI_LZ1OhMOj0O_O3Jc08YO10J1K3ON8O9OI6d6`3oI^L[1OhM0h0OA4H:ND=L91\\O74Ha00\\O036i6`3oI^L]1LeN2ZO3I;NCZ1OgNO4OL3>MK6d6a3nI]L`2OnL0H<f1B\\N7g0NS6a3nI]L`21cLL71L=f1DZN5j0MR6c3mI\\La24jLJM<e1EZN5j0MR6d3lI[La24kLLM9f1EYN6j0MR6d3kI\\Lc27eLH1:Z1BmN3H7j0KS6e3jI[LH2EIU2f0eMJ4Cn0OVOb0b0AU6f3fIVL[O4?5CIc0OANT1?fN83^On0MWOc0a0AU6f3fIUL\\O4>7DFc00m0=_N72^Ok0LTO18`0b0ER6g3eITL]O4>9;DBNj0>oN6O@k0LTO1004>>AC6g6h3dIZLM5i0CM9lNH:=JCn00POO2?i0GP6h3dIZL4I\\OO_21VN;e0EmN:j0Kk5i3cIYLd0HO2KNJ;c0FmN2G2U10i5k3bIXLf1HmM1m0OJ:EF=0]O3G1V11h5l3aIWLg1HmM0n01H9FF=0]O3G1U1NkN0n6o3aIWLg1HmM0m02QOOd09JF=0VO208T1GjN1n6o3aIWL2HM5`0L^OO:2ZO12M:>ICK1P10QO>U1Eh5l3aIWLHH025>8AH185^OI:>IHOJd03XO?V1Cg5n3`IUL4IHa0<_OG274^OK:<JCK24Me02XO303T1Oh5m3_ITLa08JAF165^OK:<JBM3h0MXO1032MN0j0O[O7f6n3^ISLb0JSO;f0D>1lN03N:=HCM6Q1J60nN7f6o3]IRLP1MZOO?LPO0?>BCL8Z2GSN4_6R4]ISLR1LXO0X1:XNNU2DUN3_6S4]IQLS1LWO1X1:\\NIS2HSN4_6T4]IoKS1MWO5T16`NFf2No3V4\\InKU1LWOO`0NC`0_OEg2No3W4[InKR1IhN0k11iN?]O_O04k20o3W4VIQLV1Fh03YNKNa0K_OO3^1M@0^O4_6W4VIgKN6V1Mi0NQNM90Na0O@Y11N2_5W4VIfKO7U1Nh0L^NNL0I>5BY12AN[O4a6X4TIQLV1JOJ@1GNL1H=5Cl22k3h4]JZKI9QOB21NO>a0DBk20l3h4^JYK^Of0XOWO;14>FDk2Ol3h4_JXK^Of0WOXO50N0=?FDj2Nl3i4]KQLlMUONO?`0CDk2Mm3j4]JYK_Oi0[OTOOO>a0DCk2Mm3j4WIVKm07AO_OKOc09[O8a0CDl2Ml3i4XIXKj06COEJK?`0_ODc0LEo2Jl3i4XIVKk0:AMBH02O=b0A@f0NAo2Kl3i4XIVKk09BMBIO2O<c0B^Oh00^Om2Lm3i4XIUKl0:AN@92Ai0a0XOAl2Nl3W3UIhL2:MH2b0X1@XOe0d0HnNBl9T3YFQM0;Q1AXOd0f0XOhN=4BM1o9W3YFQM1:Q1AWOf0h0DjNFl9T3YFQM1:Q1AWOf0AWOQ1<QOHj9T3YFPM1;Q1BWOf0@YOo09UOFj9Y3UFlLNI0c02]On08\\O5B4l0NZOBi9[3SFRM052^Ok0:^OJDJ6?d02[OBh9Y3VFmLLK0`04]Ok0<^OIDJ6?L@c0b0_OCi9X3VFmLLK0`04\\Ok0>^OHDK5=MBc0a0_OBj9Y3UFlLNJ0a02\\Om0=]OIDL4<h03WOCj9Y3UFkLOI1c0V1FTOI15l02hNLl9X3TFhL9>n0FSOJ13Q10dN0l9W3TFhL:=n0BVO0M0S10cN2k9X3SFgL;=n0BkNK356NS12bN2k9W3TFiL9<o0BgNi02VO[15dNNl9W3TFjL7<Q1f0eNlN[18fNLk9T3XFjL4=L]On0a18mNfNKo2Fj3]3[IjL5<K]Oo0c16kNhNLb1EG1_5S3WITM415:K]Om00QOc1X1kNhNKb1GF1_5]3ZIlL69R1m02nNfNNe9R3XFoL96Y1AfNN9Oo0ObN<20c9`3cFgLm3^OmK902c9`3dFfLe1_OQN020l1:VNOd9b3bFfLd1EQN03Ic1:`NJKNi9j3`FgL\\1]O]N0O`01@a1=aNGLNi9f3VF_L1`0e1ZO`N?M@`1?aNIg9`3UFZM3POZ10hN>NA`1>aNHMJU2OZ5h3`HZM3POZ10dN0O`01_Ob1>aNHMKf9j4\\FTK\\12bNh02VOi00D?DGNLe9i4oGUK]N0O2N61Jf1=]NGOJe9k4bJcKjKFk9g4[JcKkKDk9i4[JaKkKFj9i4[JaKjKFl9j4YJaKjKGk9h4TFVKo3<RLGj9g4UFWKZ1NiN10000e0N\\O24<IGj9g4UFVK[1NjN0K0O150e0OWO0O1:=HHi9f4VFUK\\1OiN0J2OO2OO16O50F0O10001562NOJ[9l4`FTKc30gL313_9e4RKXKP5h4PKVKR5j4nJVKR5k4lJVKT5j4lJWKS5i4SFTKQ20\\O0hN132J1j9h4TFVK[1OiN0O1001N:1F5KM81J1<Kl8l4gFUK\\1OiN0K0O2OO114O;0F1J00093J14JK2Y9j4gFUK\\1OiN0J2OO11OO2OO11O50J150K1OO1053M2OJO102Z9i4hHTKnM11OO1501O00O1LOO1:3H2OJe9k4VIUKZM0d01@150T9i4QIUK`M200e0OBO01D1d9i4YIVKYM1c13l7g4VIVKZM0c14n7f4lHYK_M2NOh0JE2m9j4iEUK\\1OiN0O2JO1j0:VOJ33OQ:i4iEVKg0O]OO02O3MT14mNJ24MT:g4jEVKg0NG1F1JO0Y11hNO0O10a0Y:X4jEUK[10iN1J0O10R12mNO0Og0Y:S4jETK]10gN1LOOY10hN1OO?0EX:[3gEjMo1gNWN4Km0=ZOT:S3_EmL0?W2ZOjMk0=\\OS:S3_ElL1`0V2ZOjMm09[OX:R3^ElL0a0W2\\OgMj0;ZO[:U3ZEkL1a0W2b0oMfNf:i3SEPM3UO[1NjN0Of1k:V3QEWKf0MH2E0Oe1m:U3QEWKY1NkN1J0Oc1T;W3oDVK[1NeN0O10g1S;T3nDVKd10YNb1Z;X3jDUKc1a1i9Z3eDTKb1i0YN\\O060Ga;j4]FmKTNK_;X4]FnKSNIa;Y4[FcLg9]3_DWKZ1MgN_1b;]3\\DYK2M2090Gd1`;V3\\DYK<K41Dd1a;W3[DYKa0KJ0E10d1e;W3\\DVKZ10cN]1i;]3PF`LR:`3nE_LS:a3mE]LU:c3fEVK\\NW1o;c3dEaL]:_3SD\\KS1S1l:a3QD]KNGS1W1P;e3nC]KZ1i0i:j3mC\\K\\1i0g:k3nEkKS:T4RFeKQ:[4PFcKQ:]4PFaKQ:_4oEaKQ:_4TFWKQ:h4d20000000000O1000000000000000000001O000000hLl@aN0N2k2R?fNl@cN3g2Q?eNm@dN2g2Q?fNl@dN2f2R?fNm@dN1f2Q?fNn@dN1f2Q?fNn@dN2e2P?gNn@eN3c2n>hNo@e1Q?[No@e16lL_>_1[Ae15XMQ1L`;W1[Cd14YMP1N`;U1\\Cd15oLI2S1JmN=e<U1\\Cc15ZMk03c;Q1_C_11jM>Om;h0fC]1OPNN;Y<:hC[10BW<TOhCZ11BW<TOiCY11lMMTO52Nm0Z<f0oCQ1OZMG1N16Ne01VO0O11OO0`=OSDa0]NG08g?"}}, "object_label": "bus", "attribute_label": ["color:blue", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The bus in the image is a double-decker bus, which is a type of bus with two levels of seating. It is parked on the side of the road, and a woman is walking past it."}, {"question_id": 197, "height": 640, "width": 480, "image": "000000336265.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [241.1, 301.81, 32.18, 62.11], "segmentation": {"size": [640, 480], "counts": "Ubg43kc0<D:G9\\OQOf]OQ1Wb0TOe]Om0Zb05f]OiNZb0Y1f]OfNYb0b1O2N2M3N1O01O00001O1O2N:E2O1N1O101M2N4D;L4J6MmQQ4"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, pose, gender", "answer": "The image features a young boy wearing an orange shirt, standing in a grassy field. He appears to be enjoying his time outdoors, possibly playing or exploring the area. The boy is holding a frisbee in his hand, which suggests that he might be engaging in a game of frisbee or simply playing with it. The scene captures a moment of leisure and fun for the young boy in the open field."}, {"question_id": 198, "height": 360, "width": 480, "image": "000000338905.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [365.4, 223.2, 114.6, 136.8], "segmentation": {"size": [360, 480], "counts": "UoP43P;7L4L4M1N2O2N1O1O1O1N2O100000000000001OO101O01O2aNWO[Hj0b7ZO\\Hh0`7\\O^Hh0\\7[OdHe0Z7^OdHb0[7AcH`0[7DcH<[7HbH:[7M_H5^7NaH2]70bH1\\71dH0X73gHOW71jH0S73lHNQ75nHOl64RI0j61VI1f62ZIMe64ZILf65ZIQNEg1Q7:XIHh69WIGi6:UIGk6;PIHP7X20000001O000000001O00001O1O001O1O001O1O001O1O1O001O1O1O1O1O2N2N2N2N3M1O2N1O2N8H1O1O0000001O001O00001O1O1O001O1O1O1O1O1O1O1O2N1OTG"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:curly/curled", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose, gender", "answer": "The image features a woman sitting at a table, eating food. She is wearing a black shirt and appears to be enjoying her meal. There are other people in the scene, with one person sitting next to her and another person standing behind her. \n\nIn the background, there are two motorcycles parked, one on the left side and the other on the right side of the image. The presence of the motorcycles suggests that the location might be a restaurant or a gathering place for people with a shared interest in motorcycles."}, {"question_id": 199, "height": 360, "width": 480, "image": "000000338905.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [20.22, 287.06, 131.06, 69.57], "segmentation": {"size": [360, 480], "counts": "f^21V;10000000000000001N10O100000lN0PG0Q91mFOS93jFOV91iFNX94fFL[95cFK]97aFI`98^FHc99[FGf99YFGg9;WFEi9>TFBm9>RFBP:;QFEo9:hEE42S::iEF20]9NUGO]O81IO2\\92[G2ZOKN1\\95[GO[OIO3Z96\\GN[OHO3NM[9=\\GK_OKU9`0YGDBLT9b0ZGBALU9c0gF[O>6FLKM\\9g0SG_OFOW9c0SG^OD0Z9`0SG@DO[9>RGCCMLMT91UGa09DAMMMT92UG>:F@MMMU91VG<9I_OMMMd9`0lFFCMMMg9b0eFDFOg9;cFFFOi99aFHFMNMn9;^FKFMT:2VF1FLh:4XELh:5WEL[:0lE4ILOMf:8[EKOMe:9\\EJOMd::]EHf:8[EGd::[EGe:9[EGe:9[EG^9OeG9nNI\\9MgG:mNIc:7]EIc:7^EGc:9600000YEH^:8cEG]:891000000000000000O10000000O100000O10000000000000O1000000000000000O1000000000000000000000000000000001O0000001O010O0010O10001N3N000001O1N02O0O2N1O3MRZc3"}}, "object_label": "chair", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency, material", "answer": "The chair in the image is a wooden chair with a black seat. It is placed in a room, and a person is sitting on it. The chair is positioned near a dining table, and there is a person sitting on the other side of the table."}, {"question_id": 200, "height": 360, "width": 480, "image": "000000338905.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "length, material, pose, texture", "region_anno": {"bbox": [238.84, 242.9, 13.01, 58.34], "segmentation": {"size": [360, 480], "counts": "hYd28j:7ZOEmEm00POi9^1L2M3M4O11M2N2Bf0F8H3@Tb_2"}}, "object_label": "bottle", "attribute_label": ["length:long", "material:glass", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, texture, pose", "answer": "The image features a bottle with a yellow label, which is placed on a table. The bottle is positioned in the center of the scene, and it appears to be the main focus of the image. The table is covered with a cloth, and the bottle is the only object visible on the table."}, {"question_id": 201, "height": 420, "width": 640, "image": "000000353180.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [409.97, 188.54, 95.88, 187.7], "segmentation": {"size": [420, 640], "counts": "Z]Z55m<3O0N3N101O2N1O2N00H_CK1N]<6dCI13Y<5lCKS<7fCE24W<e0O001hCZOP<T1I3M2N3M5K4L3N3L4M3L6K3L4L3M30O1ON3M4N7G6J2N2N1L4O1O2N1O1O2MULjFk3T9VLoFh3o8ZLPGg3P97O001O0000SLWG_3i8`LYG_3h8^L[Gb3T91O2M3N3L3N8G3N001O2N0001O10O03Mg0XO;F6J7H6J?A7I:F3jNdD>_;[OgDc0n;N3N2M3L6Gh]g1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, pose, gender, maturity", "answer": "The image features a group of people gathered around a vehicle, with one man in the center of the scene bending over and holding onto the back of the vehicle. The other people are standing around him, possibly assisting or observing the situation. The man in the center is wearing a tie, which adds a formal touch to the scene. The group appears to be engaged in a collaborative effort or a shared activity, possibly related to the vehicle or the road they are on."}, {"question_id": 202, "height": 480, "width": 640, "image": "000000369442.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [266.05, 214.12, 23.98, 92.87], "segmentation": {"size": [480, 640], "counts": "hnl38U=OVD2h;9nCHQ<g0`C[O^<l0[CUO_<i1M6L3M1000K51O1O5`CaMU<f20eMlCi1S<TNRD=Kb0S<nNZD5Jk0m;mNUER1k:kNYE=dN2h=K\\B2k=FZB6PUU5"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, pose, hair type", "answer": "The image features a man standing in a dirt field, wearing a white shirt and a pair of shorts. He appears to be looking at something in the distance, possibly observing a cow or another animal. The man is standing near a pile of trash, which is located in the middle of the field. There are two other people in the scene, one standing to the left of the man and another person standing further to the right."}, {"question_id": 203, "height": 480, "width": 640, "image": "000000369442.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [375.83, 136.97, 16.63, 27.84], "segmentation": {"size": [480, 640], "counts": "^k`5;c>8I3M2O1O1O000001O1O1O2M2N4J`Sd3"}}, "object_label": "stop sign", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:blue", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material, color, pose", "answer": "The stop sign in the image is blue and white, with a red circle in the middle. It is mounted on a pole and is positioned in front of a building. The sign is clearly visible and stands out against the background."}, {"question_id": 204, "height": 458, "width": 640, "image": "000000447314.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [46.48, 289.86, 83.37, 115.57], "segmentation": {"size": [458, 640], "counts": "b^d05T>2N1N3N1O1000O01O000010O0010O10OQDEP:<PFEn9;SFEl9<TFEk9;ZEL]OIX;;XE1_ODY;;VE4@AY;;PED]Oc07@[;8oDT1o:lNnDX1Q;iNkD[1T;fNhD^1W;cNdDc1Z;g000O000M3O101N2O1N101O1N2O10O000GQEXMo:c2YEZMg:e2?N3N1O2M3N2O1O10lDdM[:[2dEfM\\:Y2eEgM[:X2m0L3L5G9E;N200WORC4R=ZO^Cd0W=M3M0000O001N1001O1O1N2N2O1N2O2MRfT7"}}, "object_label": "person", "attribute_label": ["gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a young girl walking on a grassy field, wearing a pink jacket. She is holding a cell phone in her hand, possibly playing or using it for communication. Another person is visible in the background, standing on the grass and watching the young girl. The scene appears to be a casual, outdoor setting where the girl is enjoying her time and engaging with the cell phone."}, {"question_id": 205, "height": 458, "width": 640, "image": "000000447314.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, pattern, size, transparency", "region_anno": {"bbox": [484.98, 317.86, 32.12, 39.18], "segmentation": {"size": [458, 640], "counts": "YXi64R>4M4M3L4N1N3M2O2M2O2M3N100010O100O1O3M2TOcBh0`=O00001ZOcB>e=O1O2N2O0O2MkSg1"}}, "object_label": "kite", "attribute_label": ["color:green", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "size:small/little/tiny"], "control_dims": "pattern, transparency, material, size, color", "answer": "The image features a colorful kite flying in the sky. The kite is shaped like a hat, with a distinctive design that makes it stand out. It is soaring high in the air, capturing the viewer's attention. The kite's vibrant colors and unique shape make it an eye-catching and enjoyable sight for anyone watching it fly."}, {"question_id": 206, "height": 427, "width": 640, "image": "000000455624.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [522.24, 132.78, 41.62, 65.59], "segmentation": {"size": [427, 640], "counts": "gRk61e05h;NPD:o;ERD<k;FTD;^<000OBWC<i<3O1O1jNGYE9f:MUE4j:1PE0o:2QENo:2lD\\OFc0];1mD3T;MlD4S;LlD7Q;JmD9R;GmD:S;FkD<U;EjD:W;FhD;Y;k0001O001O0O2O1eNcDe0_;WOeDh0^;QOjDk0X;ROkDl0k;N3N3Ja[P1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, hair type, gender", "answer": "The image features two men standing next to each other, both wearing baseball caps. One of the men is wearing a red jacket, while the other is wearing a brown jacket. They appear to be engaged in a conversation or enjoying each other's company. The men are positioned in front of a field, which suggests they might be outdoors or attending an event."}, {"question_id": 207, "height": 427, "width": 640, "image": "000000455624.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [418.36, 133.98, 32.89, 48.45], "segmentation": {"size": [427, 640], "counts": "bY_51f<2iC2S<1jC2R<4hC0V<4eCOX<e0N3L100O2O001O1O001O001O0000M4N1_OoCGS<6QDGR<6PDIP<6RDHo;5VDIj;O_DOb;0l002O1Mde^2"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity, gender, hair type", "answer": "The image features a man wearing a red jacket and a hat, standing outside in the sun. He is looking down, possibly at the ground or at something in his hand. The man appears to be wearing sunglasses, which suggests that it is a sunny day. The scene takes place outdoors, with the man being the main focus of the image."}, {"question_id": 208, "height": 479, "width": 640, "image": "000000468632.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [292.13, 140.69, 125.65, 269.57], "segmentation": {"size": [479, 640], "counts": "_XY47f>3M3M3M3M3M3L3M4N2M3N2N3M2O1O1N1OZOfBJ=_OV<g0`CJ8BU<e0fCG3FU<d0jCEOJT<b0oCCJNV<?QDCE1Y<>RD5n;KTD3k;OUD0k;4RDJn;:PDEP<=nCCQ<a0lC^O^;\\OiDY1FZO`;BfDU2X;oMfDQ2KcMU;>oD]2k:eMSE^2j:dMTE_2i:cMVE_2h:o0M2N2M6K3M3M3M001O1O1O102M2O1O1N203L3M;E9H3N0O10O6JkGUJS7m5hHWJV7k5gHWJY7k5bHXJ]7j5`HWJ`7j1UHh18_Lc7g1WHm11]Lh7]1aHk2^7mKjHKKW4\\7lKlIS4T6nKlIe0`Nk1c7`MnIc0fNFAS1l7cNoI`0SOTOF^1X7nNPJ?5<k5UOPJ>;8e5YORJ>=6`5\\OTJ=?4]5_OTJ=b02Y5AVJ<d00V5DVJ<f0OS5EXJ:BZO]Od0i6HXJ:@\\O@b0g6HZJ8[OCE<f6IZJ8VOHL6c6J\\J;nNI31d6J\\J;hN08Kc6J]J;ZN>@jNT1b0e6K^J;TNe0l0ROb6N_J:QNh0P1oN_6NbJ;lMj0V1jN\\61bJ<iMl0Y1gN[61dJ<fMm0\\1eNZ62eJT2SOhMX64fJS2ROiMX64gJR2ROiMV66hJ\\1gMeNZ1IW66iJX1mMhNQ1IY67jJS1RNkNk0KY67kJP1SNnNj0JX68lJl0VNQOg0JW69mJi0XNTOd0HX6;mJf0ZNVO]83[Id0ZNYO[83\\I`0]N\\OW84]I=_N^OT86]I9aNBQ86]I6dNDo76^I3eNGm76_I1eNIl77_IMgNLj78`IHhN0h78aIEiN2g79]KFc4;\\KEd4;]KCd4<]KDd4;\\KEe49Q5O2O1N2N]TX3"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, hair type, maturity, pose", "answer": "The image features a man wearing a gray shirt and black shorts, jumping in the air while playing baseball. He is in the middle of a jump, possibly attempting to catch a ball or hit it with a bat. The man appears to be focused and determined as he engages in the sport."}, {"question_id": 209, "height": 640, "width": 329, "image": "000000500478.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [0.06, 179.44, 33.02, 64.04], "segmentation": {"size": [640, 329], "counts": "f5j1Vb00O1O10001O00000001O001O100O5_Ng]OR1db0O1O0O3M2K6N1O2N2N2N2N1O2M5K6J3Mk\\i5"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, hair type, pose", "answer": "The image features a young man wearing sunglasses and a red shirt, sitting in a stadium or an arena. He is looking at his cell phone, possibly checking messages or browsing the internet. The stadium is filled with numerous chairs, some of which are empty, while others are occupied by other people. The young man appears to be the main focus of the scene, as he is the only person in the image actively using his cell phone."}, {"question_id": 210, "height": 480, "width": 640, "image": "000000540932.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [175.47, 261.83, 23.27, 19.21], "segmentation": {"size": [480, 640], "counts": "gWc21n>1F2bAN\\>4801O[AL_>4]A0b>8O000L4N3O00O111N5L0O2N2M3N2M[^^6"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, pose", "answer": "The image features a man sitting in a boat, holding a paddle in his hand. He appears to be focused on rowing the boat, possibly enjoying a leisurely activity or engaging in a sport like canoeing. The man is wearing a black shirt, which contrasts with the white boat he is in. The scene captures the essence of outdoor recreation and the man's connection with nature."}, {"question_id": 211, "height": 432, "width": 640, "image": "000000558213.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [133.04, 249.97, 26.48, 74.43], "segmentation": {"size": [432, 640], "counts": "nih14W=6A>M3O3N8H7gChNl;_1D;00OIdDZN^;^1>O22M4MaNWD[1m;1XD_N];c1^DbN`;g11O1lNmDC_OJg;=nDE];8fDF];7fDEj][6"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, gender, maturity", "answer": "The image features a shirtless man standing on a bicycle, possibly performing a trick or simply enjoying the moment. He is wearing black pants and appears to be in a park-like setting. The bicycle is positioned in the middle of the scene, with the man standing on it and facing the camera."}, {"question_id": 212, "height": 432, "width": 640, "image": "000000558213.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [246.68, 343.93, 50.71, 17.77], "segmentation": {"size": [432, 640], "counts": "gSX33]=1O1O01O0000010O0100O2N10002M003L100002N1O01OGnB3R=NoBMU=3kBMT=4401O01eBLX=70O000000010O01O2N01O0000001O0001O0002N2N0O2O001O1OhW^4"}}, "object_label": "skateboard", "attribute_label": ["color:brown", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, pose", "answer": "The skateboard in the image is a long, narrow, and black board with a white stripe down the middle. It is being ridden by a person who is wearing a black jacket. The skateboarder is in motion, possibly performing a trick or simply enjoying a ride. The skateboarder's shadow is visible on the ground, indicating that they are moving at a considerable speed."}, {"question_id": 213, "height": 640, "width": 429, "image": "000000559160.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "gender, hair type, maturity, pose", "region_anno": {"bbox": [185.03, 179.11, 175.89, 408.8], "segmentation": {"size": [640, 429], "counts": "bke38dc08J4fA_OP9d0SF^OlKj0f=L\\FZOnKe0OYOf=j0\\FUOSL?M@?0h<m0RGAh9a0XFYOk9i0WFTOi9m0XFROf9o0\\FoNc9P1[FWOeKIc=R1`FHkKWOZ=Q1eFPOoKS1W=ORG0k82\\GiN`Ke03ZOQ=Z1`FgN[M2QO:W=P1]FeNiM0jNNe<d1dF^NXNNR;f1fF]Nn:h1QEYNl:f1WE]Nd:a1aEaN[:_1gEdNT:k0^FVOmKDK3T=S1UGXOiKNo<i0[G\\ObKLQ=h0^GDaK\\OQ=o0`GCaK[ONMP=T1bGM_83cGNZ81hGMY82jGMV82lGNR81PH2l70TH1j7OVH2h7OYH2d7N\\H4c7L]H4d7K\\H6b7HaH8]7IdH7[7HfH:X7HhH6Y7JgH7W7KhH5X7KhH5W7JlDKh1=Y90lCfN?W1[23X9JkCC5=KmNl2Y1Z9JjCS1k2SOZ9W2dFiM[9GmC^1f2kN]9[2bFeM]9^2aFbM^9b2`F]M`9j2YFUMh9n2UFRMi9W3PFjLo9]3jEcLU:c3gE\\LW:i3fEWLZ:k3eETLZ:Q4bEoK]:V4_EkK`:Z4\\EeKd:`4WE`Ki:d4TE[Kl:i4PEXKP;k4lDWKR;n4jDWKP;n4kD^K\\1XN_7`6oFfKS1oMj7U9lGnFS8X9VG]F1a0h8[:01O0O100O1O1O2O000O100O10000O100O1000000000eLhGRJGfN`8W7[H_I\\OWOY8Y7WI_HgN7R8Z7WJeHi5Z7XJfHg5Y7\\JfHd5Y7^JfHb5Y7_JfHb5X7`JhH`5U7dJkHS5GfG\\7Y3lHo4KhGU7]3PIg4OlGo6d1kHN7`62mGi6i1lHL7]6]7fK`H[4]7T4N2O1N1O3N1N3M3M3M3C=N2L4G9ROn0I7N3N12O2M4M2N2M3N2N2N2N3WCbJk:_5REaJo:c5e12VG[JU3_1^Gb2T>^MlAd2S>[MmAf2m0jKT<n5fCTJ[<_1oBV34^Kl<[1RC<7P1e<dNTC6`0V1Z<cNXCNh0^1n;eN[CGo0a1f;gN\\CEU1_1_;lN]CB]1\\1V;QO^CAc1Y1n:VO_C_Oj1W1g:YO`C]Oo1V1b:\\O`C\\OQ2V1`:\\ObCZOT2V1[:_OcCUOY2Y1U:_OfCRO\\2\\1o9_OWG<k8BYG;i8@^G:e8D_G8c8F`G6d8DaG:b8CaG7e8CaG:WK[Om<0YH9QKGfj11hhN4G11N2N[\\ON]c00c\\O1enV1"}}, "object_label": "person", "attribute_label": ["gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, gender", "answer": "The image features a young man wearing a black and white shirt, riding a skateboard at a skate park. He is in the process of performing a trick, as he is seen jumping in the air with the skateboard. The skateboarder is the main focus of the scene, and his skateboard is clearly visible beneath him.\n\nIn the background, there are two other people present, one standing closer to the left side of the image and the other person further to the right. The skate park appears to be a popular spot for skateboarders to practice and showcase their skills."}, {"question_id": 214, "height": 480, "width": 640, "image": "000000046252.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [205.84, 131.05, 30.41, 64.54], "segmentation": {"size": [480, 640], "counts": "TfP34k>3N3M3M2N3N1O1001O010OO12N2N0O2O100O2N10O01O0001000N1N3MRem5"}}, "object_label": "baseball bat", "attribute_label": ["color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, texture", "answer": "The image features a baseball bat with a black handle, held by a baseball player. The player is wearing a red helmet and a red hat, which are both visible in the scene. The baseball bat is positioned vertically, with the player holding it in a ready stance, likely preparing for a swing. The player's focus and determination are evident as they grip the bat, ready to hit the ball."}, {"question_id": 215, "height": 368, "width": 640, "image": "000000051712.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [78.85, 259.11, 251.47, 73.45], "segmentation": {"size": [368, 640], "counts": "f[m03\\;2O1O10O0100O0011N100001OO3NO1O01O010O0010O0010O01O010O0010OO2O1O1O0O2M2O2O00001ODRE7m:ISE7n:IQE8n:5010O001O0ASE;R;0O00001O00001O00010O0100O1O4M00O000100O01O0010OBIcE7\\:KcE6]:JbE6_:IbE6]:HfE8Y:IgE8W:IjE6V:JjE6h:001O00000^OJjE6V:JkE5U:KlE5S:KnE4R:LnE4h:O01O01O0000010O0O11O0000010O00O1100O0000001O00000001O010O0000001O0O101O00001OO1000001O00001O100O1M3N1N2N2M300O2O010O000000001O000000010O001O01O0001O0001O0001O0000010O0000001O00001O01O000001O0001O0001O0001O01O00000010O000001O000000O100O1O1O1O1M3O1O1001O001O00000O2O00000000001O000O11O00000O100000000O2O0O2O1N1O2N3L[S_3"}}, "object_label": "skis", "attribute_label": ["color:red", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, material", "answer": "The skis in the image are red and white, with a red stripe down the middle. They are designed for downhill skiing and are being used by a person skiing down a snow-covered slope."}, {"question_id": 216, "height": 480, "width": 640, "image": "000000055528.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [550.68, 420.27, 86.5, 59.73], "segmentation": {"size": [480, 640], "counts": "kgR84j>2N2O1O1O1N2O1O1O1N2N2O1N200O1O100O1N2O1O1O1O1O1O1O1O1N2O1O1O1O1O1N2O1O1O1N2O2N1O010O100O10000O100000000O10000000O1O1N2O1O2N1O1O1O1O1O1O1N2O1O2N1O1O1O2N1O1N3M3M2O2N2N3L3J9I_`0"}}, "object_label": "remote", "attribute_label": ["color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, color", "answer": "The image features a close-up of two remote controls sitting next to each other. The first remote is larger and has a more traditional design, while the second remote is smaller and has a more modern appearance. Both remotes are placed on a table, with the larger remote on the left side and the smaller remote on the right side. The remotes are likely used for controlling various electronic devices, such as televisions, DVD players, or sound systems."}, {"question_id": 217, "height": 480, "width": 640, "image": "000000055528.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [152.58, 430.17, 117.05, 49.83], "segmentation": {"size": [480, 640], "counts": "nhV21o>000O100K2XANg>600O1O100O101N100O10000O100O10000O100O1O100O100O1O100O1O100O1O100O1O1O100O1O100O1O1O100O100O1O1O100O1O100O1O1O1O100O1O1O1O1000000001O001O1O001O001O1O001O001FZBXOf=g0\\BXOe=g0[BYOe=f0\\BZOe=e0[B[Oe=d0]B[Od=d0\\B\\Oe=c0[B\\Of=c0[B^Oe=a0\\B^Od=a0]B^Oe=a0[B_Oe=`0\\B@e=?\\B@d=?]BAd=>\\BBd=>]BAd=>\\BBd==]BCd=<\\BDd=;]BEd=:b0O0O101N101O00000O2O1O0Njm]5"}}, "object_label": "book", "attribute_label": ["color:black", "color:white", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "material, pose, state, transparency", "answer": "The image features a close-up view of a book with a brown cover. The book appears to be a hardback, and it is placed on a table. The cover of the book is slightly frayed, giving it a worn and aged appearance. The book is open, revealing its title and author, which are not visible in the image. The focus of the image is on the book's cover and the details of its worn appearance."}, {"question_id": 218, "height": 480, "width": 640, "image": "000000055528.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "cleanliness, color, material, pose, state, transparency", "region_anno": {"bbox": [447.67, 110.5, 26.47, 108.94], "segmentation": {"size": [480, 640], "counts": "cda63l>9G8I3M2N1O1O000000OoCXOoM1g;g0WFDh9:mE2S:N\\Ea0f:JeD?`;]1CRMoDi2i;J6K7I4J5E>B>Ab0C9FdS^2"}}, "object_label": "toothbrush", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:dry"], "control_dims": "color, state, pose, material", "answer": "The toothbrush in the image is black and has a blue handle. It is being held by a person, who is wearing glasses. The person is looking at the toothbrush, possibly examining it or preparing to use it."}, {"question_id": 219, "height": 640, "width": 360, "image": "000000060899.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [285.23, 141.14, 72.62, 141.53], "segmentation": {"size": [640, 360], "counts": "j[b56gc03N1N1N2000O0001O1N1O200O011N00010N200N2N1iN@l^Of0Ta0n0501N2M2N3M3TOe]ON`b01c]OCgb0=Z]OAfb0a0Y]O_Ogb0a0Y]O@fb0a0Y]O_Ogb0`0Z]O@fb0`0Z]O_Ogb0b0X]O^Ohb0b0X]O^OQ2N]>d0b_O^Ohb0b0X]O^Ohb0b0X]O_Ogb0a0Y]O_Ogb0a0Y]O^Ohb0b0X]O^Ohb0a0Y]O_Ogb0a0Y]O_O>Lca0e0n]O@hb0`0X]O@hb0`0X]OAhb0>X]OBKLib0b0Y]OIgb07X]OF0Fib0Q13CT]OFb0Fea0c0n]OC=Jea0c0n]OCJKjb0a0]]OHbb07_]OIab07_]OIab06`]OIab07`]OEcb0;b0O000O10001N1O101N2M`S1"}}, "object_label": "chair", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose", "answer": "The image features a wooden chair with a yellow seat, placed in a room with a hardwood floor. The chair is positioned near a window, allowing natural light to illuminate the space. The chair is situated in front of a dining table, which is also visible in the room."}, {"question_id": 220, "height": 612, "width": 612, "image": "000000066817.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [229.67, 466.22, 78.39, 137.53], "segmentation": {"size": [612, 612], "counts": "eeT43ob02O1M3N2M3N2M3N2N2N2M3M3N2N2O1L4O1N001OO0100000000O02OO101O0O11OO101N11O0O11O0O2O000OO2O1O1O010O10001N2O2N2M4M2N2N2M3N3M2N2N3L3N2O1N1O1O1O2N020N[bm5"}}, "object_label": "spoon", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color", "answer": "The spoon in the image is made of metal and is placed on a plate of rice. It is positioned in the middle of the plate, with the handle facing upwards. The spoon is long and has a fork-like shape, making it suitable for scooping and eating rice. The plate of rice is white, and the spoon is the main focus of the image."}, {"question_id": 221, "height": 612, "width": 612, "image": "000000066817.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "color, material, pose, texture", "region_anno": {"bbox": [20.63, 431.93, 198.04, 173.29], "segmentation": {"size": [612, 612], "counts": "Yh73nb06L1O1O001O10O01O00000001O000010O1O0001O0001O0000010O00010O0010O0000010O01O001O00010O000010O0001O001O1O01O001O00001O00O1010N11O01O0010O00001OOHCl]O=]b0010O010DEn]O;Tb0Dk]O=]b00U^OARa0?n^OCn`0?l000O2N0000000100O00010O00010O001O000_^O@``0?a_OB]`0>d_OB[`0?U1O0010O00000d^OBT`0=Y100001O010O000001O01OO10001O0000010O01O10O00010O0010O0000001O000010O1O01O01O000001O0001O01O000001O01O0001O0001O0000010O000O1001O00O1010N11O000O10000O1000000O10000O100000O2O1O2M3M2O4K3N2Nej\\7"}}, "object_label": "spoon", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, texture", "answer": "The spoon in the image is made of metal and is placed on a wooden table. It is positioned next to a plate of food, which includes rice and possibly other dishes. The spoon is resting on the table, ready to be used for eating the meal."}, {"question_id": 222, "height": 480, "width": 640, "image": "000000088269.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [339.78, 14.02, 247.01, 131.6], "segmentation": {"size": [480, 640], "counts": "\\^P55i>3N101N10000O10O0100O010N101O0O2O1N2O001O100000001O000010OO1000O10000O0010OO101N101O010O00010O010O01O010O001O100O010O100O010O001O1O10O010O01O010O00010O010O1O010O001O10O010O010O01O10O01O00100O010O00100O0010O0100O0010O01O10O010O01O010O10O010O01O10O010O01O10O0100O10O0010O00100O010O010O010O010O010O010O001O0100O010O010O010O010O01O01O10O010O010O010O00010O10O010O01000O0000100O010O10O1O0100O0010O010O01O10O10O1N10100O01O01O10O10O1O1O01000O100O010O100O100O00100O1O1O1O100O1O2N1O2N1N3N1O2M[Wj0"}}, "object_label": "spoon", "attribute_label": ["color:brown", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The spoon in the image is made of metal and has a handle. It is placed in a bowl of soup, which is filled with a red liquid. The spoon is positioned in the middle of the bowl, and it appears to be a metal ladle. The bowl is placed on a dining table, and the spoon is ready to be used for enjoying the soup."}, {"question_id": 223, "height": 480, "width": 640, "image": "000000088269.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, length, material, pattern, pose, state, transparency", "region_anno": {"bbox": [29.12, 2.16, 537.17, 311.73], "segmentation": {"size": [480, 640], "counts": "lm31dj8e0^cGa0C9F9I5J8I6J6K5K4K7J3M4L5K3M4L4M2M4LSNUEJi:ZOVE@9T1]:]O`EXO7[1V:YOiESOa0]1d9]O]ERO`02b0^1_9ZOXFVO<`1X9[O]FVO;OlN\\1Y:_ObFVO>\\1m8^OgFUO=]1j8^OjFUO<_1g8\\OnFUO=^1c8[OSGWO;1bNY1n9_OVGWO?Z1Y8[O]G[O=X1T8\\OaG]O<W1P8YOhG@?Q1f7AkG]O`0S1c7AmG\\O`0T1a7AoG[Oc0R1\\7EXJ9f5H[J8c5I^J7`5EhF\\Oj3o0\\5FjF[Om3m0X5CoFAl3j0S5ERG@m3k0n4GWG\\Ol3m0k4FaK:^4FcK:[4GgK8W4IiK8U4HmK7R4IPL7n3IUL6j3HYL9d3F^L;`3EbL;\\3ChL>U3ClL=R3EnL;Q3FoL:o2FRM;l2FUM:i2EZM<c2D_M<_2DcM<\\2DeM<Y2EgM<X2DiM<U2HiM8U2IkHXO_4P1c2IoM8P2GRNb0c1_O^Na0`1@nHVO_5R1bJZOg6>XIVO`5Q1bJ\\Oc6>[IUO`5f1R1VO^ITOa5h1n0YOROi0j0YOVO0_JBX6?XOO`JET6=]Ok0a0TO@m0>TOCl0<SOFo07QOJ0ZJGk59K0ZJHi59NP10PO0R1MRO1o0MQO4P1JoN7S1GlN;T1DjN>W1AhNa0Y1]OdNg02RJ0V5Mi06nIOW5Im08lIOW5GP1c1oNZNT1>fINW5@V1a0cIOW5_OW1b0bIOW5^OX1l1hNQN\\1o1cNPN_1o1aNmMd1l0XIIT5[Od1m0WIHU5ZOe1n0UIIV5XOg1n0SIJU5UOl1V2SNiMP2V2RNgMo1Y2QNeMQ2[2PNdMQ2[2oMdMS2[2mMeMS2[1fHCd<\\100001O0000001O0UOZC\\Of5WOY1\\1RI\\Of<_11O00iHjMd1V2[NlMe1S2d50001O001YOUCWOk<_10000\\HmM\\2R2dMoM[2Q2Z501O001O0000[HQNY2o1]5O0_OQCQOo<o0RCoNo<Q1PCPOP=`11O00001O0000001O00001O0ElBjNT=V1mBiNS=b1001O000IlBbNT=d1101O0KjB`NV=`1jB`NV=`1iBaNW=_1iBbNV=^1jBaNX=^1iBaNW=_1iB`NX=`1hB`NX=`1hBaNW=_1iB`NY=_1400004L00N3O01O000000000010O0000000000000000001O000000000000000000000000000000jGaNl2_1SMbNl2^1TMcNk2]1UMcNk2]1UMcNk2]1UMcNk2]1UMdNj2\\1VMdNj2\\1VMdNj2\\1XM`Nj2`1[5000000000iG_No2a1QMbNl2^1TMcNk2]1UMcNk2]1UMcNk2]1UMcNk2]1UMcNk2]1UMcNk2]1UMcNk2]1UMbNl2^1[50000000000000000000O1000000000000000000000O100000000000O10000000O1000kGbNh2^1XMcNf2^1ZMcNe2]1[McNe2\\1\\MeNc2[1]MfNb2Z1^MgNa2Y1_MgNa2Y1_MfNb2Z1^MgN`2Z1`MfN`2Y1aMgN_2Y1aMgN_2Y1aMgN_2Y1aMgN_2X1bMhN^2X1bMhN^2X1bMhN^2X1bMhN^2X1bMhN]2Y1cMgN]2X1dMgN\\2Z1dMfN\\2Z1dMfN\\2Z1dMeN]2[1cMcN_2]1aMcN_2]1aMbN_2_1aMaN_2_1aMaN_2_1a5O10O1000O11O0O1000O10O1000OVHaNT2`1jMdNT2\\1lMiNo1V1cH^N\\5=P2U1dH^N\\5=o1V1TNfNbJGZ7c1TNdNR2[1`H^N[57U2Z1aH`NY55V2[1bH_NY55V2[1bH`NX53mJNn6_1kHcNf52]1Z1nHdNe53\\1Y1oHdNe53[1Z1PIcNe53[1Z1PIcNe53[1Z1oHdNf52Z1Z1QIdNe52Z1Z1PIeNf52X1Z1RIcNg53W1Y1SIcNf56V1W1TIcNf56U1W1TIfNf54U1V1SIhNh52U1U1TIiNg52T1V1UIhNf54T1T1VIhNf54T1T1UIiNg54R1S1XIaNN2k5:o0S1XIgNh56P1S1XIdNNMj5<o0T1XIhNh54P1S1YIjNe55P1Q1[IkNe54P1o0]ImNc54P1o0]ImNc53P1P1^ImNb52Q1Q1]InNa50S1R1[IoNb5NS1T1YIlNOEf5:S1T1YIjNj50o0^1VO_Nl0`1VO_Nk0a1UO^Nl0`1WO]Nj0d1Y6IfBgNP6MW1\\1jHfNP61S1X1oHdNP64Q1X1TOhNk0X1UOjNi0W1WOiNi0V1XOkNf0U1\\OiNe0W1\\OfNe0Z1[OgNd0Z1[OjNjIIa6]1EjNgI0NJ_6]1KiNiI2[6U1MiNhILNN_6[1MSOdID\\6Z10\\OLb06_OI`08VOaIGV6T1:SOcIGS6U1;UOaIET6V1<VO_IDT6V1>WO]IBV6V1>XO[ICV6U1`0XOZIBW6U1`0^O_Ob0?B@=a0C^O>b0A^O?c0\\OYI_OT6T1d0]OXI^OT6U1e0]OWI]OT6V1f0@ZO?g0AXO`0h0@XO?i0AWO>j0BUO>l0UORI1R6j0l0UORI0R6k0m0UORINQ6m0P1SOnH0R6m0Q1]OnNc0S1]OlNc0V1\\OjNc0W1^OgNc0Z1[OfNe0\\1YOeNf0\\1ZOcNf0_1YO`Ng0a1ZO^Ne0d1ZO[Nf0g1YOXNg0j1\\OQNd0P2\\OPNc0R2\\OmMd0U2\\OiMd0Y2\\OZIEQ3o0f3]OVIFS3m0i3\\OTIGR3m0l3[OSIGQ3l0n3_OnHCV3n0n3^OjHEX3l0Q4_OfHDY3m0S4^OdHEX3m0U4^OcHEW3m0X4@^HCZ3l0[4AYHB\\3l0]4BVHC\\3k0`4ATHC\\3l0b4AQHC\\3l0e4BQL>Q4BlK>V4ChK=Z4BfK=[4CcK>_4E\\K;g4DWK<k4DSK<o4DnJ=T5CjJ=X5CfJ=\\5CbJ=`5D]J<e5DXJ<j5DTJ=o5AoI`0S6_OlIa0V6^OiIb0Y6]O]HCnNP1g8[OVHLlNITOn0n9[ORHNkNm0U9ROSHMkNP1U9POWIP1k6nNRH0dNR1f;nN[C2m0P1m<ON2MlN]BT1c=4L3cNhNTEX1d:TOWEl0k:YOkDl0V;^ORDTO6`1g;\\11O2N2N2N2M3N2L4O3K5K5K7G8I6H`0nN^n0L^RO0Z]10F1obN1O000fba1"}}, "object_label": "bowl", "attribute_label": ["color:white", "length:long", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:tiled", "pose:horizontal/lying", "state:full/whole"], "control_dims": "length, color, pose, state", "answer": "The bowl in the image is filled with a red liquid, which appears to be a soup or stew. It is placed on a dining table, and there are two pieces of toast or grilled cheese sandwiches on the table as well. The toast is positioned on the left side of the bowl, while the grilled cheese sandwich is on the right side. The arrangement suggests that the meal is ready to be enjoyed."}, {"question_id": 224, "height": 427, "width": 640, "image": "000000092053.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [341.71, 303.75, 135.67, 122.99], "segmentation": {"size": [427, 640], "counts": "gb`46U=0OOnB0n<MSC5Q=0O2oBHj<>OFVC5i<7O2N1N2N3N1aCWOZ<n000O100101OO201hCSOm;U11O1O1O2N14LO2O000O12O0OO100N2O2N1O1O1O1O1O2N100O3N_DYO]:f0U100O0100O1001_O]C7d<D`C<h<000000000O10000000001O00001OO1000O2O00001OO11O01N10O101O000000000000001O000000000000001O0000001O000O01O1O1O1O1O1O1O1O002N001O1O1O1O001O1O1O1O1O1OSoS2"}}, "object_label": "fork", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, texture, pose", "answer": "The fork in the image is silver and has a long handle. It is placed on a white plate, which is filled with food. The fork is positioned near the center of the plate, and it appears to be resting on a piece of food. The fork is also accompanied by a knife, which is located on the right side of the plate."}, {"question_id": 225, "height": 361, "width": 640, "image": "000000093437.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [575.78, 205.62, 18.31, 33.16], "segmentation": {"size": [361, 640], "counts": "`X[66Q;k0WO2N00O1000000000000000000O1O1F;DjP`0"}}, "object_label": "cup", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, material, color, pose", "answer": "The image features a large metal cup, possibly made of stainless steel, sitting on a table. The cup is tall and has a silver color, giving it a sleek and modern appearance. It is placed on a countertop, and its size and design make it suitable for holding a variety of beverages or serving as a decorative piece in a kitchen or dining area."}, {"question_id": 226, "height": 480, "width": 640, "image": "000000106235.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [110.56, 270.59, 32.01, 10.51], "segmentation": {"size": [480, 640], "counts": "bhd15j>2N10000001OO1000000000000000000000000000000O10O10O1001N10aUY7"}}, "object_label": "remote", "attribute_label": ["color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose", "answer": "The image features a remote control with a brown wooden handle. The remote is placed on a surface, possibly a table or a countertop. The wooden handle adds a touch of elegance and sophistication to the remote, making it stand out from typical plastic or metal remotes."}, {"question_id": 227, "height": 480, "width": 640, "image": "000000106235.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "color, material, pattern, pose, transparency", "region_anno": {"bbox": [1.03, 118.71, 638.97, 354.06], "segmentation": {"size": [480, 640], "counts": "S:1810001O0O1M4N11N1KO1411OO1O100\\:NeE11O00L410M<0F0O2O3MO1O2N0Q:KoE10510O0Om10TN001f0m9S40O3RKPF6OT30`MV:TOmE2M10i00i00^N0?0F1O0I12T:0kEn3ObL1^Oh90^F3Im30fLQ:]OoEm30bL0@R:OPFP3NkM0\\O1O0IW:U1hESO0X10[O2[O1OV:m3hETL20NJS:S4nESLN20IV:P4jEaL0_O\\:a41OO1G^KSFc4m9]KTF_4IbKa:[3_EVM0F0Ib:0_El2O[M190FOJa:[3_EcMS:VOPF\\4P:`KnE04^4S:aKUFW4Z:0O2\\OgKQF09Y4Y:03L2^LVEl2i:f0DnKiES4W:lKcEO5T4]:kKjEn3V:RLkEm3P:TLdE1:m3Q:WLnEj3V:RLkEm3f:JoDXLT;m2lDUM0?j:B\\Ed3JYLg:5]Ee3c:[L]Ee3c:WLYE07g3MWL\\:1aE1:c3I[L[:8kE]3J[LW:<eEI3`3c:aL\\EO1_3h:\\L[E3O^3n:bLSEo2JVM0IT;4PEZ3P;hLnDX3S;hLlDX3Z;bLjDZ3V;gLjDY3V;gLiDY3W;jLfDV3d;N3MZNjLcGg2[NeMR:DbGU3_8kL`GV3f8nLVGl2j8UM_G^2XN^MY:=XGm1`NgM1NW:>mFCkN02\\2MeM2NW:>lFImNV2NeM2NX::fEGV15lNV20dM10n90WF2KN00`1Y2cNhMk9O[HV2hMmMm9MTH2nMT22lMl9NRH5PNo14mMQ<2lCQ21nMX:NfE1N1h1P2YNSN[:LeE0O1c1NaNg1K`N2NZ:MeE1OOb11aNe1M_N10Z:5SGg1dN]NX:IfEIc11]Nf12YNN:n9E[F8GIl1c1ZNcNJIn92ZF6HIP2V1PNoN60l9MTF:h1l0RNmN2JO6Q:MSF<f1l0UNkN2KN5R:MSF<KAi1Y1YNlN05o9HUF>J@n1T1VNoNM8o9HVF=JAn14SN10:3NLCP:2VFa0c1[OYNU12^OR8]ObI6[N`0e1\\OYNS13^Ol9EQF>1ZOh1T1ZN_Ol9:PFUO10k1o0YNAk9_OQFg01_Om1NQNM1?4MKDP:OPFU1l1UOTN65LLDP:0oEV1d1kN^Nm03ZOKI2No91oEV1n1DVN_OLH2NR:X1jGiNTN0O?4NT:m0jGUORNNS:n0bGdNYN1N?4NS:P1`GcNYN10?3MU:R1fGlNQNE6<T:X1iG[NYN<n9^1VHZN`MM[:j1WGWNeNN93BMX:l1WGWNeNO64FJX:l1XGVN`NN1190E11NX:k1oFWNPO28LA2OOZ:e1eE\\NV14RON9LA2OOX:k1lF[NkNK51LN<0D10OW:l1mFZNkNM348JF00OY:j1kF\\NkNM438JF00Oo90VFk1S1VNhN0:0]:0]Ej1h1UNl81\\Ej1Y1UNi93mDh1NWNU1NkN0P;2SEi1LUNT10mN1O0P;1TEi1LUNT11lN0O11N;0S:0fEl1LTNe00E2FOO11N61I11NW:2lEl1e0SN^OOI3O50J74KJ10Q:4nEk1h0RN]O6I52D07OK1N`00m82hFj1d0UN\\O6I56KLIe01g81jFi1c0VN[O6LJ1431e0Lc80jF`1HeNk0I\\O7KI52O0h02`8OhF_1JdNl0J[O74KJ2LLh05e8NgFh1g0UN\\O45NE5NJh05e8OgFf1h0UN[O39MD6LKg06e80fF]1NaNm0LYO2a02YOLe08f8OfF]1O^No0NSO0N2h02YOKc0:g8NfFb1n0WNSO5g0NWONc09g8HgFO0g1o0XNRO6f0MXONc09n8F`Fd1O]NP1ORO5g0NWOMc0;S9D]F02S1KoNU1NRO2b01M:\\9HPFd0OXO_10YO2K<k8BQG4Bi0]1SOZO2K<j8DeF212Mg01ROY11^O2K<k8BjFOL5Lj01QOY11gNOc02O>^9EnEk0_1WObNI?23?_9DnEk0^1]ObND<06a0`9e0SGiNnN0Oa09@6b0U9_ObFU1m0iNnN1Na09@6a0V9B^FS1Q1iNmN0Oa00^O2000=d0V9CZFj00VOU1JlN11>5@=e0m8[OcFj0M]OOK50Q14lNKO1056I;g0o8YObFY1OlNT11lN0O12IN1a0f0n8ZOcFY1MlNV10lN1N02JO0`0g0o8ZObFX1OkNU11lN1N02J0O?h0o8ZObFi0NA2GU14kNKN0151Ic0i0k8YObF:N04ILM2OW17gNK00051Hb0k0m8WObFh00BNFY16gN:0@2N;l0R9WOcFh0NFY1GgN:0@2O:k0T9VObFh00FW1HgN:0@2N:m0U9SObF7M10K0O512MS17hN0N02I=o0f8QOZG6B11J0O52[16`NN0KO0b0o0b8QOSG1J401NK1O52\\15`NN0KO0a0P1b8QORG2L20:2ELM2NW18iNNOMOO`0P1d8POSG2I3293CLO1NW18iNIO11O0O>S1c8POTG:KJNK10501NP16iNL2O000Ob0T1_8nNVG:IKNK106N10n07jNK2O000O`0V1a8nNSG9LONF60LN10R1=kNE2O0O`0V1a8oNoF;001FML1OT1<kNE11OO2O:U1g8nNVG2HJ63J26MKN10R1=kNE101N118V1i8kNiGN[O000W12bN0001N11OO107Y1j8hNTHOa02^NN10<Y1_8kNiGL\\O0`13ZNM1050<Y1]8nNQGIe00A0_14[NM000O01a0Y1]8nNRGHd01BO_14[NMO11N10?[1^8mNRGHe01@O10S11eN22NO11Nd0\\1Z8lNRGHd02AN10R12gN000001Nc0]1[8lNPGI<NK2O000S11gN50J10c0[1\\8PORGC60K7M020NJU12kN50Od0V1\\8lNPGIe00AO20I0T11lN0000000b0\\1[5bNRM1YMOW10F1lNO1001OOa0_1[5bNQMO[M0m20`M`1Y8aNYGOW10K0mN0?`1X8dNQHLF1`00lNO60?`1Y8bNQHNWO0]11]NO61=`1`9_NSF0]11]NO61JO>b1e9^NSF0X11aN11O0O11OO=c1e9_NSFOX10bN2O00O2O0O=c1h8]NlF3;4D3Y1GfN;1EO0>b1f9]NSF0\\1<^NE0O=c1g;hNlCEb0c1b;hNlCEa0c1f;bNgCM2Na0c1g;`NhCN0O`0e1j8[NeG0?0hN0c0f1a8ZNeG0?0Dg1X8YNeG0?0Dg1X8ZNdGOf1g1a6YNlF1l01SONT11[OO4g1g8YNRI0jNh1n;O100000O2M2O1_GUN51[LN`1l1P2UN42\\LM`1k1j6WNYJi1_9000XLUNZJm1l0TN51mNk1n0TN50nNl1l8SNoCm1Q<TNnCl1Q<UNoCk1T4SNR20aJ2YOk1R<TNmCm1c<0O1[LSNVJm1k5SNTJn1_90O2O0eNoMgEQ2\\3nMW21gIO2R2P4nMa3S2_LmM`3T2`LlM_3U2aLkM_3U2f40lLlM[IU2c6RNWIo1i6SNUIm1k6]N]F^O2NT2W2]7fNbHZ1^7gNaHY1\\5iMaJo02X1\\5kMaJn02W1^5iMaJQ10V1_5iMaJQ10U1c7lN[HU1d7lN[HV1d7jN[HW1e7iN[HW1e7iN[HW1e7iNZHX1e7jNYHW1P6dMkIf0[NHi1m1R6eMjIV14U1i7lNnGjNeNU2KmMb9S1WHP1WNmMa99`FGOO16OKk1X2b7PNdFE2137JJl1Y2a7QNgFF1>d1k1d7hMcF42O0<e1i1f7]NdFJf1i1f7_NdF^OONf1V2g7^NeF]ONOf1V2f7_NeF]OONf1V2f7QO[Ho0e7`NdF\\O0Mf1X2e7VNeFD2O1Mb1V2[NjM[9?fFE1JO121a1W2\\NjMZ9=gFF1LNN327Nn0^2S8QNfFG000O71l0X2X8gNdFmN`0Md0c0lNW1\\9QOeF\\Ok1X2`7\\NfF[Oj1=TNW1]9POdF]Ok1<TNW1]9QOcF]Ok1;VNV1\\9ROcF\\Ok0J3^2^8\\NeF\\Oj0J2_2_8RNdFA0O15j0NL^2d8bN`GQOK\\2f8dN^GPOK]2g8bNdGlNEb2g8oMdFD30e1L[N[2X9TNgFD20Q1K\\O2CZ2W9VNeFD4OQ1K\\O2CY2X9WNdFE3Oo0K@1BY2X9VNeFE30n0L_O0CY2W9mMfFO1J82j0O\\O0EY2U9lMiFI000181i01[OODNM[2Z9lMhFK4041i01\\ONC\\2X9iMhFL2140j02XOKG2O[2[9jMfFL3030m0OWOOE01\\2Z9kMeFL5N11P1MUO1E02[2X9mMfFK5O00R1LTO2E02[2X9mMfFK5O00R1MSO5GX2Y9lMfFK5OO1S1LSO6FV2[9lMfF73ES1LROb2G`MZ96gF74DR1MQOc2H`MY95hF4OD53\\1a2_N_MY9h0kFXOT1MoNd2I_MY9g0kFZOT1LoNi2S9RNiFYO_1e2h7SNhFXO`1e2h7SNhFXO`1e2h7SNhFXO_1f2i7RNgFYO`1e2i7RNhFWO_1h2h7dMgFL3G^1j2g7cMhFL3F_1k2f7RNiFSOc1j2d7WN]Hh1d7WN_Hg1`7VNdHk1[7UNfHj1Z7VNfHi1\\7WNcHd1a7\\N`Hd1^7UNeF_Om1\\2TN_MT9b0kF^O2ON2`1MlNb2EaMS9o0jH`1SN`MT9R1gH^1TNaMU9P1hHd1X7QNnF^Ok1`2V7_MoF:0Gl1_2U7`MoF:0Gm1^2T7aMoF:OHn1X2PNcMU93nF:0Gl1Z2QNbMT94oF90Gl1_2S7bMPG92Ek1`2S7VNQGZOm1_2S7aNmH_1S7WNPGZOm1[2PNbMS94PG92Ek1\\2QNaMR95QGOM14Nk1[2RNaMR96PG80Gl1Z2RNaMR96PG80Fm1\\2V7fMlF64Hj1Q2QNQNU90lF66Gh1R2VNkMm60mJ7RN56Gh1R2_7RNbF66Gi1P2`7SN_F94Gm1l1^5mMbJ7PN85Fl1l1\\5QNcJ4RN2NJ72Q2`1hM]N_71aJ3TN29Ll1_1[5aN[J2UN28Ml1_1]5_NZJ4SN2OI62Q2a1^5]NYJ4SN4OH61i1NYNa1]7`NYJ4QN61ES2:TNW1^7`NYJ4QN60GQ2:WNU1^7`NYJ4QN;o1NYNS1a9XOSHH[NP1b9fNVF:k15ZN]ONl0MWOk90WF22Kf1d0PO@VO02I10h92WFN261Ma1k0TOTOXOOO1S:4oE12L`1l0TOUOWO3T:NoE41I_1Q1SO\\O^9FlE7j1l0lNhN]O1N0R:d0aGn0J^NP8e0SHI_Nf0\\1oNQ8b0RHS1bNZNT11X8g0kGY1HRN\\8a0fFYOV1V2GPN\\8a0lFZOk0[2QOgMd0Me84hF1L16Lg0R3TOnLd92^F:2Ef0Y3i8hL]F=2Cf0Z3WOcL>Ob86PG;4Bd0W3XOhL2N;1b8i0WGWO=[2]OdN1RO`0O]8j0YGUO:^2_ObN2PO?1_8i0fGh1ZO_N0QO2N;1b8n0`Gh2A[L2O:0c8R1\\Gc2G[L0O;1a8S1\\Gc0FZO0A0E2Ia9U1dF?I^N11O01M1b0NE1K01O3h9n0_Fi1I[M09a0_OI0^8S1_Gh2KUL10422N_8Q1aGj2NUL11JO30b8m0YGTO;j1E@0gN11O47I10K020a8n0hGl0C\\OOmN0O11O00Oa0NB020a8n0hGm0BE0cN047I11J010d8n0eGQ1DI2WN1001N115d88\\GK?_1_OYN16On00QO2J0O11N1101Nc85[GL1O61?f1[OYN08N:0A0:0K0J2N11N11Oj83_Hc1kN\\NJO11O:0F0:0K0K0N31M010k82^Hd1hNYNO2O00?000O2EOLk82^He1fN_N0K0f12cN1Dd82dHg1eNdN0i00[O2JZ:^1dEdN0F0?0F0K091F1OO100\\:R1cE]O1LOF000005000K091F1OO100\\:f1cEeN0K0d00A0E25NK]:f1cE[N05000d00E2K[:[1dEZN07ON4d0LG2FNK_:<aED1;OF041K65IK<:DK11OO20NK_:;cEC17MK1000001N66IL<9CL11OO2JO2ON`:=`ED1`0OE1K64JL<c0CL2I^:[1bE[N070I=X1ASO`:3`E40O2@O61I?Q1_OQOo::REGOO150LOO151JO2OOf00ZO6092_Oo:;PEHOO151KN0151JO2OOf0O[O7O8V;`0jDA2@O6h0d0^:h0iD_N151Ib0l0f:d0fDbN151Ic0>[OIa;N_DM1;OF092E06NJg00ZO1001Nf;4^D8JG091F1OO5j0LWONm;1WDT1MTOV=n0jBROb=I]BO0006OISW:0ikE0R90dF0dM2X;NnD0V21cM1LNY;0gG0VM0\\g30ocL0\\G0XM20Nm:3[EM[21c82QE1h=0XB0h=0XB0h=0XB0Y2Lg82RE1W2M\\92cFOZ80QFOc15[8LRFO]11dM55J^:2XHNdM3_O42I10b:0mH2`LOO1e<1[CMc12[;7dDG];;aDF^;:bDF^;3iDLY;1l10aCOP:0oE1Q:O\\E1bN0E1j:NaH1PMOG0g:2Q41O1bDMo73QHMo73QHMPMOb:3mHMS73mHNWLOg:2mH0[L1OO7NX:2nHOiL;LD01]:0oH0iL1I0106Ni=1\\BOG0W>1iLOeH1dLOY:0SI1cL1LN`=0eB1O1GN10c=2eBO02EO2O0O^;0mD0S15hNK01H72IO11NZ=2dBO80KOM>0E03[=LfBO71Hm0\\=QOQC2C01`0ODj=MWBM4>MB01l;0kE2XNM4>1Df;0mE5ZN92Ah;1lE5ZN9NEl;NXEM]O1H2H3U:JfG3XON_:OYF4VON`<1aCO1NXO0`;3WE0K4QO10Jk0NU:2UF0lNNk07TO01Jm;1WE3KMROO5Og;2WE4Z<LgC3a1Ko72aF2CNXONe00\\O001OO11O0O1e:OcF0k00nMO11OO020N`:1bI0nKO`:0cI1mKO`:0YI0XL1N1001N[:0TI0bL1N115NK2NX>0jA5NKZg01aG000iF0\\JO1042KNZ82iLOXK0EO100001OO[80gL3hKMWO1OO[81fL2iKMWO1OO[81fL2_KMF1I11NZ84fLNQKN51J0O1050K1NU85kLL`KOA001N11OZ84fLKTL0W76cGK_10m1OY66\\FJ_10`21RLO100000Y86TMLaJ51JO11O0OV86WMMaJ0000O11OO2NV86iLJ\\K1D114O11JW85eLK_K0D114O11JU88^IHa1OnL2O7M81AV87]IIb1NmLP1MWO2IP87nGJe1O[10[M2F4O2000K0O2NP86\\LKcK130?N@1N11OO11O0OU86VL:ZLA[O000000OZ86oK9eKB;OI2M1OO11OO101O0OP86XL5gKE117d0GM0_OR85^LNnK\\1d7fNXIK\\2c0[LDOO1LONR85WIL\\2c0\\LCOO1LOOQ84XIL]2`1[4dNXILZ2N_La1o7eNWIM[2^1]LaNR83VIN[2`0]L_O1001OO10001NR84TIO[21]LO1M21N11N11O000000OR84TIO[21]LO0:0E11O0000O1OS83TIO[21]LO0?04S8^OUIN]26[LR1S8jNUIN^2d0ZL5S8YOUIN^2d0ZL5S8YOVIM^25YLT12fNm74[IL]25ZLV1OfNo73UM0mJR1OlN2No72SM2nJ3NL0O11O0041KU8NUH0m00W23cL3OL1O0000O1001NU80SH3\\41\\K3NL0O11O0041KU8NTH3\\41\\KU1`8jNTL1\\KU10gN\\84RHN1Nl25fLS1OhNZ86SHN0Mm25hLQ1MjN[85SHNOMo25fLS1MhN\\85SHNNN\\2NiM2^OO4[1Y8iNRHNd3NQL[1Z8hNQHOe3MQLX1KiN^83iGLO0Q40oK3K5OK050K0O1OT8ORH30Nb3OkL0BW1JjNU8ORH3N1b3NSMY1e7eNiG3OMW33[MU1WOiNj81]GNX33ZMS1YOjNh82\\GOY33aLNd0T1^OjNi81[G0Y37TMo0^OkNi8O]GOR20jM0k0:XOF4\\1`8eNnJ7kLT1W8eNeK2bKU1OjNi80jGOV3]1WLdNj8NhG2d24jLL:NJZ1f8fNgG3X2j0bM<_8gNgG3X2j0cM2DSO1Oj8ObG6]21XM;NB9OG42Il81`GOO6]2N\\M2K9<He8K[GN15[1KVOT1[OVOHFm81^GO24Z1MTOU1[OZOJAO1c8OiGO15[1KVOU1XO]OIEe8IhG006MMS29cML000I7f0I\\O0Na8OkG204MNU20dMOON02OO101N4Q10POQ8OUH2O1EN:3S2o0fM2NPOV8KTH3L47KP2R1dM9U8dN]H8JGR2T1bM:T8dN\\H7@Gk2T1VMONTOT8OZH3CGk2U1VMMOTOS81XH3EFk2U1UM8R8kNXH2GFj2f2Y5`MUH4IGh2T1VM8Y8cNQH8EH22i28VMMN54P1_8gN^GO1O0O12j22TMN50LOO10O4R1KTOb8M`GLZ20cN;RO:3g0^8hNlI0^NP1XO9\\8cNaG2]21_NR1VO8\\8dNcG0000OT21hNT1UO8\\8dNcG0O11NT21hN6ROe03a0\\8dNgG1LNT21hNf2a7ZMgG0MOQ24UNL9Y1_O3g8dN[G0S21iNW1RO4g8dN`G0]10I3mN0F30MON3Y1o8hNaHOK1oNOI1LOO02Y1f:gNbEOe04ROM33L3O02S1f:iNbEONN<:^O?Oc0T;gNSEN;V1_O5R;fNUEO:4]O21:0A1[1Q;eNVEOIO60M5L101001J1[1g:dN]E4ONK06NNS1KoN3Z1f:fN\\E3M1OL1N101X1O4f:fN[ENO130MO<9DMN1O03U1g:gNXEMQ19TOG02K42U1f:iNVEMT13lNNa0OB41V1f:lNYEIk09XOI00L42U1f:fNVE33Mj09UOL092l0k:hNREO6N=W1@4m:fNPE25M202>GI062n0n:mNTEIMO11OO3>LI062o0m:mNQELOM101N3X1N4P;ROmDI2I4m0JZO4U1o:QOnDJ1I5k0J\\O3U1o:QOTEC58DJ1050L42W1n:POUEC58DI2140L43V1m:QOTED6a0E_O02O53U1o:QOPEG9Q1G8P;YOXEa0H5P;VOnD_O7h0JD1o0Q;ZOnDYO2j0ND2n0P;[OmD[O100U116Q;CnD628o:BoD628n:jNQE4NF101S137m:fNPEN2?MC1S146Q;fNnDb0Me004U;eNPE`0Kh0O3V;eNPE`0Kh0O3k:fNZEN82INMX1M4i:iN[EKk0W1QO5i:hNkENJd2Z:\\MnE2Gb2[:[MoE3ZOL=a2X;`M[DO`0^2Y;cMkDk0ZO`0g;jNoDS2\\:hM_E67P2o:nMUEo1V<H4K3[NkB\\1n:cNQE4o1X1Q9cN]GY1W;jNYBo0d:nNdHP1f:01OTMQOjGk0V8WOoGc0Q8]OPHa0Q8_OoDN>0k1b0h8_OoD43NLN0OW2`0j8BPE32OLN1NW2`0kM"}}, "object_label": "couch", "attribute_label": ["color:tan", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying"], "control_dims": "transparency", "answer": "The couch in the image is a large, white sectional couch with a wooden coffee table in front of it. The couch is situated in a living room, and it is accompanied by a chair. The room also features a potted plant, a remote control, and a cup on the coffee table."}, {"question_id": 228, "height": 480, "width": 640, "image": "000000106235.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, pose, transparency", "region_anno": {"bbox": [192.65, 27.98, 86.09, 128.07], "segmentation": {"size": [480, 640], "counts": "Yhn22l>3O000YA1\\>=M1N2O1N2N:F3N2M7I4K9@UNZCR2`<:N1N3M4L2N1O5L3L3N00001O0000000001hNTD[O\\;jNPEk1FZOY;=gDRO1`0X;=hDnN1BM<O8\\;n0dDmN3BMR1];]26JI7H^LQEc3m:90000000gLoDc2Q;f0O1000000000000000000001N1000>A>A=Cg0WNZ1Bbj]5"}}, "object_label": "potted plant", "attribute_label": ["color:brown", "color:green", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency, pose, color", "answer": "The image features a potted plant placed on a wooden table, which is located near a window. The plant is a large, leafy green tree, and it appears to be a houseplant. The plant is situated in a pot, and it is positioned in front of a window, allowing it to receive natural light. The scene is set in a living room, creating a cozy and inviting atmosphere."}, {"question_id": 229, "height": 480, "width": 640, "image": "000000109441.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [316.23, 322.04, 9.57, 23.55], "segmentation": {"size": [480, 640], "counts": "Umd45j>`0A0O10000000000mkb4"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, material, texture, pose, transparency", "answer": "The traffic light in the image is a yellow traffic signal, which is mounted on a pole. The traffic light is illuminated with yellow lights, indicating that it is about to change to red. The yellow light is surrounded by a row of black lights, which are likely to be the traffic signal's other colors. The traffic light is positioned on a gray background, which provides a clear contrast to the yellow light."}, {"question_id": 230, "height": 359, "width": 640, "image": "000000112798.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [623.58, 129.34, 16.42, 64.08], "segmentation": {"size": [359, 640], "counts": "Tcj65l:7I7I7J5K6L3I7\\Oc0MJWGUNi8h1=M3O100_N_FZ1c9fN]FW1f9iNZFV1k5"}}, "object_label": "book", "attribute_label": ["color:orange", "material:paper/cardboard", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, transparency, material, color", "answer": "The image features a bookshelf with a variety of books arranged on it. The book in focus is a large, colorful book with a red cover, which stands out among the other books. The bookshelf is filled with a total of 13 books, with some books placed closer to the front and others further back. The books vary in size and color, creating a visually appealing and diverse collection."}, {"question_id": 231, "height": 359, "width": 640, "image": "000000112798.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "cleanliness, color, material, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [66.54, 138.88, 442.56, 161.71], "segmentation": {"size": [359, 640], "counts": "f_i0=c::@>J6M4L4J7G8L4L3M3M3M3M2N3M2N3L4N2N1O1O1N2M3M3O2O0O2N1O2N1O2O0O100O2O0O1O1O2N100O101N100O100O101N100O1000000O100O2O000O100O10000O10000O10000O100O10000O100O1000000O1O100O010O1O100O100O1O1000O0100O100000000000O1000O100000000000O100000000O10O10000000O100O10000O100O01000O100000000O100001O1O2N1O001O00001O000000000000O100000000000000O1000000000000000001OO01000000000001OO10000000O10001O00000O10000000000O2O001O000O1000000O10001O0O1000000O2O0000001O000000000O1000001O0000000O10001O000000001O00000O100000000O1000000000O100000000000000000000000000000000000O2O01O00O101O001O001N10001O000O101O0O100000000O10000000O10O100ON3O02O0001N1000000O10O010000O100O10000O01000O1000000O10000O01kLnHU2R7\\MmHD160j2R7\\MmHO1e2R7\\MmHS3S7a0000O1000000O100O10O10O10000O100O101O000O2O1O0O101N101N1O101N2N1O2N1@XH`Mj7[2_HZMh7d2>O1O2O0O1O2N1O2M3N1O2N1O2N101N2N1UNhFf1Y9YNkFc1^9NM3001M3N2L3J7G9N2N3J5O1O1O100O1O1O2O000O101O0N200O2O0O2O001N_m`1"}}, "object_label": "cat", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "material:asphalt/cement/clay/concrete/stucco", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:sitting/sit", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color, state, pose, maturity, pattern, cleanliness, material", "answer": "The image features a large, fluffy cat lying on a table, possibly a desk, with its head turned to the side. The cat appears to be relaxed and comfortable in its environment. The table is covered with various items, including a book, a computer mouse, and a cup. The cat is positioned near the center of the table, taking up a significant portion of the space."}, {"question_id": 232, "height": 375, "width": 500, "image": "000000119828.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [314.53, 57.54, 14.04, 44.63], "segmentation": {"size": [375, 500], "counts": "heb39];5L3M4M3N2OOOO3M3M5K3N3M`do1"}}, "object_label": "cell phone", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color", "answer": "The cell phone in the image is a small, rectangular device with a screen on the front. It is placed on a surface, possibly a table or a counter, and is turned on. The phone is positioned in the center of the image, with the screen facing the viewer."}, {"question_id": 233, "height": 375, "width": 500, "image": "000000119828.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [344.78, 116.2, 60.35, 48.99], "segmentation": {"size": [375, 500], "counts": "Vhm32a;6\\ONTE?h::N2N2O1N2O001O0O2O00001O00000O10000O1O100O100000000000000000000000000000000001O0000001O00001O001O1O0O101L3K6J6K5J6JVQS1"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a cup filled with a dark liquid, likely coffee, placed on a table. The cup is positioned in the center of the scene, and it appears to be a glass cup. The liquid in the cup is bubbling, indicating that it is being heated or stirred. The cup is surrounded by a few other cups, suggesting that it might be part of a larger collection or arrangement."}, {"question_id": 234, "height": 427, "width": 640, "image": "000000123131.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [72.67, 183.12, 81.97, 85.67], "segmentation": {"size": [427, 640], "counts": "YSo04V=7AG_C:a<FZC:k<FUC9Q=N[OIZD0Q;OiD8n;JoC8o;JiC?U<=N3M4L4M5J8I1O0O10000O1N20000O100000000000O1O1N2gNnDEELO0g;9U1010000O010O10000O100O10000000O10O2O000000O0101O000OO20000002N00N2O10O100O100O1001O01JmB1iY[6"}}, "object_label": "truck", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, pose", "answer": "The image features a large white semi-truck with a chrome grill, driving down a road. The truck is positioned in the center of the scene, and it appears to be a big rig. The truck is also equipped with a large chrome grill, which adds to its impressive appearance."}, {"question_id": 235, "height": 427, "width": 640, "image": "000000124798.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [408.67, 299.31, 67.74, 54.32], "segmentation": {"size": [427, 640], "counts": "ekZ54R=a0@?C5K3M2N3N10O01000N2M3O10O102N2N1O00000O10O1N2N200O1000000000001O000001O000001O00000010O4L1O001O01O0O2O2M3K5J7L22M4NO1N1O3M1O3L9EoQT2"}}, "object_label": "truck", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, transparency, color, pose, texture", "answer": "The image features a white pickup truck driving down a street. The truck is large and has a black tinted rear window. It is also equipped with a pizza box on the back, possibly for transporting pizzas. The truck is driving next to a car, and there is a person visible in the scene, possibly a passenger or a pedestrian."}, {"question_id": 236, "height": 427, "width": 640, "image": "000000124798.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, length, material, pattern, pose, texture", "region_anno": {"bbox": [170.82, 238.56, 237.57, 125.47], "segmentation": {"size": [427, 640], "counts": "_dW24U=4nBI]<g0aC[O1Oh:9]Ed1R:TNnEe2h9d0O1O100O10000O1000O10000O010000O102N000000000O100000001N10001O1O2N000000001OO010O10000O1O1O100000000O1000000000000O1000000O1000000000O10000000000001O0000000O100000001O010O0001O0001O000000000001O0000000000000O1000001O1O2N1O\\L^F_3a9bL_F^3b9aL^F_3b9aL^F_3b9aL^F_3b9aL^F_3b9aL^F_3b9aL^F_3b94010O2L3N2N2N200O1000001O000000000000000O100000000000001O000000001O000001O1O2N1O0000001O00000000000000000000O1O2K4O2N2O1O1O1O1N2O1O1O2XM`Ea2e:O10L_M^Ea2b:_M_E_2b:aM^E_2b:aM_E^2a:bM^E`2a:5001O1O01N10100O1O0001O4L2N0000010O0000001O0O100L4L5N1N2O1100O11M6Ki0UNmCk0_<J?[OSCOiWQ3"}}, "object_label": "bus", "attribute_label": ["color:blue", "color:yellow", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "length, material", "answer": "The image features a large blue and yellow bus driving down a city street. The bus is positioned in the middle of the street, and it appears to be a public transit bus. There are several people around the bus, with some standing near the bus stop and others walking along the sidewalk.\n\nIn addition to the bus, there are two cars on the street, one located behind the bus and another further down the road. A bicycle can also be seen parked on the sidewalk, close to the bus stop. The scene captures a typical day in a bustling city with various modes of transportation in use."}, {"question_id": 237, "height": 640, "width": 427, "image": "000000154358.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [305.62, 282.41, 12.19, 19.61], "segmentation": {"size": [640, 427], "counts": "UUP63hc08K3O0O20O0000O1005GRkS2"}}, "object_label": "vase", "attribute_label": ["color:brown", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The image features a black vase sitting on a table, possibly a coffee table. The vase is positioned in the center of the scene, and it appears to be a decorative piece. The vase is quite large and has a unique shape, making it an eye-catching centerpiece. The table beneath the vase is also black, complementing the vase's color and adding to the overall aesthetic of the scene."}, {"question_id": 238, "height": 640, "width": 427, "image": "000000154358.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, pose, texture, transparency", "region_anno": {"bbox": [242.84, 270.78, 36.31, 41.71], "segmentation": {"size": [640, 427], "counts": "jlk45hc04N2O1O001N1`\\OIWc07h\\OKWc0`002M0O100O1O10A?O2O0O2N2M\\kQ3"}}, "object_label": "potted plant", "attribute_label": ["color:green", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose, color", "answer": "The potted plant in the image is a vase filled with white flowers, placed on a wooden table. The vase is positioned in the center of the table, and the flowers are arranged in a visually appealing manner. The white flowers create a sense of elegance and freshness, adding a touch of natural beauty to the room."}, {"question_id": 239, "height": 612, "width": 612, "image": "000000158660.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [393.43, 127.42, 149.87, 123.86], "segmentation": {"size": [612, 612], "counts": "k]]74Pc01M3N2O1N100O1O1O001O101N1O1O1O1O100O100O10000O1000000O1000000O2O00000O100O101f^O^OP`0d0\\_OOc`0Z1N3N1O2N1O1O2N1O1O1O1N2O1O1O1O1N2O2N1O2N1O1O1V@kL03Z?R3f@kL00NO\\?V3f@kL0O0OZ?W3f@kL0OO0[?V3g@jL03T?Y3i@eL42R?^3o@aLP?`3PA`Lo>_3RAbLn>\\3SAeLl>]3SAbLn>^3QAbLP?^3o@bLR?^3m@aLU?_3k@aLU?`3j@_LW?b3h@]LY?b3h@^LX?a3i@_LW?a3j@^LV?b361O00001OO100O1N2O1M3N2N2N2N2N2N2M3K5N2N2L4K5K6K4QNW_Ob1Wa0Hb^OfNaa0X19YOb^OA_a0?`^OBaa0=Z^O^OL5ja0<[^OIea04\\^ONda02]^OLda04\\^OKea04]^OJda03b^OHaa05i0LT]OMmb06ab0Jc]O1OO2000000000O10001O0000O2O00000000\\i10jcM1hRY1"}}, "object_label": "oven", "attribute_label": ["color:black", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, color, texture, pose, material", "answer": "The oven in the image is a large, industrial-sized appliance, likely used for cooking or baking large quantities of food. It is located in a kitchen setting, and there are two apples placed on the countertop in front of it. The oven is open, revealing its interior, which is likely designed for easy access and efficient use. The presence of the apples suggests that the oven might be used for baking or roasting dishes that require the use of apples, such as apple pies or apple crisps."}, {"question_id": 240, "height": 480, "width": 640, "image": "000000164602.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [1.27, 305.72, 85.87, 67.58], "segmentation": {"size": [480, 640], "counts": "o9_1a=0O2O0O2O0O101O0O2O0O10001N100O2O0O101N100O101O0O10N2L5L4L3N3M2M3\\O^BHe=5]BHf=6]BFf=:ZBCi===00O1N2M3L4M3M]a71a^H2O200O001N101O010O1O0O11O0010O0001O1O10O0000O3M3N3M[^R8"}}, "object_label": "sink", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, pose, texture, transparency", "answer": "The sink in the image is white and appears to be a bathroom sink. It is located in a bathroom setting, and the person is standing next to it."}, {"question_id": 241, "height": 480, "width": 640, "image": "000000164602.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [26.4, 68.65, 324.0, 405.4], "segmentation": {"size": [480, 640], "counts": "lT52l>3M2M3O1O0N3O1J6\\NCcD?Y;HaD<\\;I`D8[;3^DN^;;]DE`;b0\\D^O`;h0^DXO_;m0_DSO\\;U1ZDoM4l0Z;d1bD\\N[;f2N2N2N2M3N2M3M3M3M2O3I6M3L4LkNoEbMo9`2SFaLMf0l9m2YF[LKi0g9P3_FVLJj0e9S3`FSLKj0a9W3aFRLOe0_9Z3bFRLNf0\\9Z3fFPMX9P3jFPMS9R3mFoLP9m2PGkKN[1Q9h2TGmKLZ1m8g2bGXM\\8U1`GdN1nNEY1h8R1iGbNCXOJOOU1i8Q1QH_N]O^OHZ1h8j0UH^NYOR1`8>THAVO]Od8R1mG[NDf0KMb8R1PHV1n7iNTHX1k7hNTHZ1j7eNVH^1h7bNUHc1i7]NXHd1g7[NYHg1f7YNYHi1e7UN^Hl1a7TN_Hm1`7RN`HP2_7oMaHS2^7mMaHU2]7kMaHY2^7fMbH\\2]7dMcH]2\\7bMeH_2Z7aMeHa2Z7]MfHf2X7ZMiHg2V7ZMiHg2U7ZMjHg2V7XMjHj2S6YK[Jl1Bo2Q6XKZJh1ER3o5YKYJe1GT3P6YKVJb1LV3n5ZKSJ`1L[3o5WKRJZ1CXN<Z5n5VKQJX12e3k5VKPJU13i3l5UKmIQ19j3j5XKjIm09P4l5UKiIi0:W4j5eLXJ\\3g5cLVJb3i5\\LVJg3j5YLVJh3i5WLTJo3j5PLTJT4k5lKUJT4k5jKXJV4g5kKXJV4g5c2N1O1O002N1O1O1O010N3M2000O01N3N1O100O1M3O100O1N2O1O100O002N1O1O1O1O1N2O10000O1O1N200O100O10000000000000000000000000000001O0000000O1J60001N1N3J5N2M4M2M4L3O1N3M2N2M3N2N2N3M2N2O2L3N2M4N1O1O1O100O2N1O101N1O1O1O10000O1000001N100O100N2O1O000O2O100O1O1O001O010O0O2O1N101N10N100F;H\\HSIf7j6nHUIa6l6h04MHVHaIb7b6]H_Ic7`6]HaIa7\\6hJ]IZ3`6jLaIS3^6oLcIo2^6RMbIm2^6SMbIl2_6TMaIj2`6YMZI\\M1Y5g6`MXI^2i6cMWI\\2i6^MXI^M0R5j6`MVId2j6g22M3PKQIP2P7PNPIo1P7o20O3L300N3WKfHk1Z7VNfHg1\\7XNeHg1]7YNcHf1]7ZNdHc1^7^NbH`1_7n23N1iK[HP1j7nNXHn0k7R31N]JUIW3h6kLYIT3h3_JQO`2TMS3g3dJQOn7o0VHnNj7Q1ZHjNh7T1]HfNf7Y1\\HbNg7^1\\H\\Nh7c1ZH[Ng7e1ZH[N_1TNh3`3kJ[N\\1VNi3^3lJ\\Nb7b1aHSNRObN^8[3aHRNQOdN\\8[3dHPNPOfN[8Y3gHPNlNiN]8W3gHiMlNlN21\\8Y3hHfMnNoNO0\\8Z3iHfMlNPO0OK1[8Z3PIfMgNQO34V8R3SIjMbNPOON37b1Ho4Y3lJiMaNPO1N16Z8R3TI^M`N_O5L14W8R3UI]M`N@NM0116]8o2WI[M\\N7^8\\2YI[MZN8_8\\2WI[M]N6]8]2XIUMXNL43J5b8f2ZITMcN0C4a8f2\\ITMkN4k7g2[JXMg50XG^2R3bMf5OYG]2T3bMd5d2]J]Mc5`2oI[MgM4[8_2PJ^McM3_8\\2PJ`MbM4^8Y2UJcM[M2c8U2eJkM\\5Q2gJnM[5P2fJPN[5n1eJSN[5l1fJTN\\5g1fJZNZ5b1jJ^NW5`1iJaNX5]1iJbNY5]1gJcNZ5W1[4lNdBKI3S>Oh0OO11OO2N0XAOd>51O3MoALW=3eB3Y=MeB5R>OEIQB6^>L[UZ4"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, face expression, hair type", "answer": "The image features a young man and a young woman standing in a bathroom, both brushing their teeth. The man is on the left side of the image, while the woman is on the right side. They are both holding toothbrushes in their hands, with the man's toothbrush being closer to the left side of the image and the woman's toothbrush being closer to the right side.\n\nIn the background, there is a sink visible, and a bottle can be seen placed near the left edge of the image. The scene appears to be a casual and everyday moment captured by the woman, who is taking a selfie with her cell phone."}, {"question_id": 242, "height": 427, "width": 640, "image": "000000164885.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [251.51, 249.28, 107.63, 10.54], "segmentation": {"size": [427, 640], "counts": "n_X31X=3O1O0000001O00000001O0000000000O100N2O1N20000001N101O001O00000000001N1000O101O0000000001O000000000000000000O1000000000000000000000000000000000000000O10000000001O000000001O000000000000O10000001O001O000000O010O100000O1O\\`d3"}}, "object_label": "skis", "attribute_label": ["color:black", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The image features a pair of skis floating on the water, with one ski on the left side and the other on the right side. The skis are positioned horizontally, parallel to each other, and appear to be in a shallow body of water. The skis are not attached to any skiers, and they seem to be floating freely in the water."}, {"question_id": 243, "height": 427, "width": 640, "image": "000000165039.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [406.12, 93.34, 8.34, 36.36], "segmentation": {"size": [427, 640], "counts": "QjY52R=<\\CGk;b0lC@S<l0109F8H=C_fm2"}}, "object_label": "traffic light", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The traffic light in the image is a tall, skinny structure with a large number of lights on it. It is located near a building, possibly a skyscraper, and is situated in a city setting. The traffic light is positioned in the middle of the scene, with the building in the background and the lights on the traffic light being the main focus of the image."}, {"question_id": 244, "height": 461, "width": 614, "image": "000000175364.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [232.87, 116.4, 12.1, 26.49], "segmentation": {"size": [461, 614], "counts": "`PY3b0j=2N1O100001O00001O0O2ORPV5"}}, "object_label": "bottle", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, transparency, material, color", "answer": "The image features a silver bottle, possibly a canister or a metal container, sitting on a wooden shelf. The bottle is positioned in the middle of the shelf, and it appears to be the main focus of the scene. The wooden shelf provides a contrasting background for the silver bottle, making it stand out."}, {"question_id": 245, "height": 480, "width": 640, "image": "000000195842.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [420.7, 131.12, 8.65, 30.84], "segmentation": {"size": [480, 640], "counts": "oPU62[>5lA1j=NRB`0n=AQBa0m=_OVB?i=BWB=i=CXB;j=DWB9m=F\\BN`VS3"}}, "object_label": "remote", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, material, texture", "answer": "The remote in the image is a white, rectangular object with a handle on the top. It is placed on a surface, possibly a table or a counter, and is positioned in the foreground of the scene. The remote is likely used for controlling a television or other electronic devices, and its presence suggests that someone might be watching TV or using other electronic devices in the room."}, {"question_id": 246, "height": 480, "width": 640, "image": "000000195842.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [279.69, 288.44, 172.56, 95.79], "segmentation": {"size": [480, 640], "counts": "XPU43^Q60]]J<E8H2N100O0001N2O010N101N1N3O1O0010O10001N101O1N2O001N2O001N2O001O0O100000N101M300O1M2M4M2L5M3N2L4Oid6O[YJ0lQO1O2O100O1O0^MLYF5g9KYF4h9LWF4j9LUF4l9LRF4P:LPF3Q:MnE2T:NdCOT22Y:0bCNT24Z:MgCOh16a:LcC2j13d:JbC3i15e:HbC2i16e:HbC2g18g:FbC2f19h:EbC2e1:i:DcC1c1<j:CcC1c1=i:BdC1b1>j:@eC3_1>R;ClD>T;DiD=W;DgD>Y;]O[C0[1d0^;[ObDf0_;YO`Dh0k<1[NXOQEi0o:VOQEk0a<1_OTOmBn0R=ROhB0IQ1^=POhBT1`=2L4O1L400N2AaN\\Ca1b<?0RNWCe1i<ZNYCe1g<YN[Cg1o<O0100O100GXNYCi1^<UNeCR2\\<nMdCR2\\<oMcCQ2]<oMcCQ2]<QNaCn1a<QN_Co1a<RN^Cm1c<SN]Cm1d<RN\\Cm1e<SNZCm1g<SNXCn1i<32O2M101N010O1O100O100O1O1O1O1M3L5L7AcYh2"}}, "object_label": "couch", "attribute_label": ["color:blue", "color:yellow", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose", "answer": "The couch in the image is a blue and yellow children's couch, featuring a colorful and playful design. It is placed in a living room, and there is a box on the floor next to it."}, {"question_id": 247, "height": 480, "width": 640, "image": "000000195842.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "color, pose, texture, transparency", "region_anno": {"bbox": [496.63, 19.0, 39.25, 40.18], "segmentation": {"size": [480, 640], "counts": "WPY75f>9J4L4L3N2N2N2N2N101N100O2O0O1000000000000000O10000O2O0O2N1O2N2N2N1O3L4M3K8DSg`1"}}, "object_label": "clock", "attribute_label": ["color:white", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, transparency, texture", "answer": "The image features a white clock with black numbers and hands, prominently displayed on a wall. The clock is positioned in the upper-middle part of the wall, making it easily visible. The clock's hands are pointing to the numbers 12 and 1, indicating that it is almost 12 o'clock. The clock's design and placement create a sense of order and time awareness in the space."}, {"question_id": 248, "height": 367, "width": 500, "image": "000000225757.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [95.92, 217.55, 70.51, 20.35], "segmentation": {"size": [367, 500], "counts": "foR13Z;4L2O2N1O2O00000O10000000O0100000O100000O10O100O1000000O1000O10O10000000O100000000000000O1000000000000000O0100000000001O0O101O0O101N2N2Ne_g3"}}, "object_label": "remote", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, material, texture, color, pose", "answer": "The image features a close-up view of a remote control, which is placed on a wooden table. The remote is black in color and has several buttons on it, including a large one in the center. The buttons are arranged in a way that allows for easy access and control of various functions. The remote control is designed to be used with electronic devices, such as televisions or audio systems, to operate and adjust settings without the need for physical interaction with the devices themselves."}, {"question_id": 249, "height": 367, "width": 500, "image": "000000225757.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [319.33, 40.86, 161.93, 154.37], "segmentation": {"size": [367, 500], "counts": "Vjb3438b8I]GV1;Ac7d2N2O0O2O001O001O0001O01O0000010O0000001O0000001O01O000001O00001O00010O0000001O000001O01O0000001O0001O0001O0000000001O01O00001O0010O01O0000000000001O010O00000010O000001O00000000001O010O0000000010O000001O00000010O00000010O00001O0000001O0000010O001O0000010O001O0000000001O0001O0001O0O1O1O1H8H8H8J6G9H8H8H9C<D<I7H9Gej7"}}, "object_label": "tv", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose, material, color, state", "answer": "The image features a flat screen TV mounted on a wall, displaying a sunset scene with a cactus in the foreground. The TV is positioned in the upper left corner of the image, and the sunset is visible in the background. The cactus is located in the center of the screen, adding a unique and interesting element to the scene."}, {"question_id": 250, "height": 333, "width": 500, "image": "000000226417.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [430.21, 210.13, 15.73, 24.65], "segmentation": {"size": [333, 500], "counts": "eQ\\42Y:;F1O1N1O2O101N1N200001O2M2Fmea0"}}, "object_label": "fire hydrant", "attribute_label": ["color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, transparency, texture", "answer": "The image features a red fire hydrant sitting on a sidewalk next to a building. The fire hydrant is positioned near the corner of the sidewalk, making it easily accessible for emergency services. The hydrant is surrounded by a metal pole, which provides additional support and stability. The hydrant's color and design make it stand out against the urban backdrop, ensuring that it is easily identifiable in case of emergencies."}, {"question_id": 251, "height": 423, "width": 640, "image": "000000229358.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [410.44, 300.72, 47.94, 15.68], "segmentation": {"size": [423, 640], "counts": "`RZ52U=1N2O1O1O1O1O1O0O1000000O1O10000O100O10O1000000000001O0O10000000000O0100000O1O100O1O001O1N3N^lZ2"}}, "object_label": "bowl", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The image features a bowl with a unique design, resembling a bird or a bird's head. The bowl is placed on a table, and it appears to be made of glass. The bird-like design adds a creative and artistic touch to the bowl, making it an interesting and eye-catching piece."}, {"question_id": 252, "height": 423, "width": 640, "image": "000000229358.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [198.7, 75.65, 17.09, 43.3], "segmentation": {"size": [423, 640], "counts": "mka21S=:G;F7J8G5L010O0001N10002N3M<D;Ee^_5"}}, "object_label": "bottle", "attribute_label": ["color:white", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a clear plastic bottle with a blue cap, containing a white substance. The bottle is filled to the top, and the white substance appears to be a liquid. The bottle is placed on a table, and the close-up view of the bottle highlights its contents and the blue cap."}, {"question_id": 253, "height": 423, "width": 640, "image": "000000229358.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "cleanliness, color, pose, state, transparency", "region_anno": {"bbox": [369.68, 280.03, 22.21, 81.32], "segmentation": {"size": [423, 640], "counts": "n`i46Q=8Gj0XO3M32M5H5K5J2N3M4L5K8GhPY3"}}, "object_label": "toothbrush", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "state:off"], "control_dims": "pose", "answer": "The image features a white toothbrush with a green handle, which is placed on a countertop. The toothbrush is positioned vertically, with the green handle at the top. The toothbrush appears to be a manual toothbrush, and its design is simple and functional."}, {"question_id": 254, "height": 346, "width": 500, "image": "000000236599.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [278.61, 88.55, 36.5, 47.13], "segmentation": {"size": [346, 500], "counts": "d\\n24b:5K4M3N2O1N3NJnEFP:866M7J4L3M3N1O1OZO^F4_9]OaF=43[90hFMY91kFDG2]99oFDCN11^9=oFCBOc9`0kF@B2`9a0PG^Oo8e0oF]OQ9a0nF@S9L`Fa0<CW9=jF@X9?b0J6O10001N2N2NY]n1"}}, "object_label": "kite", "attribute_label": ["color:blue", "color:yellow", "material:paper/cardboard", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, pose, color", "answer": "The image features a colorful kite with a long tail, flying high in the sky. The kite is shaped like a bird and has a long, curved neck. The tail of the kite is made of many different colors, adding to its vibrant appearance. The kite is soaring above the ocean, creating a beautiful scene with the sky and water in the background."}, {"question_id": 255, "height": 427, "width": 640, "image": "000000239041.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [30.66, 280.25, 29.28, 61.54], "segmentation": {"size": [427, 640], "counts": "bV=2X=1000O0100[C>a;B^Dc0];@UDQ1f;a0H3N1O09G100O3M;E1O0O10001O0O3M7I8H;Ef[b7"}}, "object_label": "bottle", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose, material, color, transparency", "answer": "The image features a bottle of hand soap, which is placed on a counter or table. The bottle is blue in color and has a pump dispenser attached to it, making it easy to use. The soap dispenser is located on the left side of the bottle, and the bottle itself is positioned towards the center of the image."}, {"question_id": 256, "height": 427, "width": 640, "image": "000000239041.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [0.0, 294.58, 87.32, 127.62], "segmentation": {"size": [427, 640], "counts": "X:S3X:000O1001O00001O001O0O10000^Ob0M3M3OWOlM]FS2c9oM\\FP2e9PN[Fn1g9RNYFl1i9TNWFk1j9UNVFj1k9VNUFi1l9WNTFh1m9YNaEK<l1T:]NlEc1T:]NkEc1V:]NjEc1V:^NhEc1Y:\\NfEd1[:]NcEd1]:]NaEd1`:RNZE0;m1o:01O2N:E3N1O001N10000O1000000O100O01O1O1O1UOkN`ET1a:POZEQ1f:XOoDj0Q;g0101O0O10001N101O001N2O001N2O1O0O101N2O1O1N3N1N6J7I7Ha0^OPXV7"}}, "object_label": "sink", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The sink in the image is a white porcelain sink with a metal faucet. It is situated in a bathroom, and there is a bottle of hand soap placed on the edge of the sink."}, {"question_id": 257, "height": 612, "width": 612, "image": "000000305609.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [337.51, 109.22, 114.14, 61.21], "segmentation": {"size": [612, 612], "counts": "oZX65mb05K4M2N2N2N101O08G3N2GV]O4ob0N0100O01O10O00000TONf^O2Ya01d^O0\\a03_^ONba05Z^OLea09W^OGia0;P^O@O6Qb0;n]OA03Sb0i0O1000000O100000000O0100O100O10O010000O1O10000O1000O01000000000000001O001O001O001O0010O01O1O001O1O1O1O2N00100O1O1O1O1O010O00O100O2O000O101O0O101N1O2O001N100O2O0O2O1N1O2N2O1M3N2N3L4LjYn2"}}, "object_label": "bowl", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, color, material, transparency, texture", "answer": "The bowl in the image is white and filled with a creamy substance, possibly soup or a sauce. It is placed on a dining table, and a spoon is resting inside the bowl. The bowl is positioned towards the center of the table, and the spoon is located towards the left side of the bowl."}, {"question_id": 258, "height": 612, "width": 612, "image": "000000305609.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, material, pose, size, texture", "region_anno": {"bbox": [206.88, 264.25, 57.97, 103.33], "segmentation": {"size": [612, 612], "counts": "aok34nb04L4M4L3f]OBja0P1K9Hf0YO8H6K4K5LO100002M2O1O001O0000000001O0000001O00001O001O10O02M2_Mi_OS2i`0K2N3L3N3L3N7H6K3M<C5L2M3N2M9FQ^a6"}}, "object_label": "bottle", "attribute_label": ["color:gray", "length:long", "material:glass", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a small glass bottle filled with salt, sitting on a table. The bottle is placed on a tablecloth, which adds a decorative touch to the scene. The salt in the bottle is white, and the bottle itself is clear, allowing the salt to be visible inside. The table appears to be a dining table, and there is a bowl located near the top right corner of the table."}, {"question_id": 259, "height": 640, "width": 480, "image": "000000328683.jpg", "category": "description", "question": "Describe the parking meter in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [163.59, 36.04, 134.89, 203.77], "segmentation": {"size": [640, 480], "counts": "miW3c0[c08I6J5K3M5K5J5L3L4Mb0]O:F6K4L4L3M4L3M3M3M4M1N3N2N2M3N2N3M2N5K7I5K7I6J4L6K5J4L100O10O010O001O010O1O0O2O1N1O3N1N2O1N2O2M3N1O2M2O1O1N101O001N101OO100O1O1O10000000N10100005LO01O1O01O1O001O00001N2O0O2O1M3J5H9G9H9F9G9M3M4M4K4L2O2M2O2N1N3L3N3L3WO\\^OQOja0j0h0M4H7J8I8AaQf3"}}, "object_label": "parking meter", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, pose, color, texture, transparency", "answer": "The image features a parking meter with a bird perched on top of it. The bird is sitting on the parking meter, which is located on the side of a building. The parking meter is positioned near a window, and the bird appears to be looking at the camera. The scene captures a unique moment where the bird has found a resting spot on the parking meter."}, {"question_id": 260, "height": 640, "width": 480, "image": "000000328683.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, length, material, pose, transparency", "region_anno": {"bbox": [169.84, 251.88, 50.2, 247.7], "segmentation": {"size": [640, 480], "counts": "c`Z332^1ka0l0Eh0YOi0XOm0S@VKj>X5H11O2OXAUK:KLLJMS=j64_NhB_K0GY=c4PCaKJJW=d4nBcKKHY=b4cBSK8c0NFX=b4nBhKO@V=<fBa36aLOBW=9fBc35aLOAY=6gBg30cL0@^=OeBm3MdL1^OR>n3mAcL1_OT>m3jAeL1^OY>i3fAiLN_O_>f3eAjLi>T3XAkLi>U3WAjLj>W3TAjLl>V3TAjLm>U3SAkLm>V3SAiLo>T3RAkLQ?S3o@mLS?Q3m@mLGIS?Z3UAoLGDZ?i0g@^18UNHC]?d0f@c15mMFOj?:`@i1OnMJM0NO0^?4PAR2IoMLKM4LN[`0R2R@PN17l?g0m_OD8\\OGN02I6\\`0c0d_OVO<b0h0I\\?<R@GNA37U`0>k_OIMC24Y`0?h_OJMBH0Ta0c0W_OK4Fh`0:V_ONLFca0Oc^O6MM[b0Ni]O0j`T5"}}, "object_label": "potted plant", "attribute_label": ["color:gray", "color:green", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "length, color, pose, material, transparency", "answer": "The potted plant in the image is a small tree with green leaves, placed on a sidewalk near a building. It is situated next to a bench, and there is a small sign on the tree. The tree is surrounded by a variety of colorful balls, which are likely decorations or ornaments. The combination of the green tree, the bench, and the colorful balls creates a visually appealing scene on the sidewalk."}, {"question_id": 261, "height": 426, "width": 640, "image": "000000334555.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [125.67, 160.79, 44.36, 46.2], "segmentation": {"size": [426, 640], "counts": "\\bd13V=9lBL92d;R1O01O1O1O1O1N2O1O1O1O1O1O1O2M1010O001O2N2OO01O000001O0O2O0O1O2M3M2O2N3M4J5L[PU6"}}, "object_label": "car", "attribute_label": ["color:blue", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, pose, material", "answer": "The image features a blue car parked on the side of a street. The car is positioned near a gate, and there is a person standing next to it. The car appears to be a compact vehicle, and it is parked in a parking space."}, {"question_id": 262, "height": 375, "width": 500, "image": "000000341973.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [0.0, 344.66, 59.83, 26.13], "segmentation": {"size": [375, 500], "counts": "i:i0n:00000000000000000000000000000000000000000000000000000000000000000000000000001O00000000000000000000001OO1L4M3K5K6IRaQ5"}}, "object_label": "bench", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, pose, texture, transparency", "answer": "The image features a wooden bench with a brown surface. The bench is situated in a room, possibly a kitchen or a dining area, and is located near a wall. The bench is positioned in the middle of the room, and it appears to be the main focal point of the scene."}, {"question_id": 263, "height": 375, "width": 500, "image": "000000350054.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [287.58, 143.6, 33.4, 46.25], "segmentation": {"size": [375, 500], "counts": "hcY35a;100N2O00001O1O4hDH1N`:<\\E41CW:W100000010O0001O001O001O1O2N2TObE;c:ZOdEe0h:O1O2N2N2MdSR2"}}, "object_label": "teddy bear", "attribute_label": ["color:brown", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pose, color, transparency", "answer": "The teddy bear in the image is wearing a Santa Claus hat, which adds a festive touch to its appearance. It is sitting on a couch, possibly in a living room. The teddy bear is positioned in the middle of the scene, and it appears to be the main focus of the image."}, {"question_id": 264, "height": 375, "width": 500, "image": "000000350054.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, pose, state, texture, transparency", "region_anno": {"bbox": [139.95, 30.15, 231.18, 153.87], "segmentation": {"size": [375, 500], "counts": "]ec11263K1Oh:\\1\\Oc1\\NX1iN8H2N1O1O1O000000EoHPLQ7P4oHPLQ7P4oHPLQ7P4PIoKP7Q4PIoKP7\\400000`LoHZ2Q7fMPIY2P7fMQIZ2o6hMoHX2Q7W10000000TLoHR3Q7mLQID02O^2o6mMPID21N_2P7i1000cLPIR2Q7Z10O1O1VLmH]O11OR3S7gMnHX2[7R10O1O100mLbHm1^7RNcHn1]7dMbH\\O0810O]2^7oMeHDMi2^7cMgHf2Y7ZMfHg2Z7YMfH?LQ1_7`NeHS2NgM]77eHn19aMT7`0cH@LX2V8XNnG_ONV2V8[NlG@LU2Y8\\NjGj1W8UNjGk1V8UNkGi1V8WNkGf1W8ZNjGd1W8\\NiG4Ie0^8XOhG3JYO0X1^8\\OhGd1V8]NeGh1[8XNgGf1Y8YNhGh1W8XNfG[O10OX2Y8\\NhG\\O5X2R8\\NSH]ODT2X8_NmG[O02KU2W8`NiG]O3\\2P8]NoGYONU2Q8bNRHVOMZ2Q8^NSHi1O]Mg7j0ZHi1OgM]7`0dHi1OiM[7=fH:L;2PO[7;iHi1JnM]7:hHl1KhM[7?gHi1NiMZ7?hHg1NlMX75iHX2O\\M0KW7`0kHENW20gM41m6<UIAJf23^Mn6:PI[O46KS10:2hNo6:WIQ2H\\M0808l63]IBGO0m12mM00O10e0k6O]Ia1GWN0D2042L:j68\\Id0HB2ENB60N1L4l6>[Io07]NE:4E11NOL6j6?[I7N@d0NNG^O0K1m6c0ZI\\OKf04Ch0JBODN06h6>[I[OMd0M@05d1K\\N014j6=[I\\OJX1i1lNWNK15k6`0ZICLg0h1VOVNK15k6`0ZICLg0i1UOZNOh6b0YIDKe0l1UOXN0h6c0RIZO4\\1U2fNe4g0XICKa0W2SOf4h0[IAHd0X9KPGEH<X9LQGf0o8ZOQGg0n8YOmF[ON\\1U9YORG_OFR1X9@jFZO2]1T9YOjFZO2]1T9YOPG^OJLOR1W9CQG\\OG05R1R9BRG_OLP1Q9@VG_OGR1S9_OWG^OET1T9_OSG\\OG[1V9YORGl01eN[8?eGm0IkN`88jGCENOW1b8XOjGDD^1`8mNjGd1S8\\NlGe1T8[NlGe1T8\\NkGd1U8\\NiGf1W8ZNjG^OIS2\\8_NlG\\OJT2Z8`NlG]OHT2\\8_NjGh1U8XNjGj1U8UNlG8Je0Z8TOkGk1T8m0O\\MhGi1X8WNhGYO1[2W8ZNhG]O0[2W8WNkGo1T8PNmG2MU1V8iNlG2OV1T8d1O00XMlGn1S8QNnGZOOa2S8SNoGR2Q8nMoGR2Q8mMQHR2o7nMRHQ2n7l001OZMnGg1R8YNnGf1S8TNmGR2S8nMmGQ2T8i0000O10000N200O100000000\\MhG80>X8o1O]MiGg1V8n0O000O10XMmGl1S8TNmGm1R8RNPHm1P8SNPHm1P8SNPHm1P8SNoGn1Q8RNnGo1?]Mm6^3PIiLl6W3TI^LD8X7a0iHHNa1a0VNg6Z3YIeLh6[3YIcLh6d0gHm1a0]Mj6f0eHm1a0\\Mk6`3oH_LX7`3gHbLY7g0\\Hc00I8PO\\7d0\\H@0g005:mNW7M`Hb3o73000001O0000[LQHb3o7^LQHb3o7^LQHb3o7]LRHc3n7^LQHb3P82002N0000kH`LT6_3hI^LYO3n6`3gIfLY6Z3fIaL[O0n6_3cIdLALl6`3bIeLBKm6_3`IgLCJm6_3TIcLL;0DP7a400O10mNSIaLNe0o6i2WI^LLh0m6h2\\IXMe6g2YI\\Mg6d2SIbMm6_2QIbMP7^2oH`MS7a30oNnH^MS7a2oH^MQ7d31_M\\ILf6XOjHTOc1IkNe0l6ZO`L<dQ`1"}}, "object_label": "tv", "attribute_label": ["color:black", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "state, transparency", "answer": "The television in the image is a flat screen TV, which is turned on and displaying a Christmas tree scene. The TV is placed on a wooden table, and it is surrounded by various stuffed animals. Specifically, there are three stuffed animals sitting on the table in front of the TV, with one on the left side, one on the right side, and another one in the middle. The arrangement of the stuffed animals and the TV creates a cozy and festive atmosphere."}, {"question_id": 265, "height": 640, "width": 480, "image": "000000350148.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [0.0, 112.94, 83.31, 111.58], "segmentation": {"size": [640, 480], "counts": "n3c2]a01O2N0000O2O0010N1O1O11O1O00O1001O0000O10000001O0000000000O10000001O0000O100001O00000000000O1001O000000001OO100000000001O0000O11O3M3M2N2N10O000000OdMV_O@Ol1k`0[NU_OH4ONm1i`0[NW_OH:m1_`0\\NV_OF<n1^`0\\NT_OF`0n1\\`0\\NS_OJ>j1``0WNV_O;LD2d1ca0YNi^O2FY1cc0dN\\mg7"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, texture", "answer": "The image features a white car parked in front of a building, possibly a business or a shop. The car is parked in a parking lot, and there is a sign on the door of the building, indicating that the business is closed."}, {"question_id": 266, "height": 480, "width": 640, "image": "000000356169.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [0.0, 295.8, 27.38, 66.08], "segmentation": {"size": [480, 640], "counts": "X9Q2o<O2N2N1O2M201N101O001N101O1N3M2O2M3N2N2N2M2O?A2N5EZA0Tno8"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a black car parked next to a blue car. The black car is positioned in the foreground, while the blue car is in the background. The black car is parked in front of a building, and the blue car is parked further away. The scene appears to be captured in a blurry manner, giving it a slightly distorted appearance."}, {"question_id": 267, "height": 480, "width": 640, "image": "000000356169.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [364.28, 322.07, 18.31, 14.36], "segmentation": {"size": [480, 640], "counts": "ZnZ53i>5N2N2N1000O100O100001O00001O02N1Ojch3"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, material", "answer": "The image features a silver car parked on a street. The car is positioned in the middle of the scene, with its back end visible. The car appears to be a compact vehicle, possibly a hatchback."}, {"question_id": 268, "height": 480, "width": 640, "image": "000000356169.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [45.28, 334.55, 17.32, 37.71], "segmentation": {"size": [480, 640], "counts": "gle053O=M_=P1N3O0M3N22N1O1O1O1O3^O\\BAh=1nA5g>O001NRc^8"}}, "object_label": "fire hydrant", "attribute_label": ["color:blue", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose, material", "answer": "The image features a fire hydrant with a red top and a blue hat, standing in a grassy area. The fire hydrant is located near a tree, and it appears to be a bit blurry, possibly due to the camera's focus or the movement of the person taking the photo. The hydrant is positioned in the middle of the scene, and the grassy area surrounding it adds a natural touch to the image."}, {"question_id": 269, "height": 427, "width": 640, "image": "000000476119.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [77.13, 361.49, 119.86, 53.3], "segmentation": {"size": [427, 640], "counts": "o_P1:P=3N1O001O000001N10O10000001N5H5N1001O0CO`C1`<0_C0a<0_C0a<1]COd<1[C0e<0YC2g<NXC3h<MWC5i<601OO1000O10O1GXC0g<N\\C1d<O\\C1d<N]C2b<O^C1b<O^C1b<N_C2`<O`C1`<O`C1`<NbC1^<ObC1^<ObC2]<NbC4]<LbC7\\<IaC:_<FaC;^<EbC;^<EbC;^<EbC;^<EbC;^<EbC;^<EbC;^<EbC;^<EbC<^<CbC=^<CbC=^<CaC>^<DcC9^<G<MUC4LLS=420O1O0010O01O0010N110O00001O10O00010O01O00010O000100O010N110O01N10100OnBNl<3TCMl<2UCNl<0UC0k<064N2M4K201N10000001O0O100O106Fl[h5"}}, "object_label": "skateboard", "attribute_label": ["color:gray", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color", "answer": "The skateboard in the image is a black and white one, with a person riding it on a sidewalk. The skateboarder is wearing black shoes, and the skateboard is positioned in the middle of the scene."}, {"question_id": 270, "height": 375, "width": 500, "image": "000000501023.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [211.9, 34.9, 135.8, 324.4], "segmentation": {"size": [375, 500], "counts": "g[]26_;4M2N3M2N2N3M1O2O1N2N2O1N2O1N1O2N2N2N2N3M2N2N2N1O2N3M2N2N3M3nGoMZ6R2aI^NcN_O\\7U2mInNe5U1YJmNUOkNR6Y2hJmNTOnNP6W2kJfMlNOO_1Y6n0kJdMPO^1T6P1lJaMPO_1S6R1lJ_MPO`1S6T1kJ\\MPOb1T6S1lJ[MPOb1S6U1lJYMSO`1P6Y1kJXMTO`1P6[1jJUMUOa1P6\\1jJSMWO`1o5^1jJQMWOa1n5`1jJoLXOa1m5b1jJmLXOa1n5d1iJkLYOa1m5f1iJiL[O`1k5j1hJfL]O`1j5l1gJeL^O`1j5m1hJaL@a1g5P2mJPNR5R2hJ]LBa1e5S2iJ]L@`1g5U2hJ[LB_1e5Y2gJXLD_1d5[2gJVLE_1c5]2fJTLH_1a5_2gJQLH`1`5a2lJ_MS5c2lJ]MS5e2mJZMS5g2kJZMT5h2kJXMU5h2fJiKK`15]OS4\\3jK]M0Jg3i2XL]M28W3[2gL]M2P1M]M\\2T4fM_MO_1U2R1lM_MNj1m1f0UN`MNR2f1=\\NaMNS2f1;]NbMLS2h1:]NmKKb10W2i18`NaMGW2j16aNbMEW2l15\\NRLK`1OX2k14\\NTLJ`1OW2m13[NVLI`1OU2P23YNYLG^15Q2m15XNPN?V1[1i0VNQNn0g0l0V1YN_LB_1k18=i1VN_LC_1[2F0Y2TNbLA_1[3aNVO]3nMcLA`1P6k1eJTN]5i1_JiL^O_1S6g1`J]Na5a1`J_Na5`1_JmL\\O_1V6b1cJ^N^5`1cJ`MVO<Z6Q2aJcMUO<\\6n1`JfNa5V1^JmNc5Q1YJ]MYOc1_6n0YJ_MXO0O`1a6j0bIfMf00\\O_1]6i0fJWO[5g0bJiMmN0O\\1d6i0eJkMgN\\1e6g0dJ]O]5a0]JPNmNb1f6=^JQNkNc1h6:^JSNjNc1i68^JUNjNb1i67_JVNhN1O_1k68bJYNcN_1m65aJ\\NbN_1m64^J]NfNb1m6O^J5c5I^J7c5G^J9c5E^JeNaNc1R7FbJgN\\N_1S7HbJiN[N_1T7FbJkNZN_1U7C_JnN]Nb1U7^O_JPO[Nc1W7[O_Jh0b5VO_Jj0a5UO`JUOXNc1Y7WOcJVOUN^1Y7YOdJYOSN^1Y7YOdJYOTN]1Y7WOdJo0]5POcJo0_5nNdJo0^5POjJh0X5VOiKF[4:b3N2N3L6JYVg1"}}, "object_label": "stop sign", "attribute_label": ["color:red", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, color, texture, material, transparency", "answer": "The stop sign in the image is a red and white sign with a yellow background. It is placed on a pole, and the sign is positioned on the side of a road. The stop sign is located near a dirt road, and there is a car visible in the background."}, {"question_id": 271, "height": 359, "width": 640, "image": "000000534394.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, texture, transparency", "region_anno": {"bbox": [3.09, 224.66, 87.24, 120.44], "segmentation": {"size": [359, 640], "counts": "S7=5Y2j7hMUH^2e7dMYHa2b7_M^Ha2c7^M\\Hc2d7`000000mL]Ha2d7_M\\Ha2d7_M\\Ha2d7^M]Hb2d7^M[Hb2e7^M[Ha2f7_MYHb2g7?00000PMYH_2h7`0000O1000001N1VMVHW2j7hMWHX2i7gMXHY2h7c0000O10000O101O000O100O10000O2O000O100O2O000O100O2O0O101O0O1O2O0O2N100O2N2N1O2N101N2N2N1O3M1O2N3K4N2N3M3L3L5L5K6H9FgcQ6"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, color, material", "answer": "The car in the image is a white car with a side view mirror. The mirror is positioned on the side of the car, allowing the driver to see the surrounding area."}, {"question_id": 272, "height": 427, "width": 640, "image": "000000059044.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [343.91, 182.89, 30.71, 22.11], "segmentation": {"size": [427, 640], "counts": "VW_41Y=2N1O1O1O2O0O1O1O1O1O1O1O1O1O1N2O100O1001O0O2N101J5O100O2O1M2OXZ^3"}}, "object_label": "remote", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The remote in the image is a white, rectangular object with a button on the top. It is placed on a surface, possibly a table or a couch, and is located near a person's hand. The remote is likely used for controlling a television or other electronic devices."}, {"question_id": 273, "height": 427, "width": 640, "image": "000000084752.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [298.31, 343.94, 17.26, 11.71], "segmentation": {"size": [427, 640], "counts": "\\cl35U=1O2N100O1000000O00100000L4M3O1OPVW4"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color, material", "answer": "The image features a row of cars parked in a parking lot. The cars are lined up in a straight line, with one car being red and the others being black. The red car is parked in the middle of the row, while the black cars are positioned on either side of it. The cars are parked close to each other, creating a neat and organized appearance."}, {"question_id": 274, "height": 427, "width": 640, "image": "000000084752.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [310.72, 340.18, 22.6, 16.22], "segmentation": {"size": [427, 640], "counts": "kPR45T=2O2N001O1O1O10000O10000000O1000000001O00LPfo3"}}, "object_label": "truck", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "texture, material", "answer": "The image features two trucks parked next to each other in a parking lot. The first truck is a red pickup truck, while the second truck is a black van. Both vehicles are parked in a line, with the red pickup truck being closer to the left side of the image and the black van being on the right side. The parking lot appears to be a covered area, providing shelter for the vehicles."}, {"question_id": 275, "height": 427, "width": 640, "image": "000000100274.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [173.14, 205.49, 57.61, 19.72], "segmentation": {"size": [427, 640], "counts": "jUY21W=3O1N20000O1000000000000000000000000000000000001O000000O10010O0000001O001O001OmBMo<3PCNo<2QCNP=1oB0Q=0oB0Q=50O2O2OO1O0000010O01O2N2M\\mY5"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a white car parked in a parking lot, with another car parked behind it. The white car is positioned in the middle of the scene, while the other car is located towards the right side of the image. The parking lot appears to be a busy area, as there are several other cars parked around the white car."}, {"question_id": 276, "height": 427, "width": 640, "image": "000000100274.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, transparency", "region_anno": {"bbox": [488.55, 145.7, 40.39, 49.05], "segmentation": {"size": [427, 640], "counts": "nd[6124d<f0I3M1O2N2O0O10001N101O001O001O001N10000001O00001O001O1O00001O01O10M201Ob0^O3M1NRa^1"}}, "object_label": "train", "attribute_label": ["color:black", "color:orange", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque"], "control_dims": "color, transparency, material, length", "answer": "The image features a large train traveling down the tracks, with a yellow and orange color scheme. The train is moving along the tracks, and it appears to be a freight train. The train is quite long, with multiple cars attached to it. The train is positioned in the middle of the scene, and the tracks are clearly visible."}, {"question_id": 277, "height": 612, "width": 612, "image": "000000121506.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [26.43, 357.51, 109.26, 37.63], "segmentation": {"size": [612, 612], "counts": "hS><gb02N101O0000O01000000O10000O1000001N101O000O10O10O2O00000O1000O10O10O1000O100000O10O100000O10O01N1010O101N01000000O010O10O01000000O100O1000O10O1000000O101O0O10000O1000000O10000O1000000O100000000O100O10000O10000O10000O011O0O1000000O10O100001N1O2NnTf8"}}, "object_label": "dining table", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color, texture", "answer": "The image features a wooden dining table with a bench on each side. The table is placed in a grassy area, surrounded by a few trees. The benches are positioned on both sides of the table, providing ample seating for people to enjoy their meals or gatherings. The table appears to be empty, with no people or objects occupying the space. The overall setting gives a sense of tranquility and relaxation, making it an ideal spot for outdoor dining or socializing."}, {"question_id": 278, "height": 424, "width": 640, "image": "000000158744.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [485.79, 163.97, 88.99, 113.39], "segmentation": {"size": [424, 640], "counts": "W_Y65o<6J5M3M3M3N2M3N1O2N2M2O2BlN`DONX1`;<01O[NdD^1d;0O10O01O001O0O1N3N1N2N3N1POUNcFl1\\:0mNUNhFl1W9UNgFm1X9SNSFN;a0_Ok0P:gNVFO:=Bm0k9iNZFM8<Fm0g9iN^FL5=Hn0e9iN\\FM8;Io0b9kNYFL=8KP1^9nNXFK`05KR1]9nNXFIc05JS1Z9POXFHe03KU1W9QOnGn0R8QOoGo0S8lNQHR1R:1O0O10TO^D3b;LaD2_;NaD2_;NbD1^;OaD3^;MbD3];OcD0^;OaD3];NbD3^;McD2];NcD2];OcD1[;OfD1Y;0gD0Y;0gD0X;1hD0W;0iD0W;0jDOQ;6oDJR;4oDMQ;2oDNR;1nDOS;OnD1R;OmD2S;OmDOT;1lDOT;1mDNS;2nDMR;2PEMP;2REMn:2SEOl:1UENk:2VENj:1WENj:2VEMk:3VEKj:0]ENd:O`ELd:1mUk0"}}, "object_label": "chair", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "material", "answer": "The chair in the image is a white plastic chair with a clear plastic bag covering it. The bag is placed over the chair, covering its entire surface. The chair is positioned on a street, and the person holding the bag is standing next to it."}, {"question_id": 279, "height": 424, "width": 640, "image": "000000158744.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [433.91, 236.78, 29.74, 58.37], "segmentation": {"size": [424, 640], "counts": "Roc5a0Z<=I8F:J6O00001O001O0001O0000000000000000000O10000O2mNiD3\\;EPE2iiY2"}}, "object_label": "suitcase", "attribute_label": ["color:orange", "material:leather", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, material, pose, color, texture", "answer": "The image features a red suitcase, which is sitting on the ground. The suitcase is open, revealing its contents. The suitcase is placed on a surface, possibly a sidewalk or a street, and appears to be empty."}, {"question_id": 280, "height": 427, "width": 640, "image": "000000214539.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [349.23, 231.41, 92.39, 9.29], "segmentation": {"size": [427, 640], "counts": "\\Xd44V=2O00000000000000O01000000O1000000000000001O1O00N2O101O00000000O10000000000000000000001O1O0000000000000001O00O10000001O0000000000O10000001O0000000001O00000001O001O0O11N1NUhb2"}}, "object_label": "bench", "attribute_label": ["color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "material, color, transparency, texture", "answer": "The image features a bench situated in a park, with a person sitting on it. The bench is located near a tree, providing a pleasant and relaxing spot for the person to enjoy the outdoors. The person is wearing a green shirt, which contrasts with the greenery of the park. The scene captures a moment of tranquility and leisure, as the person takes a break from their day to sit on the bench and appreciate the natural surroundings."}, {"question_id": 281, "height": 480, "width": 640, "image": "000000227491.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, material, texture, transparency", "region_anno": {"bbox": [40.66, 341.19, 528.58, 138.81], "segmentation": {"size": [480, 640], "counts": "i`d08g>1O2O000O100000000O101O000O10000O10001N100000000000000001O00010OJBjA>V>BjA>V>BjA>V>CiA=W>CiA=W>CiA>V>BjA>U>CkA=U>7O1O100000000O2O000O1O1O10001O109TBMNmNS<h2O000000M3K5O1MfC`MZ<^25F6mMZCP2j<3WCmMd<U2[CkMd<P2^CoMf<n1XCSNm<h1SCYNQ=b1oB_N0OQ=b1oB_N0OP=Y1PChN0O2N10n<[1PCeN_=Z140O10001O0nBdN`<\\1`CdN`<\\1`CdN`<\\1`CdN`<1UCS1b1mNZ:R1_DnNA0n01i:N_DS12ZOd0Fk:N]DS12[Of0Dk:N]DS12ZOg0DS;R1_1lNbB03S1[=mNiBS1W=mNiBS1b=06nNoAi0U>NL5L50O8H2NO1O14L2[OfA`0]>001L34L4K3NbWc0L^h\\O5\\AHOO\\>b0hA^OP>b0PB_OP>7mAG2021P>3kAN?Nf=4kAMg>7OOgAIQ>1oAOndc05oZ\\OKo==7100000O001000000O10001N10oAG[=9eBG[=8fBHZ=8fBHZ=8fBHZ=8fBH[=7eBI[=7eBI[=7eBI[=7eBI[=7eBI[=7eBI\\=6dBJ_=3aBM_=3aBM_=4`BL]=7dBH[=9f000000001O00000000O100QBGW=9iBGX=8hBHX=9g0000000000O2O0001O01O001O001O00010O00000000000001O04L1O1O00002N1O002N0100O02N1O00001O0004M`N[O^C4i0`0g;M[D0d;D\\C1Q1<b;A`C2o0<a;D^C0Q1?^;LbD4^;LdD2\\;E_CNV1<[;E`COV1<Y;OgD1X;0iDOW;2hDOW;1iDOW;1iDOW;0jD0V;0lDOS;1mDOS;1nDNS;1nDOQ;1oDOQ;0PE1o:LTE4l:MSE4l:LTE4l:LUE3k:LWE4h:LXE5g:LYE3g:MYE4f:HREFPOb0m;HPEJSO>l;GQEMRO<m;FRENQO=m;DSENPO>m;ERELSO>k;GREFiN1;`0k;J]2O000MhBKj;4WDOg;1YD0g;M[D2f;NZD2f;OYD2f;0XD1g;0XD1g;NZD2f;N[D1e;O[D0f;1YDOg;1YDOg;1YDOg;2XDNh;1YDOg;1YDOAKV;5ZE1POJE041LNm;6^E1_OJW;5ZE1_OIY;6WE1g;1WDNj;3UDMk;2VDNk;1UDNl;3RDOJIn:<UELFJVO0n;=REJ@HE3JN2Nj;=VEL_OID1LOo;;SEK^OJEOL1n;;RELR<4mCMS<3lCOS<1mCOCDk;=bDO@HFMJ4m;8SE0^OHI3e;5SE1]OJJ1f;4RE1]OKK0f;3SE2\\OKK0f;3SE1_OEB1750H\\;<[E2@II10H\\;=ZE1AJIOe;6PE2BIJJH1k;:QE2BIJ1a;4SE2BIK1_;4QE6DEM0^;5PE7EDM0^;5oD8FCNO];6oD8GBM1\\;5oD9HAM1\\;5mD;J_ON0[;6lD=J]O1M[;8jD>J]OP<5VD>J]O3I[;<hD>J]O2KBOe;<kD>L\\O3JA1d;>fD>1ZO4HB2c;?dD>3YO7LQ;=eD>4XO4OS;;dD`04VO5OS;f1hD\\N3OU;f1fD\\N5OU;d1fD]N5OU;d1fD]N6NT;e1fD^N5MU;f1eD]N6MU;f1dD^NHH;4X;g1dDfN0C\\;g1dD]NJJ81Z;h1eD[N:NP;g1fD[NJK83X;g1fD\\NHM71[;g1eDdNNH\\;d1fDdN1FY;f1eDdN3EX;i1cDbN5EX;j1_DdN8@\\;d2cD]M];c2dD\\M\\;d2eD[M[;V300O00O1O1O10001O0001O00lN[DnM==X;e1\\DlM=4B4f;g1YDRNe00^O6e;m1YDmMd06S;c1XDgN<_OF7f;\\1aDlN2CF4h;\\1\\EaNkN4i;Z1\\ElNe:S1`EhN`:W1aEeNc:a0XDMU1Ad:c0VDKX1_Od:g0SDJ^=BkBMK?Y>N2M2O2Mji2KeUM?lAIo=7QBIP>MnA113l=g0O100000O_CROR;n0mDUOQ;j0oDWOQ;h0PEXOP;h0PEXOP;g0SEWOm:i0QEZOn:e0RE\\On:d0QE^On:b0RE^On:a0SE_Om:`0TE_Om:a0SE_On:?SEAm:?SEAm:>TEAm:?TE@l:?UEBk:=UECk:=UECk:<VEDj:<VEDk::VEFj:9VEHj:8WEGi:8XEHi:7WEIj:5WELj:2VENl:OUE1m:IWE7i<001N11O0000000O2O0O01L3011N1E^A8f>N2N2MniX1"}}, "object_label": "bench", "attribute_label": ["color:gray", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color, transparency, material", "answer": "The image features a wooden bench situated in a snowy environment. The bench is located near a snow-covered picnic table, and it appears to be a popular spot for people to sit and enjoy the winter scenery. There are two people sitting on the bench, one closer to the left side and the other closer to the right side. \n\nIn addition to the people and the bench, there are a few items on the snow-covered picnic table. A bottle is placed on the table, and a pair of skis can be seen leaning against the table. The presence of the skis suggests that the people might be taking a break from skiing or preparing to go skiing."}, {"question_id": 282, "height": 302, "width": 500, "image": "000000002299.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [3.58, 123.55, 33.32, 131.85], "segmentation": {"size": [302, 500], "counts": "_73m`0>oG3N2N100O100O10XO[Ge0T9D000O1OWNOVJ2b5;XJDg5c0TJ]Ok5d0UJ\\Oi5f0VJZOj5g0VJZOh5f0XJZOh5g0WJYOi5g0XJYOg5g0YJYOg5g0ZJXOf5h0ZJXOf5g0\\JXOe5f0\\JZOd5e0]JVOeN2n6f0^JXOfN1m6`0dJ_O^N0R7<bJD\\N0Z90eb00[FOg]O0V90oF2o84L3LHRG7Q92gYV4"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:sitting/sit"], "control_dims": "maturity, pose", "answer": "The image features a young girl sitting on a bench, wearing a plaid skirt and a tie. She is looking at the camera, possibly posing for a picture. The girl appears to be the main subject of the image, and her attire suggests a formal or semi-formal setting."}, {"question_id": 283, "height": 480, "width": 640, "image": "000000008690.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [285.84, 73.35, 220.46, 323.59], "segmentation": {"size": [480, 640], "counts": "dai42m>2N1N2O1O1O1O2M2O1N101O000O2OO01OO2K41O0O2O1O1O2M2O2N2N1O2N101O1O1O1O1O1O1O1O1O1O1O000OO200N3O00O011K8L100McNcB]1\\=400000`NdB[1e;jNnEV1Q:oNeEEjN\\1`;SObEBmN\\18bNl:b0oER1nNhNm:7UFb1d9fN[FZ1[9QObFP1Z9VOaFn0Z9VOdFl0Y9XOeFi0X9[OgFf0U9]OjFe0R9@kFa0S9BlF?Q9DnF<Q9GlF;R9GlF:S9JhF8W9JgF7W9LgF5X9k2O0O100O1O1O1O101N1O1_JTJn1l5QNVJn1j5RNWJl1j5SNWJm1i5RNXJn1h5RNXJn1h5RNXJm1i5SNWJm1j5QNXJn1h5QNZJn1f5RNZJn1f5RN[Jm1e5SN[Jl1g5RNZJn1f5RN[Jm1e5QN]Jn1d5RN\\Jn1d5RN]Jm1d5QN]Jn1d5RN\\Jn1d5QN]Jo1c5QN]JP2b5PN^JP2b5PN^JP2b5PN^JP2b5PN^JQ2a5nMaJQ2_5oMaJR2^5mMcJT2]5kMbJV2^5iMcJX2\\5hMdJX2\\5hMdJY2[5hMdJX2\\5oMZJU2e5RNRJP2n5a301O01O02N1O001O001O01eI[JZ3d5dLcJX3[5eLlJY3S5fLPKY3P5eLQK\\3n4aLVK_3i4_LXKc3f4]LZKf3d4XL^Kj3`4TLbKm3]4SLbKP4\\4oKeKR4Z4nKfKT4X4kKiKX4T4gKmK[4f0`I_1V2kM]45bIZ2n1bMe4JhI=_Of0T2hNnM[OW7<[Ij0]Of0U2QNU7Y1eFjN2f1a;E`D;_;G^D:b;b100000010N13ON1O10^ObD_M_;_2c0L3M4K4L5K5K5K5L5UOm0C`dn1"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, pose, gender", "answer": "The image features two young girls standing next to a black goat. One of the girls is wearing a pink dress, while the other girl is wearing a blue dress. They seem to be enjoying their time with the goat, possibly petting or interacting with it. The goat is positioned in the middle of the scene, and the girls are standing on either side of it."}, {"question_id": 284, "height": 480, "width": 640, "image": "000000010707.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [347.01, 187.53, 125.44, 264.78], "segmentation": {"size": [480, 640], "counts": "[_S52i>9G7L5K3N2N3C<M3N3M2O1N2O001O1N102N;QDkM\\:\\2^EdMb:e2SE]Mg:NiDi2<YMk:NiDn27SMo:1jDV3LkLY;0jDZ3T;iLjDZ3a:cLfEl3P:f0N3N2L4N2M3L4N2N2M3N2N2O1N2L4M201O1O1O1O1O001O10O3N^OSJQHi5S8XJhGNGj5b8\\J_Gj5b883PNdGXM^8g2hGRMX8P3jGnLV8k2ZGoKc0S1T8P3XGlKg0n0W8l1QGZN2kNk0j0[7XO[Hi2]OWM2m00QOo0e0X7[OSHT3DmL3n0OQOT1?m6GXHR3IfMZ1[Og63kGT31_Mb1SOb6]4UHiKHHa9c4iFcKFJ`9b4mFcKW9j2[F`N?fNU9^4bF]KM7a9S5\\FfJ`9Z5_FhJ`9\\5000000010N1]MaFEc9k24K3O2J3SMTFd0n9XOTFg0m9VOVFe0GcMT:e1WFg0GbMS:e1WFk0m9TOQFo0o9POQFR1n9lNPFX1P:gNoE[1Q:aNPFa1Q:^NoEW1HfMZ:R1oEX1GbM^:R1kEBHT1NWN^:S1mEAIT1MWN]:T1mEBGS10WN\\:i0iEUO5j0EP13VN[:j0iEVO4_2FbMf:j0_EVOOW2OiMm:k0QEYONT2\\;VNcDK3[2OaMOL5O[:<bEEN05Z3]:nLbEFMP22AR;3lD`N<X1g:\\OkD25XO9V1ChNU;g0lD23YO9=b;AQDf0132ZO6NG=P<BPDg0O3b0F];@TDe1>hNc;X1mC]N?:e;S29WNdCFNk0`<]OcCi0f<WOYCM11m<ITCFN`000R=ITCg0R=[OjBd0\\=96G9I>AbQ^2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:curly/curled", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, pose, face expression", "answer": "The image features a young man sitting on a red couch, smiling and enjoying his time. He is wearing a black hoodie and appears to be engaged in a fun activity, possibly playing a video game. Another person is standing nearby, also smiling and enjoying the moment. The scene suggests a casual and relaxed atmosphere, with the two individuals sharing a pleasant experience together."}, {"question_id": 285, "height": 640, "width": 427, "image": "000000013201.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [93.41, 86.99, 226.14, 423.32], "segmentation": {"size": [640, 427], "counts": "YWj14jc04N2N1N10000O10005K1O001N10000kB3W6MaI=dNQOS3c0TNe0fNgNS3O`He0d5j0hNaNS3j0RNj0hN\\NU3l0PNm0Z6SOcIR1[6nNcIU1^6iN`IZ1a6dN]I]1f6`NSIh1m6XNQIj1P7UNnHm1Q7TNjHQ2kN]Mf4b0]LR2jNbMf4=^LR2iNdMi4:]LS2hNfMj47]LT2dNWMnL?P87\\LS2aNWMRM2OO294Fe7g0`LS2aNbMYML0Ig7f0]LT2aNdMZM3g76\\LS2cNdMZM3h76ZLT2fNTM]M2I`0k77WLT2UMSMb03WN<OAl7i0ULU2UMWM`00ZN81Dk7i0RLU2WMYM?M]N70Fk7i0oKV2YMXM?M]N61Gk7h0mKX2[MnLoNNa1g0]N^Ok7h0jKY2^MjLi0d0SNDl7e0iKZ2^MiL\\O7d0i0j6NeKZ2]MhLB:a02PO2m7`0bK[2ZMnLZOI0:n01oN3n7`0`K\\2YMoLYOK4Me0OF5A91Bh7n0cK^2ZMmLYOLT1K^O4^O:Q8`0ZK_2[MnLYOJk1OUN:T8a0UK`2]MlL\\OEl1e0W6;RK_2^MPM[16V6;oJa2_MoL]14U6<mJc2_MnL_O_Om1e0W6<lJb2`MoL@_On1b0W6>jJc2^MPMC]Oo1b0V6>iJd2]MPME\\OS2>T6a0eJf2]MQMGZOf11dN0F5W8i0dJg2\\MRMGXOi11cNOG7V8h0bJh2^MQMGXOi11cN0F4Z8j0]Jj2^MPMIWOi11bN1G1]8l0YJj2^MQMJVOi11bN2GN_8n0UJl2^MPMMTOW11VO1N2\\8l0kIn2^MPM0ROW11kN1407O\\8o0fIR4\\OnJa7P1PIU4n8kKPGV4R9jKkFX4ElJ]7m0jHY4HlJ^7k0hHZ4LgJ_7P1aH\\4a9eK[F]4g9cKVF_4j9bKRFa4>[J_7R1QHe4S:[KnDoN6i52VJP:S1dERO5h54VJAMX:W1gEQO8i53[J@D_:W1eEVO2g5LlIM21>e:f0]Eg59aI\\:g0[Ei5=XI]:m0VEn5;SIa:o0SER6_;mIaD^6U;aIkD`6V;^IjDRON\\7Z;`InD^OGc6];mImD]OIe6[;mInD[OHLM11a6];VJnD[OGMNO1b6];WJnDYOGOMO1b6_;UJnDYOOb6S;VJ\\Ek5f:TJ^DYOg0c6l:SJfD[O5a6W;SJdD]O4_6Z;SJUEl5m:SJSEl5o:SJQEl5Q;SJoDm5Q;SJnDm5T;QJmDn5U;QJjDo5X;oIgDS6Z;lIfDR6\\;mIeDS6\\;kIfDR6];mIeDQ6\\;mIfDQ6\\;nIdDP6_;oIaDQ6`;nIdDl5j<N2OOO1nLmA8l=OUB0k<RMQDn2UO\\NN6m<`NgC2_Ol20[NO5l<bNfC2@j21ZN06j<dN]COK20OJd26aNN5l<fNdC1A0Kc26`N04k<hNaCU3EmM15i<jN_CU3HjM16i<kN\\CV3LgM17g<lNZCX3OcM27f<WOnBP3;aM37d<g2ZCPM47c<n1oBfM;348c<n1oBfM<249b<l1PCiM;059b<m1mBkM>K6;`<o1kBkMa0I6;`<]OdB[24UNd0D6>^<_OdBZ24UNe0B7>\\<U2hBjMR2NV;X2iBiMT2KT;]2hBgMX2Go:a2lBhMm?Y2S@fMm?^2P@aMP`0`2o_O`MR`0X2k_O\\M2<S`0X2l_O]MO;V`0X2l_O\\MM=W`0V2m_OPNS`0R2k_OoMS`0P30000O100000O10001O0O101M2O1N2O1O2N2PNa_O7f`0GZ_O7i`0_12L4\\NR_OOTa0LR_OORa0OQ_OMRa02c^OPO7k0Ya0Oe^OXO1f0_a00Z^OWO138c0ca08U^ORO7?Qb0Cm]O9KE=3]b01\\]OL[c011Oc\\O1\\c01c\\O01NRc03k\\O1MM011NRc0b0l\\OA0OTc0h0001Hk\\OCWc0b00Kk\\O_OUc03i\\ON15\\c0:f\\O_OUc0a0k\\OATc0f000O01L4N1L4K5O2O1O010O12NO0O101MW\\ONhc02Y\\OMgc025O000000]hZ2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, gender, pose", "answer": "The image features a man wearing a black shirt and a bandana, skillfully riding a skateboard down a ramp. He is performing a trick, possibly a kickflip, as he jumps in the air. The skateboarder is the main focus of the scene, and his action captures the essence of skateboarding."}, {"question_id": 286, "height": 480, "width": 640, "image": "000000013729.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [77.59, 89.57, 183.58, 385.6], "segmentation": {"size": [480, 640], "counts": "ZRT12m>1O2O1O1N3N3M2N1O1O1N1000000O2O0O100[GAh2`0PMLj26SMOoKAiNKY6g0mNk0PKQOm57ROQ2b0RN]OU2SMoLe0T1a0iNTNY39XMBQ2n1cMlLJ24?`3d0lMQOZ1l2WN]Me2;]1X2oK\\Md22g1a2iKYMa2BZ2T3XKXM^2C[2U3YKUM^2DZ2V3[KTM`8k2bGTM^8k2cGUM]8j2eGUM[8k2gGSMX8m2jGQMW8o2iGPMW8Q3iGnLV8S3lGkLS8W3mGiLd7e3f16L4M2N3M3M3M3M3N2L4M3eN[KXHi4d7^KTHf4h7eKmG_4n7\\1K5M4L3O2O001N2O001O1O1O1O1N3N2N1O5J2O3M8G3N2N4K;^I^GQ6k8N10O2O4L2N1N2O001N2O0O2O1O2N2M4M1N4M2jHQIU6Q7iIPIV6^1eI_N^Om4d0VKY6X1PJa3FZKY6P1WJf3]O[K]6l0YJj3WOZKa6m0XJi3UO[Kc6l0YJi3RO[Kg6j0ZJk3kN]Kk6i0ZJe1jNFm6fNZJ_1nNIi6gNZJ]1POKg6fN\\J[1oNOe6eN^JX1QO1d6hN[J8MP1i5hNZJVOaNHY2Z2l4gNUMW1m2gNUMX1l2gNUMX1m2gNSMX1o2fNRMX1Q3eNPMZ1R3dNQMY1R3iNmLS1U3POjL3_KHh76QNAQ2?QN]OP2c0PN\\OQ2c0PN[OR2g0mMVOU2j0Q600O1010O1O00O11O0001N1O2O020N1O1O1O1O1O0O2N1010O1OO2O0O2N2N13M4MO00O100O01O001O1O001O1O1L4N2N2003MO1O`ib5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, face expression, gender", "answer": "The image features a woman standing in a living room, holding a Wii remote and actively playing a video game. She is wearing a white shirt and appears to be enjoying herself. There are two other people in the room, one standing near the woman and another person further back.\n\nThe living room is furnished with a couch and a chair, providing a comfortable space for the group to gather and play games. A handbag can be seen placed on the floor, possibly belonging to one of the individuals in the room."}, {"question_id": 287, "height": 480, "width": 640, "image": "000000013729.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [153.17, 79.82, 75.5, 263.19], "segmentation": {"size": [480, 640], "counts": "lkV2460X>`0M3J6M2N2N3[BnNX=T1eBUOR=l0lBBh<^1L2O001O001N101O0010O01O1O0010O10O010O1[EhMa8X2SGVNk8j1PG]Nn8d1PG^NP9EhEW1W1VOR9^OmEY1R1ZOP9ZOPF]1P1ZOR9SOPFc1m0]Oe1kN_43oHf1m0]Ob1mNa40PIg1m0]O^1mNU5f1^I]OZ1nNX5g1aIYOR1RO^5g1^IYOP1QOb5h1]IXOm0ROg5f1]I\\Oe0oNn5f1]IC;gNZ6d1^IF5fN]6`1cIJNgN`6a1SH[NR1\\19iNc6n1RIZO7jNg6n1RIYO2kNm6n1PI\\OIhNY7l1mHD\\OfNg7h1lHh0V7WOjHh0W7XOjHe0X7[OhHd0Z7[OfHc0]7\\ObHd0_7\\OaHb0a7^O`H`0a7@_H>d7B[H=h7AXH=l7ATHIWOZNX9IcFY1n08FbNS9V1WG\\OROEn0Fk8Z1TGWOi0\\O[8W1kFTO\\;k0eDPOa;n0`DmNf;Q1W1O3I7IkiR6"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, pose, face expression", "answer": "The image features a man standing in a room, wearing a white shirt and a baseball cap. He appears to be looking at something or someone, possibly engaged in a conversation or observing an event. The room has a chair positioned in the background, and there is another person standing nearby, possibly a woman. The scene suggests a casual gathering or social event where people are interacting and enjoying each other's company."}, {"question_id": 288, "height": 480, "width": 640, "image": "000000014226.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [208.65, 30.81, 332.97, 339.46], "segmentation": {"size": [480, 640], "counts": "feR33j>5M2N2N1`AGY>b0N2iA\\On=m0M3JnNZBV1a=lN^BV1_=kNaBV1^=8N1O00dNeBT1Z=lNfBT1Z=lNfBU1Y=kNgBU1Y=jNiBU1X=jNiBU1W=jNjBV1U=kNlBU1S=kNnBT1R=lNPCR1P=nNQCQ1o<nNTCP1l<POTCP1l<POTCP1l<POUCn0l<ROTCm0m<SOSCm0m<SOSCl0n<TORCl0n<TORCl0n<TORCl0n<TOSCj0n<VORCi0o<WORCg0P=YOPCe0R=ZOoB>X=BiB0B4g=KQC1Q=OP110O001NPY33mfL2N100O1O2N100O101N100O100O1N3N100O1N2O1O1O1O1O1N3M2N2N2O1N2N201M2O1O101O0O11O000O02N1N2N2N2N2O1M4K4K5F:UOk0K5M4M2O1^N`LeFO;c3i8[MRGf2j8`MTG`2k8dMQG]2n8fMPG[2l8jMQGW2m8mMPGT2o8o1N2O1O2N1N102O0O1O1O1O1O1O1O1N2N200O1O3L2O1O1O100O10001N101O0O101O0001O0000010O00001O01O01O00YITIZ5l6dJXIZ5h6eJZIZ5g6eJZIZ5f6fJZIZ5f6fJ[IX5f6hJZIQOJk5l6TKZIPOLk5j6gJoHE<IKk5i6fJTID9JKk5e6hJZIB6JLl5d6fJ\\ID4JLl5e6eJ\\IDa0f5S6eJ]IE2KMk5f6cJ[IG2LLj5g6cJ[IG1MMi5f6cJ]IG0LNj5c6eJ_IE0LNj5Z6nJhI\\O0LNk5g5VJRJ0Og0;\\OOMMj5b5SJXJ4NO4e08^OOMMk5i5TJoIO<`01ENMMk5k5QJoI0<a0OEONLl5b6WJYIJ;5NNLl5e6QJkI5DNLm5_7VJeHMLm5_7VJeHLNn5\\7VJfHLNn5\\7VJfHLNo5\\7TJgHLMQ6[7SJhHKNS6Y7RJiHKNS6Y7QJjHLMT6X7PJkHLMU6X7nIZIR6h6lIXIU6i7001O1O01O2O1N10000O01O1O0010\\J[GB1o4c8_KgGb4[8\\KdGe4\\8SKWGJ?U5V92O3TGfJl7]5iGnJT8S5jGPKT8X5cGjJ[8o5O3M4L000O100O100O100N200O100O1000001N100O100O2O0O1O101N100O1O2N101N100O101O0O2O000O2O001N1O101O001N101N1O2O0O2O0O2O0O2N1O2N2O001N2O001O1O1O001O1O0O2O1N2O1O1N2N2N2N2N2N2O0O2O1N2O1O001M2bKbFY3a9bLhFW3Z9eLnFT3V9gLPGV3S9dLRGX3`:J5M4J=C?B8G;\\OmBfN_=f0g0K6J7J_g\\1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, maturity, gender, face expression, pose", "answer": "The image features a man sitting on a train, wearing headphones and looking at a laptop computer. He appears to be focused on the screen, possibly working or enjoying some form of entertainment. The man is seated on a chair, which is positioned near a dining table.\n\nThere are a few other objects in the scene, including a backpack placed on the floor near the man, and a handbag located on the dining table. Additionally, there is a cup placed on the table, possibly containing a beverage for the man to enjoy during his train journey."}, {"question_id": 289, "height": 480, "width": 640, "image": "000000018193.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [85.21, 45.3, 395.87, 427.15], "segmentation": {"size": [480, 640], "counts": "SRZ1:b>8J3L6J5K5J7K4J6J7K4K5M3K5M4K4L5K3L5K4B>ROfLoE`3n9hLkEZ3R:l0M3M3N1O2N2M2K6L3N2]OkJYGX5b8e0N3L3O1O2M2O2N1O1O1N2O1O1O1O001O001O001O001O10NTHXIc7h6^H\\I]7e6cH]IY7c6hH_IV7b6iHaIU7^6lHcIR7_6lHcIR7W7N2N101N1O3M2N1OiN\\IUJb6U7O3M2N2N2M3M2O2M2O1N4M2O1N1O2N2N2N2O001O1QNbFWNb9e1lFPNAdN`9V3XGWNh8e1`GVMPOe0a9P2dGUMVOf0V9Q2[HmMd7P2bHlM^7Q2fHgMb7V2bHhM^7W2dHgM^7W2eHgM\\7W2fHhMZ7U2kHhMW7U2l2N1N3N1O2N1O2N100N2O1O100O2N10000O00100O1000000000000O11O000O11O01O0000001O000000000000000001O01O0O2O00001O0RG]N_4d1`K]N_4c1aK]N_4d1YK[NQL2e8d1UK^NT5b1mJXNTL1n8i1T40dFVN[L0R9j1cJVN[L0R9k1bJUN[L2O4j8e1lJVNYL205i8d1nJZNYL3=Gl7m1`KVNWL7g8c1SKUNWL73H[8m1[KSNXL82H[8n1`KXN^LIk7P2fKPNTL2;Ok7Q2hKPN\\L0l7Q2gKPN\\LOn7P2bKoMUL44K01V8P2`KYNYLG1OW8Q2^K[NZLD10W8R2gGnMb3=cLDU8Q2dGPNc3;dLDV8U2UKWNV5i1jJUNX5k1gJRNfLH^8V2kJQNhLI^8V2hJRNjLI^8U2hJQNc5P2\\JkMi5W2mIgM]6[2T30O3M2N1O3M6dLXMTJj2UOZM\\7i2RGTM><^8j2hFQM?<i8[3mFlL[4SOL^51fJN\\5OeJ1_5HdJ8^5EcJ;_5@dJ`0_5TOjJl0Y5QOfJP1]5mNbJT1`5jN`JV1`5jN`JV1`5kN_JU1a5kN_JU1a5kN_JU1`5lN`JT1`5mN`JR1`5nNaJQ1_5oNaJQ1^5POcJo0]5QOdJm0]5SOdJl0\\5TOdJl0[5TOfJl0Z5TOeJm0[5SOdJn0\\5QOeJn0\\5QOeJSNCj0i5S1dJoMIl0c5T1fJjM0o0Y5V1hJiM2R1T5U1kJfM6R1P5W1jJeM9S1n4W1iJeM;S1n4U1iJfM;T1l4V1iJdM?T1k4T1hJfM?U1l4R1fJhM?T1m4R1eJiM`0T1m4P1dJjMc0T1i4Q1fJiMe0S1f4R1fJjMf0S1f4o0fJnMe0R1g4l0fJRNc0R1h4g0jJUN?T1h4d0kJUNa0V1g4=mJ[N?W1e4QO[IM0Cf17;X1m4^NaI6i13JY1]8gNdGX1\\8hNlECX1d1l8iNeGX1Z8hNfGX1Z8gNhGX1X8hNiGW1W8iNiGW1X8hNhGX1X8gNjGW1X8hNhGX1X8hNjGV1V8jNjGV1V8jNjGV1V8iNkGW1V8gNkGY1U8gNkGZ1T8eNnGZ1S8eNmG[1S8dNoG[1Q8dNPH\\1Q8bNQH]1o7cNRH\\1i:00000CdNVC\\1j<eNUC[1k<fNUCY1m<eNnB1MZ1U=eNoB0MZ1b=O00LgNaBY1]=iNcBW1^=hNbBX1^=iNaBW1l;gN]E1kN0LX1X=hNkB1NV1X=hNjB2NV1_=iNbBV1S;iNSG0lMV1o:mNYE1_1R1Y9lNZE0]1T1P9jN[E290T1O`NU1h:jN[E2:NT11_NU1h:jNZE59K]1V1X9QOfEIH0F08W1f:jNfFO`N0FW1a=jN_BU1P<lNeD0YO3`0Q1`;POcD8Jh0c;POcD;Gd0h;POcD:Ef0i;nNlD3[Oo0i;nNmDN^OU1Y:kNVF0[O31Ll0V1b9mN`E04MG2441Lm0T1c9lNdEN50J0X1V1U9kNQH1ZMS1f:lNPF1g0NmN0HT1_;oNjEOdN1;Q1U;QOeDLm01nN1;Q1U;QOeDMl00oN0<R1T;QOeDMl00oNO=S1T;QObDNn05ZOl0V;]OTEA^O81FNU1U;nNnD=6AJ5K52F0T1_;UO^DJg0O\\O80F0T1];VObDEh02ZO9OGOS1];\\OcD_O24NO3NO:OF0T1R;d0nDbNOG1R1R;f0oDXN60IR1R;b0lDZN`04BP1Q;mNnD=0a00QO60O4KQ1R;lNoD3M31h02RO1320LR1R;lNoDONW14kNK36MLS1R;lNSEU1OUOOGMS1S;kNRET15ROJLLS1S;lNQEj0JUOc04COLR1S;lNQEm0MQO;5HNMS1T;oNjD=2`04POLT1U;TOkDJ7n0MnNMV1W;QOiDL6o0LoNNT1[;nNgDO51FN020?4_OOT1[;oNfDNMN3T10lN0U1Z;oNeD5Nl0:1R;nNeD_19CR;nNfD\\1:FP;nNgDW1KfN?T1Q;mNgD5I?1E>k0Q;jNmD1I>OBM3;T1S<oNkCL1V1o:gNiE6POK028V1n:iNjE1lNO10309V1o:iN_EOYO;LG4O9Y1h;@nCWO:Y1Z;gN`Dn0KRO:Z1e;D`D<T;eNeDn08=Q;gNfD>LI<Q1R;jNcD3K0807T1Q;kN_D53J717U1o:WOeDC516U1Q;VOeDAJO:38W1o:VOeDE3N8Y1o:fNbD74MJM11?Y1W;lN_D4KE`0[1W;jN^D5ND>]1W;iN]D56EO\\1_;jN]D45FO\\1_;jN^D35ILY1a;kN^D36HLY1`;kN_D45GOW1^;kNaD6GGm0l0P;XOSDO13V1?j:BlCN2LO1n=NVB2L0O32KZ>2fA5;IK2^=O^B4:KJ2\\=2_B1;LD6a=O`BM=8GE01I2l00n:4mD4^O6c0@YO1m;2iD5@8h<BSCN?1BO6`09Ai;OgC4;N1>GBOO`<5_CKM6`0M@317c<I\\CK04b0M^Od0h<[OcCN93]O?R>BnA:P>LPBOS>4lAKU>5kAJ_>LcA1`>MP]]2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, maturity, pose, gender, face expression", "answer": "The image features a woman sitting in a chair, eating a piece of food, likely a sandwich or a hot dog. She is wearing a green shirt and appears to be enjoying her meal. The woman is seated in a camping chair, which suggests that she might be in a camping or outdoor setting. The scene is set in a wooded area, with a dining table visible in the background."}, {"question_id": 290, "height": 426, "width": 640, "image": "000000018380.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [220.45, 78.45, 44.47, 95.35], "segmentation": {"size": [426, 640], "counts": "WRl27P=5M2M4L5L6_CAk;Q1N2N2N1O0000000001OYOaNUEN8b1`:kN]EU1d:POXEo0h:d05N2O1N201N101O1O1N2N2N2N2O1N3M2O2DUDUOm;f0YDYOh;c0\\D[Of;c0b0M5I8IhZl4"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "maturity, gender, hair type", "answer": "The image features a group of people sitting around a dining table, with a man in the center of the scene wearing a purple shirt. He appears to be looking at the camera, possibly posing for a picture. There are other people in the scene, including a woman sitting next to the man in the purple shirt. \n\nThe dining table is surrounded by chairs, with one chair on the left side of the table and another on the right side. There are also a few books scattered around the table, possibly indicating a recent gathering or a shared interest in reading."}, {"question_id": 291, "height": 426, "width": 640, "image": "000000018380.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "material, size, state, texture, transparency", "region_anno": {"bbox": [311.6, 190.81, 41.56, 25.71], "segmentation": {"size": [426, 640], "counts": "jTQ48Q=3N1O8H2N4L1N100001O00000000000000000000000000000O10000010O010O0001O001O1O1O1O2G\\CHf<4<L2NQif3"}}, "object_label": "bowl", "attribute_label": ["material:glass", "transparency:transparent/translucent", "size:big/large/giant/huge", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, transparency, state", "answer": "The image features a large glass bowl filled with a delicious-looking dish, possibly a casserole or a meat dish. The bowl is placed on a dining table, and it appears to be the main focus of the scene. The dish inside the bowl is covered with a layer of sauce, which adds to its appetizing appearance. The table setting also includes a fork, suggesting that the dish is ready to be enjoyed by someone."}, {"question_id": 292, "height": 427, "width": 640, "image": "000000021879.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [84.39, 49.93, 111.94, 39.26], "segmentation": {"size": [427, 640], "counts": "mRS12W=3N1O100O10000010O0000000100O0O2O1O1O2N1012NO000N2N101O0O00FZC1e<0\\COc<1_CMb<3`CK`<5bCI_<6bCH`<8<NO1O100O10OQCHl<7SCJn<5RCKn<91N2O012M01O03MMMnB3R=NmB1T=3N2O100O000100O11O0QCJi<=O0000BWC9j<FXC9h<GWC9j<HTC9l<GTC8m<300O001O10O01O010O1000000O10000O1H8N2N200O10001N10O101O001O1N2@bC1b<HbC7j<N2N2O001O1N\\Ri5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:horizontal/lying"], "control_dims": "maturity", "answer": "The image features a young man lying on a surfboard in the ocean, enjoying a day of surfing. He is wearing a red and black wetsuit, which provides him with the necessary protection and buoyancy while in the water. The surfboard is positioned underneath him, allowing him to ride the waves with ease. The young man appears to be having a great time, taking advantage of the ocean's waves for an exciting and thrilling experience."}, {"question_id": 293, "height": 640, "width": 480, "image": "000000060347.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [102.34, 234.95, 262.34, 360.37], "segmentation": {"size": [640, 480], "counts": "UUR24jc04M1O2O0O100O100000O10000O10000001O0O10000O1000O02O0O00100O1O1O100O00O20O010O000O2O2L3N2N2D=H6L5L4M3K2R^OUNha0P2X^OoMea0U2\\^OjMaa0Y203L5K3L5M3L7H5K5L4J6J7L3K4M4O1N2O10]Og@^LY?_3e0N3N2N1O2N2M3K5M3L4N2L3LlA_MS;_2nDcMQ;[2oDfMR;V2QEkMo:R2SEoMm:l1WETNj:i1XEWNi:f1ZEZNf:[1dEeN]:S1jEnNV:l0oETOR:j0oEWOQ:i0nEXOR:g0mE\\OR:e0lE\\OU:c0iE_OW:b0eE@\\:`0cEA]:?bEB^:>`ED`:<^EFb::]EGc:9\\EGe:9ZEHf:8lAnNU3k0n:7iATOm2o0Z;9VD6j;KnC<R<FgC?Y<C]Ce0c<^OUCf0m<[OiBm0W=UO^BS1c=nNUBY1k=hNkA`1V>T21O1O1O1O2M100O0`K]Ac3e>_L[A_3e>i04jKWAX3i>iLWAV3h>kLZAR3f>oLZAQ3f>oLYAR3f>oL[AQ3d>QMZAo2e>SM[Al2U;QLWHT1dLj2T;VLUHP1hLj2R;XLTHm0lLi2Q;bLPEAc2U1\\Md2T;RM\\G:`M_2W;[MVG8bM[2U;cMVGi3k8ZLSGc3o8_LiFe3Y9]LaFf3`9]LVFi3l9XL\\ET4o:mKmDS4V;oKfDo3^;RL_Dk3f;WLUDY3ISK\\<e1hCR3i<PMTCo2n<RMPCo2o<SMPCn2o<R200OPNTCnLl<S3SCmLl<l2QCaK1c1n<T5000000000001O00O100000001O00001O00001O1O1O001O1O001O1N2O2N1O1O1N3N1eJ]BW4f=cK]B]4f=\\K_Bc4f=VK]Bi4^>O1O1O00001O001O1O1O1O1N101O001O001O10O10O0O20000O1O1O001O1O1N2O00100O1O1O2N2N2M2O2N2M3M4L3N3L3M6J5K3N4K4L5L6I5J7J8oN_^OSOla0;glV2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, maturity, pose, face expression", "answer": "The image features a man sitting on a wooden bench in a park, surrounded by trees. He is wearing a white shirt and appears to be looking at the camera. The bench is located in a wooded area, providing a peaceful and serene environment for the man to relax and enjoy the natural surroundings."}, {"question_id": 294, "height": 375, "width": 500, "image": "000000061584.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [234.37, 96.54, 80.83, 185.16], "segmentation": {"size": [375, 500], "counts": "dbe24l71eK0X45cKNoLLl69RLNoLMk69RLMRMKi6<^I]Om1e0jMDj6o0jJCXNZO35j6P1fJE^NVO06l6o0UIPOP1g0nNDm6f0UIlNo0e1l5@UIiN522m1d6YOUIbN003j2Y6ZMoIX1N^1R6`MlIR11[1W6eMfIQ12Y1X6hMdIU10P1^6lMaIU1Oo0a6nM]Ij3d65`0L4dKgHY4]7N3LOmKbH13d3b7[L[H15X3j7gLQH36l2h7a04J7O1O2M2O1N3O1M3K5N3N1O2N2N2OcHcMb5=gH[1Y9`NjF_1g9010O0001N1O2O0N3M20XH`NZ5^1YJlNl5R1SJPOo5FVHn0b2WOS5e0mJ\\O]MHe7g0lJC]5:aJDg57YJJi52WJ1k5JWJ7d82@D_Ec0[:AaEc0]:^O`E`00YOc:Q101FmNhE11::FE6V:;\\FES9g0SGXOc8JeFh00_Ol0Oa8i0cGVO]8j0dGUO]8h0gGUO[8i0[1M4K4L5KVmS2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "maturity, hair type, face expression, gender", "answer": "The image features a man and a woman sitting on a statue of a horse. The man is holding the woman in his arms, and they appear to be enjoying their time together. The woman is wearing a red shirt, and the man is wearing a blue shirt. They are both sitting on the horse statue, which is located in a garden setting."}, {"question_id": 295, "height": 375, "width": 500, "image": "000000061584.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture", "region_anno": {"bbox": [249.87, 163.42, 73.85, 121.78], "segmentation": {"size": [375, 500], "counts": "aal25a;200O1O1O0fNHUG9a80_G1V89jGHS8:mGFP8=QHCl7`0QHCl7?SHCk7a0aGWOE9i8U2M3M3L4M300O1O1OoNeGnM6<U8a1]HZNc7`1fH]NZ7_1kH`NV7\\1mHdNS7\\1lHeNT7[1lHeNS7\\1lHeNS7\\1lHdNT7]1fHiNY7X1_HPO_7S1XHUOg7l0QH\\On7W2O1N2O10IkGlLT8]2THaML9o7S2ZHcMJ7k7U2iHjMV7T2dHeMC5h7T2iHgM_O4h7S2lHhM]O4f7S2[IkMf6S2`1O0OjGmMl6Q2VIoMj6k1\\IUNd6Z1mIfNS6X1iIiNSN0T8U1PJkNP6R1TJmNm5R1]2O103M3M000O3M2M3N2M3M4L3MooP2"}}, "object_label": "horse", "attribute_label": ["color:gray", "material:stone/granite/cobblestone/gravel/marble/pebbled/rocky/sandy", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:smooth/sleek"], "control_dims": "pose, material, texture, size, pattern, state, color", "answer": "The image features a man sitting on a statue of a horse, which is a unique and creative display. The horse statue is made of metal and has a distinctive design. The man is wearing a colorful shirt, which contrasts with the horse statue's appearance. The scene appears to be set outdoors, possibly in a park or a public space."}, {"question_id": 296, "height": 640, "width": 427, "image": "000000073153.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [206.59, 26.36, 190.7, 613.64], "segmentation": {"size": [640, 427], "counts": "YoP4<]c0b0Cg0T]O\\Noa0P2J5F;J?^Oe0]_O]Ld?]4_O9J5J:C:I8I5L4M6I5L3TDQJb9R6SF_Jd9i5oE_Jn9k7N2XEkFb:[9N011N101O3L100O101OO0LiEaFV:_962cE`FU:P:jEUF2JX47`0^:WK\\E`0NF2h28j1o;eMSD[2U<ZMnCe2U<VMnCj2W<oLkCP3W<mLkCS3U<lLlCS3S8ZKWG<b3S1VMV3Q8\\KXG1N5e3R1XM\\3m7\\KaG0^3k0^Mh3c7^K]GOJ1j3>eMS4[7`KVG8S4EcMb4T7bKUG9l5T4Q3QLoLn3S3QLmLU1gJOCcNi8IRG203l5Z1VKIWOlNf8LQG16Ng5]1bKROcNJ<GR?[1hBjNj=S1c2O1N2N2O100O1N2O100O100O1O10000N200O1000000O1000000O10000000000000000001O001O00001O001O00001M2M3M3N3L3N2M4M2N3M2O2M2O2N1N3N1fAPNb:S2ZERNb:P2^EPN`:S2^EnM`:U2`EjM]:Z2dEeMY:]2jE`MQ:f2a34M3J6K5M3K5L4M3N2J6L4N2M4XGRLV1S4WNcL\\1h3^N^LS1Q4hNSLcLkN`1]5\\LdJc4[1XMoN]1b5[LYJj4`1UMPOU1Q6b1YKPMoNP1Q6Q2SKiLoNk0X6[2nJdLlNh0^6d2lJ\\LmNa0a6S3gJVLkN;i6^3aJPLjN:k6f3_JkKjN6m6n3dJ\\KmN2k6b4T6O0000002`Li@R2Z?hMm@T2T?gMRAV2R?aMVA]2m>]MYA`2V`0N4M1N2M3N1O3L2O2M3M2M4M2N2N3M3M2N2M4M3M3L3M3N4J6He\\d0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, maturity, hair type", "answer": "The image features a man standing in a wooded area, talking on his cell phone. He is wearing a black shirt and appears to be engaged in a conversation. The man is positioned in the center of the scene, surrounded by trees and foliage. The focus of the image is on the man and his phone, capturing the essence of a casual, outdoor conversation."}, {"question_id": 297, "height": 640, "width": 480, "image": "000000092416.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [0.0, 227.55, 18.8, 59.73], "segmentation": {"size": [640, 480], "counts": "U7S1mb00O10000001O0YOT]O;lb0BY]O<N\\Ofb04_]Oc0Rc0M3M1O3K2L5N1O2Nn_P9"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:young/baby", "pose:sitting/sit"], "control_dims": "pose, gender, maturity, face expression, hair type", "answer": "The image features a group of people sitting on a boat, enjoying their time together. There are three people in the scene, with one person sitting in the middle and the other two sitting on either side of them. They are all wearing white shirts, which adds a sense of unity and harmony to the scene. The boat appears to be a small motorboat, providing a comfortable space for the group to sit and relax."}, {"question_id": 298, "height": 428, "width": 640, "image": "000000117492.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [375.18, 130.98, 48.93, 161.44], "segmentation": {"size": [428, 640], "counts": "XVn41Z=2VE0V81hG0W82hGNW82jGNU6NZI6XNJQ23[63WI1\\NJR22Y67VI5a0CY6>oH1g0BY6?mHIhNFS23W6a0kGG9ON9i0AU7a0hGK8MER1e0eNe7c0gGN4i12iMS8f4O0100000000O2_O`0N3GQGnK10P9o3;O1O2NVGULU8S3XG]M>D\\8k2YGbM8De8c2VGhM2Gi8^2YG]Nh8b1YG]Ng8b1\\G\\Ne8b1_G[Na8_1mGXNU8Z1lFYNR1:T8]1iFXNW18P8b1hFSN\\17o7g1VHVNm7j1THPNQ8o1g1N4L5Kf0oNj`j2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, hair type, pose", "answer": "The image features a woman wearing a pink shirt, walking through a grassy area with several children. She is holding hands with the children, creating a sense of togetherness and playfulness. The woman appears to be leading the group of children, possibly guiding them through a park or a playground. The scene is lively and full of energy, as the woman and the children enjoy their time together."}, {"question_id": 299, "height": 428, "width": 640, "image": "000000117492.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [438.72, 199.84, 20.43, 29.56], "segmentation": {"size": [428, 640], "counts": "cSh53:2^<1`C1^<0`C3_<M`C4_<M`C4_<LbC4Z<OgC1X<0iCOW<1iCNX<2iCMW<2kCMU<4bCG54Y<:eCF\\<:dCF]<8dCG]<9cCF_<9aCEc<8:O6ImP[2"}}, "object_label": "teddy bear", "attribute_label": ["color:violet", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, color, material, transparency", "answer": "The image features a purple teddy bear, which is being held by a person. The teddy bear is large and occupies a significant portion of the scene. The person holding the teddy bear is standing in a grassy area, possibly in a park. The scene appears to be a casual and relaxed moment, with the person enjoying the company of the teddy bear."}, {"question_id": 300, "height": 428, "width": 640, "image": "000000117492.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, pose, texture, transparency", "region_anno": {"bbox": [214.57, 191.49, 8.75, 38.67], "segmentation": {"size": [428, 640], "counts": "cQj2=n<k0VO0000DnCWOY<?gCBc<;8O2N2N3MVk\\5"}}, "object_label": "chair", "attribute_label": ["color:black", "color:gray", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, color, pose", "answer": "The chair in the image is a folding chair, which is designed to be easily portable and collapsible. It is currently folded and placed on the grass, with a person standing next to it."}, {"question_id": 301, "height": 327, "width": 500, "image": "000000125936.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [400.54, 64.52, 99.46, 262.46], "segmentation": {"size": [327, 500], "counts": "QSQ47m98H5M2M3N5K7I2\\L]OaMf0U2FfM>n1LPN6l1NRN5l1LSN6[1;cNHU1?jNAe0^NRMU2W2_Oc0aNSMR2Y2]O9[N[Mm2Z2iNnN\\NSO8ES3Y2YNmNo2R1RMdNX3Z1iLRNVN3V5j1dLQNYN1X5l1`LQN[NOX5o1]LPN^NNX5Q2a2O0001O00000000000001O000000O20O01N102O0O1O2M200PIeMR6]2hIoMP6Z2eIiMZ6R3cMaLRN^3m1eLRN[3k1hLTNZ3i1hLWNZ3f1hLZNX3d1kLZNV3d1fLXLHS2b3d1oLZNQ3e1QMZNo2f1RMYNo2d1SM\\Nm2d1TMbLVO`1g3m1UMbLUO`1f3m1WMZNi2e1XM\\Ng2d1YM\\Ng2c1ZM]Ng2a1YM`Nh2_1VMbNk2]1UMdNk2Y1XMhNg2W1ZMiNf2U1]MjNd2S1^MmNb2`0QN@P2<hLdMg0o1c2:hLgMf0n1b2:UN_OS2>oM_OT2`0QNUOW2j0iMQO\\2P1iKmMD0b1Q1T3Q1eKSNW1h0Y3Y1XKnMe1N_N6k4X2VMaMn2_2^2O12OO0L[HcM20a7\\2aHdMa7Z2]HgMe7X2[HhMg7V26OcK"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression, hair type, gender, maturity, pose", "answer": "The image features a man standing in a store, wearing a plaid shirt and a watch. He appears to be looking at something, possibly a product or a sign, while standing near a counter. The store has a variety of items on display, including several bottles placed on the counter and shelves. The man seems to be browsing through the store, possibly considering making a purchase or looking for a specific item."}, {"question_id": 302, "height": 327, "width": 500, "image": "000000125936.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, pose", "region_anno": {"bbox": [81.93, 131.35, 135.34, 189.87], "segmentation": {"size": [327, 500], "counts": "nVi04o95J6L3N2M3L5K4I7F:I8N12N1O00100O`MeNTL[1j3lNQLT1o3oNoKP1Q4ROnKn0Q4TOmKl0S4VOkKj0T4YOkKf0U4\\OjKc0U4_OjKa0V4AhK?W4EfK;Z4JbK5]4OaK0^43`KM`47]KHc49\\KGd4;ZKEf4<YKDg4=YKBf4a0YK]Og4e0YKYOf4j0YKVOg4l0WKROc4mN`JS2m0nNd4nNaJU2i0lNe4QObJT2h0jNf4b1YKZMXOP1_5g1`KZMPOf0a5Q2XKXM_Og0X5@`JY2R1VN_4@bJX2n0YN`4@bJP2NlMP1d0`4AaJm12mMl0NPOf0a5CaJg10PN41m0c0\\4IbJb1:UNe0>`4LaJ`1;XNEJk0`0d4O`JV16\\N87>6d4e1bKPNK5e4j1dKQNkNOg0On4o1^2NXIRNZ5m1[ITNg01]6m1nHVN9MF65J]6n1_IVNOL22M63J4Ml5m1lIVN230L10070J4Nl5l1oIVNO30M3NO6020Hn5m1SJ^NMG64O:1@^5h1[J[N3?4HJ20BQ6i1PJWNOj052Q6l0kIWO0LY6[2lIPMY6g2`ITM2Oo6d1PI@Z7?fH[O`7N`HO2]ON1b7a1^HlNa7o0cHVOZ76cHWO;>C\\O`7>cHF506>D^O^7;VIIHc0T7BUIJHc0V7^OkI?Z6^OgIa0_O]Oi51iJ9X8L6Ima20X^M0X`30X_L1?2N00030NO0000jd0NX[O0^n01`QO01Oeb11Z]N2N02MT^l2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "pose:vertical/upright/standing"], "control_dims": "gender, face expression, hair type, pose", "answer": "The image features a man wearing a chef's hat, standing in a kitchen and preparing food. He is surrounded by various fruits, including bananas and apples, which are placed on a table in front of him. The chef appears to be focused on his task, possibly working in a restaurant or a bakery.\n\nIn addition to the chef, there are two other people in the scene, one standing near the left side of the image and another person on the right side. The presence of these individuals suggests that the chef might be working in a busy kitchen or a shared workspace."}, {"question_id": 303, "height": 427, "width": 640, "image": "000000130699.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [364.15, 235.22, 56.71, 90.85], "segmentation": {"size": [427, 640], "counts": "_`h45U=2N1O1O1O1O00N100010O0101O0001KJTC6l<4M3N2O1TOm0M200O011O001G`NgD`1U;<0O2O100001O2OO3N;D1mN\\D=f;@^D=g;^O\\D`05^Oi:0TEW1m:gNUEX1l:gN[EQ1b;N2N3BjC@Z<2onm2"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type", "answer": "The image features a man wearing a blue shirt and blue shorts, running across a grassy field. He appears to be actively engaged in a game of soccer, as he is kicking a soccer ball. The man is the main focus of the scene, and his athletic attire suggests that he is an active participant in the sport."}, {"question_id": 304, "height": 453, "width": 640, "image": "000000139099.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [249.29, 88.49, 61.93, 94.81], "segmentation": {"size": [453, 640], "counts": "cf^34P>2N1O101M2jCH^:9`EJ`NLh;=YDDZ10fN1^;b0aDAk05[OHW;b0hD[Og0=ZOFV;a0gEKTOAW;d0cENf:2WE3h:MTE7k:JUE5l:JVE3k:MYEOh:1UE]OSOa0h;1VE^OSO?h;3ZELg:4YEJi:5ZEIf:7ZEGh:9YEEh:;YEBj:=_10001O1O100O3N2N1N2OO01O1O10O010O10O1O00cBMi<2UC1k<MUC4[=4O06K0OLMUB5j=51ON2O22M10il0FeQ`4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:curly/curled", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, pose, hair type, gender", "answer": "The image features a woman wearing a pink shirt, standing on a street with her head down. She is holding a white bag in her hand. There are several other people in the scene, some of whom are also carrying handbags. One person is wearing a hat, and another person is holding an umbrella. The scene appears to be a busy street with people going about their daily activities."}, {"question_id": 305, "height": 453, "width": 640, "image": "000000139099.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [557.0, 144.58, 11.3, 24.89], "segmentation": {"size": [453, 640], "counts": "nSf72l=:F8O10O2N001O01O0001N1N3H[jn0"}}, "object_label": "handbag", "attribute_label": ["color:brown", "color:white", "length:short", "material:leather", "transparency:opaque", "pattern:floral", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material, pattern, state, color", "answer": "The handbag in the image is brown and appears to be made of leather. It is hanging from a hook or a rack, possibly in a store or a room. The handbag is positioned in the center of the image, and it is the main focus of the scene."}, {"question_id": 306, "height": 356, "width": 640, "image": "000000143961.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [82.93, 16.12, 69.52, 107.22], "segmentation": {"size": [356, 640], "counts": "cnl0<a9F_Ga0^8C\\Ga0b8B[G?c8D\\G=`8G_G9_8J_G8^8K`G6_8K\\G:b8IXG<g8R1N1O2O0O1O100O1O100_OeMXH\\2g7iMTHX2j7mMRHT2m7b0O010O101N2O2M2O1O0O1000N2M3GWHSMn7i29M2M4M2J7YO\\GkNg8o0_GmNf8GRG42a0:AV9=mF@T9?j0N1O101N1O2O1O0O2O001N2O1N2O1O1O2NfoZ5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type", "answer": "The image features a young man sitting on the grass, wearing sunglasses and a white shirt. He is surrounded by a group of people, with some sitting and others standing. There are at least four other individuals in the scene, with one person standing close to the young man and others further away.\n\nIn addition to the people, there are two dogs in the scene. One dog is located near the center of the image, while the other dog is positioned towards the right side. A handbag can also be seen placed on the ground, close to the center of the image."}, {"question_id": 307, "height": 356, "width": 640, "image": "000000143961.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [295.57, 8.17, 110.38, 94.38], "segmentation": {"size": [356, 640], "counts": "nXW33P;3M4L4L4M0bECT:?iEDf01_8<kFE=6h85kFG95m8c0PG^Oo8f0mF[OS9[10O010cNmFj0R9VOnFj0R9VOnFj0Q9WOnFk0Q9e0RGQNd8S2XGQNe8V201000TN[GX1e8iN[GW1d8jN\\GV1d8jN\\GU1e8d0001O1O1N2O1I7M2M4M3N2N2N200O001O1O1O10000O100O10000O1O1000001C[FXOf9e0>J6O1O1N200O101N10000000001O001O001O0102NO00001O1O0O1O101N10001O001O0010O011N10O00001O1NRRc2"}}, "object_label": "umbrella", "attribute_label": ["color:green", "color:yellow", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "size:big/large/giant/huge", "state:open", "texture:smooth/sleek"], "control_dims": "pattern, color", "answer": "The umbrella in the image is a large, colorful, rainbow-colored umbrella. It is open and providing shade for a group of people sitting underneath it. The people are sitting on a grassy area, and there are several chairs scattered around them. Some of the people are sitting close to the umbrella, while others are further away. The scene appears to be a relaxed and enjoyable outdoor gathering."}, {"question_id": 308, "height": 539, "width": 640, "image": "000000146667.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [251.94, 37.55, 204.7, 268.89], "segmentation": {"size": [539, 640], "counts": "djV4;72`?g0L4M5L4L3L3N3M3M3M3M2N3M2O10LaAlM^>U2bAjM_>V221N110N200ON3O10O101N101O2M5L1O0000000RG]Md3c2\\L^Mc3b2\\L`Mc3`2\\LaMd3_2\\LbMc3`2[L_Mf3c2WL]Mk3c2TL\\Mm3f2RLWMP4k2P50O3M1lFQM[4P3aKRM`4n2]KTMc4n2ZKSMg4o2lJ[MT5g2hJ[MY5f2cJ\\M^5e2^J\\Md5f2XJ\\Mg5g2UJZMl5g2QJZMo5i2mIXMS6j2jIWMW6j2fIWMZ6n2aIRM`6P3PGWLn1i0T7d3dH]L]7f3^HZLe7f3XH[Li7e3UH\\Ll7d3SH[LP8d3\\F_K_1n0V8f3dF\\Kh0n0f8^3[FfK7N>0@n0a9\\3\\FgK41<3_Oi0g9[3ZFhK41<5]Og0l9X3VFlK538T1a9k2QFmK755S1d9j2PFoK842S1h9h2mESL2M065T1o9c2kEWLON162R1W:`2gEcLN]1^:m1dEdN_:Z1`EfNc:V1]EjNf:U1YElNh:b315K1\\EkI`:X61O01O001O001O010O00O100O2N100O101O1N101O00001O00bEoIR:P6nEQJR:o5>0O00000[EPJ`:o5`EQJa:n5^ESJc:l5]ETJc:l5^ESJc:l56000cEYJg9f5YFZJg9f5h0O1O1OQEYJj:k52N101O1O1O2N10O02N1N2O10OO2O3L2N2M4M3N2N2M3M3L3M4M2M4L3M4L5K5L4K4M3N1N6J4L2N3L5J5L5J4jMbAl1h>VNWA]1o>\\N^AY1Y?H6J8UOl_Ob0Y`0M3M3M5KbbY3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, maturity, face expression, pose", "answer": "The image features a woman standing next to a motorcycle, which is parked on the side of the road. She is wearing a white shirt and appears to be looking at her cell phone. The woman is also holding a basket, possibly filled with groceries or other items.\n\nIn the background, there are several other people present, some of whom are carrying handbags. The scene suggests that the woman might be taking a break from her shopping or preparing to load her groceries onto the motorcycle."}, {"question_id": 309, "height": 640, "width": 480, "image": "000000150265.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [122.25, 375.37, 199.91, 254.56], "segmentation": {"size": [640, 480], "counts": "Vo]23jc05L4M3J6I7L5J5M5I:H6J9G6H9I;E8H8H6I8^OULa@T4T?VLd@Q4T?g0F7I7I<E7I7I4L3MnLkB\\OT=b0oB^Oo<d0gBhL0e2W=k300O2NYMoBbNo<_1XC[Ng<d1_CWN`<g1fCVNZ<i1kCSNT<o1PDlMP<V2bDVM^;n2cDmL\\;[3bDaL];g3_DUL`;a4lCWKXOAl<[5jCPK_OCf<_5lCeJZOL6Oc<b5oC_JZO04Mc<f5VD]JS<d5lC\\JT<f5kCYJT<j5kCTJV<m5m03M3K5J7J5L5L4L3M=B4G_HnCl7g;VHXDj7h;7OH[DWHd;j7XDZHg;P8O1O1O100O100000fJ]D_1OWLd;j6^DVIb;i6^DXIb;h6]DYId;c6\\D`Ie;]6]DcIc;[6^DfIb;W6aDiI`;S6bDnI^;m5fDTJZ;m1ZDLOWNb00U;m1ZD\\MOV21]Nf0\\O]O8f;]2WD\\M0U20YN_1\\O_:^6^DaIM1X<a7J3M\\OhCoH;6j;[4jCkMd0iM`;\\4lCUMb1ZN`:i2nCb0d1eL_:f2PDc0n=UORBi0R>VOmAnMO`00Q15XNc=Y2YBk03nLd=a5YBfJd=Y5\\BkJb=S5^BPKa=d1]BP13^M^=l4bBVK]=k4bBVK]=k4aBWK^=R1bBg2\\=WMeBVOOb2[=XNeBm2Y=P2NeNiBTLo<i3TCWLl<b3ZC_Lg<f1PC^N:Od<a1TC`N0[N1f1k<_1RC`N1^N1g1j<o2VC]KNe1l<k2XC`KLh1l<d2ZCgMg<Q2UCeK6\\2d<l1bCRNa<j1bCTN_<k1aCUN_<l1`CTNa<QO\\CR1EeM:X2e<nNcCR1]OiM100[2Q=bNjCW1YOlMK\\2S=_NoCT1UO?l<]NSDi3n;VLVDf3k;YLWDe3k;ZLYDa3g;bL]DW3d;RMYDg2h;_MUD]2l;dMUDY2l;fMXDV2j;hM[DS2h;kM\\DiNSOU2b<ROcEg0^:YOgEa0]:\\OjE<W:DnE6T:IVFLk94WFEn9<RF^OS:b0nEUOY:l0jEmN[:S1Y41O0001O02N3M2O1N001O010O4L2N1O3M010O10001N3NO112NO0O10N2O1O2N1N3M1N3M2O3L=C4L3@PdV3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a woman wearing a green jacket and a white shirt, standing on a sidewalk. She is carrying a handbag and a backpack, which are placed on her shoulders. The woman appears to be walking down the street, possibly on a city sidewalk."}, {"question_id": 310, "height": 426, "width": 640, "image": "000000151000.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [175.75, 35.45, 214.91, 381.11], "segmentation": {"size": [426, 640], "counts": "hVZ26R=4I7L3L4K6L3L3N2O2N1N3M3M4L2N3M3N1M4eGQNW5R2gJPNV5R2iJoMV5S2jJlMT5W2lJgMS5\\2lJdMR5_2mJaMR5a2kJaM^MO^7a2TK`MR5c2h23QHYMX5h2hJXMV5k2iJUMU5m2kJSMS5P3lJoLR5U3`21]HkLo4g1fHB[2gNm4a1TIEn1jNl4]1aIDc1oNh4_1hIB^1POh4\\1nIDZ1POf4\\1RJGU1mNg4[1WJJQ1iNg4[1[JNm72TH1g7O\\H1a7OaH2]7MeH6W7IkH8a1`NZ2W1WL9\\1dNPML42JNo02g2U1QN:Z1cNQML36NIf05j2S1VN>T1]N]M:FE3OM03400_3Q1[Na0o0ZNeM051@1\\3S1]Nc0X6\\OjIe0T6[OnIe0P6[ORJg08VNINP1U1POh06UNR3R1iLk03RNU3R1iLn0EQN[NNW5S1iLo0CRNYNOZ5Q1jLo0ASNYNNZ5Q1nLo0^OPNm3P1fLR1JkMT3S1RMT1HiMU39hJH2`0Z2g1Q5PNmH5T2k1n4nMPI6S2m1l4kMSI8Q2n1l2fMeJ1i10gN:P2P2h2lMoLHkM;`2Q2d2nMiLFWN1J:c2S2Z2RN_MI8U2^1PNVL6T2C9X2[1nN]NhN9Z2S1fMWLX1\\2hN;Z2P1WOdN_N>W2n0\\OeNZN?Y2j0@f1?WNEXNQNe1Y23Gi14XN0h1MWN7i1GVN<j1@WNc0i1[OXNf0h1XOXNj0h1UOXNl0h1SOXNn0h1ROVNP1j1nNWNS1i1hNVKeNV1O[N0k0g2^4bNoJfNI;n0g0]Ok1m4[NPKGKo3U5VLRKT5n4jJQKY5o4cJRK`5n4]JPKh5P5VJQKk5o4RJSKo5m4PJTKP6l4mIVKT6j4jImJDJd6Y5hImJa6f1oH\\1?mLd6^1mH_N3U3:jLINi6c1SI_N1V3:jLGOl6a1SI_N1W39iLG1l6`1RIbNOT3g0gLZ6d1nHo1m7f1100eLTHRNNR3o7cNPH`N9k2h7aNTHbN5l2h7bNSHaN7k2g7cNSHbN6k2g7^NnGgN507T1KTOJc0R8>nGeN518Q1MSO4=d7j0RHfN?h0o0\\Oa6V1QHgN?c0_9f0RFgN:f0f9c0PFgN2i0S:`0kEfN3i0T:a0iEdN:d0n9j0XFlN_OFl00\\8_1YGkNb0JQ8[1]GkNHH86_8X1`GiNJH88]8X1aG`N]O2Z13m5L_J^1SOaNR82kH^1R8bNnG_1]O`NW70aIc1c7_N]Hd1_7[NcHg1Z7ZNfHh1V7ZNjHg1Y1UN^26YLe1Q7\\NPIe1HUNY57oJe1CZNY54TKc1VOYNjN1l63TKe1ROgNi5CUKg1TOUNlNKT78lJk1e6SN]Io1b6nM`IT2g5kMfHOd1m1kMXNg7NkHJe1o1kMXNd7OWKi1UMXNb7O[Ki1SMWNc7K`Km1mLXNc7K_Kn1nLWNc7J`Ko1mLXN`8KcIl1nMYN_8LbIk1oMYN_8LbIl1nMXN`8LbIl1nMYN_8JdIm1mMXN`8KcIm1mMWNc8J`Io1mMUN4NW8MhIQ2lMSN61S8LkIP2mMQN66:J`5OYK1j0o1nMoM778Kn60eJP2YNPNC1T8OPJP2_NRN`7MQJQ2_NWNKMh6KoJQ2_NoN`6oNRKR2`NnN]6POSKR2aNoNZ6oNUKS2`NPN[Oj0W2SOiM2OO4On31TNQ2iNkN[1WOQ2NiMQ2SOoMjN?W2CS2NiMQ2TOnMmN1L5i6KZKR2EoMR5M\\KT2HPNn6P2SIQNj6P2VIRN\\OId30VMV2ITNg6k1ZIYNQ2D:T2fMXNj1K=m1iMYNf12<f1mMZNb18<^1RNZN`1;SNTOd0X2ORNV1i0eLTOS1JS1X21oMo0`1fM[NSOOQ2W27oMm0e1fMYNW1T26nMi0l1fMRN[1U25eMjM4o2S2fMiMa1[25iM?\\20LAgM=a20IBgM;d21FCgM:g2WNUMj0_2c0fM;g2ZNUMd0_2i0bM8V1^M;k0bNb0\\2n0`M5U1cM`0e0cNa0Z2P1^M6m0aMYO1`1f0dN`0Y2Q1^M6g0hM^OJd1c0aNc0[2P1ZM6>cMC018j1H]N`04e0\\2P1UM8<dMFO0d0]1\\OhN25<8b0Y2`3_MfKDa0h1ZOfN;9b0Z2S1oL6=PNCb0Z2_OaNc0X2S1nL95VNK>Y2YOeNe0]2U3kL_LJ?2WOV3c09ZO_L8OQ3e0hL^Oi0N\\OY3>h1_1nKeNQO]O[3>k1W1lKoNd2Fb1W1kKUOd2Cd1h0gJkNj0OZOh0l3DZ1`0bKXOVO0O:\\4Kn0>\\K\\OYO32L11e45d09`KCRO2c5MM8aK3i;K4O2NR=KXgU3"}}, "object_label": "person", "attribute_label": ["face expression:fear/surprise", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose", "answer": "The image features a woman standing in front of a window, holding a cell phone in her hand. She is taking a picture of herself, capturing a selfie. The woman is wearing a white shirt and appears to be focused on her phone.\n\nThere are two other people in the scene, one standing behind the woman and another person on the right side of the image. The woman holding the cell phone is the main subject of the scene, as she is the one taking the selfie."}, {"question_id": 311, "height": 640, "width": 385, "image": "000000151657.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [10.09, 16.58, 204.68, 616.93], "segmentation": {"size": [640, 385], "counts": "X\\8Z1^b0j0WOd0^O?]Oi0XO>oN_1WO5M3M4K4K5F:A?K5L5N2M4M2N2N101N2O1N101O0O2O2ZDkG];]8N4M001N101O001N101N2O001N5L7I8G5ZI]F\\LLX6n9aLXGeNPOh2n9WNaGfNhNn2l9SNbGjNeNS3T:bMaGVO\\NW3`:SM\\GAUN\\3h:eL[GLmM_3Y>]LgAc3\\>YLeAg3]>WLcAi3`>RLbAm3Y?0000O10000O100PNQ@Oo?0S@Nn?2S@Mm?3S@Mm?3T@Km?5S@Km?4U@Kk?5U@Jl?6T@Jl?6U@Hl?8T@Hl?8T@Gm?9S@Fn?:S@Em?;S@Dn?<R@Co?=R@Ao??Q@@P`0`0P@_OQ`0a0o_O^OR`0b0o_O]OQ`0b0P@]OQ`0a0U@ZOl?`0e@TO\\?g0PAQOQ?j0YAPOh>l0bAmN_>o0[2L4M3N2ON2N2O100O200N101O1N2N2N2N2M3M4K4N2I8F9K5ZMdMkBY3S=jLWA0OOe05BIK\\3^?dLl@7JKKn01WONK2g1^?WNk@2G041J?0_Oa00Je1]`0ZNZ_O1X1c1Qa0^Ne]O]1\\b0aNf]O]1Zb0eNd]O\\1[b0eNg]OY1la0fNZ^O1LX1ia0jNX^OOOV1ia0POS^O[1[>]NkAN12O1O1O0e1o1Y<RNoA:OH2d00XO^1Q2a<dNoA_O2d0OYO9Lb0\\2T=fNRBINZO8MJO8O1\\2f=eNQBVON;1BW1X2k<iMmAb06ZO02L34JT1[2j<hMmAO1OO2OO11h00i00^NS2e8RNeGI]49YK8?@D42Lf0N@\\2j7bNmGWOb4j0]KQO1303O10Oh0M_O\\2h7]NTM^OnJL04Nh07XOLLM`2m6ZMmIo0VOSOe50`J5Ml01\\2i6\\NVIUNn56QJc4j6RMWIUNe51^JR5f6hLeNWNeJ2NQ5g6fLZOX3mLQKc00\\L43o0^6]O_I^O110M2a3k2eLh0K]L45n0\\6mN_I6NL1N1164GT3k2PMi0J^L32JNR1a6@]I@101O0b3f2iLk01`LEOo0]6OaIj2e2dLm02^Lh0_6e3SLcKo0[1o2R3oKeKR1Z1c2TNUJP5Q2dKW1X1\\2TNUJ43T5l1`K`1T1Z2WNUJ33\\5Y1bKU2g0a2YNRJb5l0fKd2eN_L5MT1U6fN]J<^OF33N[4j0mLP3gNXLT1g6hNVI31O1N51L6M;0@2^3c0oMo2bN_L5OR1S6hNSJ00<HF24Oc46PM\\3YN_L5OQ1Q6lNRJ0Nb0N_6c3kHbL4OS1P6jNTJOM?KC2R7U4oHjKk0i7I]HP5W4VK]3\\OVHL;c5Q4UK\\3G\\HZ5X4oJh1SOUJ1H51O>`0BZ5Z4nJY2BkI8_O[5\\4kJ\\2[OXIJ2N<6BL6W6V4dJ\\2_OZIE0O66IL5X6V4bJi1TOSJ0Kk0MG0n5^4XJf1[OPJW8f4hGd1OhIe1Li4f;SK^Dk4b;SK_DGJl3e;`L_DFKk3n8lJdIf1bMDMj3a;aLbDELk3f6[K[I<OZO3Oh2^1XMo4W6oK]L`MZM^12T5S6ZLdKSM^N1Md1Mo4f5hLgKdLgN3LP2Nc4f5QM_KYLPO5Kg8e5oJgK5eNn0[5WOSKmKGN:`0@l23b1n4VKRKU4NiK61M_4N=\\4<fKlJL\\42>S4c0mKcJN]40?l3R1^LmIHT4No0c3W1^LdI70K001NU9R3hMPMXIMc9e2f7D?DnEUN_2NfEY1R8jN]2f0i8E;J6Jke_3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, hair type, pose", "answer": "The image features a man wearing a black suit and a red tie, standing next to a woman. The man is wearing a hat, which adds a touch of style to his outfit. The woman is also dressed in black, wearing a necklace that complements her attire. Both individuals appear to be posing for a picture, possibly at a formal event or gathering."}, {"question_id": 312, "height": 480, "width": 640, "image": "000000156643.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [559.82, 160.45, 80.18, 142.79], "segmentation": {"size": [480, 640], "counts": "WUX81c>4^A7Y>=K4K3J6N2K5H9N1O1O001O1OO2O0O002L3L5O100YOfBAKN^==kBCH2\\=;jBDJ2]=4aBF57K2f0EP<8]CH3h0;^OV<M`CNNh0NMl<[ORCO0f1m<_NSC3OS1P=iNQC12V1k<iNTC02W1j<iNTCN4NJ11<N7S;E]FLcNM3N21I64:l:CREM^13bNO2M59J8l:CQG1QNM86J:k:CUE2`1M^N066J9l:ERE3h0E02\\O7M30IO7n:e0_EPOH28OGg0L[O18m:g0]EmNK38MGi0K[O27k:JTEi08ROM3`0NZOd00_O37h:KUEj07QOM;>`0_O@j:m0ZEjNK=`0FBk0i:;WEZO>\\O@O3o0i:ROUEO0S10C>^ODk0h:SOZEk1<VN_O20e0j:XO[Ej1f0UNVOi0i:XOXEl1P1kNg9ZOXEl1m0PNTOj0g:ZOYEk1a0ZOV:kNYELNm1a0^OX:iNYEl1;^O\\:fNXEm1;^O]:eNWEn16oMMd0M3i:\\OXEl16bNK=g:UOXEl17[N5?\\:ZOXEl17ZN7?Z:^1`EnM:d0V:^1`ElM<f0T:^1`ElM=e0S:\\OXEl17TN>d0S:\\OXEk17RNc0f0o9]OVEh1;UN`0e0P:[1aEPN?e0P:Z1bEPN?e0Q:Y1`FeNa9[1[ERNh0c0o9AREb16ZNh0c0Q:ARE^1M_N70i0a0R:BQEb1U1lNk9CoDMNe03OO[OQ1a0Q:>SEEK\\O72<?`:;VEALCN7?9c::UE^O0JF6b07g:6TE@N0E1a0:k:AbD2j00\\OMN71K6OH`0a;AXEM\\O2I84I52F>P6"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:curly/curled", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, face expression, pose", "answer": "The image features a man sitting in a chair, holding a cigarette in his hand. He appears to be looking at something, possibly a cell phone or another object, as he smokes. The man is wearing a striped shirt, which adds a touch of color to the scene.\n\nIn the background, there is a potted plant, and another person can be seen sitting in a chair nearby. The setting seems to be a casual and relaxed environment, possibly a cafe or a similar public space."}, {"question_id": 313, "height": 480, "width": 640, "image": "000000156643.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "material, pattern, pose, texture, transparency", "region_anno": {"bbox": [9.29, 7.23, 193.03, 467.61], "segmentation": {"size": [480, 640], "counts": "ob1181f>0Un01XkN0TN0cI3a3Kk04Z:3N2M3N2M3O1M3M3L4K5N2L4M3L4M3M3M3M3K5M2M5L3N2K5M3L4mDdN]8a1YGXOU8k0iG_Oi7g0SH`0\\O_LV7S3]I`1c5eN]Je1_1]KQ1U3_Mk1^OeJ^1g0dNWOV2o3YNb2@`I50JX7`0T700O1O1000O11O000O1O100L_AIa>56N2000000O100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001O1O000aFKS46kKKU45kKLT44hKJnJ2Z95lKIU48Y52N1O1O001O001O2fN@PDa0W=001O001O001O001O1O0000001O1O00001O00001O1O1O6J1O5VBBh<HWCh58hI\\7?]HU6c7lI\\HU6c7d00c0]OY1RIXGR5\\:oN7I6I6K5J4M3N2M102M2N3M3M2N2N2N3M3L3O3L3L7G;\\Oa0@lj]6"}}, "object_label": "bottle", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, texture", "answer": "The image features a large bottle of beer, possibly a Carlsberg beer, sitting on a table. The bottle is almost empty, with only a small amount of beer left in it. The bottle is placed on a table, and there are two people in the scene, one standing near the bottle and the other further away. The scene appears to be set in a bar or a similar social setting."}, {"question_id": 314, "height": 640, "width": 428, "image": "000000190637.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [14.25, 182.44, 413.75, 349.66], "segmentation": {"size": [640, 428], "counts": "XT92mc02N2O0001N_d50`[J3N101O000O10002[\\OI]c0>O000O10000000000001O001N2O5J2O1O0OeNNj^O2Ua01j^OMVa06Z11N3M100O1O1000000001O1O00001O1O00001M2O3Gaf?3aY@4a\\OLib08R]ONib06U]OKhb09U]OJib0g0O1M301N1O1N3M1O2N3N2N1O2N100_Ob0M2O101N1O101N101O00001O00001O0010O00010O001O0010O1O0100O1O10O0O1N2M4M2O1O2N1O1N2O2O0O1O2N2N101O001O001N10001O001N2O001O00001O000010OO101O010RKfLTI[3h6nLRIR3i6]MmHc2P7iMgHW2W7UN`Hk1\\7^N^Hb1a7eNYH[1f7jNVHW1f7POVHP1j7ROUHn0i7UOUHk0k7VOTHk0k7UOUHk0k7UOVHj0i7XOWHh0g7YOZHf0f7ZOZHf0f7ZOZHf0d7\\O]Hc0V7WL_FW3[2c0`7^OaHa0_7_ObH`0_7_OaHa0^7@cH?]7AdH>U7\\LUFV3g2>Z7BfH=[7CfH<f6]LmFZ3^28d6^LnF[3`25a6aLhFOM\\3j23b6aLnF\\3`22e6bLjF[3c21c6dLjF[3e2O_6fLoFZ3d2M^6iLoFY3e2LQ73PI_NkL@V:R2oH[MlL62;S:U2PIXMoL21a0n9W2UISMnLM6g0V9lNjF^3o2oLPMF7o0b9\\2YImLhMg0P9[2YImLhMf0a8POcF^3U3jLiMf0_8TOaF\\3[3fLgMg0^8XO_F[3Q5[M`4WObF^3P5XMn4i2TKSMl4n2VKnL[4C^Fc3[5_L]4OVFe3c?[L^@d3b?^L\\@b3e?]L[@c3e?^LZ@c3^?YLa@50b3_?YLm@h3R?XLn@h3R?XLn@h3Y?YL_@h3`?XL`@h3`?YLa@e3a?ZL`@e3_?[La@e3P`0NA\\Lb@b3n?0010O1O4M0O3M010O10O0002N5L4KNQMU_Om2m?SMm@0VOm2m?SMm@0WO4Ma2P`0]Mk@0\\Ob2i?^Mk@0\\Ob2i`0\\MX_Od2Ta0M100ObN`M^A`2b>`M^A`2b>`M\\@0f0_2[?aMe@^2]?cMb@[2_?fMa@g1Ua0M4K3N3NiNeNm_OX1W`0gNi_OX1`a001N1O2N1O100N2O[OPOP^O022Fh0Tc0N3L6J6EVn6MSRI4Z\\OL[c06c\\OL\\c0>N0O100g_ODn<<QCFm<;oBJP=6oBKP=6oBKe<Ee@`0e2Me<De@`0c2Ng<Dd@?c2Oi<Cb@`0b2Ol<Ba@?a21n<@a@`0`20o<;PCFP=;oBEQ=<nBDR==lBDT==h@iNi1j0_=j0]BWOc=k0ZBVOf=k0YBUOg=l0WBUOi=l0VBTOj=m0UBSOk=n0SBTOl=m0RBTOn=l0RBTOn=m0QBSOo=m0PBUOn=m0QBSOj=S1j@kMW1S1m=S1m@kMT1R1n=T1n@jMT1S1m=V1VBjNj=V1VBkNj=U1UBkNk=V1TBkNl=U1SBkNn=V1PBkNP>U1oAkNQ>8VAROh0g0R>2]AVO`0h0R>OcAXO]OCe0V1\\>MfA[OVOAh0W1]>GlA@oNAh0Y1\\>AWB@eNHg0V1^>XOaBNPOk0_>UOjBJfNP1a>SOkCn0V<mNZCJoMZ1g>iNPDV1]?1O010O010O001O010O0010O002N01O01O0001O00000001O0001O0000001O00000000000010O000001O0001O000001O01O0O_6"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:young/baby", "pose:sitting/sit"], "control_dims": "gender", "answer": "The image features a young boy sitting on a couch, holding a Nintendo Wii game controller in his hands. He appears to be enjoying playing a video game, possibly on a Wii console. The boy is wearing a blanket, which adds a cozy and comfortable atmosphere to the scene. The couch he is sitting on is white, and the overall setting seems to be a relaxed and casual environment."}, {"question_id": 315, "height": 457, "width": 640, "image": "000000210230.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [210.36, 60.73, 423.67, 396.27], "segmentation": {"size": [457, 640], "counts": "]_f21X>0Za>1dPAOX50dj32R^L4UN2WENf:7XEIa:KUDa0V1Dc:LXD`0T1Eb:MYD?S1Gc:I[D`0Q1Gd:H]Da0o0_Ol:OWDa0m0_Om:0UDa0o0@oN0d;N^Db0o0Ja:EcD0I5V16^:FXF0SNO01e;0WF1TNN2O\\;1dD0k13QNO2N[;4fDLl1:QNG\\;3gDLl17UNHe=4:O^LOjFNg04oML21T:2gFNYO3i1:V8EQG0k00k90UF0kNOV<1jC0l9N]G2gN0j90_G0gN0U<0kC0]9M\\H3WN1Z9O^H0XN1k8LdF4Y2OXN1j8OaF3]2MeMM56e9ObHMWN3W=N1NdLOaH2]70oGNlM2c=0[h0NfWO3ONW`00h_O201OOdl0M`SO2NOcl0O_SO1RD0`92[20N22N0OiX1Nn\\N0_61^I2gLOW9ORJ2_LMi90jI2]LNf=1ZBOf=1ZBOe=2[BNg92lI1[LOMNf94QJ=m5D^GM\\1`0W7C\\GM]12cM4e9MZGM_11cM1h91VGN_1NeM1h92oFLUO4k<NPD0TO3OLg<4SDOVO7e<JTD0WO9b<GWD0WO;a<GTDb0]O[OU2Nf76ZFIM1M6O`0W2ZOf79WFE5S1m1POf7;VFB6T1Z1lNPO3Z9`0ZFb0R<^OhCg0X<e0aESNb8n1\\GfNYN^Ob9n1SHkNm7V1QHjNP8V1oGjNQ8W1nGiNR8X1mGhNT8X1kGhNV8W1jGiNW8W1hGiNY8V1gGjNY8V1gGjNY8W1fGjN[8T1eGlN`8P1_GPOa8R1\\GoNe8Q1ZGoNf8Q1ZGoNg8P1YGQOf8o0ZGQOg8o0XGQOg8P1YGPOg8P1XGQOh8P1WGQOh8o0XGQOh8P1WGPOi8P1WGPOi8P1WGPOi8P1WGPOj8P1UGPOk8P1UGPOk8P1UGPOk8Q1TGoNm8P1RGQOn8o0RGROm8n0SGROm8o0RGQOm8P1RGQOn8o0RGQOn8o0RGQOm8P1SGPOm8Q1RGoNn8Q1RGoNn8Q1RGPOm8Q1RGoNn8Q1QGQOn8o0RGQOn8o0RGQOn8n0TGQOl8o0TGQOl8n0UGSOj8m0VGSOi8n0XGROf8o0ZGQOb8S1^GmNa8S1`GmN_8T1aGlN^8U1aGlN^8U1aGlN_8T1aGlN^8T1bGmN^8T1aGmN^8T1RG`MD2OO1\\1Z9V1jF]MK<1Q1Z9n1hFPNW9P2nFlMQ9S2PGlMQ9T2nFmMR9S2nFmMR9S2mFSNn8m1PGXNMcNf8U3[GZNOaNf8T3[G[N1^N2OZ8X3cGoN[8R1fGnNY8Q1hGoNX8Q1gGPOY8P1gGQOW8P1iGPOV8Q1hGfLMf00i0a5bNTMZ3]MfLNe00A0n0`5lNVMZ3\\MROZ1cMb23gNY3^MPOR1lMg2LiNW3_MQOQ1lMf2MhNX3`McLNY2Y1iMa24hNW3`McLO0OT2Z1mM_26iNU3aMdLN00S2Z1mM]28jNT3aMeLLO3T2Y1kM\\2:kNR3bMjLMo1Y1lM\\2:lNj2mMmLBS2Y1lM[2:nNZ2\\N^MPOS2?jMC1b02_1N[O:V1Y2]NH]OfMCOb03^13VO7\\1P2TNfMDX23jMCK>3b16RO5`1n1RNnM\\OG0[2>cM:2X1?lNMf1o1QNf0g0mLe0f0hNIk1n1dMcMNY3X3bMeLVO:`0V2f5k0QKfLZO_2e5j0iKUOX4j0iKTOY4l0gKTOY4k0PLhLmMi1S6`1^L\\Nc3c1`LZN`3GeIc0n2B^3JfIb0n2B\\3NdI`0R3@[3n1fLQNY3P2hLnMY3Q2jLlMV3U2kLiMU3=dI7X3UOY3;^IPO1`1Y3ROZ3=]IPO1a1Z3lN[3d0ZIPO0`1\\3kNZ3e0[Ij0^3^NV3i0\\Ii0_3]NU3j0[Ij0b3ZNR3l0]Ij0d3WNm2Q1^Ii0f3UNf2_3\\M_Ld2a3_M\\L`2j1dIK^:5bEK]:6cEJ\\:6eEJZ:7fEIZ:6gEJX:6jEIV:7jEIV:5lEKT:4mELS:4mELS:4mELS:4mELS:5kELU:EgERO0Y1Z:DeETO1X1[:CdETO2Y1[:MmE2T:@bEmN0O:d1U:_OaElN307e1U:DdEfN8f1U:CRF=o9CbEeN9h1V:C_EgN6NJh1b:M^E]NOf1d:B\\EiN103e1`:]O\\EnN1O022c1c:]OZEoN1O022c1d:FZEiN1`1f:FYEjN1`1g:DYElN0`1h:_OWElN15Oa1j:]OUEoN130a1k:\\OTEPO1N10Of1k:BYEhNLf1l:@YEjNKf1m:^OWEmNMe1m:]OXEmNJf1o:\\OWEnNJf1o:\\OWEnNJf1P;[OVEPOIe1R;oNnDC2NN`1R;EnD;S;DmD=S;BmD>T;AlD?U;@kD`0V;_OjDa0W;X11O0jMhD[1Y;cNjD[1W;eNfD]1[;h0001O1O1O1O1O1O1O2N1O1O2N1SNYDV1h;jNWDV1j;jNUDV1l;iNTDX1l;gNTDY1m;a01TNRD[1o;dNQD]1m2XNQ6:RG^1m2XNR69QG`1k2XNU67PGb16_Nn1Km6h2nHYMS7h2oFRM1Ob17`7P3_HPMb7P3]HPMc7R3[HnLf7T3VHmLl7R3SHnLn7S3PHnLP8S3nGmLS8U3jGkLV8[3dGfL\\8[3bGfL^8Z3`GhL`8W3`GiL`8Y3]GjLa8W3]GkLI@W8f3nGlLH@Z8e3mGlLGA[8d3lGmLGA\\8e3iGmLH_O_8h3cGZM^8Y4O0O2O001O001O1O100O001O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1N201N002N1O1O1O2N1O1N201N2N1O3M1O4L1O2N2M202M3M3M4L2N5K^MhIVMU6a5N2N3eNkG\\LX8a3kG\\LY8V1dGN6jNY8S1hGN0nN^8k0iG3KPOc8d0hG7GTOc8`0SH1]O]Ob8=YHOYOB`89`HMTOI`82eHMPOO`8G^J7n9L2N1O3M2Mb_8"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression", "answer": "The image features a woman in a military uniform, possibly a sailor, who is smiling and holding a hot dog. She is wearing gloves, which suggests that she is handling food or participating in an event where hygiene is important. The woman is standing in front of a table with a hot dog on it, and there are other people in the background, possibly attending the same event or gathering."}, {"question_id": 316, "height": 480, "width": 640, "image": "000000231580.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [142.38, 31.28, 171.51, 361.35], "segmentation": {"size": [480, 640], "counts": "aeS22n>1N2O1O001O000O2AJRB6n=KQB6n=KPB6P>KoA6P>JoA7Q>JnA6S>JkA8U>90001O01O00001N10000O10O10O100000000000O100O01O0100O1000OkA[OP>f0oA\\Oo=d0RB]Om=b0SB_Om=a0SB@l=a0RB@5L^=e0\\B@5Me4Lm3Q1[GUO_46R4Q1iKTOV4l0SJfNjNa0R7j0VHg0>fN[7d0oGP1<cNc7`0nGR17cNi7=nGX10_Ni7a0SHk2b7`M]Ha2`7b2L4]MnHSKJe1]7T3XIgLl6V3WIfLl6Y3WIaLn6]3VI^Lm6`3WIZLn6d3VIVLm6h3UITLo6k3RITLn6l3SIQLP7m3QIRLP7n3QIPLP7P4QImKP7S4XIeKh6\\4n1000O0GfKnEZ4n9lKoEU4m9a0M3I7J6L4I7F:I7B>F:C>J5N2N30O110O2N2N2O2M4M10hHbHk6Q8J1NO2M2N2N2N2N101O1O2M2N2N4L2O1O2N2N1001ON3N1O1O`LXIiNf6n0fIPOY6l0VJjNh5j0hJVOU5c0TK]Oj4=]KPMQNT2a6h0dKmLRNY2Z6e0XL[Oh3?]LCc38bLIPMeMQ6]2TM9m2AZM=g2XOdMf0^2SOiMl0Y2lNoMQ1V2dNSNY1Q2RN[IFm4V2e7O2M21OO1N2N1O3N2M2N2N2M3M3N2N3L4iNbBf0n=M3M7I5K4L4LYmh4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression, hair type, pose, maturity", "answer": "The image features a man standing in a field, wearing a blue jacket and a white shirt. He is holding his hands out, possibly giving a presentation or speech. The man is surrounded by a group of people, some of whom are standing close to him, while others are further away. \n\nIn the background, there is a cow, which adds to the rural setting of the scene. A dining table can also be seen in the background, possibly indicating that the gathering is taking place in a farm or outdoor event space."}, {"question_id": 317, "height": 427, "width": 640, "image": "000000235241.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [43.18, 46.06, 152.57, 379.98], "segmentation": {"size": [427, 640], "counts": "_Uc0:j<7^LAjFU1n1Ai6V1mHPOk6Y1QIjNh6\\1UIhNe6^1WIgNQ6mNoHa2m0eNQ6ROhH^2h0nN`6c1]I`N`6c1]I`N^6Y4L4K5L4K5J6J6K5N2N2N2M3L4M3M3L4N2M3N2M3M3N2N2N2N2O1N2N2O1N2O1O1O1O1O1O1O1O1O100O2N010O10O001N1O2O0O1010O101N4M1N2O2N1N2O000O100O100O1QO`FSN`9i1hFRNY9h1PGSNR9j1Y1M3M3M3N2K50000O1O100O100O100O10000O10000000000O100000000000lFfNU21oNY1iNiN6MoN7o1T1jNiN4n0[M3c36mNjN1`2o0fNPOjN0e2l0aNTOjNOi2j0^NUOkNNk2iMiLk2a1]OlNMm2jMfLl2a1[OPOLQ3h0oMYOSOLQ3k0mMVOUOLQ3n0iMTOZOiNS4P2dLTO\\OhNV4P2`LVO^OcNY4T2[LTO`5j0`JSOd5k0^JPOf5o0\\JnNg5P1[JlNj5Q1WJlNm5R1UJjNo5T1UJeNQ6X1bJQNe5k1P3O2aNcDj0_;SOdDFNo0c;WO]DP1f;98H001jNTD1Lc0k<E8I2NaWk5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, hair type, face expression, pose", "answer": "The image features a man wearing a green shirt and black shorts, walking on a beach. He appears to be a young man with a beard and a ponytail. The man is walking alone, enjoying his time on the beach."}, {"question_id": 318, "height": 427, "width": 640, "image": "000000235241.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, material, size, state, texture, transparency", "region_anno": {"bbox": [345.5, 302.9, 192.56, 84.65], "segmentation": {"size": [427, 640], "counts": "bc`42V=3M3O2M2O1O1O2M2O1O2M2O1N2O2M2O1O1N3N1O100O1N1001O100001O0oCjNm;V1RDlNm;R17O1O1O100O100O1N2O10000004L1O001O001O1O000000001O0000000000001O0000000000000000001O000000001O00001O0^DhNQ;Y1lDjNS;W1kDjNU;Z1eDhN[;d1001O01O0001O0000001O0010OO2O1O000O2O01`D[NY;l1O1O01O001O0000001O001O0001O01O0001O01O00000010O0001O000010O0001O0010O010O0001O0010O01O010O00100O1O001O100O001O10O0001O1O0O2O001N2N100O2N2M3O0O2N2N1O2O0O2O0O1O2O1N3N3L4L4LScZ1"}}, "object_label": "umbrella", "attribute_label": ["color:blue", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "size:big/large/giant/huge", "state:open", "texture:smooth/sleek"], "control_dims": "texture, transparency, size", "answer": "The umbrella in the image is blue and white, and it is open, providing shade for the people underneath it. The umbrella is located near the center of the scene, with a person standing underneath it."}, {"question_id": 319, "height": 480, "width": 640, "image": "000000246883.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [257.88, 226.23, 47.68, 125.25], "segmentation": {"size": [480, 640], "counts": "bgh33f>a0C;D5J6iCiNa:Y1_EgN_:h0[D^OU1L]:b0fD@l0O]:=QE_Oa05^::iE?V:BeEc0Z:^OZEn0f:VOjDV1V;mNcDQ1EYNh;m0XDl0P<m04M4J6G9MFoMiCP2X<:2N2O1N3N2O11O5K5K5K4M3bDUM`:=kDY24]MP;9mDg2U;VMmD4OP2f;oM_Dm1b;RNbDj1_;VNeDe1\\;[NjD^1X;aNbE:_NDo;2eENkNHb;8^FHe97YFIj94VFLc_n4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity", "answer": "The image features a man standing on a beach, holding a surfboard. He is wearing a wetsuit, which is a common attire for surfers to keep warm and protected in the water. The man appears to be preparing to go surfing or has just finished a surfing session. The surfboard is positioned in front of him, ready for use. The beach setting and the presence of the surfboard suggest that the man is enjoying a day of surfing and outdoor activities."}, {"question_id": 320, "height": 334, "width": 500, "image": "000000261061.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [260.16, 41.7, 111.51, 292.3], "segmentation": {"size": [334, 500], "counts": "c[d21V13i74SHNj77XG16L_8\\1N2M3B=H9L4cNaMdJd2Z5oMkI\\2R6Q1M4M4K7I:Ea0A5K5M2M2N3N2N1N3N1O1O1N3M4M2N2N1O10O0WNbL`K19`2FgM`42^Lj1\\ORNW40gLe1VOYNS41hLc1ZOYNo3GTMm1QOZNP6d1SJYNo5d1UJZNl5e1_1O1O1N2O1O1O100O100O100000N2J6TOk0G:K5M3J6J501O1O1O001O1O10000WK]L<NgMi0Z1n2b0]L:X1nMgNNM9i3`1]L2R2XNb1f1]LE_6:bICa6<`I]Og6b0ZI]Oh6a0YI@f6?[IAf6<\\IDd6;]IEc6;]IDd6<]IBd6`0ZI^Oh6a0ZI^Of6b0[I\\Of6d0\\IYOe6f0^IfN^O1W7Y1`1O001N101N1O2N1O2N2N2N3M2M7J2G\\FCi9;:IRZ[1"}}, "object_label": "person", "attribute_label": ["face expression:disgust/frowning", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "hair type, pose", "answer": "The image features a young girl running in a grassy field, with her arms outstretched. She appears to be enjoying herself as she runs through the grass. The girl is wearing a red shirt and shorts, which adds a pop of color to the scene. The image captures her movement and energy as she runs, creating a lively and playful atmosphere."}, {"question_id": 321, "height": 640, "width": 424, "image": "000000271402.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [129.64, 95.58, 282.35, 469.94], "segmentation": {"size": [640, 424], "counts": "cXd21a_11nSO8b\\OMb3MWMNo=c0gE]OW:k0[43M5Kb0^O8H4K5L3M3M2N3N1N2bA]M\\;e2cD[M];g2aDYM^;i2aDUMa;l2i21N2O1N2N101o_OcM]>]2^AVNT>k1gA]NU>g1dA_NY>f1^A_Na>b3N3L3N1O10O01O1O0001O0001O000001O0O`B\\Jf<d5ZC^Je<a5ZCbJd<^5\\CcJc<]5]CeJb<Z5^CgJa<Y5_CiJ_<V5bClJ]<S5cCnJ\\<R5dCPKZ<P5fCQKZ<m4gCRKZ<m4gCjJZOKQ=Y5eCmJYO4h<n4PDdKm;[4SDgKl;W4UDnJXOo0m5QONQ2SJe0j0ZMXO_1S1]Nl28l1l1SJg0i0YMYO\\2OhMn32o1g1SJj0h0XMXOn2k3\\MS2c1RJk0h0YMWOn2j3]MU2_1TJm0e0a0Q3TMX2Z1TJQ1c0a0P3VMZ2V1SJT1b0SM[OV3e3_M[2S1SJV1a0RM\\OV3c3aM_2o0RJW1?TM^OU3`3cMa22kIVO0?8^2;VMAV3Z3`Mi2AcJICk24WMDe0Nh1l2YN]3WOaJ1@l22XMEb02o1_2UNk4WOlHn2OWMH?6T2S2TNT5TOlHg4OWNh1oMR5mNRI1;k4NZN\\1oMX5kNSI0;m42YNS1PNg5jNTIm43\\Nm0nMl5iNTIl44aNf0lMg6b3dHeNa0jMk6a3XHTK0d3f0jMR7]3YHUK8]38TNW7Z3WHWK;_3OSN_7W3VHWK3NOb33TNe7U3VHWK200d3NPNk7U3THWK401d3GRNP8U3RHTK716\\5a7_O`HWK4T5]7IZHSK;S5\\7MUHPKd0m4[72SHmJH0M0i0j4`78SHnJE1N0W1[4T7j0SHkJCOZ1W4Q7P1jIjNV6X1iIfNY6Y1bGlJ8MY1n3o6Y1_GmJ7NS1NiNm3b8X1[GQK6KLNS12nNj3d8d1_GaJK1S11nNd0NW2m8d2[G_Jm0k0mNn1R9f2\\HoJ`NN5U2Q9lNlF`2]1VLbN225:o1j8X3VHcJcNO587n1k8Y3UHhJjN17k1l8\\3^G^JJ;D29f1m8^3YGdJ^OLNO45L059KF2Q2[9\\3UGfJ^OO2OO04LLi2]9h2RGeJ@N30OO3S1L<_9o3oFeJBL32OO17L=4i0]9Q4nFcJDL32OO00M2Oc04]OLT1a9[4nF_JNNI10N8f078R9b4hFaJW13dN19h0V9c4eFaJX13cN2FO>g0_9b4aFcJf00RO1O4KN32M0>e0b9a4oFeJ[OOK211N3LN32M1b0=a9i4`FfJ@22NO012M10M4;>1a9n4]FgJ@20O1N14M01K8;;J[OKX:Z5YFgJB30N1N14L11L9;9G]OKY:\\5WFdJE5MO2M14L0O11N1:c0Cj9Z5YFhJ\\O01M04M1O02M0<U;n4iEeJ]O3D11M=7k:Q5WFkJ`N1]<T5REkJbN00Ml00U:W5\\FmJcNO0M20:OB3T;T5[FmJcN00M20:OB4T;S5[FmJaN13K11?3b:S5gEhJ[O2K2M2=M93^:Q5\\FlJaN34J11a08\\:m4SFjJkN2N0450K2Oa05YONT;P5SFlJoN2O30Ml03oNOV;P5oEmJPO2O21MT11n9Q5mEnJPO2O11Oa<l0\\CP3S1RLQO1O11Nb<j0]CT3P1RLRO0O01Oo00mN1N0X;f0oDW3m0SLRO0N13Mm02nN0N1Z;`0REY3i0ULQO1M3Y1MkN0U;=RE]3h0TLPO2MON0[13[:6lD`3e2YLjLMO3OO_;OYEh3`2YLjL5NK]<d3lF[LiL;\\<X3RF_LiMM6;Q<W3aD_LD0KOA56MON2:Y<V3eD`L50mN279T<S3bDcL;OcN2;:V<Q3bDcL:0cN3;8X<P3`DeL:0cN4<5X<P3gEhLiM0M3<LA4h<S3PGlLQ9S3oFmLR9Q3lDQM4OR;n2iDUM4MT;l2jDVMLK_N3l<l2kDSM01W;k2gFUM[9j2dFUM_9l2RETMiN0]<l2hDTMjN1`<j2b3000O001O10O103L1O1O2N2N1O001O001N2O00001OO10001N10[Nd^Of0[a0XOj^Oe0Va0ZOl^Oe0Ta0YOo^Og0o`0XOT_Oh0k`0VOX_Oi0h`0UO[_Oj0e`0SO__Om0``0ROa_On0_`0POd_Oo0\\`0oNf_OQ1Z`0mNh_OS1X`0kNj_OV1U`0hNl_OY1T`0dNo_O\\1\\a0O000001O000O10001O01O0012M5KO1O3N1O03NO101N1007I2M02O01N01O0003OOO1O10001N1O4L2O0O020OOO2NkMX^OT2fa0lM[^OT2ha010lM[^Ol1da0UN[^Ol1da08109F1UNn]Of1Rb0YNQ^Oe1Vb0O1N103MH7104L3L2O1M3iN\\]OO000g0fb0WO\\]O1N10f0nb061O2M204C?I3KYo6"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, hair type, pose, gender", "answer": "The image features two young girls standing next to each other on a tennis court. Both girls are wearing tennis outfits and are holding tennis rackets. One of the girls is holding a tennis racket in her right hand, while the other girl is holding a tennis racket in her left hand. They appear to be posing for a picture, possibly after a tennis practice or match."}, {"question_id": 322, "height": 640, "width": 416, "image": "000000276018.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [109.0, 126.6, 110.19, 146.77], "segmentation": {"size": [640, 416], "counts": "bj[26d0N^ONkb05g]OL@Nhb06V]OK>1bb00f]OOjn4OiPK1Vc01g\\O3Wc0Mg\\O6Wc0Kg\\O9Tc0Jk\\O7Sc0=O0O1O1O1O001O0W]OROab0n080T]OSO80Pb0m0i]OSO8Oma0o0l]ORO81ba0OT^Oo02QO81aa01R^On06oN84]a0S1[^OjN84[a0Q1Y^OjN11;3[a0S1X^OkN00=2Za08Y^O<2XO01;2[a03W^OM3d0f0ZOQa06W^OJ6c0\\a0_Ob^O78MDJ8a0Va0<h^OYO6KC91EYa0T1l^ORO<5i`0m0g^OPO0I=7j`0_1i^OZN`04f`0c1j^OYN?5e`0e1k^OVN6O07MJj`0k1S_OUN`05b`0h1n^OSNa01b`0n1m^OQNia0o1W^OQNga0Q230j^OTNY`0l1f_OWN^OG<1i?Q2^@WN]OH:1k?Q2o_OmM6:EGf`0R2^_ORN35IGe`0R2a_OQN1:IF^`0o1j_OnMIO2g0Y`0\\1Q@oMDf0[`0[1Q@oMCh0Z`0Z1S@nMCi0Y`0Y1S@oMDh0Y`0Y1R@PNGe0V`0\\1S@oMGe0V`0^1X@dNh?]1V@cNk?\\1V@dNj?Z1X@kM_Og0Z`0^1W@kM_Og0Z`0_1Z@_Ng?a1[@]Ne?c1[@\\Nf?d1Z@[Ng?e1X@[Ni?e1e_OjM<a0o?e1W@[Ni?g1W@VNk?j1X@RNh?n1Y@iMWO3a`0T2\\@lMd?S2^@kMd?T2T1N3N1O1N2M4J6N2N2N3N1OX^OcNn`0[1`_OfNS`0Y1[1L5I7G;I_Wl3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "face expression, maturity", "answer": "The image features a group of children, with one girl holding a white teddy bear in her arms. She is wearing a pink jacket and appears to be smiling. The other children are also smiling, and they are all standing together, possibly posing for a picture. The scene suggests a happy and joyful atmosphere among the group of young children."}, {"question_id": 323, "height": 426, "width": 640, "image": "000000278973.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [81.37, 101.47, 195.29, 192.42], "segmentation": {"size": [426, 640], "counts": "V`V11V=4OO10Z=OgB0of3:dXL9H6J5L4J6SDjN42j:^1XEdNGJ0Oe:c1fEmNX:V1hEiNU:[1bEUN0c0\\:W2N00001O2N2N3L3N2N2N3M3L4M3N0O1N2O1O`MdFU1Z9lNeFT1[9kNeFW1[9\\1OO1O101_MdFS1\\9mNeFS1Z9nNfFS1X9mNhFU1V9lNkFV1Q9jNPGX1m8iNSGW1l8iNTGW1m8hNPGfNOb2P9d100O1OSMSG^1n8bNRG^1n8_1O100O100O01000O10O100000O100000O10000000000O100000O100D<N2O1N2N2O2N1O0O2O1N2M2N3N2O0O2O010O1O1O1O100OSO`HRL`7m3aHSL^7m3cHSL]7l3eHSL[7m3gHQLY7o3hHoKY7P4lHlKT7T4nHjKR7U4RIgKn6Z4RIfKn6Y4SIgKm6Y4SIfKn6Y4RIhKn6W4SIhKo6V4TIhKl6W4UIiKk6V4WIiKi6V4XIjKi6T4ZIiKg6V4W1O2N2N1O2N2M3O1K5M3N4HiGnLa6P3\\IUMf6d2lGQMY1`0k6]2nGSMR1e0Q7U2nGWMl0i0V72mGh02^Nh0k0Z7LnGj01_Ne0n0]7FnGm00^N>W1f7[OmGo0K^N`0a1i7nNoGQ1J^N020h1U9GQGcNGg1X9FiFbNNS2Y9i101O01_OkFkLU9T3mFkLT9R3oFmLQ9P3SGoLn8n2UGRMj8m2XGRMi8i2\\GVMe8f2^GZMb8c2bG\\M_8_2fGaM[8\\2gGcMZ8[2hGeMX8X2kGgMW8V2kGiMW8S2d1K<C6J6K8F9A>Dhdg4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:horizontal/lying"], "control_dims": "hair type, pose, gender", "answer": "The image features a man wearing a wetsuit, riding a surfboard on a wave in the ocean. He is skillfully navigating the waves, showcasing his surfing abilities. The man appears to be enjoying the thrill of the sport, as he skillfully maneuvers his surfboard through the water."}, {"question_id": 324, "height": 640, "width": 419, "image": "000000281754.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [50.34, 20.13, 184.09, 585.07], "segmentation": {"size": [640, 419], "counts": "Zfm04cc0;N08GUX1KYU1g0ZoLABH76Ua0l0P_OXOMMm`0Q1[_OlNLLh`0]1]_OeNc06m>Z1_@aN:NTO=e=G[Db1aN]N7b0j<JRC[2MYMINOd0X=]3PCRLGO0b0S=c3UCmKHN0a0o<i3YChKHM1c0g<n3`CbKHM1c0c<Q4eC_KGMIN46NOg<e4hCZKF4MMn<h4_CWKF8IIP=i4bCVKEb0f<[4dCTKFa0d<\\4hCRKE`0b<_4jCPKILF8h<l4jCPK3OS<R5kCmJG1h<T5oCRKo;n4_CiJI=g<g4aChKb<V4^ClKa<U4\\CSL_<m3^CYL_<i3^CZL`<g3]C\\Lb<f2YCaL3l0a<^2eCeLFS1a<V2jCiNU<U1iCSOR<n0iCYOT<i0kCYOQ<n0iCWOR<`4H7H9iFQHQ6V8fIYHo5m7hIbH@mNc4i8fKgHYOjNf4g8kKhHWOgNEZOa4_9]LiHUOROY4Z8\\LoJV3X5dLPKT3V5dLSKT3U5dLPKX3o:L5K4L4K4M4L4L3M3M3N3L3N1O2N2N1O2N2N100O1O1OjLYNUDg1e;dNVD[1h;jNVDV1g;WOoCh0n;^OoCc0m;JhA]Nm1i1W<=^CD`<c0ZC^Ob<k0XCVOd<Q1XCoNf<X1SCkNj<_1lBdNQ=h1_B_N]=T4I7I7E;M3M3M3dLbHRJb7c5PIRJT7g5UIUJn6S3VHfLT1RN^Oj0\\7^4RHdL]1cMHn0n6j4mGaLn2ZNZ5^7[IPH]N2S:j7cG`HV8[7nGnHk7o6WH[I_7b6cHUJg6h5\\IaJV3\\N`MQ7]OdJn2_NcMP6^MmI^2C`MU2d4`NPNj5c0hKV1iNQN^5i0oKl0hNZNY5f0bImLb2j3hNdNR5i0\\LlLkMc2m0Gk4k0\\M_NcNe0P4n0aMSNfNn0h3n0fMoMdNS1d3P1lMfMdNZ1Y3V1WN\\MZNRObM_2j5Q1SJaL]4h0lMZOhMc2k5j0UJ`Lb4e0dMY2c3b0WJ`Lk40gMP3T3a0m1A`HoLZ5`3V2cL\\Hj22SM[5a3dJ^Lg70[Hi2NXM\\5a3dJ^Lm7n2]Md0fJ^Lm7P3[Mb0hJ^Lg70[HR3T5`0i2AVM`0_2]LdHS3h4d0[2[LjHN3U3c4d0a2ZLPIW3]4?c2ZLoHY3[4?h2ULkHa3JcLS4j3d33SL0n33jK2T43gKOW44cK1Z43\\K6_41UK8k4KhJ`0U5EdJaLPNdN8Y3m6l1eJYLmNd1n5d2TKgKTO`1X5Z3bKnIYNm00jN20e0o2d4VMSK]6V1PK^OZ1P4hMPKX6^1fJCY1i3Q5bL\\IhNhNR1h2`3Z5aLoHi0a1]2j5cLcHY1]OeME31Oc1V4m6iL\\H^1_OcME1d1m3T7oLTHg1YO\\MK1e1c1lNEa8@kGm1XOXML3e1Y1XOGZ8BiGU2XOYM^1l0JCT8O]G[2XOTMa1c0]:^OhC1X1k2RORMm?0n_Oo2T`0VMh_OX34cL^?\\4J6K5I5N101O0O`NQAQNo>h1dAlM\\>Q2jAkMX>Q2RBhMn=X1RAUNM=\\1Lk=j0oARO;K`NK]?j0j3ERTi3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type", "answer": "The image features a woman sitting on a ledge or a wall, holding an umbrella. She is accompanied by a young child, who is standing next to her. The woman appears to be smiling, and the child is looking at her. The scene suggests a warm and friendly atmosphere, with the woman possibly providing shade or protection from the sun for the child."}, {"question_id": 325, "height": 375, "width": 500, "image": "000000292456.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [184.55, 45.56, 227.85, 305.24], "segmentation": {"size": [375, 500], "counts": "oe\\24b;2M9I1N100N2O010O1O100O01O010OO101O1O00010O001N101N100O11ON3N1O1M300O2M101010O01[HnN]MKK0Q7X1gKlNd4V1jJkNQN1U7V1eJlNSN17Gc6^1nJmNTNE19Z7X1]JPOWNI\\7X1ZJQO\\NANNd6OQJd1m0oN`ND_63lI\\1R1oNcNB\\6;jIW1l0BmNfNQ6f0UJX1;N]5mNWJa3KhKd5O_Jj01_3OdK`57]Jg03`3e5jL[JU3f5kLYJU3g5lLYJg20XLf5d1WJd1W6n10O10O2O0000^LkIa1U6`NlIVNN20O1K2b2S6\\OkIjN0k1U6[OjIa1V6_NjIc1T6]NlIc1T6]NlId1S6\\NnIb1S6^NnI^NNJ5\\2Q6\\OlI]N<U2j5^OiI_NOJ4Y2T6:iIGV68iIMU6WOkId1U6\\NlIiNOR2U6UOmIhNNR2W6YNlIG3b2S6dMmII1b2T6aMnILMd2V6\\MPJ0F[O0Y3]6VMQJg3R6QLSJn3k6O1_L_Hl2b7SM`Hk2`7UM`Hk2a7TM^Hm2b7SM]Hn2c7RM]Hn2d7QM\\Ho2d7QM\\Ho2e7a0002N1O00000000OTN]HFc77nH[OR7c0QI\\Oo6c0SI\\On6c0\\IWNmNh0g7Q1eIVNdNa0g7Y1iIfNW6Z1jIeNV6[1S20eHVNX41gIh1f1ZNQNM_65iId1`1YNUN2h62dIb1f1`N^4NWJLYOX1R2oN\\4NQJJC11U1n1SO\\4OQJHD03U1m1SOZ4MeIJn0V1S1UOW4GlI0f0W1W1SOU4IfIM03l0U1Y1SOT4HgI2Q1IPOT1T2YOT4GhI2W1k0m0]OS4FiI2X1k0k0]OT4FiI2Z1i0i0@S4NTKb0i0@S4NVK`0g0BS4NkIDW1k0k0CS43RK;j0CS4GmIIM4Y1i0i0DT4FPJL7N<l0X1FU4CPJM7O:l0Z1EU4BRJM40;m0[1DT4AQJO40`0h0U1KU4_OQJNOML55Ka0h0ZO[Oi1e0Z4\\OQJ1L3Q11@GX1j0Z4OXJWO98j1c0f3BkIGe00\\ON92V2h0e3_OfJOBFR2o0o4YO`Kj0_4UOiHIO2W2R1S5UOhHIU2T1R5SOiHHJ1V2`1n4eNQIJJ2l1M]Nd1l6bNoHLM3g1LbNc1l6hNlHIS2e1l4_NSIGM2T2j1k4\\NSIIM3S2j1l4eNTK]1n4UNRIMT2n1k4SNQIN11k01NNUOj1Q7\\NQINh05JF]Ok1R7[NmH1j03\\OF8k1f6gNdIH]OH9h1BZNm65RIOn0JXO19o1@QNk64WI1l0J[OO6R2BRNh62XI2l0I4j1QOZNj6NWI3i0K5j1TOYNf6O[I2c0K9k1WOWNb6OXIOM5j0J8k1XO[Nb66mIF92oN`18eN`65bICM2R1a1hN\\N2;d63bIGJN0N728a1^O^N2;e60cIFI00M935`1@_N1=d6MdIFJ1?OO`1_OaN0=f6KbIGL0[1Z1bNeN0a03^ON1U6:oIHMO\\1Z1bNeN0j0OYOW66oIILO^1Y1bNeNOm0MXOY65oIJIO4MV13gNQ10oN0n0NPOZ68nI2JHb023U1ZOLZ6ROmI2IJ`0LB3e0`2b5eMoI1IJ=OE0g0^2_5hMQJOGL>NE0f00UOS20SNZ61RJMIKf10fN;@F0k06VOR67UJJGMe12jN5\\OK2i05VOS68UJJENc026OI7\\Ob05VOS67VKNdNJd1Q1_NPOT66mJKkN41Ld1n0_NROS63dKLMm0[NTOT62cLLSNl0UOWO]:P12NmNoNcGm0^8UObGi0k9JlM^OWI7T7GnH6\\9K34L8IN2NRNFaH;^7I^H7e7GZH9c9OO1\\NElG;h901LeNK[G0i81hoo0"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "face expression, pose, gender, maturity", "answer": "The image features a man and a woman sitting on a blue scooter, with the woman sitting behind the man. They are both dressed in business attire, with the man wearing a suit and tie. The woman is holding a handbag, and the man has a briefcase. They appear to be posing for a picture, possibly in a store window. The scene is set in a city environment, with a potted plant visible in the background."}, {"question_id": 326, "height": 427, "width": 640, "image": "000000309964.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [340.83, 95.42, 183.82, 326.47], "segmentation": {"size": [427, 640], "counts": "ZV_4`1k1mNe7W1THPOi7T1kGWOR8l0[GGc8e0nF@P9_2N2N2N2N101N1O2N2O5J6K3L4M3Le0\\O6I9H3L3N2M3N2N2N3cITIU6S7SOoH\\KR7b4QI\\KP7c4RIZKo6d4UIYKm6]4^IaKb6Y4fIdK[6HoHV4j0oKe6o3_InKb6o3_1N2N2N5K2N2N2O2N2M4L3N1O1O001N101O001O001O01O0001OYLUMnLl2Q3VMmLj2S3YMjLh2V3YMhLg2X3_McLa2\\3fM\\L[2d3gMZLZ2e3iMXLX2g3SN]JmN?Q3S5[NUJfNf0P3T5_NQJcNi0o26iLa3j1WKbNQ1m2NoLi3W2WLn0JmLo3V2VLQ1FiLU4W2TLU1ROZL9;a4W2SLY1[OcLa4V2RLW1[OeLc4V2PLV1[OeLe4V2oKV1YOgLg4T2oKP2Q4PNoKP2Q4RNlKo1T4RNkKn1U4TNiKm1V4UNhKk1X4VNgKj1Y4WNeKj1[4WNdKj1Z4YNcKh1]4YNbKh1]4YNbKg1^4[N_Kg1`4\\N\\Kf1b4b3SMdGk0]8TOcGk0_8TOaGl0`8SO`Gl0b8TO\\Gm0e8SOZGl0h8TOWGl0k8SOSGm0o8SOPGm0R9e11N2N3N2M2O1N3N2N2N2M2O2N1N3N1N2N2UOmE[NV:b1kETNMMY:n1jEUNNK[:Q2dETN1K\\:f21N2O2N1N2O1O2O000O23L3OM3N4K100O0000O8I1N1001O000O2N1002OO01O0001O001O1O1O1O102M103L5K4L6J4L5J7Ia0SOhha1"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose, hair type", "answer": "The image features a man sitting on the grass, wearing a camouflage shirt and sunglasses. He is smiling and appears to be enjoying his time outdoors. The man is sitting next to a green bucket, which is filled with golf balls. There are several golf balls scattered around the bucket, indicating that he might be playing a game of golf or practicing his swing.\n\nIn the background, there is a tent set up, suggesting that the man is in a recreational area or a park. Additionally, there are two bottles placed nearby, possibly containing water or other beverages for the man to stay hydrated during his outdoor activities."}, {"question_id": 327, "height": 640, "width": 427, "image": "000000343803.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [19.15, 135.18, 314.89, 474.1], "segmentation": {"size": [640, 427], "counts": "ZR=3kc03O0O101O001O000QGHVN9g1KWN5g1OWN1h12UN0i12oM5Q2KlM8T2BaEMW8f0Y2ZObEOR8j0\\2VOcE0o7l0]2UOdEOl7o0`2SOfMn0Z2TOcMm0\\2TObMn0^2POcMQ1]2nNbMT1]2lNcMU1\\2lNbMV1]2jNcMW1\\2jNbMX1]2iNaMX1`2gN^M\\1a2eNPMj1n2WNmLo1R3RNjLR2U3nMjLT2U3mMhLU2X3lMfLV2Y3lMbLX2]3jM^LZ2b3hMWL]2i3dMSL^2m3cMPL`2P4`MmKc2R4^MkKe2S4]MiKg2W4XMhKj2W4VMhKl2X4QMiKP3W4PMiKQ3V4nLjKT3V4jLjKX3U4gLjK\\3U4aLmKa3R4`LlKb3R4_LmKc3R4]LmKd3R4]LmKe3R4\\LmKe3R4[LmKg3R4YLnKh3Q4YLmKi3R4XLlKj3T4VLjKf2mJdMW9GlKc2TKbMo8LkKc2YK^Ml8NkKe2]KZMh8NmKh2bKTM`84nKh2eKRM\\86oKh2gKPM[87nKh2jKoLX8:mKg2mKmLV8=lKf2b5ZMZJi2f5XMVJk2j5UMPJQ3P6PMmIQ3U6nLeIX3[6iL`I[3`6eLSHJlMc3R:cLcG]OgMm01Z3e:\\LVGb5k8^JRGe5o8ZJPGf5R9ZJmFf5S9[JkFe5V9[JjFe5V9[JhFf5Z9YJeFg5\\9ZJbFd5b9[JVFk5l9UJTFg5Q:YJnEb5W:_JhEa5X:`JgEX5b:hJ]EU5f:kJZER5i:nJWEo4m:PKSEn4o:SKoDm4S;RKkDn4W;RKiDm4Y;SKfDl4[;UKdDk4];UKbDl4];TKbDm4^;TKaDk4`;UK_Dl4b;SK^Dm4c;RK\\Do4d;RK[Dm4g;SKXDm4h;SKXDm4h;TKWDk4k;UKTDj4m;WKRDj4m;VKSDi4o;WKPDh4R<WKnCh4T<XKkCh4U<XKjCh4X<XKgCg4Z<[KdCe4]<[KaCe4`<\\K_Cd4b<[K]Cf4d<ZK[Cf4e<[KZCd4g<]KWCc4k<\\KTCe4m<[KRCe4o<[KPCd4Q=]KmBd4T=\\KkBc4V=]KjBb4X=^KgBc4X=^KfBb4\\=^KbBb4`=^K_Bb4a=_K^Ba4c=hM]BMe=3\\BLd=4\\BLd=4]BnLNh2e=;`BG^=<`BD`=_3N2N2O1N2O1N2O1O2M101O1N2O1O1N2O1N2N2O1N2O1O1N2O1O1N2N2O2NaLgCWOX<i0kCVOT<i0oCWOn;i0UDVOj;i0XDWOg;g0\\DYOc;f0`DYO_;e0dD[OZ;c0jD]OU;b0nD]OQ;b0RE]Om:b0UE^Oj:a0YE^Oe:b0]E_Oa:`0aE_O_:`0cE@\\:`0eE@Y:?kE@T:?nEAP:?QFBn9>TFAk9>WFAi9=ZFCd9=^FCa9<aFD^9;cFF\\99fFGY98hFHX97jFIT97mFJR95PGJP95RGKm84TGNj81WG4d8L]G7^8IdG;W8EkG?o7@THc0g7\\O]Hf0^7YOgHh0T7XOnHk0m6TOVIn0f6QO^IP1^6oNeIS1W6lNlIW1o5hNSJ[1i5dNYJ^1d5bN_J^1^5aNdJa1Y5_NiJc1S5\\NPKf1l4YNVKi1eM[Ka5k2lLn1]MZKe5g2QMZ2mLPKQ6e2TMe2`LfJ\\6d2WMQ3PL[Ji6d2XM[3g2cL\\M\\3d2cL_M[3a2eL`MZ3V2SJdIb2X4Z3l1XMUNg2e1]M^Nb2\\1bMgN]2W1eMkNY2o0lMSOS2l0nMVOP2h0QNYOo1e0RN]Om1b0UN^Oj1b0VN_Oi1`0ZN@d1?`N@^1?dNBZ1>gNBX1=jNFR1:nNIo06RO5c0K]O<<CEf02ZOMR1HmN<W1]OiNe0\\1TOcNQ1]1kNbNZ1`1`N`Ne1b1TN^No1d1kM]NZ2dKmJo4e2\\Oc2^KmJW5]2[Oj2ZKjJ]5Y2YOY3oJ^Jj5V2WO`3kJZJR6R2SOo3P1nKPOR4Q1mKoNS4T1jKlNV4W1gKiNY4Z1dKfN[4^1bKbN^4`1`K`N`4b1^K^Na4e1\\K\\Nd4f1ZKZNe4i1YKWNf4n1VKRNh4R2VKnM\\1QK>T7TNlM]1WK7V7TNcMf1\\KOT7YNaMg1aKIP7_N_Mh1iK@k6fN]Mi1oKjMgNQ1n7[O\\Mi1VLbMhNT1i7_OZMi1hLcNP6CYMi1kL^Nn5IWMh1oL[Nl5LVMd1VMZNf52UMa1^MTN`5:SM_1W6`NkI^1V6bNjI]1X6bNiI\\1Y6cNgI[1[6eNfIY1[6gNeIY1[6gNfIX1Z6hNfIW1\\6gNfIX1Z6hNgIe0YJmN28Q<5dIe0eJmNj;>bIa0o6_OQI?R7@oH=T7AoH;S7EnH9T7FmH9S7GnH8S7GoH6R7IRI1R7MQIKV74]6L\\Uj1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression, pose, hair type, gender", "answer": "The image features a young man standing in a park, holding a frisbee in his hand. He appears to be preparing to throw the frisbee, possibly engaging in a game of frisbee with friends or family. The man is wearing a black shirt and blue jeans, which adds to the casual and relaxed atmosphere of the scene. The park setting provides an open space for the man to enjoy his frisbee activity."}, {"question_id": 328, "height": 425, "width": 640, "image": "000000356505.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [222.64, 85.72, 175.98, 269.79], "segmentation": {"size": [425, 640], "counts": "gPn28P=3L3N100O2N010O01O001O00100O10O01O10O0O100O2OO1O1000O101N100O2O0O2O0000001O0O100O1N3M2N2L4L3F<L2O2O1O01O1O1O2O0N3N1O1NoNXOgEf0X:^OfE?]:BcE;`:F^E7d:NXE2h:0VE1i:0VE0j:2TEOl:W1XHmMX4V2dKPNY4P2gHeMh2?_4m1iHcMg2d0]4j1eKZNY4g1dK]NZ4g1`K]N]4e1RI[M[2U1`4c1^KbN_4^1_KgN^4Y1aKiN]4Y1_KlN_4T1_KPO_4P1`KSO^4m0`KVO_4j0_KZO_4f0kIWM\\1V2g4c0kI[MZ1V2i4?lI]MX1W2l4;lI_MV1Y2l48lIbMU1Z2m44nIcMR1^2n4OoIcMQ1T1SOIj5o1QKWNXOI5hNT56`Jk2l0^N_OG0mNT5U3\\KWNCEMoNT5W3XKUNKCIQOT5X3VKSN1BESOU5W3SKUN7]OYOUO23\\5V3oJVN>YORO[O50^5W3iJUNg0\\OPOZOa5W3bJTNS1WOhN@c5?\\Jo10mN_1\\OV4D^JT2MiNc1gN]N<m5GWJ]2MgNi1bNXN416m5KVJQ4i1nKTN6Z6k3]KlKXN407[6T1cIQ1k1`MUN626Z6e3fKQLRN9Y6d3oK\\LQ4c3QL\\LP4R1bIQ1a2jMo3P1`IjN0[2e2gMm3e3l2O3M1O2O2M1VO\\FnMh9n1YFQNi9m1YFPNj9m1XFSN>E^8V2VGSN6Oe8j1XGUNN8j8a1ZGVNH>o8X1\\G\\Oe8`0]GAd8=[GEh87WGLQ9InF:]9ZOVFSO0i1j9QOWFWOMj1k9nNYF[1g9dNZF]1d9cN[F_1e9`NZFb1f9\\NZFg1e9XNZFk1d9VNZFm1e9m0O1O2NjL]Ff2b9XM_Fj2X1mLh6X2VHhNo0QOm6Q2ZHnNf0ROQ7m1\\HQOb0ROS7i1_HVO;ROW7MjGb1h0_O4SO_7]1`HANROc7Z1dHDFSOg7U1gHK]OQOm7Q1jHOUOQOQ8m0nH7iNnN[8f0RIl0P7QOTIm0n6oNWIn0l6kNZIS1j6fN]IV1_9K5L5K3M4K5L3L3N4L2M3N1O2M2O2MSfS3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, gender, hair type", "answer": "The image features a woman in a bikini, skillfully riding a wave on a surfboard. She is positioned in the center of the scene, with her surfboard beneath her. The woman appears to be enjoying her time in the ocean, showcasing her surfing abilities."}, {"question_id": 329, "height": 375, "width": 500, "image": "000000357978.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [97.21, 107.67, 61.99, 178.63], "segmentation": {"size": [375, 500], "counts": "VUT15_;3N3L3`MDjHW1S7nNhHU1T7UOcHn0X7YO[HR1Y7l1C<I8L4N2NZOSIeLl6Y3YIfLf6V3`IiL^6U3gIjLX6S3mIlLS6R3PJlLP6T3QJlLn5U3RJkLn5U3SJjLl5W3TJhL`5KgIa3g0dL[5P4dJnK\\5S4dJlK]5T4R12O001O6J3M3M3\\I]Kn5g4gI`KY6Z2gIZM1^2Y6ZNiId3W6[LkId3U6[LmId3S6[LQJc3o5\\LUJ`3k5_LZJ]3g5bLoJ\\1jNVOZ6[O_KJTN;R1L]5JdKEXN8Q17Z5AgM>j6O1O001O1O0000000O100O2N2MS[m3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, hair type, face expression, pose, gender", "answer": "The image features a man wearing a white shirt and camouflage shorts, walking down a red carpet. He appears to be looking at something in the distance, possibly observing a display or an event. The man is also wearing sandals, which adds to his casual and relaxed demeanor.\n\nThe scene takes place in a room with several chairs placed around the area. Some chairs are located near the man, while others are positioned further away. The overall atmosphere suggests a social gathering or an event where people are mingling and enjoying themselves."}, {"question_id": 330, "height": 640, "width": 483, "image": "000000358195.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [202.79, 106.43, 138.06, 438.65], "segmentation": {"size": [640, 483], "counts": "imR4e0Qc0>mKnNjD\\1h:TOjDV1c:]OSEl0h:ZOPEm0l:XOkDP1R;SOeDU1Y;XOcBdNf0@\\Ol2X=KlBh0R=U3N1N3L3M3O1NYOZCQJLIi<T6k0N2M34L3M3M2N2N2O1nH_Ib0b6lKgJZOlNh4^6[KjKYOkMZ5\\6aJoLIhLe5Z6TJbMOULm5Z6fIQN9fKP6[6^I^N:XKX6k;cIWD]6k;`IVD`6k;_IUDa6l;\\IVDd6c<00O100000O100000000000000O100O2N1O1F[IWCh6h<9N10001O1O1O0O2O1N2N3M2N3N2L3]MgH\\H[7b7oHTHT7l7PImGS7S8UI`Go6a8YISGk6m8[IiFh6X9Q26JjGfEQ7m9g1KcFXFg8`9WGbFP9X9nFhFW9b0RFm7e0bG[9;UFS8=cGa96SF\\84bGk9MTFT9n9hFTFX9[:0O10O010O01O00001O001O1O1O001O1O2N2N1O1N3N2N2M3YL_FkLd9]2oE_JR1P3S9X1iEmK2MP2k2Y8X1YHcNW8m0mGnNV8P1nGkNY8m0SHnLWMl0P;o1fHoM^7m1eHQN_7k1cHSN`7j1bHSNd7g1bHTNc7g1gHnM`7l1cHPNe7h1a5H>ROb]O\\O_mj2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, maturity, face expression, pose", "answer": "The image features a young girl wearing a pink shirt and striped pajamas, standing on a skateboard. She appears to be enjoying her time outdoors, possibly in a park or a similar setting. The girl is the main focus of the scene, and her skateboard is positioned under her feet, ready for her to ride."}, {"question_id": 331, "height": 640, "width": 425, "image": "000000369037.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [133.75, 230.11, 291.25, 409.89], "segmentation": {"size": [640, 425], "counts": "c`c22>5jb0Lo\\OOM7Sc0Jo\\O0N5Tc0Ko\\OOM5Uc0Lo\\ONL6Tc0LU]O4GMmb01V]ONJ<Pc0HR]O=ob0:000Ao\\OD17ob05Q]OB2:kb05W]OKjb04U]ONjb05S]OLlb0e0O01O0001O01O1O1N2O00101N010O00001N100000101N1O1O100O000010O0010O01O0000010O0000010O001O001O0001O0001O010O00000jAYOS9h0kFZOVK2OO[=e0iGJS85lGNR82lGYOlJd0X=3lGZOkJc0Y=3PHLo76QHWOmJ:R=?ZH^Oh7b0XH^Oh7c0WH\\Oi7e0WH[Oi7e0XHZOg7g0YHYOg7h0XHXOg7i0YHWOg7i0YHWOg7i0YHWOg7j0XHVOg7k0YHUOg7j0ZHVOf7j0ZHUOg7k0[HQOg7o0e5O01cBQOi7o0WHROh7m0gBRO_52h7Q1WHPOh7R1VHPOh7P1WHQOh7P1YHkNeJOR=V1YHjNk7W1^51N20OjBgNf7Y1[HgNd7Z1\\HgNcJ0j<Z1cHfNbJ1j<Z1dHeNbJ1i<Z1fHeNaJ0g<]1iHbN[7_1b5001O0VC`N_J1a<_1QIeNo6Z1RIgNl6Z1TIfNk6X1XIhNf6Y1[IbNWJ2Y<_1fI_NY6b1Q62N1O1J6O1iCRN[6P2fIQNW6P2jIPNT6R2l5001O000O00101O1O001OO1000O2O00M3O100010O2N3N8G7bDWMY5m2bJUM]5S3ZJoLd5Y3jEhLTOKo36R7c3ZEfL[2E_ML20N3N2o:c4UGYKjM00j0O\\O2No:d4VGXKjMO3h0O\\O1Om:f4RGWK^N1C3j;d4VFYKfN0U;d4XF\\KcNO22TO3f:`4bG\\KXNOe0<`9W4cGaKmMM10m0<a9T4fGPLhMBo0<V7CoI\\4iNgKSOM6NL19i0b0Fk63WJi3ROeKRO01d0N30ZO1001M>e77VJc3AfKgNg0ONKn0d7YOWJ]3_OQMfNR1b7dNVJV3AHX6TMVJQ3@0X6RMVJh2]NSLR1X4Z6nLWJe2D?T6nLeHgN^1j3DWLmN]4[7ZMiIR2Nj0Y6UMgIo12m0V6WMfIi16Q1T6ZMaIc18Y1V6XM_I^12_LYOn4V7XM[IW16m1_6RLfH^Oa0a28T2`6mKhH@>]2:X2`6kKhHB:\\28eL_Oe5W7hKhHC9W2;d2c6dKhHC7U2>e2c6cKhHE4S2a0f2c6bKhHF2S2b0f2d64YIOf61XI2h6JYI9g6A\\Ib0c6YOjH_Jb0[6c6VO`Il0`6SO]IQ1b6oN\\IT1d6iN]IY1b6dNaI]1_6bN_Ia1a6]N^If1b6ZN]Ig1c6XN\\Ij1d6TN\\In1d6mM^IV2b6iM[I[2e6cM\\I^2d6^M^Id2c6YM\\Ij2d6TMZIP3g6nLXIT3h6kLVIX3k6fLTIn21cHl6[4SIU3[7iLeHX3]7fL`H_3_7`LaHc3^7[LbHg3]7XLbHm3[7PLfHU4X7fKcHTL2\\8X7_KiHg4V7XKiHi4W7UKiHm4W7QKjHP5W7oJhHR5Y7mJdHV5]7f31O1ZEjH^OGh7a7eHoH_O@l7b7cHoHc8S7ZGoHe8T7XGlHh8V7UGlHj8W7QGmHm8h7ZF^Hd9P9O1O2N2N3M2N3M2NN2N200O1O1000000000000000000001O000eJTFb0m9WO^Fd0b9ZOdFb0]9XOoFa0Q9UObGb0_8XOlGb0T8\\OPHlMiMZ1W:g0VHkMjMX1Q:l0_HaMeM_1m9o0fHWMfMd1d9W1PJ^MbK`0_:X2kISMjKc0\\:[2_IdLQMl0a9g2VI]L\\Mi0_9S3RJlLn5W3^ESL]4e0U6`3jI^LW6i3]HdKSN?`9S4VH^K]N=_9_4hGRKmN=[9c4fGQKnN<]9b4dGWKnN4_9d4cGYKnNOb9h4`GYKQOJc9l4VGTKmM6^<d4eEWKlM5;Ii;g4RFYKkM6f<\\4eEcKb;MRBOa0S1^O^O0M`4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type", "answer": "The image features a man standing next to a large elephant. The man appears to be a tourist, as he is wearing a backpack and is positioned close to the elephant. The elephant is adorned with bells, adding to its majestic presence. The man seems to be enjoying the experience of being in close proximity to such a magnificent creature."}, {"question_id": 332, "height": 427, "width": 640, "image": "000000377723.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [488.68, 230.25, 30.18, 25.35], "segmentation": {"size": [427, 640], "counts": "Qg[61c00Q<5jCNT<5gCNY<4dCM\\<5`CM`<?001O004L2NO10000002N1O0000001O0000001O001O1O2N2N3M3L\\ia1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression", "answer": "The image features a man sitting in a car, wearing a white shirt. He is looking down, possibly at the steering wheel or the dashboard. The car appears to be a convertible, as the man is wearing a tie, which is visible in the scene. The man is also wearing glasses, adding to the overall appearance of the scene."}, {"question_id": 333, "height": 428, "width": 640, "image": "000000380913.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [256.8, 168.38, 118.3, 252.95], "segmentation": {"size": [428, 640], "counts": "^R\\38f0Lb;8WD1b;P1M2N1VFjN]7Y1]HmN`7T1_HnN`7S1^HnNa7T1^HoN_7R1_HSO]7m0eG]N0i0Y8k0fG\\N[OLa0Q1\\8g0iGZNMS1W8e0lGVNMW1P8i0RHQNF0HY1Y8R1RHfMK1IX1k0oNQ6[2ZI]M2OI[1d0UOP6[2_IVM5NH]1=ZOU6X2aIQM;h2h5YMmIo21PM50Fh2T6^MkIl2e0oL\\Og2R6g0bJaL[Oi2Q6h0dJ\\O[5f0UJ]L7l2c5h0VJ\\L6m2c5h0WJ[L6m2b5i0XJZL6m2b5i0XJZL7l2`5k0YJYL7l2_5l0jJTOT5n0mJQOR5P1mJQOR5P1nJPOP5R1PKnNo4S1QKmNn4T1RKlNm4U1SKkNl4W1SKiNl4X1TKhNk4Y1VKfNi4[1WKeNh4\\1XKdNh4\\1XKdNg4]1YKcNg4]1YKcNf4^1ZKbNf4^1ZKbNe4_1[KaNe4_1\\K`Nd4`1\\K`Nc4a1]K_Nc4a1]K_Nc4a1]K_Nc4a1]KcMF]Nn4P4\\K_MFfNm4k3]K[MIkNj4j3]KYMFROm4e3^KYM@VOR5c3\\K\\Nd4e1[K[Ne4f1ZKZNf4i1XKVNh4j1XKVNi4j1WKUNi4j1WKWNi4h1XKXNh4h1XKXNi4g1WKYNi4g1WKYNj4f1WKYNj4f1VKZNk4f1TKZNm4e1SK[Nm4f1RKZNP5e1oJ[NR5d1nJ\\NT5_N_Jf1=KW5[N^Ji1:MZ5WN^Jj1JWM:h2b5RNZJo1;Nb5jMUJX29Nh5cMoI`2IVM9h2e64QIVM02Mf2R73PI:P7EQI;o6_OoH\\M50Jo2R7EoH[M7OJP3Q7EVI\\MKo2P7DUI]MKo2Q7CTI^MJo2S7CSI]MKo2T7EoH=V7CiH9]7GaH^O\\8`0eG\\O_8c0aG[Oc8d0\\G\\Of8L[GhNO[1h8J\\GiNM[1o8CXGROG[1T9\\O[GZO^OX1c9\\N_F4n06SOd0O^OS;MPEb0LRO72S;8mDa0JUOg;7bDb0c;\\O_Da0e;[O^Dd0W<M3N4J2LPCLQ=2PCMR=2oBNR=Oje_3"}}, "object_label": "person", "attribute_label": ["face expression:sad/unhappy", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, pose, maturity", "answer": "The image features a woman sitting on a bench, talking on her cell phone. She is wearing a white shirt and black shorts, and she appears to be engaged in a conversation. The woman is sitting next to another person, who is also on the bench. The scene takes place in a public setting, possibly a train station or a waiting area."}, {"question_id": 334, "height": 435, "width": 640, "image": "000000390555.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [534.93, 117.81, 78.61, 162.12], "segmentation": {"size": [435, 640], "counts": "]PS71`=6K3M4jCEm:`0eDLX;Y1N2O1O100N5I9I4L3[OdMnEa2i9gMSF`2d9hMTFb2]9T1I<D4L1O2O00O1000000O100O101O00001N101N2O1UOcG]L_8_3iG[LZ8c0QGU2o9fMSFY2Q:cMPF[2X:]MjEc2d:N1O2N3N1N2O001O00001O5K:E:G7I4L5K3M2N013L6J>AP[`0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "maturity", "answer": "The image features a group of children posing for a picture. There are at least six children in the group, with some standing closer to the front and others further back. One of the children is wearing a tie, which adds a formal touch to the group photo. The children are all smiling, creating a happy and memorable moment."}, {"question_id": 335, "height": 427, "width": 640, "image": "000000398203.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [200.4, 17.27, 161.35, 354.08], "segmentation": {"size": [427, 640], "counts": "dXg25T=2N2O3M101O1N101O0O1O0010000WJF`N;^1HaN8\\1LbN5[1NeN2Y10gN0XM^OW1e0^10VMAY1b0_1MTMHY1=b1KSMLW1<e1JmLb0k0EX2IhLi0m0_OZ2IaLP1T1XOZ2F_LX1U1UOZ2D]L[1Q1ZO`2\\O\\L]1k0Ag2SOZL`1i0Dj2nNZLa1c0bM^NT2b4jNZLc1`00T3^NWLg1`00X3ZNULi1`01X3YNWLe1`04X3YNVLd1a05X3WNmKoNHf2P17Z3UNhKS2l0J\\3TNdKU2n0G_3d1`LYNb3j1\\LSNg3o1VLPNl3S2PLnMP4U2nKjMS4Y2hKgMY4^2`KeM_4c50[ObK]H`4_7fKYHCOi4e7h0K6N1N3N2K5L3O2M3M2K6N1O2O1N2O1LSKhIo2U6PMPJn2P6PMSJP3j5kL^JU3a5SLWJWO`0e4Y5oK^KQ4`4lKeKS4X4kKnK_3YN]Lm5MlK\\3eNcLe5IhK\\3mNhLc7U3bHiL_7T3dHjL]7U3dHkL\\7T3eHkL\\7T3gHiL[7T3_1O101N101N10O001O1M2M4N1K6M3I7J6N2\\Od0L4J6L4hLVKkMn4S2UKgMQ5V2SKdLQ6Z3XJ`KB9X6T4I[KlKc4V4^KjK`4W4`KiKo1lM;\\6gMhKm1jM<`6eMhK[4e6bMRG<R9_OSG?n8_OTG`0m8_OUG<P9@SG=c6RN]K^1SN=b6UN\\KZ1UN`0_6WN]KW1VN?_6ZN\\KV1VN>_6[N]KR1XNg0P6[NXILa2P1YNh0m5_NmKb0\\No0e5`NRL:]NV1a5_NWLIgNg1\\NZNe64oMd1R2YNPNg1k6M3N2N2N101O1N3N1N2O2N2M2O2M2O1O1O2N1O1O1N3N8G6JkVd3"}}, "object_label": "person", "attribute_label": ["face expression:fear/surprise", "gender:male/man/guy/boy", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "face expression, pose", "answer": "The image features a young boy playing soccer on a field. He is wearing a blue shirt and black shorts, and he is actively engaged in the game. The boy is positioned near the center of the field, with a soccer ball located in front of him. \n\nThere are several other people in the scene, some of whom are standing or sitting on chairs, while others are standing or walking around the field. The presence of multiple people suggests that this might be a casual soccer game or practice session."}, {"question_id": 336, "height": 480, "width": 640, "image": "000000417632.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [335.1, 2.28, 284.81, 475.72], "segmentation": {"size": [480, 640], "counts": "cVn4195l=8QBJl=8SBJl=7RBKl=f0N2O1N2N1N3M3N12O5K0000O10O1OcFBY4>]KLc43UK5k4KnJ<S5BhJd0[5YO_I^OVNb1\\8oN\\IP2d6nM\\IT2e6jM[IW2f6gMSIYOUNP3j8eMPI^OTNo2k8bMQIg2P7WMZH^O[O[3Y5dLUMb0TNLSOP3b5eLVM7\\Nm3X4RL[M1^Ne1gN3]5[N]MJlMHJP2B2X5`N]MGmMMIj1E2V5cN^MBoM2Fg1G2R5hN`M^OoM3Hd1H3m4mNcMWOPN7Hb1I2j4QOdMTOoM9J_1J3e4VOgMnNoM=I]1M1`4[OkMiNoM?I[1JQNMQ2`4BQN`NoMc0GZ110T4GiNSOQMU140P4J\\NXNcMk0JT18Om3L\\NYNcMP34kNk3OUN_NjMg28jNg32VN^NgMj2<fNd36VNh1WNRNb38TNh1[NoM`3:TNYNlMk2a0bN^3<SNVNQNj2`0cN[3>RNXNQNg2c0cNY3`0RMRNXOi3>dMW3c0RM`2HmLV3d0PM_2LlLS3f0QM^2LlLR3g0RM\\2MmLP3i0RMZ2NmLo2j0SMX2OoLm2i0SMY20mLm2k0QMZ22kLl2l0RMX23mLi2l0UMV23mLh2m0WMR23QMe2n0[Mn10TMd2o0^Mj1OWMc2o0_Mh1OYMb2o0aMf1M[Ma2S1bM^1O^M_2U1eMX1LeM]2U1iMS1HjM_2W1mMf0EVLoNj1k2bNYMn2Z18D^LoNi1h2W2gN_OFZNb1Y2hN[OG\\N`1Z2jNXOG^N^1\\2kNUOG_N\\1_2oNnNFcNZ1a2POjNEgN[1`2POgNFjNY1_2ROfNEkNX1_2UOdNDmNV1]2ZOdNAoNU1\\2\\OdN_OPOT1\\2@aN]OSOS1\\2@`N_OSOP1]2C_N\\OUOQ1\\2C]N]OXOo0\\2E[N\\OYOo0\\2D[N^OYOn0\\2CaMPNmN`1V1m0[2D`MUNjN\\1Z1j0]2E]MXNjNZ1\\1i0]2FQLmMn0<VOY1_1g0\\2HoKmMP1;UO[1_1e0]2HnKoM31<8H[1^1d0^2JmKmM4O=<YOC8h1c1a0`2LlKkM?0Fa0KX1KXNc1a1]3d0mKPNRO`05T1LXNb1Z1d3j0gKkNUOi0OYN`1V1g3n0fJoMf0k0]Oi01ZN^1S1j3o0eJPNe0k0\\Oj02XN]1T1n3n0cJPN<MDQ1Mk02WNY1Y1U4f0hJmMKO7Z3HhLX1`1W4?iJPN5Y3CiLn0h1a44gJQNJ1=X3DjLj0k1f4NjJUNKOMX3OjLj0l1g4JjJYNH1MS32mLj0k1g4HjJ[NB0N42P34nLj0j1j4DgJ`NA0O31Q33oLm0g1k4AfJeN_O07T3LoLn0f1n4]OcJkNIS3HoLR1b1n4\\O_JQOIh2D\\MQ2o0V4I\\JUOHf2G\\MS2l0T4KZJVOIf2G\\M2Ng1n0`4IWJYOIf2G\\M11f1k0e4EVJ[OIg2F\\M2Nf1o0h4[O[IGY1d2mN[MT2n0j4ROUJe2\\1XN_4SOUJe2\\1XN`4ROTJf2]1WN_4SOTJg2\\1VN`4SOoIm2`1PNh5i1eG^Mb2i0b4SOoIW1lN34iN`2i0a4UOnIU1oN33iN_2j0h59hG23jN^2j0f5:lGNk2HY59nGL5POV2j0f5:QHIl2MS50hGZO;g0l2Nn3WOiIg0J3_2Om3XOhIg0N0_20k3ZOgIe01O^22i3[OhId02N^22]1[O\\M1gNd02M_23\\1[O\\M1gNe02K`23[1\\OfL2QOL=h02Ia24l2BTKb0_OGa25k2CTJJ<g04Fc25i2DTJK;f06Ec25h2ETJK;?UOBR18c27g2ETJK;:ZOFo07c28e2FUJI;9\\OIm06b29d2GVJI:9\\OHn05d29?_OhM9aNI::[OGP14d29>@hM9`NK:8[OGR14d28\\2NXJI:6[OHR13g27X21YJI:MXO020X1Me2;Q27^JG7J[O3OM`57=<bJE5H]O;_5K<>cJE49o4C8b0dJGO4Y5@3f0eJTOBe1h5_N1h0eJTOBe1k5\\NgLNc0m0YMTOBe1l5[NNk0cJVODc1k5\\NO3UJa0=]ODb1m5\\N4d0[J^OD[1T6cNMd0[J^OC]1T6aNNd0ZJ_OD\\1T6aN;7mI\\1i5]NYN1aM5]N\\1j5^NUN6cMN_N]1j5_NSN7dMM^N^1k5^NRN9dMK_N_1j5]NRN:fMH]N_1E`NW6OQN9ZLLS1[1]N`NU60PN:YLMT1Y1h4`NjM<QL4\\1P1i4`NiMV1^M:i4`NiMV1^M:i4`NdM[1dM4h4aN[Me1lMG]NeN\\6O[Me1kMH_NcN[60[Me1kMH_NcNZ61\\Md1kMGm4eNXMd1kMGm4eNYM`1XL`Na1\\1o4cN[M]1VLdNa1[1n4dN\\M\\1ULeNa1[1m4eN^M^1dMNn4fN\\M:YL`0\\1`0o4mNaIFc3;cLa0Y1a0Q5VOkLIkL?Z1b0P5WOjLHlL?Z1?`NgN`6c0mICW22]MG6g0[1d0^NfN`6d0hIF\\2KjM:CAc1Y1]NgN_6e0cIHb2GjMOA00M5O^1[1^NfN_6X1WLiNiM2AN8NL0W1[1fNeN]6Z1mLiNeLO8NL1V1Z1gNeNZ22]1Z1HjNbLJ040MW1[1hNdNT6^1\\MhN`LLN60JZ1Z1gNeNk5f1gM^N`L<V1l0gNdNe5m1oMUNaLMM6OMW1^1W4c0UNnMfL1KOS1_1Q4i0[NgMhL0J0R1[1kNeNo4`2bN_MSM0`0[1k3]1e0cNWOb1g0_NUOe1YOoLUL2l0Z1c3h1GmLeL]1`3j1JiLfL]1^3l1LgLfL]1]3m1S1RNkMmNTMV3e3`LRM^1T2XOgLm2^5kMYMc3f2]L[Mc3e2]LYMe3f2\\LYMe3f2\\LYMe3g2[LmLbNfMZ5\\5TLlLT4T3]JbJ\\1Y2X4U3kKkLU4U3lKiLU4V3lKjLW4R3iKmLZ4Q3gKoLY4Q3gKnLZ4Q3gKoLZ4oNSJj2c1VNS5VN]Ib3a1WNU5TN\\Id3_1WNY5QNYIh3^1WNf5g1[JXNg5g1YJXNi5f1XJYNi5f1XJWNl5g1UJWNm5i1SJSNQ6l1PJRNS6l1mIRNW6l1jIRNX6n1hIPN[6n1fIQN[6n1fIPN]6n1cIQN_6o1`IQNb6m1_IQNc6o1]IoMf6o1[IPNh6n1XIPNk6n1VIQNk6o1UIoMm6P2TIoMn6o1RIPNR7m1nHRNU7l1lHSNV7k1jHTNX7k1iHTNY7j1hHTN[7j1gHTN\\7i1eHPNjMDd9[2bHUN_7j1aHVNa7h1`HVNd7f1]HZNe7d1ZH\\Ni7b1XH]Ni7b1XH]Nj7b1XHZNm7a1YHXNk7f1j2M3MZE\\NX8]1j2K2N5K6J6J=BV^="}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, pose, hair type", "answer": "The image features a man wearing a gray hoodie, standing in a room with several people around him. He is holding a wine glass, and it appears that he is being handed a paper by someone else. The man is also wearing a name tag, which suggests that he might be attending an event or gathering.\n\nIn the room, there are multiple wine glasses, some of which are being held by other people. A handbag can be seen placed on the floor, and a cup is also visible in the scene. The presence of multiple people and wine glasses indicates a social gathering or a celebration."}, {"question_id": 337, "height": 431, "width": 640, "image": "000000475387.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [276.41, 111.56, 17.05, 40.7], "segmentation": {"size": [431, 640], "counts": "ffd36W=3lBIm<?F<^CUOX<S1eClNW<V1O20O1O3M2N00002N1\\OiCN\\<KnCMiYb4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, hair type, gender, maturity, face expression", "answer": "The image features a woman standing in front of a fence, possibly at a zoo or an event. She is wearing a blue shirt and appears to be looking at something or someone on the other side of the fence. There are two other people in the scene, one standing behind her and another person further to the right. The woman in the blue shirt is holding a cell phone, possibly capturing a moment or communicating with someone."}, {"question_id": 338, "height": 431, "width": 640, "image": "000000475387.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [573.43, 257.82, 16.98, 23.23], "segmentation": {"size": [431, 640], "counts": "[c`71[=3K6L3L4O2N1O1O1O10O10000000002M2O4L3Ke[d0"}}, "object_label": "backpack", "attribute_label": ["color:blue", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "texture, transparency, pose, state, material", "answer": "The backpack in the image is black and features a white logo. It is being held by a person, who is wearing shorts. The backpack is positioned in front of the person, covering a significant portion of their body."}, {"question_id": 339, "height": 480, "width": 640, "image": "000000507473.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [29.12, 3.1, 398.03, 476.9], "segmentation": {"size": [480, 640], "counts": "bh?c0X>8I7J6J4K5M3M3N1L5L4N1N2M4M2N2O1O2M2M3N2O2M2N2N2N2O1O1N2N2O1N2N2O1N2O1O1M3O1N2O1N2O1N2N2N2O1O1N2N2N2O0O2N2N2N2N1O2O0N3O1N2M2O2O001N2O10O01OVNTFkL1a1k9^3O2OfMZF\\Od9f0YF]Of9<_FG^9<_FG_96_F1_9KgF5W9MhF3W9MgF6W9KhF8U9IkF9S9EQG:m8HTG8JUMl71lHb2A7GWM]7n0hHg145S7W1nHkNo6X1QIiNn6W1SIiNl6U1WIkNi6T1WImNi6Q1XIoNi6n0YITOf6k0ZIWOf6f0[I^Od6?]I@U7NiH4b7A^H`0b3lLkKLg3d2lLe0`3QMJS2fLl0_3SMMn1cLQ1^3SM0i1cLT1V3\\M6`1cLU1Q3eL]Lg0o3^1dLV1e2gLgLo0P4S1eLW1`2PNj0i0fLX1\\2SNl0f0iLV1Y2WNk0e0lLU1W2XNl0d0lLT1U2\\No0`0lLS1S2`No0?mLQ1Q2dNP1=oLn0i1nNV16PMm0i1nNV16QMj0f1UOX12RMh0BfLi1e2b1MSMh0b1\\OY1NSMg0c1]OY1MSMg0a1_O\\1JRMg0_1C_1FRMg0Z1Hc1BSMe0X1Le1^OSMg0m06o1TOTMf0l07P2SOSMf0j0;S2YMoL:4Q2g0`0U2mLoMLTOh2e0b0X2iLRNKQOj2?h0]2bLVNKmNk2?j0^2`LVNJnNl28P1d2ZLWNImNl26T1e2mKiLM^16nNk24X1g2jKiLM^16mNk2N`1n2bKhLN_14nNj2Md1n2`KhLN_14nNm2Ch1X3eKWNFnNh2CR2X3`KXNEmNS8j2XHZNEjNU8l2VHZNDjNW8l2UHZNDjNW8l2UHZNDjNW8l2UHZNDiNX8m2SH[NEhNX8`2aG\\Mb0\\1EgNY8[2iG_M9_1EgNY8X2hHjMcNj0;UOZ8S2lHUOjNhNZ8R2mHVOiNhNZ8P2PIWOeNjN[8n1QIXOdNjN[8m1SIXObNkN[8l1TIYO`NlN\\8j1UIZO_NlN\\8i1WI[O\\NkN^8i1WI[O\\NlN]8i1XIZO[NnN\\8g1ZI[OYNnN^8e1\\I\\OVNoN^8d1]I]OUNoN^8c1_I]OSNPO^8c1`I\\ORNQO^8c1aI[OQNRO^8c1aI[OQNRO^8c1bIZOoMSO`8c1aIZOoMTO_8b1bIZOoMTO_8a1cIZOoMUOf3Ch0l1eM\\OmMUOa3DWL2f0MW3k1_N]OlMUOa3JkLLW3i1_N]OnMTOa3NgLH[3j1^N\\OoMTOa3DWL<7DI2l3i1\\N_OPNROa3DXL011OO7OJ2j3i1ZNCRNoNb3DoL1S3i1XNESNnNc3CPMOS3k1WNESNnNb3Eo0g1]MFQNoNc3Fm0e1_MGoMoNd3Fn0d1_MGnMPOd3EP1d1^MGmMROa3FUMIS3h1ZNHlMPO]3_OeL>`0AY3j1YN=T1PNhLJ0<_4]1dM>U1oMmL4[4_1bM?e1RNi0_1^MVNRNh12eNg2DQN8h3`1_MOSNcNg2EoM7j3a1]M1WN^N`3Om0a1^M0WNZNE1o3Og0e1`M0UNZNG1k2OSN2e3c1bM1XN[N]21UM2g0Nm3a1dM3V1ZNcL3g0Ol3a1cM3\\1\\NcLOO6JLe4^1eM6n1ZNhK21Ne4^1fM8n6ETI<l6CUI=k6BUI<aM[Nk2Ob3Y1RL>bMYNY9W1WI`0mM\\Ni3M`L3n2S1lNb0lM]Nh3LRL001J4b3o0oNc0kM^Nc3JRL24O10K5a3n0oNe0jM_Ne2HfM0[O2O00O1050K5a3k0ROh0gM_Nc3HSL2f00l2m0VOSOXM^1:hNh3H=m0bNc0XMhN\\8e0\\J@_M2EBJ7S4H=k0]NVO]M1?9\\OHK5R4H>j0^NWO]MO`0:WOLM2T4I<i0_NWO[NOhN60:R4BSLN<3l2f0[OXOXM1\\13eN;Q4CRLN;3n2e0[OXOXM1\\11hN;o3DRLN:5n2c0[OZOXM0]1NkN<k3FaL6j2`0AXOkN;[2EfL1d2g0_1B7FZNg0MYOSN:f3FZNf0NZOSN8f3HYNe0O[OSN7i2IVL2@O`3c0N]OTN4]3MfN`0@^OjN3R3OcN?B_OPM0g62gL=DBlL1h60hL<ECkL1h60hL;ODZ30hL;ODT7;i3OWLFnH9S7H\\EOW38X;0000000PEHX77i30aDIU87kGIU86kGLT84kGMf3O^M4lNMU83kGMU83jGMW83iGMW83iGMi3M]M6iNNX82hGNX82kGKU86jGKU85dGIVM2U;6bGJYM0U;7aGG\\M2S;7aGG\\M2S;8_GH_MNR;=ZGGdMMQ;>[GBeMOQ;`0S31O1O1O0WD]OhM0Q;c0WG]OhM1P;b0XG^OgM0e01Z9a0ZH^OgM0e05V9=]H@gMMg07T9;`H^OgM0f07R9:QJEo5;QJFn5;QJFn5:mH@TN6o8;lH^OVN8m8:lH^OXN9k89mH^OXN:j89mH]OZN9i8:mH]O[N9g8;mH[O]N;e8:WJFh5:XJGg5:YJFf5;ZJEd5=[JDd5<`FYOd3:m5f0RJZOn5f0SJZOl5g0SJYOm5h0SJYOk5g0UJ\\Oh5e0WJ\\Oh5e0XJ[Og5f0YJYOg5i0WJWO`L@R9Z1]JUObLBP9Z1]JTOcLCo8[1]JQOeLDm8\\1`JgN]LN76d8V1hJcN_L175a8X1PKbNaL4_8[1oJaNcL3IK]8c1fJ]NeM6VOK_8d1dJ\\NfM7UO0Z8_1hJ[NjM<c7Z1bJZNlM:c7]1_JYNcMNF;Y8^1^JYNbM0G8Y8`1\\JWNfM2E5Z8b1[JWNeM4F4X8b1[JVNhM5F4T8b1]JUNiM6E3U8c1\\JUNiM5H1S8f1\\JSNhM8JLS8j1YJRNjM9NHn7o1VJQNnM9NHm7P2UJoMPN9NKj7o1UJnMTN7OKg7U2QJiMYN72Ic7Y2oIgM^N7]8V2oHeMdN5<Fm6a2QJeMgN49Go6b2nIdMjN3[8Z2gHfMoN0;Hg6d2mIdMROOW8_2\\H]MfN6h0MV8b2ZH\\MfN6k0JV8k2QHdMo8a2oF_Mg1\\O\\4[3kIYMk8k2UGUMW5\\ORJ0l2d3iMRMo1ZO]O2P2d3bLRM\\4XOQOh3aLRMY4UORK0n3R4dLkLZ4TOUOU4^LiLn3ROaK016OJj3[4bLgL^3mN\\L20O0Oh21QN_4[OeL^7lNTIc4\\OcLl2iN\\11TLl4A]Lb7fN^H10R5NZLc7W4\\HjKe7i510N10O01000O10000O0\\JZHo3f7e11eIWHD1X5g7eJXH\\6i7bI]HZ6b7fI\\H\\6e7`000O1O2N8Hf0ZO5K8H5K2N8H1N3N7I2M6K2MAkJUGU5P9lJcF32n4\\9oJcF0:j4S9UKVGg4h9JA`KbF[4^9fKiFR4W9oKlFn3T9RLQGh3R9ULSGf3W:L8H4L7H4L9F5M3L6I6K3N3L7J4J7J8F7In_S3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:curly/curled", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, hair type, maturity", "answer": "The image features a woman standing in front of a mirror, brushing her teeth. She is wearing a grey shirt and glasses, and she is holding a toothbrush in her mouth. The woman is also holding a cell phone in her hand, capturing a selfie of herself brushing her teeth. The scene appears to be a casual and candid moment of her daily routine."}, {"question_id": 340, "height": 426, "width": 640, "image": "000000515982.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [341.18, 2.0, 250.65, 413.61], "segmentation": {"size": [426, 640], "counts": "^of47Q=4M1O10000O2OO010000O10000lEA]7?f21O1nE_O[7a0bHB]7?\\H_OhM4k9=]H^OjM4h9?eHAY7a0gH_OX7b0_H]OkM2LLe9f0eH[OjM6`9`0gHYOiM8^9`0PIBn6>RIBm6?TIAk6>VICh6>XIBg6?XICe6?[IBc6?]IBa6>`IC\\6`0dIA\\6>[ISOiM`0l8<]IQOgMe0k8:dIGZ6:fIGX6:hIG_2GSNd0_OE[21mM;M@S2:kM83^OP2=jM66^On1?hM5;\\Ok1a0eM7a0XOi1c0cM6e0WOf1d0aM:j0QOd1f0\\M?P1lNa1h0TMf0[1bN`1i0mLm0c1ZN^1l0jKn1h2VM]1c4cN^K[1c4fN]KY1c4hN^KU1c4lN]KS1b4nN_KQ1a4PO_Ko0m3nKkKV38j0i3VLmKQ3;h0h3ULPLS39f0g3VLQLU38c0h3XLoKV3:a0g3XLPLX39?g3XLPL[39;]4FcK9]4GdK7]4nMiJ6j0k1[3cLbL\\1[O5h0l1T3jLiLT1]O6f0k1n2nLRMQ1ZO7f0h1i2UMXMl0ZO6f0h1e2XM\\Mj0YO7f0e1c2YMbMj0VO8f0c1b2ZMdMk0TO9e0b1f2UMcMP1RO9f0a1f2TMcMR1QO:f0^1k2RM^MU1QO<f0\\1_4WNkJ?f0Y1_4XNkJ?f0X1`4YNjJjNKX1l0d1_4YNlJhNL[1h0c1a4ZNkJeN0^1d0a1b4\\NjJcN3_1b0a1a4\\N^K00d1a4[NeKMKf1a4ZNjKNEg1a4YNoKM@i1b4XNSLM[Oj1b4XNWLKXOl1g0YMn1n0VNMUOj1e0aMl1h0\\NLTOj1b0hMj1a0aNNROi1b0oMd1:jNMQOh1b0aNR1J\\OLROh1`0hNl0DBJTOj1>mNg0^OHIVOj1=SO?[ONFYO[OeN]2e1]O9TO5F\\Oi16A5oN;EZOk17FOjN`0DZOm17HLgNe0A[Om15NHdNi0_OHb1G=FbNm0\\ON^1_Of0CaNQ1ZO1Z1\\Om0@_NU1VO4[1VOS1_O\\NQ4?`LV1^O[NU4<]LZ1]OZN]44WLc1ZOZNc4NTLi1XOYNh4JPLm1WOZNk4GnKP2UOZNo4CmKT2SOYNS5@jKX2QOYNV5]OjK\\2nNWNZ5[OhK_2mNVN\\5ZOgKa2lNUN^5YOfKc2jNUNb5UOeKg2hNTNd5TOdKj2fNRNh5RObKo2bNPNl5QObKQ3`NnMo5oNbKS3^NoMQ6mNaKU3\\NoMS6lNaKV3YNPNW6hNaKk4^600001O1O001O1O001O2N1O1SIPK^5R5_JPK`5R5ZJSKe5P5lI]KS6g4gI\\KX6k502N1N2O1O101N1O2N1O2N1N3N2N1O1O1O2N1O1O2N1O1O2N1O1O1O1O2N2N2N2N1O3M1O1O2N1O2N2N1O2N2N2N2N1N3N2N3M1O1O2N1N3N3M1N3N2N2M2O1N2O0O4M4K3M2O1N2N3M4L7I3M2N2M3M2O2\\NmDm0V;POREg0Q;WO]E;e:E_E4e:JdEIb:5]1Lgcd0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, hair type", "answer": "The image features a baseball player in the middle of a game, wearing a baseball uniform and a red hat. He is in the process of catching a ball with his baseball glove, which is positioned in front of him. The player is focused and determined, displaying his athleticism and skill in the sport."}, {"question_id": 341, "height": 640, "width": 640, "image": "000000522393.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [313.03, 503.73, 36.94, 33.81], "segmentation": {"size": [640, 640], "counts": "cTT64gc07M1N2O1BFU]O;jb0GT]O:lb0HQ]O9ob0;10000O10000O10001O0O1[On\\O<[c000O10001O1O0O2O1N2O1O1N101O0O2Ob[e5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "hair type:curly/curled", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "hair type, maturity, face expression, gender, pose", "answer": "The image features a woman wearing sunglasses and a pink shirt, sitting on a boat. She appears to be enjoying her time on the boat, possibly on a lake or a river. The woman is seated in the front of the boat, and her sunglasses are placed on her head. The boat is surrounded by water, and the woman seems to be the main focus of the scene."}, {"question_id": 342, "height": 375, "width": 500, "image": "000000526728.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [247.13, 150.16, 72.73, 128.4], "segmentation": {"size": [375, 500], "counts": "R]k21_;a0ZO_OaEh0Q:d0I7K5M3O1N1OO20O10OYOTNPG3>i1_8`N_G]1c8eN[GZ1f8iNXGU1h8oNUGQ1l8QOPGo0Q9k001000000000^NPG=P9DnF=R9U1O001O01O100O2O1N3NQGdMb85WGk14UNo8k1oFWNP9j1oFVNR9X2O100O001O1O2N100O002N1O2N2N0010O1010011M2M2N3M3cNkF2X9HUGNo8J_GLf8JQHBPRS2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose", "answer": "The image features a woman standing next to a suitcase, posing for a picture. She is wearing a black coat and appears to be smiling for the camera. The suitcase is placed on the ground, and there is another suitcase nearby. The woman is also holding a handbag, which is placed close to her. The scene suggests that she might be preparing for a trip or has just arrived at her destination."}, {"question_id": 343, "height": 427, "width": 640, "image": "000000572620.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [11.26, 244.98, 32.24, 55.38], "segmentation": {"size": [427, 640], "counts": "ae53X=1N1N3F;^CAR<o0N2N3L6L2M1O10O001O1O;F03MO100O2N2@PD@S<>`0N3M4L2O005MMOgWh7"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression", "answer": "The image features a young man wearing a blue shirt, sitting on a bench with a young boy. The young man is holding a beverage, possibly a cup, in his hand. They are both sitting on a bench, possibly in a park or a similar outdoor setting. The scene appears to be a casual and relaxed moment between the two individuals."}, {"question_id": 344, "height": 480, "width": 640, "image": "000000572900.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity, pose", "region_anno": {"bbox": [360.75, 165.68, 128.34, 206.37], "segmentation": {"size": [480, 640], "counts": "YjZ51j>0YA2e>6O001O100O001O0100O001O1O001O0001O1O1O1O10O0100000O01O1O1O01O0000001O01O01O00O10O10000000O010O1O10O0100OJaAL_>5aAK_>:0100O1O2O0O2UFAS5`0kJAT5c0fF:f2TOc6X2SIiMl6f2eH\\MZ7i2WG_M0Hi8k2RGiMDDZ9g2kFaNU9f3O000E:H9N2N1000VOdGfJg8X5b0M200RLZFc2h9Z101O00WO_FSLa9l3cFQL]9n3hFmKY9R4iFkKZ9R4k0O1PMYE>0@j:n22N2O1bLQEa12POP;\\OPEc10QOZ;QOhDm1NQOe;o0ZDQOg;R23L3K5M4K4\\NfC>^<AnC0W<NnCKV<5Z12OOdCVOc:k0YEYOf:j0TE\\Oi:g0QE\\OP;i0gDZOY;Q1lC_OV<d13M3L3N4J8G5L9G:jNmBLcnV2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type", "answer": "The image features a man standing in a courtyard, holding a frisbee in his hand. He appears to be wearing a blue shirt and is smiling, possibly enjoying a game of frisbee or preparing to throw it. The man is positioned in the center of the scene, with the frisbee held above his head.\n\nIn the background, there are two other people visible, one on the left side and another on the right side of the image. The presence of these individuals suggests that the man with the frisbee might be playing with others or waiting for them to join in the game."}, {"question_id": 345, "height": 480, "width": 640, "image": "000000572900.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "cleanliness, color, pattern, pose, transparency", "region_anno": {"bbox": [277.29, 194.02, 27.08, 31.22], "segmentation": {"size": [480, 640], "counts": "bQR4=]>7N101N1M3O100O1N200001O1O001WOlAd0T>\\OlAd0U>ZOlAf0V>1002N00000000001N2_OeAOZYm4"}}, "object_label": "potted plant", "attribute_label": ["cleanliness:clean/neat", "color:green", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "color, pose, cleanliness, transparency", "answer": "The image features a potted plant with a white pot, placed on a sidewalk. The plant is a small tree, and it is situated next to a brick wall. The pot is positioned on a ledge, and the plant appears to be well-maintained and healthy."}, {"question_id": 346, "height": 427, "width": 640, "image": "000000000885.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [400.04, 268.61, 81.34, 40.22], "segmentation": {"size": [427, 640], "counts": "\\mW51Y=3N1O1O0000000O01000000O1000000O02O000O100N20LoBOo<0SC0l<1TCOk<1VC0i<OYC0f<0[C0d<0^C0a<1^CO`<?O2N1O2N1O2N1O2N2O0O2O0O2O0O2O00000O2O000000000000000000000001N10001O0O2O1N101N2O1N2M3N3M3L7GU^R2"}}, "object_label": "tennis racket", "attribute_label": ["color:red", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying"], "control_dims": "transparency, color, pose", "answer": "The tennis racket in the image is red and white, with a red handle. It is being held by a person, who is likely preparing to play tennis or has just finished a game. The racket is positioned in a way that it is ready to be swung, indicating that the person is actively engaged in the sport."}, {"question_id": 347, "height": 427, "width": 640, "image": "000000095155.jpg", "category": "description", "question": "Describe the snowboard in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [151.62, 351.15, 87.67, 32.75], "segmentation": {"size": [427, 640], "counts": "gTP23V=2O1O010O2O0O10MPCKQ=3PCMP=3PCMP=3PCMQ=2oBNR=2lBOT=400000N20oBMk<4PC1n<610O01O00000001O001O00001O001O01O01O010O0000010O0001O2O0O0001O001N100O2N1O2N101O001O0100O4L1O0000001N1O100O1O2O0O1O100O1O2N100O100O\\kV5"}}, "object_label": "snowboard", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying"], "control_dims": "pose", "answer": "The snowboard in the image is green and white, with a person riding on it. The snowboarder is wearing a brown jacket and is positioned in the middle of the scene."}, {"question_id": 348, "height": 427, "width": 640, "image": "000000095155.jpg", "category": "description", "question": "Describe the snowboard in the following image in detail.", "dims": "length, material, pose, transparency", "region_anno": {"bbox": [539.86, 366.3, 42.23, 25.55], "segmentation": {"size": [427, 640], "counts": "dnQ73X=1N2NLoBOR=0=3E1N2K5O2M4M00O00N2N300N_O^C<b<D`C;`<E`C;`<E`C:a<F_C:a<F^C;c<D]C;e<51N100O1AWC;m<0000O1ON2011EUC4R=N2N2Omdh0"}}, "object_label": "snowboard", "attribute_label": ["length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying"], "control_dims": "length", "answer": "The image features a snowboard with green and blue accents, sitting on a snow-covered ground. The snowboard is positioned in the middle of the scene, and it appears to be a close-up view of the board. The snowboard is likely used for winter sports, such as snowboarding, and it is designed to glide smoothly over the snow."}, {"question_id": 349, "height": 432, "width": 640, "image": "000000319369.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [184.41, 279.98, 60.58, 82.65], "segmentation": {"size": [432, 640], "counts": "Q\\^23\\=1Xk0M`gN4i<>0O1O0010000010O2N1O00O0OGH^C3g;0jD:l:4QELo:5PEIS;6mDEY;;eDVOE>g;<bDG_;8`DHb;7]DJe;4\\DIg;7YDAo;=RDCo;0]DNg;OZD1g;OYD0h;0k01000O010O100001O02O01N1N4iBGQ==O010O001ON7EhlX5"}}, "object_label": "chair", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "material, color, transparency", "answer": "The chair in the image is a red lawn chair, which is placed on a grassy area. It is positioned in such a way that the woman sitting on it is facing the camera."}, {"question_id": 350, "height": 334, "width": 500, "image": "000000325991.jpg", "category": "description", "question": "Describe the frisbee in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [319.76, 218.69, 50.71, 15.1], "segmentation": {"size": [334, 500], "counts": "elY31]:1O000O10001O3M1O1N100000001O00001N2O1O000000O10000000000O1000000O1000000O10000O2O001N2O1NoUZ1"}}, "object_label": "frisbee", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "pose, color", "answer": "The frisbee in the image is white and appears to be slightly dirty. It is being held by a person, who is either preparing to throw it or has just caught it. The frisbee is positioned in the middle of the scene, with the person's hand on the left side of the image and the frisbee occupying the majority of the right side."}, {"question_id": 351, "height": 389, "width": 640, "image": "000000356094.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [402.75, 228.87, 21.37, 24.99], "segmentation": {"size": [389, 640], "counts": "`fi45h;<L4L2M2O10O001N101O1N2M2O1O01O1005IdVb2"}}, "object_label": "baseball glove", "attribute_label": ["color:brown", "material:leather", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "pose", "answer": "The image features a baseball glove, which is a piece of sports equipment used by baseball players to catch and field the ball. The glove is positioned in the foreground, with the background being a grassy field. The glove is brown in color and appears to be worn, possibly indicating that it has been used in multiple games. The glove is placed on the grass, ready for use during a baseball game."}, {"question_id": 352, "height": 389, "width": 640, "image": "000000356094.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [185.32, 35.84, 157.35, 348.79], "segmentation": {"size": [389, 640], "counts": "_UX26a;>E;J6K5L4L4aISOc1P1\\NSO_1P1\\NVO`1m0`NTO\\1o0bNTO[1n0cNUOZ1m0fNTOV1o0hNSOV1o0jNQOT1Q1iNhM^LV1f4U1kNfM_LU1c4X1nNcM_LU1a4Z1nNcMaLS1_4\\1PO`MaLU1^4\\1PO_McLU1Z4_1RO]MdLT1X4a1TO[McLT1X4c1TOZMdLR1W4f1UOWMeLS1U4g1UOWMfLQ1R4l1XORMfLR1Q4n1ARN=P2BQN=P2BQN<Q2_NkLbNT1n2R2_NmL]NJWOY1m1MgNU2g1lLaNR1?c0nNf1R2fL`NS14l0WO]1T2eLaNU1Jm4e1oI_NZ1Am4o1jI`NW8`1iG`NW8_1kG_NV8a1jG_NV8`1lG^NU8b1kGVNDDb8U2kGXNBBd8V2kGoMDKM0d8U2lGoMIL[8T2mGnMJNY8n1eHRN[7j1hHWNX7e1kH]NT7b1oH[NR7b1j1O1O010O000001O1O001O001O1O001O1O1O001O1O1O1O1O1O1O10000002N2N1O1O1O1O1O100O1O2N1O100O1O100O010O1O010O01O001PGgNR7Z1kHjNS7W1lHjNS7W1kHlNS7U1kHmNT7T1jHmNV7T1hHnNW7T1gHmNX7U1fHkNZ7X1bHjN]7j1fGaM1f0Y8o2O1O1O001O001O001O001PKULd1l3cMULTN1X4k3aMYLfMO12f4g3^MWM^2j2[MaMeNbNQ3m3UNnMaNXNX3k3TNRN`NUN[3j3PNiNn1X1PNjNo1W1PNjNo1W1oMlNo1V1nMnNo1T1bM\\O[2g0ZMEb2R5M4L7I2N7I8H5L3eNhEa0b:ROcEk0n:N3M<E5J8F^^`3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, gender, face expression", "answer": "The image features a baseball player standing on a field, holding a baseball bat and preparing to swing. The player is wearing a baseball uniform, which includes a red shirt and a number 16 on the back. The player is focused and ready to hit the ball, showcasing their skill and dedication to the sport."}, {"question_id": 353, "height": 427, "width": 640, "image": "000000359540.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pose, transparency", "region_anno": {"bbox": [339.47, 201.5, 19.23, 25.6], "segmentation": {"size": [427, 640], "counts": "_Z\\41Z=0W=4cB2F:O2N2O1O000001N0100O10N1O3L3N2O2Mc\\e3"}}, "object_label": "baseball glove", "attribute_label": ["color:black", "material:leather", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency, pose, color", "answer": "The baseball glove in the image is a catcher's mitt, which is designed to catch fast pitches and provide extra padding for protection. It is black in color and features a red strap, which is likely used to secure the glove to the player's hand. The glove is positioned on the ground, with the catcher's mitt open, ready to catch a ball."}, {"question_id": 354, "height": 427, "width": 640, "image": "000000359540.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, length, material, pose, transparency", "region_anno": {"bbox": [125.91, 201.71, 48.74, 11.6], "segmentation": {"size": [427, 640], "counts": "egd15U=101O000000000001O0001O000001O000000001O01O0001O000000001O0000000000010O0000001O01O000001O000000YfQ6"}}, "object_label": "baseball bat", "attribute_label": ["color:black", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency, color, material", "answer": "The image features a baseball bat lying on the ground, with its end facing upwards. The bat is made of wood and appears to be quite long, extending from the left side of the image towards the right. The ground beneath the bat is covered in dirt, giving the impression that the bat is resting in a field or a similar outdoor setting."}, {"question_id": 355, "height": 427, "width": 640, "image": "000000026941.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [150.64, 89.22, 82.07, 70.97], "segmentation": {"size": [427, 640], "counts": "^Ro11R=`1bN8L3N1O100O1000000000000O1000SOhDGX;7mDFS;:mDFS;9oDER;;nDER;;nDER;;nDER;;nDER;:oDVOK5V;d0PEVO10o:j0cETO]:l0Q12N0O100000000000000000000000000O1000N2O1001O001bDRO]:n0[EZOe:g0PEPOL;T;e0PECP;>nDCR;=mDDS;=kDDU;Y101O00000O2OfNoD:Q;BVE;j:C[E:e:D`E:_:EeE7\\:IgE4Y:KjE3V:LoE0P:1SFMl92XFJi96g1N1O2O0O2N3M[QZ5"}}, "object_label": "suitcase", "attribute_label": ["color:brown", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "state:closed", "texture:rough"], "control_dims": "pose, material, state, pattern, color, transparency", "answer": "The image features a collection of old suitcases, with one of them being a vintage piece. The suitcase is brown and has a tag on it, indicating that it might be a piece of luggage from a bygone era. The other suitcases in the scene are also old and appear to be in various sizes and shapes. They are stacked on top of each other, creating a visually interesting arrangement."}, {"question_id": 356, "height": 427, "width": 640, "image": "000000026941.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "cleanliness, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [93.3, 164.43, 67.65, 169.69], "segmentation": {"size": [427, 640], "counts": "gPZ14k9N]I4n4OXI0BMWO;MW1Q8k1nGUNQ8l1oGTNQ8l1oGUNP8j1QHVNo7a1]H\\Nc7]1RIUNn6n0PHbN[1=e6Q1PH`N]1?c6P1QHWNg1h0X6P1VHRNd1n0V6P1SIYNCh0Y7XOSHW1n0oNoNBd0o0\\7XOVHT1f0]OH7\\7WOXHm0f0KE1]7VO[Hf0e07DL\\7WO^HNC9n0l0EF\\7WO`HKC9R1k0_OJ\\7WOlIM[NQ1<L]7UOlIO[NP1<L^7SOYJQ1ZNK]7SOZJ2lM0H=f0>f;OgLSOUJl0Z5TOlG2k2h0X5WOZKi0b4\\O\\Ke0b4^O]Kb0]4DbK=\\4FcK:]4EcK<\\4EdK;\\4FcK:]4GoG\\O70Q3k0h4OTHWOU3h0h40dKM\\42fKMW4[ORHh0g3MV4]ORHf05[OY3b0`4]ORHf03]OZ3b0`4[OSHP1]3E`4[OSH43`0[31`4YOUH07a0V36V5BjJ?Q9O11O01O0O10000000001N10000O1O100N3O2M5K6J]mT6"}}, "object_label": "suitcase", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:rough"], "control_dims": "state, transparency, texture, size, cleanliness", "answer": "The image features a large, old-fashioned suitcase with a handle, sitting on a cart. The suitcase is brown in color and appears to be well-worn, suggesting that it has been used for traveling in the past. The cart is green and is designed to transport the suitcase, making it easier to move around. The suitcase is placed on the cart, ready to be moved or transported to a new destination."}, {"question_id": 357, "height": 425, "width": 640, "image": "000000082180.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [352.48, 168.57, 77.56, 91.04], "segmentation": {"size": [425, 640], "counts": "^Zb48o<4M2N3C@lCa0n;FQD;m;GRD:l;GTD9k;ISD9k;HUD8j;IVD7j;IVD8h;IXD7g;JYD6c:CRF8ZO4d:GoE6[O5d:JnEk0R:WOkEj0T:YOjEg0V:[OhEd0Y:]OeEd0[:@aE`0_:A_E?c:A\\E?d:B[E=g:R12N2N2N000000N2O1O10000O100000000O101OO2O001O0010O010O0100ON3M2O\\N^Ed0a:[O`Ee0`:ZOaEHK:c:IgELJ8_:GlE1H5\\:HoE2F6[:FPF4F5Z:GQF3G4Y:FRF7F2Z:CRF:E2Y;NgD2Z;MgD3X;MhD2Z;MgD2Y;OfD0\\;OeD0\\;OeDO];0dDN^;0eDK`;2n0MWnf2"}}, "object_label": "teddy bear", "attribute_label": ["color:black", "color:gray", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, transparency", "answer": "The image features a small teddy bear sitting on a wooden surface, possibly a bench or a table. The teddy bear is gray in color and has a black nose, giving it a unique appearance. It is positioned in the center of the scene, occupying a significant portion of the image."}, {"question_id": 358, "height": 425, "width": 640, "image": "000000082180.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pattern, pose, size, state", "region_anno": {"bbox": [247.32, 146.9, 108.88, 116.56], "segmentation": {"size": [425, 640], "counts": "]ZV39m<6K9H3N2M3M2O1N1H9L3N2N2N2N3M2O1O1N2O1N2N2N2O1VOkM^FW2_9oM]FR2b9PN\\FQ2c9QN[FP2c9SN[Fm1e9VNXFk1h9VNVFk1i9VNWFj1i9WNVFi1j9WNUFk1i9WNVFi1j9XNUFh1k9XNTFi1l9j00000000000O10FVFUMi9j2YFRML0k9m2[FWMc9j2]FWMb9h2aFVM^9i2eFVM[9j2fFUMZ9l2`0101O001O001O1OHPFYMn9d2VF]Mh9b2YF`Me9^2\\FdMc9\\2[FgMc9Y2]FhMc9W2]FlMa9T2^FmMb9Q2_FQNa9m1_FUN`9i1]FbMM7OJ16g9U2]FnMME18e9T2]FoM3La9S2]FPN3Ma9R2[FoMLI1O27g9Q2ZFnMNKOO19h9n1WFiMO44MMO19i9m1UFRN4IM008j9k1WFTN1JM009k9?TF;4TON>j91YF8OZON>k9NZF7O]OL>k9NZF9NZOLa0k9K\\F:MZOKb0l9I^Fj0F\\On9I\\Fk0FeN0414m98\\Fk0FdN110M29m99[FP1EaN1M28o99ZFU1D\\N16R:8\\Fa1g9]N\\F_1g9_N[F_1h9\\N_Fg0UOIb;5^DJc;6]DJb;o00YO_DEa;;bDB_;>bD@_;?dD^O];b0eDXO^;i0a000O101O0O2N1O4L7@dee3"}}, "object_label": "teddy bear", "attribute_label": ["color:tan", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry"], "control_dims": "color, state, material, pose, size", "answer": "The image features a brown teddy bear sitting on a wooden bench. The teddy bear is positioned in the middle of the bench, occupying a significant portion of the seating area. The bench appears to be made of wood and is located outdoors, possibly in a park or a similar setting."}, {"question_id": 359, "height": 289, "width": 640, "image": "000000311883.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [508.65, 124.35, 16.31, 14.4], "segmentation": {"size": [289, 640], "counts": "nQ`47h83O1O0O2O001O0000O2O001N2N4KbZP1"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:off", "texture:smooth/sleek"], "control_dims": "texture, state, pattern, transparency", "answer": "The traffic light in the image is a large, white, and round object. It is located in the middle of the scene, with a blue sky in the background. The traffic light appears to be a part of a larger structure, possibly an airplane wing or a building. The traffic light is situated in the center of the scene, drawing attention to its presence and size."}, {"question_id": 360, "height": 419, "width": 640, "image": "000000334371.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [416.18, 205.26, 129.93, 86.63], "segmentation": {"size": [419, 640], "counts": "fd[59i<8I5K7I=nClN[;e1I8lDRNc:Z2M1O1O10O01N2O1OO1O2O000000000000000000000000001O01O001O010O1O000000O101O000000000O1O1O2O000000001O000000001O000000010O000000001O000000000O2O0001O0001O00000O101N101O00000O1FUE[Nl:a1YE^Nh:a1XE`Ng:_1VEfNi:V1REcN48j:U1REcN58j:R1SEdN4:k:U1SElNn:d10001O00O1O101O0O101O00000001O01O0O1O1C=O3M2J7Jm0TOPdV1"}}, "object_label": "bus", "attribute_label": ["color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "color", "answer": "The image features a long line of double-decker buses driving down a city street. There are at least five buses visible in the scene, with some of them being closer to the foreground and others further back. The buses are of various sizes and are arranged in a row, indicating that they are likely part of a public transportation system.\n\nIn addition to the buses, there is a car visible on the right side of the image, driving down the street alongside the buses. The scene captures the bustling atmosphere of a busy city street with multiple modes of transportation in use."}, {"question_id": 361, "height": 419, "width": 640, "image": "000000334371.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [16.01, 170.66, 106.39, 89.45], "segmentation": {"size": [419, 640], "counts": "fZ63c08`:j1KO010001O010O00007I7I3M0000@eEXN[:c1eEQN2;Y:Y2000JgEbMY:j1hEbN_:]1cEaN^:`1^EUN35a:f1\\EVN3Oe:P2[EoMf:Q2ZEoMf:Q2YEPNg:W2O1O1O1O003M1O2O1N2N001O000000000000EdEnM]:m1cEmM16\\:R2cEnM]:]2O00O100HfEgMZ:X2gEhMY:X2hEgMX:X2iEhMW:W2jEiMV:X2gEjMY:W2dEkM\\:T2dEmM]:Q2dEoM\\:Q2dEoM\\:Q2dEoM\\:Q2dEoM\\:Q2dEPN[:P2eEPN[:P2eEPN[:P2eEPN[:P2eEPN[:P2eEPN[:P2eEPN[:Q2cEPN]:P2cEPN]:P2cEPN]:P2cEPN]:P2cEoM^:Q2eEjM]:U29L4O1000TEmMh:W21O000\\NWEi0n:UOUEFL31;n:LVEEL22<l:MVEEM11<m:NVEDL22<k:NWECN11>j:NXEBO0Oa0i:LfEACb0g:ITF6m9IUF6m9FUF9n9CUF;Z;0000O1K[CKf<57Kn[e6"}}, "object_label": "bus", "attribute_label": ["color:green", "color:violet", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a large, colorful bus parked on the side of a street. The bus is painted with a combination of green, purple, and yellow colors, making it visually striking. It appears to be a double-decker bus, with two levels for passengers. The bus is stopped at a traffic light, waiting for the signal to change."}, {"question_id": 362, "height": 428, "width": 640, "image": "000000494913.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [235.11, 91.74, 90.21, 78.69], "segmentation": {"size": [428, 640], "counts": "QZR3c05BY<Q2gN8I1O00O2O000O100O100000000000001O000LPElMP;T240lDkMQ;Y2OO1000001O001O0000O10O100000000O2O0001O00001O0000O10000GlDTN12T;m1kDSNU;S2O00HlDWNU;i1kDWNU;i1kDXNT;P20IkDWNU;h1mDWNS;i1lDXNU;g1jDZNV;m11GkDZNV;f1nDVNR;j18000dDVNW;j1hDVNX;j150000O10000010O000bDWNY;j1eDVN\\;j1dDVN\\;j1300O2O0M^D[Nc;d13F:A_bS4"}}, "object_label": "tv", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "size", "answer": "The image features a flat screen TV mounted on a wall, displaying a video game character on the screen. The character appears to be a woman with long hair, possibly a princess or a similar character. The TV is positioned in the center of the scene, and the character is the main focus of the image."}, {"question_id": 363, "height": 427, "width": 640, "image": "000000526751.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [579.2, 204.3, 42.2, 13.81], "segmentation": {"size": [427, 640], "counts": "Rj`71Z=0N3N2N1O2O000000000000000000000000O10O1M4N010000000001O1O000O10001O1O1O0000001O1N2OWT8"}}, "object_label": "boat", "attribute_label": ["color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "color, transparency, size, pattern, pose, texture", "answer": "The image features a small white boat floating on a body of water, possibly a lake or a river. The boat is positioned in the middle of the scene, and it appears to be a motorboat. The water is calm, and the boat is the main focus of the image."}, {"question_id": 364, "height": 427, "width": 640, "image": "000000526751.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [0.74, 149.72, 37.49, 55.88], "segmentation": {"size": [427, 640], "counts": "i5d0h<O7I1O0000000000000000000000O10000eN0[E0h:8mDH\\;o06J=C>B1O001OO100000000000O100O2NUXk7"}}, "object_label": "boat", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color", "answer": "The image features a white sailboat floating on a body of water, possibly a lake or a river. The boat is positioned in the middle of the scene, with its sails down, indicating that it is not currently sailing. The boat appears to be a small sailboat, and it is surrounded by a peaceful and serene environment."}, {"question_id": 365, "height": 427, "width": 640, "image": "000000526751.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [315.53, 136.4, 32.91, 76.65], "segmentation": {"size": [427, 640], "counts": "^TS44T=5M1000000O10000O100N2O100O1]OLnC5n;f000kNjNkF`0T95YFJi9?kEB`::iDWONO1h0_;FgDb0`<A3M1O1OVNK^F5b9K^F5\\;0000ESC8Q=M4KPbi3"}}, "object_label": "boat", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color, pose, material, texture, size, pattern", "answer": "The image features a white boat sailing on a body of water, possibly a lake or a river. The boat is surrounded by several other boats, including a large sailboat with its sails down. The scene also includes a few smaller boats in the background. The white boat is the main focus of the image, and it appears to be a small sailboat, possibly a yacht, as it glides across the water."}, {"question_id": 366, "height": 640, "width": 480, "image": "000000261706.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [131.03, 219.59, 73.24, 55.09], "segmentation": {"size": [640, 480], "counts": "XSb27gc04M2N2N2N2N1O2O0O2O0O101O1O0O2O001O00001O010O010O0010O01O0010O010O10O1O010O1N1011N10O10O0100O0010O1000O10O1O2N1N3L8I3H6N2N2NX`b5"}}, "object_label": "remote", "attribute_label": ["color:gray", "length:short", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a black and white cat lying on a couch, with a remote control placed on the couch next to the cat. The remote control is a TV remote, and it appears to be a standard size, with a few buttons on the front. The cat is positioned on the left side of the remote, occupying a significant portion of the couch. The scene captures a cozy and relaxed atmosphere, with the cat enjoying its time on the couch while the remote control is nearby."}, {"question_id": 367, "height": 640, "width": 478, "image": "000000286182.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [151.12, 193.5, 22.53, 41.5], "segmentation": {"size": [640, 478], "counts": "Uko26fc05\\Oc0M4M2M3O1O100000O100O1L4N2M3N3L8H6Hh]n5"}}, "object_label": "bottle", "attribute_label": ["color:black", "color:tan", "length:long", "material:glass", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose", "answer": "The image features a close-up of a bottle with a red and white label. The bottle is positioned in the center of the frame, and the label appears to be a fish logo. The bottle is placed on a table, and the overall scene is in black and white."}, {"question_id": 368, "height": 640, "width": 478, "image": "000000286182.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, size, texture, transparency", "region_anno": {"bbox": [145.95, 335.58, 67.08, 53.66], "segmentation": {"size": [640, 478], "counts": "j^m26:2lb04l\\O3Pc0a0N2L3N2M3O1O1N2N\\Oa]OI_b04e]OLZb03h]OMWb01l]ONSb02o]ONPb00R^O0na0OT^O1ka0OV^O0ja0OW^O1ia0OX^O0ha00X^O1ga0OZ^O0fa00Z^O0fa01Y^OOga01Z^ONfa02Z^OOea01[^OOea01\\^ONda02\\^ONda02\\^ONda03[^ONda02\\^ONea01\\^ONda02\\^ONea01[^O0da01[^OOfa00Z^O0fa01Y^OOga01Y^OOga02Y^OMga04X^OLia04V^OLja05U^OKla05S^OKma05S^OKna06P^OIQb09m]OGTb09k]OFVb0;h]OFXb0:h]OEZb0<d]OC]b0?_]OBcb0l01O2N2N2M3M3M3N2N2N2N2M4M2MmPT5"}}, "object_label": "bowl", "attribute_label": ["color:orange", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size, color, texture", "answer": "The image features a white bowl filled with a delicious-looking meal, possibly a soup or stew. The bowl is placed on a wooden table, and it appears to be a large bowl, possibly a serving bowl. The meal inside the bowl is accompanied by a spoon, which is resting on the table next to the bowl. The overall scene suggests a cozy and inviting dining experience."}, {"question_id": 369, "height": 640, "width": 478, "image": "000000286182.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "cleanliness, color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [269.18, 370.57, 97.47, 25.2], "segmentation": {"size": [640, 478], "counts": "mSY51lc05L4M2N2M3M201O00010O0001O001O0000001N101O00001N2O0O2O00001O0000001O0000001O0001O000001O00000001O000001O01O00000000001O0000000000000010O000000001O01O000000000001O00000000001O01O0001O001O002MjcU2"}}, "object_label": "spoon", "attribute_label": ["cleanliness:clean/neat", "color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "state:on", "texture:smooth/sleek"], "control_dims": "pose, transparency, state, cleanliness, color, length", "answer": "The image features a wooden table with a spoon placed on it. The spoon is made of wood and has a handle, making it a unique and natural-looking utensil. It is positioned on the table, possibly ready for use or as a decorative element. The wooden table itself appears to be a dining table, providing a suitable surface for the spoon and other tableware."}, {"question_id": 370, "height": 640, "width": 478, "image": "000000286182.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pose, size, state, transparency", "region_anno": {"bbox": [142.38, 474.61, 113.62, 106.42], "segmentation": {"size": [640, 478], "counts": "iSk29dc0:B;J4M4h]OnNZa0V1a^OiNA0ma0Z1`^OfNC1ka0[1c03X^OaNm`0a1P_O`No`0f1l^OYNUa0h1`09G2X^OkM02OOYa0U2h^OVNVa0d1P_O]Nn`0d1R_O]Nm`0d1R_O]Nl`0h1P_OYNn`0i1R_OWNm`0i1T_OVNk`0l1T_OUNj`0n1T_OSNk`0b2N1O101O001N10^O`_OeM_`0Z2c_OeM]`0\\2b_OeM]`0]2a_OcM^`0^2^_OfMb`0l201O000000_O__OcMa`0]2__OcMa`0^2^_ObMb`0o2O00O11O00000000000000O101O0000001N100O1O2O000O2N101N1O2N1O2N2N1N3L301O001N2N2M2O2L4N2N2O1N2O1N2M3O1N2N2N2N3L3O2M2N4L3L5K5K9Am[]4"}}, "object_label": "bowl", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:full/whole"], "control_dims": "cleanliness, transparency, pose", "answer": "The image features a small bowl filled with a dark, possibly chocolate-colored substance. The bowl is placed on a wooden table, and there is a fork nearby. The bowl is positioned in the center of the table, and the fork is located to the left of the bowl. The overall scene suggests a meal or snack being enjoyed."}, {"question_id": 371, "height": 477, "width": 640, "image": "000000290771.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [29.99, 376.31, 42.23, 12.07], "segmentation": {"size": [477, 640], "counts": "Sj>3i>2O0O1O100O1O1O1O10000000000000000000000000000000000000001O00O10000O100N2O1O1O1O1O1OVYW8"}}, "object_label": "book", "attribute_label": ["color:black", "length:long", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, pose", "answer": "The image features a black tablet computer sitting on a wooden table. The tablet is positioned in the center of the table, with its screen facing upwards. The tablet appears to be a small, rectangular device, possibly a smartphone or a tablet computer. The wooden table provides a stable surface for the device, allowing it to be easily used or displayed."}, {"question_id": 372, "height": 428, "width": 640, "image": "000000304404.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [248.14, 123.91, 58.67, 52.9], "segmentation": {"size": [428, 640], "counts": "TQY34W=10O11O100O1EJ_C5m<O11OO10000O100001N100000001O0O100AJfC7Z<HgC8f<1000000O10O0101O000O010000000O011O001OO10O01O100O10O01N3N0O4MiUZ4"}}, "object_label": "baseball bat", "attribute_label": ["color:black", "color:gray", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The baseball bat in the image is made of metal and is being held by a baseball player. The player is wearing a black shirt and is in the process of swinging the bat. The bat is positioned in a way that it is almost parallel to the ground, indicating that the player is in the middle of a swing."}, {"question_id": 373, "height": 428, "width": 640, "image": "000000304404.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, pose, size, state, transparency", "region_anno": {"bbox": [0.0, 0.0, 108.28, 52.33], "segmentation": {"size": [428, 640], "counts": "0a0k<1O000000000000001O00000000000000000000000000000000000000001O000000000000000000000000000000000000000000001O001O1OO100001O0000000000O10000000000O2O1O010O000O2O10O0001N101O001O00001O1O01O01O001O1O1O001O00001O001O1O2MmZn6"}}, "object_label": "umbrella", "attribute_label": ["color:blue", "color:yellow", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:open"], "control_dims": "transparency, color, pose", "answer": "The umbrella in the image is a large, blue and yellow striped umbrella. It is open and providing shade for a group of people standing underneath it. The people are gathered around the umbrella, with some standing closer to the front and others further back. The umbrella is positioned in the center of the scene, creating a focal point for the group of people."}, {"question_id": 374, "height": 375, "width": 500, "image": "000000333772.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [71.06, 184.66, 119.59, 112.01], "segmentation": {"size": [375, 500], "counts": "lbj03b;5L1O1O2O1N1O2N2O0O1O2N1O2N100O1O00001O1O00O20O0O10O11O1OOPFVOV9j0gFZOX9f0iFVO[OOl9l0iFUOY9j0hFXOV9h0jFYOU9g0nFWOQ9j0kFUO[O0j9k0]FTO38^9d0`FVOH>h9;aFK]94eF_OD2g9>fFNY91hF0X9NiF[OAd0f90jF\\O@e0e9NlF5U9JkF7T9HmF8T9FmF;R9DPG;Q9DoF=P9BRG=n8BSG?l8ATG?k8AVG`0e8UOcF:j0a0b8UOcF:l0a0a8@aG`0_8YOcFOo0h0^8^OdGa0]8[OfGd0\\8[OdGd0]8[OdGd0^8YOdGg0f9N2O1O1O1O10O0000O101O01O0000001gE_O[9a0eF@[9?aF@[O2S:>cF@ZO2S:>cF@[O4o9:hFDWO2P::jFMT92mFNS92mFNS90oF1o8ORG1n8NSG3l8MTG3k8MVG4i8KXG6h8IXGHoN<i9KYGInN=i9HZG;g8B\\GMjN10;i9EeG:l91N20O01O0010O003NO10ChD9[;1O01FeD7Y;JgD6Y;KgD5Y;IiD6];00O1NRl`3"}}, "object_label": "keyboard", "attribute_label": ["color:black", "color:gray", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, material", "answer": "The keyboard in the image is a computer keyboard, and it is placed on a wooden table."}, {"question_id": 375, "height": 333, "width": 500, "image": "000000351609.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "color, length, material, pose, texture, transparency", "region_anno": {"bbox": [202.04, 0.75, 57.63, 71.09], "segmentation": {"size": [333, 500], "counts": "lZR22[:2N1O1O1O2N001O1O1O1O001O1O001O1O1O001O1O2N1O1O2N1O2N3M2N2N3M4L2N4L3MjN^Gd0_8ZOhGc0V8[OnGf0o7WOWHi0h7SO]Hl0d8O1O0O1N2N2N2N2O1N2N2N3N2M2N2NiY^2"}}, "object_label": "spoon", "attribute_label": ["color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, transparency, material, texture, length, color", "answer": "The image features a wooden spoon resting on a window sill. The spoon is made of wood and has a handle, making it suitable for stirring or mixing ingredients. The spoon is placed on the window sill, possibly for easy access or to keep it within reach. The window sill provides a convenient surface for placing kitchen utensils and other items."}, {"question_id": 376, "height": 555, "width": 640, "image": "000000002685.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [148.5, 255.2, 24.6, 35.4], "segmentation": {"size": [555, 640], "counts": "daa23Wa03M3M2O1N3N101O2NO2O1N1O2N1OU_OGe`08Z_OKe`03[_ONg`0NV_O8k`0EW_O;l`005J3M20h^O0Ta031O1NcVk7"}}, "object_label": "bottle", "attribute_label": ["color:black", "material:glass", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material, texture, pose, color, state", "answer": "The image features a collection of wine bottles, with one of them being a red wine bottle. The red wine bottle is placed in the middle of the other bottles, which are mostly black in color. The bottles are arranged in a row, with some of them standing upright and others lying horizontally. The bottles are placed close to each other, creating a visually appealing display."}, {"question_id": 377, "height": 427, "width": 640, "image": "000000014038.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [501.8, 291.71, 43.15, 14.81], "segmentation": {"size": [427, 640], "counts": "YVa63X=2N1O11O1O00O1010N10O100O0001O0000000000000000O1001O0000O100000000000000000000LLPC5P=JQC6R=00O2NolV1"}}, "object_label": "book", "attribute_label": ["color:white", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "material, transparency, texture, pose, state", "answer": "The image features a stack of books, with the top book being red and the bottom book being white. The stack of books is placed on a table, and the books are arranged in a way that they are leaning against each other. The stack of books is quite tall, with the top book being the tallest and the bottom book being the shortest. The books are neatly arranged, creating an organized and visually appealing display."}, {"question_id": 378, "height": 427, "width": 640, "image": "000000014038.jpg", "category": "description", "question": "Describe the microwave in the following image in detail.", "dims": "color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [160.48, 286.17, 73.61, 38.61], "segmentation": {"size": [427, 640], "counts": "dbR2?k<=D;D1000000000000000000000O11O000000O20O00000000000000000000000000000000000000000000000000000000O100000001O000O10001O01O1O000O2O0O100000O2O00002UOmCL21o<NcoX5"}}, "object_label": "microwave", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, texture, pattern, state", "answer": "The image features a black microwave oven sitting on top of a wooden cabinet or shelf. The microwave is placed in a corner of the cabinet, and it appears to be an older model. The microwave is surrounded by various items, including a bowl, a cup, and a bottle. The bowl is located on the left side of the microwave, while the cup is situated on the right side. The bottle is placed above the microwave, slightly to the right."}, {"question_id": 379, "height": 365, "width": 500, "image": "000000016249.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [427.01, 172.04, 47.25, 83.67], "segmentation": {"size": [365, 500], "counts": "nPh4<n:4EE^E?c:6011NO2N4Lg0fE]N\\9P2J1NGlF]NR9b1QGdNh8[1YGdNg8\\1ZG[NJ0n8j0PGLc9WO^Fi02Oc90]F1b9O^F1b9N_F4a9IaFKLL_99eFKL9n8YOQGc04LM8R9LQGLN7Q9MQGL32m81PGM6Ok83oFO>Ef89lF3o9LQF5P:IoE8S:FmE;e9[OcF9G>e9YOdF:E?f9WOcF0G906OI7KT9OmFNJh02AM3T9JnFe04Lo8^OmFd07Mm8_OjFc0<Mk88YGFi86\\GGf86]GHg82fGC]89eGF]87eGH_83`1Nnh9"}}, "object_label": "chair", "attribute_label": ["color:black", "color:brown", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "material, pose, state", "answer": "The chair in the image is a wooden bench with a metal frame. It is located in a public area, possibly a park or a waiting room, and is currently empty."}, {"question_id": 380, "height": 437, "width": 640, "image": "000000039484.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [604.29, 11.75, 27.73, 11.67], "segmentation": {"size": [437, 640], "counts": "eVR81c=2N10001O0O100000001O0O100000O100O1000000O01N200O10O2KcBOd\\3"}}, "object_label": "airplane", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, texture, transparency, state, material, pose", "answer": "The image features a large airplane flying in the sky, with its wings spread out. The airplane is positioned in the middle of the scene, and its wings are visible on both sides of the image. The airplane appears to be a commercial jetliner, possibly a jumbo jet, as it is quite large and occupies a significant portion of the sky."}, {"question_id": 381, "height": 437, "width": 640, "image": "000000039484.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [598.96, 358.91, 9.0, 26.31], "segmentation": {"size": [437, 640], "counts": "Tbo71Y=?K1M4O2N4L01IXC^Oka>"}}, "object_label": "chair", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:full/whole", "texture:rough"], "control_dims": "material, color, state, texture, transparency, pose", "answer": "The chair in the image is a black chair, likely a part of a dining table setup. It is positioned in the middle of the room, with a person standing behind it. The chair is placed in front of a wall, and the person standing behind it is wearing a black jacket. The scene appears to be a casual gathering or a social event, with the person standing in the background possibly waiting for others to join them or engage in conversation."}, {"question_id": 382, "height": 428, "width": 640, "image": "000000045472.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [180.44, 383.01, 62.8, 44.99], "segmentation": {"size": [428, 640], "counts": "Qd[25T=8I5L5K6J5K2O0O100O1O10000O100O10000O100000000O10000000000O10000000000000000001O000000000000001O00001O0000001O1O001N2M2L6G:]OWC6`nU5"}}, "object_label": "cup", "attribute_label": ["color:red", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency, material, pose, texture, state", "answer": "The image features two red cups, one of which is filled with water, while the other is empty. The filled cup is placed on a table, and the water inside it appears to be murky. The empty cup is positioned next to the filled cup, creating a contrast between the two. The cups are placed on a surface, possibly a table or countertop, and they are the main focus of the image."}, {"question_id": 383, "height": 490, "width": 500, "image": "000000058111.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [147.8, 10.1, 109.46, 47.5], "segmentation": {"size": [490, 500], "counts": "lfY24T?3M4M1O101N101O10O01O001O0J7O00]O`A<`>D`A=`>601O[OaA?`>60O10O0010YOaAa0_>@aA`0_>_OaAa0_>600O0010ZObA>^>AdA?\\>@dA`0\\>@eA`0[>_OeAa0[>@eA`0\\>_OdAa0[>_OeAa0[>_OeAa0[>_OfA`0Z>@fAa0Z>_OeAb0[>^OcAc0]>^ObA95GX>0cA4ON0L32\\>ObA41N3O[>NbA0421NZ>1hA0b>1]AOc>2\\AMg>1XA0h>4TALl>4501O00n@Ln>5QAKo>4RAMm>3RANn>2RANo>1QAOo>1QAOo>1RAOm>1SAOm>1SAOm>1SAOm>1TANl>2TANl>2TANl>2SAOn>0QA2n>OQA1o>ORA0n>OSA1m>OSA1m>OSA1m>OSA1m>600000O101KPANP?1PA0P?0PAOQ?1o@OQ?1o@NT?0l@0f^j3"}}, "object_label": "book", "attribute_label": ["color:violet", "color:white", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, material, texture, pose, state", "answer": "The image features a close-up view of a book with a blurry background. The book appears to be a collection of papers, possibly a notebook or a collection of documents. The pages of the book are visible, and the book is open, revealing its contents. The blurry background adds a sense of depth and focus to the image, emphasizing the book as the main subject."}, {"question_id": 384, "height": 428, "width": 640, "image": "000000062554.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [1.93, 18.8, 638.07, 403.9], "segmentation": {"size": [428, 640], "counts": "h;a1k;0ZG`N`5a1]JgNPMJ00000O43ML10<2U6_1]LfNRMI000092=Nl5a1]LaNa5_1_J`Nb5`1]JbNb5^1\\JeNZNJn5a1jKbNb5^1`J_Na5a1U3000UG_NUM0a8a1U30000000PGdNP6\\1P30001O001O00O01000oFbNjN0b5_1e4O00000OgHcN_2OTI]1a;cN_D\\1i;O1O10nFfNR6Y1Q30O10000000OSDhNh;X1XDhNh;W1YDiNg;W1XDjNh;U1YDkNg;U1XDmNg;R1ZDnNf;Q1[DoNe;Q1ZDPOf;P1ZDPOf;P1YDQOg;o0XDROh;n0XDROh;m0XDTO]2Ii6S1jFTO]2Hj6S1jFUOg;j0YDWOg;i0YDWOg;i0XDXO[4Gm2P1iHYOZ4Gm2P1iHYOg;f0ZD[Oe;e0[D[Oe;e0ZD\\Of;d0ZD\\Of;d0YD\\Oh;d0XD\\Oh;c0YD]O`:EaFn0nN^OR4EW20PJN;n0]O_OS4CU22PJN;n0\\O@`:DbFk0nNB`:CbFk0nNBS4BT22kJj0nNB]2ASO3g40kJj0nNBQ4DV20mINe0k0XOC^:D`E46I:k0CD]:AaE94H;j0CDo3B\\28gIH<i0AFP4AU20lI90H>h0AFP4AU21jI8i0`0WOG\\:AbE:j0?XOF\\:KbEEk0i0WOH\\:JbEFj0g0YOI\\2^O^5<SHF2Nd0h0^OJZ:JbEFj0f0YOK[:IbEEk0g0XOKZ:M^F7XOMZ:L^F7XOMU2\\Oj5a0iH6XOMY:M_F5YONX:IeEDj0e0XOOY:HfECi0f0XOOY:IdECk0e0WO0V2ZOlM1g7`0PI5WO0Z:HdEDj0d0XO0Z:CdEI10i0d0XO0Z:BfEIO1i0c0XO2Z:AfEMi0`0WO2Q4ZOR29kILk0?WO2R4YOQ29mILi0?WO4Y:AhEJi0a0UO5U4WOn18oIKi0`0VO6S4XOQ25lIMk0`0UO6V2WOlM28Nh02S53kIMl0a0TO6]2XOSO1f42jILn0b0SO7_:XOcF`0oN8f;HYD9g;GYD9U2WOW7`0dF9U2VOX7a0bF:h;FWD;h;EYD;V2TOmM1S9?jF<V2WOiM09NT11j5=jH>V2UOjM0j10\\5=jH>h;BXD>g;CXD>h;AYD?V2TOkMNa03k7<cG?V2SOlMOa02j7=cG?V2ROeN1b7=dG`0T3SOX5<eGa0[2SOTN3k79fGa0T2ROkM75IL5NKX8=jGa0T2ROlM3=2m78eGb0S3SOY5;dGb0U3QOPM0K1l7<THb0U2RObN2YO:j70VHb0U2SOkM34LM4M9l7OVHb0U2SOkM0MO70N3L2T87mGc0k2QOZM0K3U89jGd0l2QOZMNK4T8:kGc0^2TOfMO05R85jGc0W2ROhM52N06U82jGc0W2POkM6OO23T85hGd0c2oNcM12OI0X8=gGd0d2nNcM11OJ1X8`1WJcNbM113V8Y1nIaNkM5M032V83gGh0`2QObM113V83gGh0d2lNaM4O4V8Y1aJcNYM4V8Y1YJaN_M5O3X8X1VJ\\Oi5]OhGk0`2Gh5^OhGk0b2mNaM3M5X8OiGl0b2kNdM1K8V80iGl0`2nNbM2M5W80jGk0_2PO`M203W80jGk0`2nN`Ma0V8FjGk0a2mNdM=Q8T1\\J^NcM>Q8T1ZJXOf5h0WJ[Oi5e0ZJXOf5h0lJfNT5Z1nJdNR5\\1[J^NfMNM8R8\\1ZJaN_M232S8\\1[JhNcMLR81jGo0b2oNhMOl73jGo0b2oNhM0k72kGo0b2POdM2o7NlGP1`2Dd5\\OlGP1a2UO^MOT8LmGP1j2jNYM9o7LnGR1U3ZOc4CYHS1j2gNYMg0a7@\\HR1h2jNZMh0^7\\OaHQ1h2kNYMh0]7\\OaHR1j2iNYM`0d7EXHS1l2gNXM2KNT86mGS1j2jNXM9NCj77VHS1c2eN_Mo01RO_77^HS1h2CR5ZOVHS1h2lNXMJO<o7KRHS1h2kN]M5i7NRHR1h2lNWM:n7HSHR1a2eNcMj0LWOi76WHV1h2jNWM;m7ESHW1k2gNYM3NJk75SHW1l2eNYM1KN20k7e1nJ^NWM;k7GSHV1k2]O[MXO]75]HS1n2lNSM6Q8KnGQ1P3mNUMNR85iGo0Q3iNPM160Q8]1kJgNRMOR84iGj0n2nNWM6M1T80lGh0U3WOoLKR86iGf0\\3VOS5S1oJmNQ5R1oJoNQ5P1oJTOoLI;0W66PId0b3WOn45`Gd0V<\\OjCc0V<^OkCa0c3WOl48aGa0b3YOl46bGa0U<_OjCa0W<91OYIPOT1P1WMROcM0U5n0lNROS1o0mNQOS1o0nNPOgJ1n5o0[OPOgJ2m5n0[OQOhJ2l54lI>a5\\OfJ3l5l0^OQOfJ3k5m0_OPOfJ5i5k0@ROgJ4g5j0BUOdJ1j5j0BQOhJ6e5i0DmNjJ:c5h00YOOg01ZONJTJd0n5CMIUJd0n5DLHVJd0c5VOfJ`0_5b0JPOfJ?_5a0JRO_JN3`0b5a0LWO`J9c5`02RO\\J=b5a06nNXJa0b5`07oNWJa0b5`07POVJ`0c5C\\Jf0j5XOWJ?c5C\\Jf0j5XOVJ?e5C[Je0k5YOUJ?f5>6ROTJ?g5?4SOUJ>g5?4FM93TOUJ?g5=5SOVJ>f5=5UOVJ>e5<WNTOmM2WN?e5:WNUOmM2WN?e5:5WOVJ`0d596XOUJ`0c5:7VOVJa0b598VOVJa0b598VOVJa0b598VOVJa0b599TOWJb0`5:YNTOPNOXNc0_5;WNTORNNXNc0_5;VNUORNOXNa0`5;VNTOSN1VN?a5>VNPOUN2TN`0a5>6SOYJ>a5a0TNoNVN2UN=b5b0RNPOWN1UN=b5c03PO[J=b5c04nN[J?a5d0;[OEf0lMmNaNOSN>a5e0kMnNaN0RN=b5e0kMnNaN0RN=b5e01nN]J<c5g0OmN^J<d5g0LnN`J:_5CaJU1`5nNaJ9^5E`JT1a5nNaJ7_5H^JT1c5lN`J7`5I\\JU1n3jNdM1bN7_5I^JU1m3jNcM2cN6_5I^JU1m3jNcM2cN6]5K`JS1m3jNcM2cN6]5K`JT1m3hNcM3cN6\\5LaJS1m3hNdM3bN5\\5N`JR1m3iNdM3cN4[5OaJQ1m3jNcM2dN4Z50bJP1m3jNcM1eN5Y50bJP1m3jNdMOfN7V5[1`N_NoM7`3Y1bN`NcMNgN:S5GdJ_1n3bNdMNgN;R5EfJ`1m3bNdMOfN:S5FeJ^1o3bNdM0eN;R5V1eN_NdM1dN:R5V1gN_NcM1dN:R5U1gNaNbM1fN8Q5U1iNaNaMOgN;o4LgJo0U6UOSOMhJn0U6UOROMjJm0U6VOQOGkJ0OR1V6WOPOGkJ0OQ1W6XOoNGkJ0OQ1W6YOnNLkJj0X6[OlNKlJi0Y6\\OkNKlJi0X4oNfM>U3JmJh0[6]OhNKmJh0[6^OfNJPKg0[6_OdNJRKg0Z6_OdNJRKg0Z6_OdNJRKh0Y6_OdNISKh0Y6_OdNISKj0W6]OfNISKl0U6[OhNJRKl0U6ZOiNBPK52Q1T6XOhNJUKP1Q6VOiNKVKQ1P6TOiNKWKQ1P6TOhNLXKP1P6TOhNLWKQ1R6ROgNMWKP1S6UOcNLZKo0T6UOaNL[Ko0T6UOaNL[Ko0T6VO_NL]Km0U6WO^NL]Km0U6XO]NK^Km0V6WO\\NL^Km0V6XO[NK_Km0V6XO[NK_Kn0V6WOZNK_Ko0W6]ORNEgKm0X6ClM@lKm0X6FhM^OPLl0X6GfM^ORLk0X6GfM^ORLj0Y6HeM^ORLj0Z6GeMQOPL91o0Z6GeMoNSL9OQ1Y6GeMoNSL9OP1Z6GdMQOSL8OP1Z6GdMQOSL8OP1[6EdMSOQL90n0\\6EdMTOPL9On0^6EcMUOoK71o0]6DcMWOnK72n0^6BbMZOnK72k0_6DaMZOnK72k0_6D`MZORL6Ml0b6D_MZORL^1_6WO`MZORL_1_6TOaM]OPL_1_6SObM^OoK_1`6QObM@nK^1a6ROaM@mK_1b6QOaMW1_2gNbMZ1^2eNbM[1_2dNbM\\1^2cNcM]1^2`NcMa1^2\\NcMe1]2ZNdMe1]2ZNcMg1]2YNcMg1^2XNbMh1^2WNnK1gNLaNa01b0i6oNnK5hN:bNa0d9VOkG8aNb0b9ZOkG4bNc0a9[OmG2bNc0Z8mNgHb04^OmNa0Nb0T8SOiHb06XOoNa0Nb0S8TOjHa06XOnNb0Oa0Q8VOkH`06YOnN`00a0P8WOlH>6[OnN?0a0o7XOlH>7ZOmN`02>n7[OkH>7ZOnN?2>n7[OjH?8YOoN>1?n7[OjH?8XOQO>Na0n7\\OiH>:WOPO?O`0h7BnH9:WOQO>O`0o6mNeIg009;VOQO>0>P7nNcIh009<LQO5P7nNYI4Gg0a09=IRO5[72TI2>GSO5R7<ZIK?EUO4R7<XIN`0BWO3Q7>VINb0AVO4R7=TI1b0_OXO2U7>mH4e0\\OYO2V7W2]IiM]OOW7Y2XIkMAKX7Z2WIkMAJY7\\2TIkMCIZ7[2RIlMEH[7^2iHgLJS13GZ7i2cH`M3G[7h2bH`M4G[7i2aH`M4G\\7g2aHbM3F]7g2aHbM2G_7f2^HcM4F_7f2]HeM4D`7g2\\HdM5E`7g2ZHcM7F`7i3bHUL_7j3bHVL^7j3bHVL^7i3cHVL_7h3aHXLb7a2SHlM<Bb7a2SHlM<Ca7a2SHkM8QOIb0g7^OZHT3MlM9POIb0n7`2PHnM`0Aa7_2PHnMa0B`7_2PHoMa0A_7_2PHoMc0B]7^2QHPNb0A_7^2nGQNe0XOe7g2eGQN\\9n1dFQN]9n22N1PO`FSNc9i1_FUNc9j1^FUNc9k1[FVNg9i1XFXNi9f1XFXNl9e1SF[No9e1QFZNP:f1oEZNR:d1nE]NT:b1lE]NU:c1kE[NX:d1hE[NZ:Y23WOdE^N^:W25TO^EdNf:Y1ZEgNf:Y1[EfNb1CY7g1SGfNe1FV7d1UGeNf1IT7_1UGhNj1JS7Z1UGiNi1OP7X1XGgNj11n6W1YGgNj12n6T1YGkNi11n6T1UGnNn1Nm6S1UGPOo1Mm6R1SGoNR2Ol6Q1RGnNS22n6l0PGnNW25l6DPGg0L@2NW27a6DeGe0C\\OO121W29_6FdGe0C@b25W6H`Ge0G^Ob25W6IcGi0V2^OW6LaGd0Y2@V6LaGd0Y2@V6MaG>]2ER6MdG8]2Ko5MnGHY2;i5NQK0P57iJIW5HWG;a3MX5HWG;a3LY5IUG<b3KY5IUG<b3JZ5JTG<b3I[5;eJE[5;eJD\\5<eJC[5=eJC[5=eJB\\5>dJB\\5>dJA]5?cJA]5?cJA\\5`0dJ@\\5`0dJ_O]5a0dJ^O\\5b0dJ]O]5c0f3HYCKg<=00000HYCKf<6ZCJf<>00001O0000O10000000000001N1MaFCU6`0hI@X6a0gI_OY6a0X301000001O0N_FCX6;iIEW6<hIDW6>hIBX6>[30M_O[Ca0[3_Ol50iFa0h<00OkF@a5>_JCa5<`JD`5=_JCa5>b3A[C?e<BZC=l3Bk42XG=m3Ci40ZG=m3Dh4O[G=m3Eh4M[G>m3Fg4K^G=^1Cl05X6K^G=]1Ec0OTN6\\8I`G=]1El05W6I`G=]1El06V6HaG=l3La4IbG;m3M`4HbG<Y1BZ1<i56bKJ^46ZJ^O[M2P1;Z7EeG<j2CXN<X7DhG<m31[4BhG=n2CRM1f0?`7@jG=R3DdM?`7@jG=n0DQ10gN`0^7@lG<S3CcMc0[7@nG:n37S4OmK4P4L[K]OZMg0Z7L\\K]OhL1=g0^7[OSH;^3CQMi0\\7XOXH:[3EQMl0X7UOaH5X3IPMQ1S7POfH6V3IQMS1Q7mNdH0N7`3JhLS1T7nNeHOM7c3HgLU1S7nNfH7n3k0\\3oNeH4h3I[LT1X7oNcH6j3H[LS1W7\\O^LBZLR1X7\\O^LBZLR1X7oNfH4R4n0W3mNiH4Q4n0V3oNeH6U4k0V3]OiLc0W3]OiLc0W3ROdH1W4m0T3QOfH1W4n0S3[OmLe0S3[OnLd0R3\\OoLd0P3POnHM40`3S1^3nN[I4W3m0^3oN[I4W3n0]3mN]I4W3o0\\3nN\\IO\\O0l3S1\\3QOkHMZ4S1i2QOlHM[4R1i2YOWMg0i2YOWMg0i2YOWMh0g2oNlH2]4o0g2kNPI6Y4o0g2jNQI8W4n0o2SOQMm0h2jNPI8Y4n0g2kNPI4[4R1d2jNnHOO5_4R1d2jNnH7^4o0d2jNoH6]4P1d2jNoH5^4Q1c2jNRI1]4U1_2kNUIN^4V1]2lNSI1_4S1_2jNRI5^4R1^2kNSI3_4R1^2kNmMU1S2kNQINh4W1W2kNQI2d4S1[2kNRI4`4R1]2jNSI0e4U1X2kNoMU1Q2kNoMV1P2jNUINe4X1V2iNUI0e4W1U2kNUINg4V1T2lNRNT1n1lNRNT1n1lNUINh4U1S2mNUINh4V1R2lNVINh4V1R2lNTNT1l1lNTNT1k1mNUNS1k1mNXILg4W1Q2mNWIMh4V1Q2mNVIMj4V1P2mNUINk4U1P2SOPNl0P2TOPNl0P2SORNl0n1oNYNo0g1QOYNo0g1QOYNo0g1QOYNo0g1POZNP1f1POZNP1f1POZNP1f1QOYNo0g1ROXNn0h1QOZNn0g1POZNP1g1oNYNP1h1oNZNP1e1QO[No0e1PO\\NP1P7O10005K3MaC"}}, "object_label": "dining table", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "state:covered", "texture:smooth/sleek"], "control_dims": "transparency, color, texture, material, pose", "answer": "The dining table in the image is filled with a variety of food items, including several plates of broccoli and other vegetables. There are multiple bowls containing different types of food, and a spoon is placed on the table, likely for serving the dishes. The table is set for a meal, and the food appears to be ready to be eaten. The arrangement of the food items and the presence of the spoon suggest that the table is prepared for a group of people to enjoy a meal together."}, {"question_id": 385, "height": 480, "width": 640, "image": "000000067616.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [345.37, 381.8, 23.01, 39.54], "segmentation": {"size": [480, 640], "counts": "PdQ51`02l=NSB3m=2mA0Q>0gA9Y>FhA;3Je=?ZB@f=`0]BYOj=e0UB[Ol=Q1LO000K5UOQB?U>AQB6R>JoA3S>MmA3IMS>1SB=i=IPB;m=:20010ZOUB8Y>O:FQSo3"}}, "object_label": "chair", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The chair in the image is a metal chair with a white tablecloth covering it. The chair is positioned at a dining table, and it appears to be empty. The table is set with a white tablecloth, and there are two vases on it, one near the center and the other closer to the edge. The scene suggests a dining setup, possibly for a meal or a gathering."}, {"question_id": 386, "height": 480, "width": 640, "image": "000000068833.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [277.97, 205.9, 32.25, 41.9], "segmentation": {"size": [480, 640], "counts": "k`R44l>7I6G9I3M3N2M2M20001O01O2N001OLnNZBR1c=QO]Bo0c=QO]Bo0c=QO]Bo0c=PO^BP1c=nN^BR1b=nN]BS1g=12NInNcBo0g=00O1L5M2L4F:J[Pj4"}}, "object_label": "bowl", "attribute_label": ["color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, transparency", "answer": "The image features a small, golden bowl sitting on a table. The bowl is made of a material that resembles wicker, giving it a unique and decorative appearance. The bowl is placed on a table, and it appears to be empty. The lighting in the image is focused on the bowl, highlighting its intricate design and texture."}, {"question_id": 387, "height": 480, "width": 640, "image": "000000068833.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [441.57, 29.99, 34.83, 39.19], "segmentation": {"size": [480, 640], "counts": "\\U`67g>5K4L3N2N2O1N2N101N10001O0000O1000000O101O1N1O2N3M2N3L8FeW^2"}}, "object_label": "clock", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "material, color, state", "answer": "The image features a small, round clock with a green face and a yellow background. The clock is placed on a wooden table, which is the main focus of the scene. The clock's face is positioned towards the top of the image, and its size is relatively small compared to the wooden table. The clock's design and placement on the table create a simple and elegant atmosphere."}, {"question_id": 388, "height": 427, "width": 640, "image": "000000133418.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [386.64, 267.68, 253.36, 159.32], "segmentation": {"size": [427, 640], "counts": "SZS51Z=0I72IdV>3^iA1N1O2N1O2M2O1O2O0100O010O01O0100O01O01000O010O10O01O0100O10O01O010O010O1O01O1000O0010O0010O010N1O2OSCGi<>O000YC@d<=ZCGf<`0O10O0B^C4a<L`C3`<MaC3^<NbC3\\<MeC3[<LeC5Z<KgC5X<LhC4W<LjC4U<LlC5S<JnC6Q<JPD6o;JRD6m;KTD4k;LVD9d;G\\D9d;G]D8d;G^D8a;HaD7^;IbD8];HeD7Z;IgD7X;IiD8U;HmD8Q;InD9P;GPE:o:FPE<o:DlDc0R;]OkDh0T;WOjDn0S;ROkDQ1T;oNjDT1U;lNjDV1U;jNiDZ1U;fNiD^1U;bNjD;Mb0X;SOjD;0c0T;P1O1O]NmDP1Q;POnDR1P;mNRET1m:f0O2N1O1O1O1O1O1O001N2O1O1O1O1O001O1O1O1N2O001O1O1O001O1O001O001O001O001O1O00001O001O0010O0001O000001O000000001O00001O0000001O00001O00001O00001O001O0ImEVMT:i2lEWMT:j2lEUMT:k2mETMT:k2kEVMV:o2001O001O001O1O001O001O1O001O1O1N2O1N2O0O2O1N2N2N2O1N3M2N2N2N2NPE"}}, "object_label": "tennis racket", "attribute_label": ["color:blue", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:dry", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The tennis racket in the image is blue and white, with a blue handle. It is being held by a man who is playing tennis on a clay court. The racket is positioned in front of the man, ready for use during the game."}, {"question_id": 389, "height": 426, "width": 640, "image": "000000171382.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [114.38, 72.89, 12.68, 20.69], "segmentation": {"size": [426, 640], "counts": "T`_12V=?C1N01O00O2OE\\C1d<LeCO[<1eCN\\<1?0\\he6"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "transparency, pose, color", "answer": "The image features a traffic light with a yellow light illuminated, indicating that the light is about to change to red. The traffic light is located on a pole, and it is positioned in the middle of the scene."}, {"question_id": 390, "height": 426, "width": 640, "image": "000000171382.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pattern, pose, state, transparency", "region_anno": {"bbox": [32.57, 177.66, 16.04, 30.6], "segmentation": {"size": [426, 640], "counts": "Z`=2V=3M3O1N1N3E:N2O1J63M002M3N3L6_O[C2g_f7"}}, "object_label": "backpack", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed"], "control_dims": "transparency, pattern, pose, color", "answer": "The backpack in the image is black and appears to be a messenger bag. It is worn by a person who is standing on a wooden floor. The backpack is positioned on the person's back, with the strap across their chest. The bag is likely used for carrying personal belongings, such as books, a laptop, or other essentials."}, {"question_id": 391, "height": 640, "width": 480, "image": "000000189436.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [82.75, 108.32, 72.73, 70.85], "segmentation": {"size": [640, 480], "counts": "agg1g0Xc03P]OCYb0T1N1O1O1O2N1O2N1O3M4L1O0000000O1000000000000000000000O1000000000000000000000000O100000000000000000O1000000000000000O1O1I7L4eNo]Oc0Ub0VOX^Oa0ib0I6Kc[Z6"}}, "object_label": "tv", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "pose, transparency", "answer": "The image features a black television screen with a blank screen, likely displaying no content or a black background. The television is positioned in a room, possibly a living room or a store, and is mounted on a wall. The screen is the main focus of the image, and the rest of the room or store appears to be empty or devoid of any other objects or people."}, {"question_id": 392, "height": 433, "width": 640, "image": "000000192670.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [0.73, 118.79, 162.94, 77.78], "segmentation": {"size": [433, 640], "counts": "k3o0b<1O001O1N2O1O001OO1H8000]C[OZ<n000OChCXOc<g04001OO1LXC_Oh<`0ZC_Of<a0ZC^Og<b0YC^Og<9=K5O10000O10001O000000O2O00003lBNc<5WCMj<=0001O1O001O01O0100O1O4L2M4M2M3N3M2N4L?A6K0O00O10000O2O000000001O001Oe0[Oc0[O^<FnC2N1PCCN2g<;ZCIg<6YCKf<5ZCKg<4YCLg<4YCLh<3YCLg<4YCLh<3XCLj<3UCNl<1TCNm<2SCNn<1SCNm<2SCNn<1RC0m<OTC1l<OTC1k<0UC0l<OSC2e<JbC1H5f<JbC<]<DcC;^<EaC<_<DbC;^<FdC8[<HfC7Z<IeC8]<J^C7c<FWC326e<G]C2O5e<I\\C3N4m<LSC4m<LSC5e<H]C4L4h<I[C3M3h<K[C2M2i<LZC;f<EZC;f<E[C:e<E\\C:e<F[C:f<EZC;f<EZC:g<FYC:g<FXC<g<DYC<h<CXC=o<0VCFZ<<dCF[<U1^CROg;^1N000001N1O1\\NZD[1h;dNZDY1h;gNYDT1j;mNUDS1l;mNSDNNQ1P<QOWDn0i;ROXDm0h;TOQDM1o0m;VOPDL4m0l;[OUDc0m;\\OTDc0l;]OVDa0i;@XD>i;^O\\D`0d;A^D=b;B`D<a;DaD9`;GaD7a;GcD4`;KS11kBLk<4PCL11Xe[6"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:off", "texture:smooth/sleek"], "control_dims": "color, state, pose", "answer": "The car in the image is a blue sedan, parked in a parking lot. It is positioned next to a chain-link fence, and there is a woman sitting on a chair near the car."}, {"question_id": 393, "height": 640, "width": 480, "image": "000000233238.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [232.76, 491.04, 71.43, 144.01], "segmentation": {"size": [640, 480], "counts": "`Ze4b0Tc0a0G5J4K4M4M3H8K4M3N3L3N3M2M4eNaNP@b1l?[1O2N10001N10000O2O00001O001O00000000001O01O0001O01O010O1O3kL\\@h1Qa0M2N2N3M3M2N3M3M2N1N4M3L5K5I6K7I7H8H<^O[Q^3"}}, "object_label": "bottle", "attribute_label": ["color:brown", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color, pose, transparency, texture", "answer": "The image features a bottle of sauce, possibly ketchup or mustard, placed on a table. The bottle is made of glass and has a white label. The bottle is filled with a dark liquid, which is the sauce. The table appears to be a dining table, and there is a bowl located near the bottle."}, {"question_id": 394, "height": 640, "width": 480, "image": "000000233238.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, length, pattern, texture, transparency", "region_anno": {"bbox": [1.58, 332.9, 478.42, 298.94], "segmentation": {"size": [640, 480], "counts": "jT11dc0`3iL2O1N2O1O1N2O10000000000000000000000O100000000000000O10000000000O1O1O1000000000000001O0000YNRLiA`0P1]3U=iLkBW3T=jLlBV3T=jLlBV3S=kLmBU3S=kLmBU3R=kLPCT3P=lLPCT3P=lLPCT3P=lLPCT3P=kLRCT3n<lLRCT3n<[LQB3R1b3m<YLTB4o0c3m<YLTB3P1d3l<XLVB3o0d3k<YLVBOGNY1j3j<YLVBNT1i3f<YLgCg3X<[LgCe3_;VL_C5R1e3^;YL^C2T1e3\\;\\L_C0T1d3\\;^L_CNU1d3Z;aLaCJU1e3Z;bL`CIV1e3X;cLcCHU1e3W;dLdCHU1c3U;gLfCFU1c3S;hLiCET1c3Q;iLlCDS1c3P;jLmCCS1c3n:kLPDCQ1b3n:lLPDCR1a3l:nLRDAR1a3j:oLUD@Q1a3i:PMVD_OQ1a3i:PMVD@P1`3j:oLWDAo0`3j:oLWDAo0`3k:mLWDCn0`3k:lLXDDm0`3l:iLZDEk0b3l:gLZDGj0b3l:fL[DGj0c3l:dL[DHj0d3l:cLZDIj0d3o:_LXDLj0e3P;]LVDNj0e3Q;[LVD0i0e3R;ZLUD2h0d3T;XLVD2g0f3Z<ZLfCf3Z<ZLfCf3l9ZLcFNBh3h9_LdFIDh3f9cLeFDEi3d9fLfFAFi3c9hLeF@Hh3a9jLgF_OGg3a9kLhF_OFf3_9PMiFZOGg3^9RMjFWOHk0bNa1k:_NjFUOIi0fNa1f:bNkFTOIh0gNb1d:cNlFSOIh0gNb1c:dNmFROIh0gNb1c:dNmFQOJi0fNb1a:fNPGmNJj0gNb1^:iNPGkNJk0hNa1]:jNQGjNJk0hNa1\\:kNQGkNJh0jNb1Z:nNPGiNK`0VOe1n9TOPGgNL:GD]Om0P:>PGgNL6o0`0U8c0PGgNL4Y1:k7k0PGgNLNb1=b7n0PGhNY39f5Q1PGfN[38e5R1PGeN\\39c5S1^LlNa3U1`LjN_3X1`LhN^3[1bLdN^3\\1bLdN^3]1aLcN_3^1`LbN_3_1bL`N^3`1bL`N^3a1aL_N_3a1bL^N]3d1bL\\N]3e1cL[N]3h1`LXN`3h1`LXN`3e1cL[N\\3g1cLYN]3g1cLYN\\3h1dLXN\\3h1dLXN\\3h1dLXN[3i1eLWN[3i1eLWNZ3j1fLVNZ3i1gLWNX3j1gLWNY3i1gLWNY3i1gLWNY3i1gLWNX3j1hLVNX3j1hLVNX3j1hLVNX3j1hLVNX3j1fEoMk68_3i1cESNm64`3P2`LPNb3n1]LSNe3k1[LUNe3k1ZLVNf3j1ZLVNg3i1YLWNg3j1WLWNj3h1VLXNj3i1ULWNk3i1ULWNk3j1SLWNm3j1RLVNn3S2iKmMW4Z2bKfM^4Z2dKZMjI6b:`2iK_MW4c2iK[MW4g2hKXMX4i2gKWMY4i2hKVMX4j2iKUMX4i2`60001O0000000Bm^OnMTa0P2P_OnMPa0n1V_OnMm`0o1V_OPNj`0n0m^OFka08[^OBma0Dg]O41Hk03jn4NVdK1001NfS71ZlH0O1O100O1N2O1O1M3L4bNBP^O52KOOc0b0[a0HT^OGb0d0Za0DS^OIa0f0\\a0^Oo^Oa0\\`0YOX_O3a0b0W`0\\OX_OOd0d0T`0]Of^O0j1`0`?E`@:`?Af^O1j1>`?@g^O2j1=c?C^@<ca001O001O0000001OlLEd_O0j2;g`0O00001O001O00001O0000001O001O001O00000000001O0000001O00000000001O0000nH1SJOn5OSJ1n<0O1000000O100O1iHL^C35Ma64i55eCHa64i55fCG_66k53eCHe4OmL8h:;ZHBgL5n::ZHEcL3Q;CfCd0f4MZLNZ;BeCc0g40ULMc;2XH8kKIo;^OfC4`4m1Y8nMhGR2T=O0000dJRN`C8h4f1f6QNbDO129f0^4X1_6QNkD<6=_4V1X6lNYEO^4U1T6QO^EJ^4U1P6UOaEG_4T1P6UOaEG_4T1P6UO`EH`4S1P6UO`EH`4S1o5VO_EIb4Q1o5WO]EId4P1o5WO]EId4P1o5WO^EIb4P1P6WO^EIb4P1P6XO]EHc4P1P6XO]EHc4P1P6XO\\EId4o0P6?oIAQ6?oIAQ6?oIAQ6?nIBR6>nIBQ6?oIAQ6`0nI@R6`0nI@P6b0oI_OP6b0TH_MPOo1k8c0UHaMmNl1l8f0VH`MkNk1o8e0UHaMlNj1o8e0THbMmNi1o8e0TH\\M_MLa1Q2l8g0UJWOk5i0dJhN\\5X1hJdNX5\\1jJbNV5_1jJ`NV5`1jJ`NV5`1lJ^NT5b1mJ]NT5b1mJ]NS5d1lJ\\NU5c1kJ]NW5a1jJ^NW5a1jJ^NW5a1iJ_NX5a1gJ_NZ5`1gJ_N[5_1eJaN\\5_1cJaN^5^1bJbN`5\\1`JdNa5[1_JeNb5Y1`JfNb5X1^JhNc5V1^JjNc5T1^JlNc5S1]JmNe5P1\\JPOe5o0[JQOg5m0YJSOh5l0WJUOj5j0VJVOl5h0TJXOm5g0SJYOo5e0QJ[OQ6d0nI\\OS6c0mI]OT6c0kI]OV6b0jI^OW6b0hI^OZ6a0eI_O\\6`0dI@^6>bIB_6>_ICa6>^IBc6=]ICe6;PEnNm2g0U89mDUOj2b0Z88jDYOk2?]85gD_Ok2<`82cDFl28b81YDmNCm0a35d80WD3U3Me8OVD5S3Mi8LTD8R3Lk8JSD<P3Ko8GQD?o2JQ9EQDa0n2JQ9EQDb0m2IS9DPDd0k2IW9AmCi0j2FZ9@lCk0]1]N]OZ1[;]OjCP1d0FPOcN<\\1W<ZOiCh3FTMc<ROfCb5[<\\JfCd5[<[JeCe5\\<ZJdCf5]<ZJaCg5a<XJ]Ci5e<VJXCl5i<TJTCn5m<]NRCXMo<e2TCZMn<c2TC\\Mm<b2TC^Mm<a2SC_Mo<_2RC`Mo<^2RCbMP=\\2QCcMP=\\2QCcMP=\\2oBeMR=Z2nBfMS=Y2nBfMT=Y2lBfMU=Y2lBfMU=Y2kBgMV=X2kBgMW=W2iBiMX=V2hBjMY=T2hBlMZ=R2fBnM[=Q2eBoM\\=o1dBRN^=l1bBTN_=k1`BVNa=h1_BYNb=f1]B[Nd=c1\\B^Ne=`1[BaNf=]1YBeNi=X1XBhNi=V1WBkNj=S1VBnNk=P1VBPOk=n0UBSOl=l0TBTOm=k0SBUOn=j0RBVOP>h0PBXOQ>g0oAYOR>f0nAZOS>d0nA\\OS>c0mA]OU>a0kA_OV>`0jA@W>?iAAX>>hABY><hAD[>9eAG\\>7eAI[>7eAI]>5bAL_>2bAN`>0`A0a>O_A1c>L^A4c>K\\A6e>H\\A8e>G[A9g>EXA<i>BXA>j>@VA`0k>^OUAc0l>[OUAe0l>ZOTAf0m>WOUAi0m>SOUAm0Xc0"}}, "object_label": "dining table", "attribute_label": ["color:red", "color:white", "length:long", "transparency:opaque", "pattern:plaid/tartan/checkered", "texture:smooth/sleek"], "control_dims": "transparency, texture, color, pattern", "answer": "The dining table in the image is filled with a variety of food and condiments. There are several bottles of condiments, including ketchup, mustard, and mayonnaise, placed on the table. Additionally, there are multiple bowls containing different types of food, such as salad and other dishes. The table is set up for a buffet-style meal, with people standing around it, likely preparing to serve themselves. The table is also adorned with a checkered tablecloth, adding to the festive atmosphere."}, {"question_id": 395, "height": 640, "width": 457, "image": "000000237928.jpg", "category": "description", "question": "Describe the microwave in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [76.85, 237.53, 127.02, 73.69], "segmentation": {"size": [640, 457], "counts": "[id12jc05M3]NG]_O9c`0G]_O9c`0H^_O6a`0Kc_O1]`0Ok1O00O2Ok0UOR1nN2N1O0000O100000O1000000000000000000000O10000000000000000000000000000O10000000000000000000000000O01000000000000000000000000O100000000000000000000000000000000O100000000000000000000O100000000O1000000O100001O000001N?^OUlm4"}}, "object_label": "microwave", "attribute_label": ["color:black", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pose, transparency, material, state", "answer": "The image features a silver microwave sitting on a countertop in a kitchen. The microwave is turned on, and it has a blue light inside, indicating that it is in use. The microwave is placed next to a red bottle, which is likely a beverage container. The scene suggests that someone is using the microwave to heat up their drink or prepare a meal."}, {"question_id": 396, "height": 640, "width": 427, "image": "000000283037.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [191.09, 199.96, 34.47, 72.14], "segmentation": {"size": [640, 427], "counts": "Yjh35<0Fo00mNoa0T2J0012Mi1WN00J6bN^1O1N2N2O100000000O10000000000000000001O000O2O5oM[Sn3"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, material, color, pose, texture", "answer": "The traffic light in the image is a red stoplight, which is currently displaying a red light. The stoplight is located on a pole, and it is positioned at an intersection."}, {"question_id": 397, "height": 428, "width": 640, "image": "000000315450.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [48.41, 222.66, 28.55, 20.53], "segmentation": {"size": [428, 640], "counts": "[fd02Z=1O4L3M3M1O2N2N1O1OO1N2O1N2O1O1O10000O100O2O002N1O3L[`[7"}}, "object_label": "car", "attribute_label": ["color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "material, state, transparency, pose", "answer": "The image features a red car parked in a parking lot, with a parking meter in front of it. The car is surrounded by other vehicles, including a blue car on the left side and a black car on the right side. The parking meter is located in the middle of the scene, indicating that the red car is parked in a designated parking spot."}, {"question_id": 398, "height": 360, "width": 640, "image": "000000338624.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [6.56, 87.16, 16.94, 12.58], "segmentation": {"size": [360, 640], "counts": "da26P;2N2000000O11O00000000101N1OdUi6"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "color, state, pose, transparency, texture", "answer": "The image features a white car parked on a street. The car is positioned in the middle of the scene, with its hood visible. The car appears to be a compact vehicle, possibly a small sedan."}, {"question_id": 399, "height": 480, "width": 640, "image": "000000383606.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [304.97, 282.46, 20.97, 28.95], "segmentation": {"size": [480, 640], "counts": "\\X_4;^>7I7N3N10000000000000000000O101O1N2_Obkc4"}}, "object_label": "cup", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "material, texture, state, transparency, pose", "answer": "The image features a clear plastic cup sitting on a table. The cup is empty and has a white lid on top of it. The cup is placed on a surface that appears to be a table or a countertop. The cup's design allows for easy visibility of its contents, making it suitable for various purposes such as serving drinks or holding small items."}, {"question_id": 400, "height": 355, "width": 640, "image": "000000416534.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [271.0, 169.0, 112.0, 87.0], "segmentation": {"size": [355, 640], "counts": "fhm2R1P:;F>B1O1O1O2mFSN34]8j1_GRN45\\8m1dGSN\\8m1cGUN\\8k1bGWN^8i1bGXN]8h1dGWN\\8i1fGUNZ8^2L1O000000000000000000000000000000000000000000000O100000000000000000000001O0O=Cj0fMgF2O0Md0ho1HUPN`00TO^9j1eFVN31]8b2I1O1O3M00000000000000000O1000000001O00000000O100001O00O100000000000000000000000000000000000000000000003WMiGN7V2\\:SNVjg2"}}, "object_label": "book", "attribute_label": ["color:brown", "color:white", "material:paper/cardboard", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "texture, transparency, state, color, pose", "answer": "The image features a bookshelf filled with numerous books, with some of them placed on the floor. The bookshelf is made of wood and has a black color. The books are arranged in various positions, with some standing upright and others lying horizontally. The books are of different sizes and appear to be well-organized, creating an aesthetically pleasing display. The bookshelf is located in a room with a table nearby, which adds to the cozy atmosphere of the space."}, {"question_id": 401, "height": 355, "width": 640, "image": "000000416534.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [60.49, 116.21, 19.9, 101.88], "segmentation": {"size": [355, 640], "counts": "RWd02n:;H7I9G:PFjN10L3S9_2oFcMP8^2PHaMP8`2:eNbGlN0l0^83cGlN23Nn0j8E^G[OHo0V9POkF8NJ2S1^9^Oo0N1M4KcFHRO0i88UHHnNOM0S98QHImN3V92mGLjN3]9NiG0h90]YR6"}}, "object_label": "potted plant", "attribute_label": ["color:green", "color:red", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, material, pose", "answer": "The potted plant in the image is a small green plant, placed on a windowsill. It is situated next to a window, which allows it to receive natural light and possibly some sunlight. The plant is positioned in a pot, which is placed on a table or countertop. The plant's placement on the windowsill and the table creates a pleasant and aesthetically pleasing environment."}, {"question_id": 402, "height": 375, "width": 500, "image": "000000509260.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pose, state, texture, transparency", "region_anno": {"bbox": [219.92, 108.1, 165.08, 67.3], "segmentation": {"size": [375, 500], "counts": "\\Ra2f0P;2SOJVF7i9KUF6k9JUF7j9IUF8k9ISF8m9GSF:m9FSF:m9DTF=l9CTF=j9DVF=i9CXF=i9BVF?j9AUF`0k9@TFa0l9_ORFc0n9c0000hNSFf0m9YOTFg0l9ZOSFf0m9ZORFh0m9XOSFh0m9VOTFk0m9SOTFm0l9ROUFm0l9SOTFn0k9ROTFo0l9POTFQ1l9oNTFQ1l9PORFQ1n9<1O00001\\NRF]1U:O00000YOlEYOO0O2O5f9KfFe0R:^OlEa0;[OQ95dF`0:[OR95dF`0:[OR95dF`08]OT93cFa09\\OS93bFd0<XOS92bFLIg0\\:\\OjENLe0Y:^OkELMf0b0ZOn84cFLNe0?]OQ90bF1Lc0?\\OT9ObF2Kc07D\\9GaF3Lb04G_9DaF3Kd0OKl9U10000O1O1O100O1O1O2OWN[F_1e9bN[F_1c9bN]F^1b9cN^F]1b9cN^F]1b9cN^F]1b9cN^F]1b9bN_F^1a9bN_F^1a9bN_F^1`9dN_F\\1a9dN_F\\1a9dN_F\\1a9dN_F\\1a9>OWN_F\\1a9cN`F]1`9dN_F\\1a9=000F_FWN04a9n11[N`FS1a9lN_FT1a9mN]FT1d9gN\\F]1d9bN^F]1b9cN_F\\1b9dN]F]1b9cN`F[1a9dN`F[1`9cNaF^1a9]NbFc1g92N21O0CTFoNl9f0bFWOd99mECg01j:0N2aN`0PF\\O2309k9[1N1000000000000000O101O0XORF^O0Jo9g0QF_O1IP:a0hF[OYR1ObXO000000000\\N2QF]1m97000000O101N1N20000O1N200000O0100O100O1000000001N101TNeFNh:0`00ZS[1"}}, "object_label": "book", "attribute_label": ["color:red", "color:white", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "state, material, texture, color, pose", "answer": "The image features a wooden bookshelf filled with a variety of books. The books are arranged in a neat and orderly manner, with some books placed horizontally and others vertically. The bookshelf is quite large, spanning almost the entire width of the image.\n\nThere are numerous books of different sizes and colors, showcasing a diverse collection. Some books are placed closer to the front of the bookshelf, while others are positioned further back. The bookshelf appears to be well-organized and ready for reading, providing a cozy and inviting atmosphere for book lovers."}, {"question_id": 403, "height": 427, "width": 640, "image": "000000001268.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [192.81, 224.8, 74.73, 33.43], "segmentation": {"size": [427, 640], "counts": "Qg`21Z=1N100O1O100N2N201N100O1O100O2N1O100O100O101N100O10001O3M5K001O00E;O100O1O101O0O2N101N101O000O2OO001M3O000001J6O10001O02O1O10000O10O10O0O2000M[Tl4"}}, "object_label": "bird", "attribute_label": ["color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, color, pattern, size", "answer": "The image features a white bird, likely a swan, standing on a rocky beach near the water. The bird is positioned close to the water's edge, with its head tilted downward. The bird appears to be looking at something in the water, possibly searching for food or observing its surroundings. The scene captures the bird's natural habitat and behavior as it interacts with its environment."}, {"question_id": 404, "height": 425, "width": 640, "image": "000000090062.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [59.98, 126.65, 359.05, 269.39], "segmentation": {"size": [425, 640], "counts": "aeh03i<i0A7I=Bn0TO6cGfMfMKc7c2aJ[NQ5l1lH^MR1R1P6`1oHcMj0P1U6[1UI4h6c3C5L3M\\MeI^NX6BnIRNMk04c1n5A[KPNcNe22VMc5W2SLf0VNVMf5T2SLQ1i3ROULQ1i3POVLQ1i3RORLQ1m3SOnKo0R4SOjKo0U4WOdKl0Z4XOaKj0_4]OUKg0k4l300OdN^KSJb4b5lK[JT4[5WLdJg3Y5`LeJ`3Y5dLeJ[3Y5jLeJV3V5RMgJn2U5VMjJj2T5YMlJg2R5\\MlJd2T5i2O1O010MoGnJQ8U5O102N3L2O1N3N2N1O2N2M3N2N1O2N2N3M2N1O2N2N2N2N2N2N2N2N3MSMhIjLLYO:a1P6Z2TJTLE5j0U1[5a2eK[M[4c2kKZMS4e2RLYMl3f2WL[Mg3d2[L[Md3d2_L[Ma3d2aLZM_3f2dLXM[3h2fLXMY3i2gLVMY3j2iLUMW3l2hLTMW3l2lLQMU3P3kLoLT3R3lLnLS3S3nLlLQ3U3PMjLP3V3oLjLQ3W3QMgLn2Z3SMdLm2\\3UMbLl2]3UMbLk2_3UM`Lk2a3UM^Ll2a3TM^Lm2c3SM\\Ll2f3TMYLm2f3UMXLk2i3UMVLl2i3UMULl2k3Y31O001O10O01O001O1O00001O10O0001O000000000001O00010O000O1MlFQLT9R4000000000000000M3O11iFPLS9S40M4N100001O003L100001M2O1000000000001O00000O2O00O100001O00000O10000000gH_Lj4a3UKaLk4_3QKfLm4Z3PKjLo4V3oIWL1g0P6R3_InL82Y6Q3ZI`Ne6a1XIbNg6P40001N1000O01000jNPJSKP6i4YJRKg5R4\\I[LQ1_Od5U4`IXLo0_Oc5S4eI[Le7e3aHTLa7l3n0O1000000000O10001O0000001N10O02O2N2N<D9F8I5K4L2N2N3M3M6J3L7J:F6J2N4L1O100O1000cNQJ_Kn5^3aJdKKj0d5V3iKfLW4V3QLfLP4X3SLgLm3W3XLeLi3X3[LgLd3X3aLdL`3Y3eLdL[3[3gLdLZ3Z3hLeLX3Y3jLgLW3W3kLhLU3W3mLhLT3V3nLiLR3W3oLhLR3W3oLgLR3Y3nLgLS3X3nLgLR3X3PMgLP3Y3SMdLn2Z3a3O100O1O101O0O10000O1O00100O010O100O100O1M3N2N1K6UNaE\\ONn0i:2XETONH18P;m0REmN3MN3n:a1QE\\NW;g1gD[NW;g1hDYNW;h1iDXNQ;n1PEQNo:T201O104L100O5K1O100O2N2N1N10000O10000000M4O000O2O0O2M2O2O1N2O7H3N1O2M2O3N2M2M5L2N2N2N2N2N2N2N2N1O1O2N2N001O2M2O1N2O1O1N2O1L4N3LZnk2"}}, "object_label": "cow", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:floral", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a black and white cow standing in a field near a pile of logs. The cow appears to be looking at the camera, possibly curious about its surroundings. The cow is positioned in the middle of the scene, with the logs surrounding it on all sides. The logs are scattered in various sizes and orientations, creating a somewhat chaotic appearance."}, {"question_id": 405, "height": 428, "width": 640, "image": "000000126216.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [404.61, 153.9, 145.0, 106.21], "segmentation": {"size": [428, 640], "counts": "elY5i0Y<`0F=_O7M3O002MN3L3N3BaDeNl;o0=E>_O[CNnl:n0n^E>AdNaDg1g:j0OO2O2N2N2N101O0012NKREoMk:Q2UEQNi:[2M4M\\O^EaN_:]1cEeN[:[1eEdN\\:\\1dEcN]:]1bEaNb:^1^EbNb:^1^EbNb:e1\\EVNd:j1]EVNb:j1_EVN`:j1dERN\\:n1iEnMU:S2b00000001O0000001O00000O2O000O100000000O2O0000O101O000000001O010O001O1O2Mf0nMYD119XY35ZSMk0WOc0]O7hDhMo:\\2N100O3M8I0O01O001O100N2O0O2J7G8J7K5K9E:H;E9F6FieV1"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "state:dry", "texture:rough"], "control_dims": "pose, state, maturity, pattern, color, size, texture", "answer": "The image features a large elephant standing in a grassy field surrounded by trees. The elephant is positioned in the middle of the scene, with its back facing the camera. The trees in the background provide a natural and serene environment for the elephant."}, {"question_id": 406, "height": 640, "width": 448, "image": "000000148783.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [82.47, 190.88, 355.12, 378.42], "segmentation": {"size": [640, 448], "counts": "^QW24fc0:I7G7X]OUOH0Ub0P1l]O_Oj1AUN0b?R2lAcNd=k1TB_N^=R2QBYNh=R2mAUNl=S4I7D<K5M4J5K5K4M3N3K4N3M1O101N2O1K5KMmCcHQ<Z7oCbH14n;g7O3N1OHVDWH13g;g7YDVH02f;P8XDoGg;U8O1O2O0OPO_D`Id;a6]D]Ic;e6^DmHn;S7SDeHK4R<X7SDcHM3o;\\7YDaHg;a7:2O1O1O0O2O1N2O1O00001OFoCfHR<Y7TDaHl;`782O1O1O1O1000N2O00000O1O0O2iNfChJ[<o4UDiJk;T5_DcJe;X5eD`J];^5d1M2O2M2N3L3M4L4N2M3L3N3L3O1O1N3N1O2M2O2N1N20001O1O1O010001N2O1O0O100O2N101O1O1O001OO10O1O10O010000O10000O100O0100000O101O0O3N1O1O4K4M4L3M5K7gA^Jf=n5O10000O10000O01N2O1O10O100O2O0O10O10OO20SDPJj9P6WDoIh=U60K4O1F;D;]Od0O1O01000001N100O100O1O10000O10O0100O1O100O0100000O010O100O10000000O010O10O0100O1O1O100000O10O100O100O10O11O0O100O1O10000O1O1O100O1O1O1O100OnAbKd<^4_1M4M200O1O1O2N10000N3L3O1N2OkFWLV2h3R70O101N2O1N100O1O101O3M0O2O000O2O2N2N00003NO01O1O002N2N2N00003N7H0001N2N2N2M3M20g@\\K[?a44M:nKU@F33m0R2Ya0]O8J5J9iNR]Oj0Uc0M3Ig\\OA\\c0b01Oc\\O@\\c0?6K2M6K08HJ_\\OJUW:"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, texture, pose, state, color, maturity, pattern", "answer": "The image features a zebra standing in a dirt field, eating a branch from a tree. The zebra is focused on the branch, likely enjoying the taste of the leaves. The zebra is positioned in the center of the scene, with its head down as it consumes the branch. The dirt field provides a natural environment for the zebra to graze and explore."}, {"question_id": 407, "height": 514, "width": 640, "image": "000000170739.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [218.56, 0.0, 274.96, 405.1], "segmentation": {"size": [514, 640], "counts": "XQ\\33n?1O1O2N1N4M3M2L4O2L4M4K3L5M2M4M1O1N2OM21ORO`A=a>AbA>]>@fAa0Y>^OhAb0X>XOoAg0o=YOSBg0k=UO[Bl0d=TO\\Bm0c=RO^BU1T>13L01O0002N1[OPA5S?=HROZAn0n>[Om@8U?Fn@N]?Kb@222]?1b@0^?0b@0b?K`@3Q\\1OQdN0J64HQ10Z<2aBOO50>1^OS1O<O]:3SDm01ROe>1ZAO1h02VOd>3YAO150L0M12o>0o@1050K0O11o>NQA<OF0O11ON3Oe>7XA10J2OO60Kf>5YA471`>KYAL0376KD`>=_AI56LD`>3^A51N57KCa>3^A000402:KCa>3^AO204O1;_>JgAKJ4JNe>OZA03N43N3LMe>OZAO30OO1323LOc>M\\AO3044L1NOc>0iA1FNO12KZ>5oA1HJO50LY>4fAK483NHL[>4eAK0O03N06NK51L[>0cA01058NGL71J\\>OiA108N3[>EgA009M2\\>EgA00:L3[>CeAOO15:M3Y>CjA1O:M2Z>CjA2OON2O5^>HfA3NM04M4_>IeA2OM13K6`>HeA4LL4?[>AeA4MK3`0[>CcA2OJ4`0\\>E_A19;X>E^AL0O2O0d0`>B^AL0O2O06N4c>1]AF2N52K7b>2^AEc04Q>NZA6i0Jn=0ZA5>KC4d>M[A4;8Z>D\\A34>b>]O^A3Na0^5\\Oa30TG3Kb0\\5GcJD7OU82iGk0W5GiJ^OV80jGj0X55k2QOmGi0Z5[OaJ7OK0JU80QHNLg0m5_OSJKO102R8MXHf0e5^ORJLO103Q8LYHf0g5[OQJOO0O3R8MXHf0W6\\Ob1NSHOLf0Q?[OPAd0j>BXA<e>HZA8f>IZA6f>J[A5l>CVA<m>@VA>h>FWA9a>DZA359a>C[A449Y?000LCc@=\\?Dd@<]?Cd@<m>ERA19;`>IUAM;:_>DWA7:5^>EYA596_>DYA587_>C\\A35<g>CYA=^>B]A2KM6`0a>A^A2JO6>b>A^A2JO6?a>@`A1I24=c>@`A1I24=c>@`A7M:b>_OaA7M:b>_OaA1I23?m>^OQA4O`0P?[OSAk0m>VORAO1f0l>\\OSAN1f0l>\\OWAe0j>[OUAe0k>\\OTAc0m>\\OTAd0k>\\OVAd0k>ZOUAf0S?10O@]ObAc0_>^O^Ad0b>^O^A`0b>@^A`0b>A]A?c>B\\A=e>EYA;g>FXA9i>HVA8j>JTA6l>`0OoNUAm0k>SOUAl0m>SOTAl0l>SOYAi0f>XOZAh0f>XOZAh0f>XOZAh0g>WOZAh0f>XO^Ad0b>\\OZAOKe0k>\\OUA40`0k>]OSA10N2d0j>CYA>f>A[A?e>BZA>f>BZA>f>]OUAO5e0g>ZO]Ag0c>YO]Ah0b>XO^Ah0a>YO^Ah0c>WO\\Ak0l>100O2N2N1N3N2M3N1O2M3O001O001O1O01001N102NYNfAe1\\>0O5L1O000eGUNS20[Hj1b5VNS22ZHg1U1ZNX;f1jDXNm:OlCi1e=WN[Bi1]4WNk4i1g4000FXNUBO1j1c4VN]4:mF_1g1WNj00iM0i89nFa1d4VN^49nFa1d4VN^4:mF`1e4VN]4W2dHjM`N0a;V2nElM^N12NW3Nb4X2gIkM^N13MV;X2XFkM^N0c;V2mESNT:m1jETN]OH;JP8Y2WHVN]OJ9I\\ONG000i70XHm1W1aN\\OK:G\\O0^8m1`H`N^OK8H\\O0^8m1aH`NeNE;8m9FnEn1U1^NbN40L\\:GjEk1X1_N_N50M9Bj93UFj1Y1_N_N52J8Dj95SFi1Z1UN_N50:2Ia:HdEl1Y1RObNYOc:N\\Eh1^1QOaNZOj:m1cFjNcNXOn1IXNNZ8V2mHVOb9i0]FVOe9i0\\FcNdNGS;d1REmMo0g0nNFR;f1QEmMo0g0nNCU;j1mDlMP1=kNJ43U;i1TFYNdNJ42`2Hn5T2hHXNgNJ23h1G\\N1O0I2_8MbGT2Z1XNgNKN2e1IaN00005X8IcGU2T1mMlN:14[1AjN1O000O7X8GdGW2W1TNlN4d1B^N10005[8Q2eHmMnNL1<a2C[M3a8T2fHlMmNN1:e2Gg5S2cGkMo02QOO13JNn20d5P2fGoMk01RO011KMn22b5n1jGQNQ10kN2JMo20b5o1jGRNo01kN3_;j1UFUN\\NOm2M^5m1dGTNX10eN50K0OR32\\5i1gGVNU12eN4OKT3NmL31MZ8j1[IYN[N8U3GZ5e1XI\\NYN9U3D[5f1YI[NXN9U3G\\5a1YI^NVN8W3J\\5]1XIaNTN7a0JS21R6Z1[IkNW:P1jEROX:k0hEQOmML]<Q1UDPO`0OnN8U2GX8n0WFVOGM7;c1FW8l0YFUO;7Y1GS8m0eETO>0a08j;c0ZCTO:1c06l;?[C\\O31h0MW10\\91`DOK3_3NW8OdD2S?Mm@3a?0G1_@Oa?1_@Ob?1701O1ORgZ2"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:rough"], "control_dims": "texture, pose, maturity, size, state, color", "answer": "The image features a large elephant standing in an enclosure, with its trunk curled up. The elephant is wearing a decorative yellow and red garland around its neck, adding a touch of color and festivity to the scene. The elephant is positioned next to a fence, which serves as a boundary for the enclosure. There are other elephants in the background, indicating that this might be a location where multiple elephants are kept together."}, {"question_id": 408, "height": 514, "width": 640, "image": "000000170739.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [466.64, 51.98, 173.26, 456.24], "segmentation": {"size": [514, 640], "counts": "mb]72_`10j_NO^?0b@0e>1iAOa>0Z_24fRMOT=?UB@I2Y19c:^1WEPO[7ZOUJi1^NTOU7WOXJk1_NPOV7XOXJl1[NTOW7SO\\Jm1YNTOV7RO_Jn1XNSOU7QO`JR2VNQOV7oNbJT2UNnNW7PObJW2RNmNV7POfJZ2lM^NNfN[7e0jJ_4R5dKmJ]4o4gKoJ\\4n4fKQKU3SNcLh6;TKU3RNfKMd0g6e0ZKY4b4jK]KY4]4kKbKX4X4lKgKT3RNTK3h0n5T1lKT3XNhKg5X1QLQ3WNgKf5Z1RLQ3WNeKd5]1ULo2XNbK]5e1ZLj2\\N^KY5i1ZLk2]NjJJ41K]5^2[Lk2[NTKZ5U2[Lk2XNkJOHW13d2b2mMj2\\NcJOLT16\\2h2UNd2i3_MWLa2d0_J`0T3mN^2Y3iMhLZ2[1\\J\\N]3;]2f2dM\\M]2a2bMbM_2Y2cMiM`2o1cMSNc2`1bMbNc2i0kMYO[24PNNZ2^OnMd0g81N2N2M3N2O1N2N3L3N2N2M3M3N2M3M3N3M2N2M3M3K5N2L4K5L4L4N2L4I7K5I7L4H\\JmEi5P:5I8K5K5K5E;L4G9L3M4D<K5G9I7E;G9K5H8N2MlGnI^6Q6cInI^6o5l1N2O10QFVJf9f5VFYJ42e9i5[FWJe9j5\\FUJc9U6ZHjIVNOP7W6fJZJX5f5dJiIVNj0n6]5PK]JTN]OO0g6V6WKiISNO020N69^6o5XKiISN0110N79\\6P6iJhImN?0OS6f5bIlI^11lN?3Nn5f5eIlI]11oN4EL0Oa0;l1MT1k5^LmI]11oNOE02O00d07c18W1g5lMlIRO0DN00:0L6P2:X1i4aLaKZ1XORO1E2OMOf0h0ZO`0?Y2f4gL^Kj0]ORO18OF30h0e0D2HS3k4]LaKi0[OUO1>OB6IL000O31d0e0^O^OLMN7o3d4bL`K@FS1MTO0?0A0J11O<0:5YOR1NkNQ4j4^LiKe0[OTO0?0A1I02O<193[OZ11dNc3i4]LUK3h0k0ZOUON10K223N8:D;4ZOb1e3Z4[MRJ]OOB41009NC7Oa04YOc1g3S4YLVJR11^ONB411N2OKX13iN;Oa0k3h4WLWJQ11BOL5AKW15iN2NM6NIe0n3Q5[MYJ14iNKW1i0fN7o3k3`LUKD6W1K05hNOS1f1k2k2kL]K?O03hN35Hb0j1Y3f2]NaKoN0eN0N0T1h1P3d2[NdKjNOnN0R1h1m2b2[NgKhN0hNO11V1g1o2_2\\NjKfN5gNOU1b1U3]2ZNWLaMFM40O0;8A>f1d33lK2`2WN\\MO80KOO5K0T1a1Y3GZLA[O@U4GjKMU1d1Y3^ObL@_O]Oi20fM0VO0R1e1[3WOeLCd2IWLHm008e1]3POiL]OcNNO2m37ULIl0M;f1a3[Nb1d0_J[O>f1Q:RO^EXOa0f1V:_NbD>3^O218O8e1U;^OTDSO3Mc0c1\\;HdD8j;ZOVDf0n;VORDj0V<nNjCS1[<gNeCZ1]<cNcC]1c<\\N^Cb1b=O1O10004L5K00\\C"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "texture, pose, color, state", "answer": "The image features a large elephant standing next to a red fence. The elephant is positioned close to the fence, with its trunk resting on the fence. The elephant appears to be looking at the camera, capturing the viewer's attention."}, {"question_id": 409, "height": 640, "width": 427, "image": "000000223188.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [0.0, 154.6, 427.0, 477.09], "segmentation": {"size": [640, 427], "counts": "Uc1f22]M0a5[;P3O0O10O0aGgDZ8W;fGkDY8T;:00O100O1O100O100OmGnDZ7R;fHnD[7o:]HRE@1X8l:XHYEg7f:[HYEe7g:[HTE^O6T8d:UHUEN2I5T8d:PH_EM44Ce7i:ZH[Fe7d9[HXFLQOk7e:ZHYFMQOi7f:ZHZFKQOl7c:ZH\\FJROk7b:YHcFh7Y9ZHiFf7T9ZHoEJ`0m7`9XHPGh7P9UHSGk7a:1O1[NRHVGn7k8QHUGo7^:0SNQHiGo7W8QHiGo7R8VHnGj7R8SHQHm7Q:aIQDm4o;QKTDn4l;RKUDm4c9fI^H^1nMl4d9fI^H]1nMn4l;mJQDiN4Z6^9fImFNY1W1bNU5T9fIUGNU1X1aNT5S9hI^GLg0X1hNT5S9hIQIU1jMT5g;mJYDS5g;mJYDS5g;mJYDS5m8cIcIZ1aMS5l8cIcIZ1aMS5e;nJTDfN2\\6i;oJTDfN3[6g8cIUJ]1QMeN4Z6`8kIYJW1SMeN3Y6a8jIXJZ1UMaN3[6b;UKdDj4[;SK\\DbN:[6Y;WKhDh4W;YKiDg4V;\\KiDc4W;_KgDa4Y;`KfD`4Z;`KdDXNJW6b;^K_DZN42MT6a;_K^D[N;U6W;`K^D[N<T6W;`K]D\\N`0P6S;dK\\D]Na0o5T;gKoDU4Q;jKRE[NZOe5e;nKXEP4h:PL[Em3f:SLYEm3g:SLXEn3i:RLXEl3i:SLYEk3g:VLYEi3h:WLWEi3i:XLVEh3k:XLSEi3m:XLREh3o:YLnDh3R;[LkDe3V;]LgDc3Y;cL`D^3`;a21O001O001O0000001O1O001O00001O1O00000000^MXHmHg7f90XM[HVId7c9000001O00001O000000001O001O00001O00001O001O00001O000000000000001O0000001O000000000000001O000000001O000000001O00000000001O001O000000000000001O00000000001O000000001O00000000000000001O3M3M3M4L2N6J5K4^J]BYO5i4n>L1O00000000O10WNRA`Nn>^1VA`Nj>\\1\\AbNd>[1`AXN\\OZOS?\\2dA\\NVOYOV?Y2fAhNY>X1hAhNX>T1mAkNS>R1PBnNP>n0TBROl=4SAlNY1P1d=2PCNP=0RC0m<OUC1k<NVC2j<LXC4h<JZC6f<F^C:T`000000O10000O100O100O100O100O10000O100O100O1O100O1O1O1O100O1XKWOWFk0f9_ORFb0l9IjE8T:LiE5W:MfE4Z:0aE1_:3\\ENd:4WEOi:2TE0m:0dDnMTN[2X=GbD`0_;@^Db0b;_O[Dc0e;^OXDd0h;\\OWDe0j;ZOVDf0j;[OSDg0m;\\OoCe0R<\\OkCe0U<\\OiCe0W<[OgCg0Y<ZOdCh0\\<ZO`Ch0`<YO]Ci0d<VOZCl0f<UOWCm0i<UOSCm0m<UOoBm0Q=UOjBn0V=n21O0000O10000000000000000000000000000000000000000O1000000000000O100000000O1O100O100O100O10000O1O100O100O100O100O1O1N2O100O1O1O1O100O1O1O10000O10000O10000000000000000O10000000000O1000000000000000000O1000000000000000000000000000000000000001O0000002TK\\CcM5<K1100GZ2Lda0"}}, "object_label": "cow", "attribute_label": ["color:black", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The cow in the image is a large, bronze statue, possibly a bull, with a man sitting on its back. The man is wearing a gold outfit, including a gold jacket and gold shoes, and is holding a clock in his hand. The scene appears to be a creative and whimsical composition, with the man seemingly riding the statue of the cow."}, {"question_id": 410, "height": 426, "width": 640, "image": "000000263860.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [259.3, 86.59, 380.7, 339.41], "segmentation": {"size": [426, 640], "counts": "Pc]31Y=1O001N10000001OM303M00N2LnBOS=2RCMi<3UCOT=O1O00J3O6PCHi<93ORDGg:4[D9j0Eg:f0XEZOf:h0YEZO_OMi:P1dESOBNg:S1fEQO_ONj:R1gEYOX:i0fEWOY:k0gEUOW:n0hEROW:P1gEPOY:R1eEoNZ:R1fEmNY:U1fElNY:V1fEiNY:Y1gEgNW:[1hEfNV:\\1iEdNW:^1gEbNY:_1fEaNZ:`1fE_NZ:b1eE_NY:c1eE^NZ:f1cE[N\\:Y20000O2O1O001O001O001N2O001N2N2O1O001N2O1O1N2O1O1O1O1O100O2N1O1O1O100O1O10O02O3L1ON3O01O101iFPLQ9_4F2N1N2O2M2O00O1N1010000O1G90O10O1CXGPL00k8m3=100O00000000000]J]L_1c3jM]Mm1c2nMkMi1U2TNWNc1i1WNoN_MUMd3l3eNNh0b0ZN6\\1m5O00000000000000000000000000000001O00001O00000000001O001O001O00000000000000000000001O000O1E;F:H8K5K5J6K5E;I7E;L4M4K4I7H8D<N2N2O1O10001O01O1O001O1O001N101N]I]Ia6a6aI`I_6_6aIaI_6_6aIaI`6^6`IbIa6]6_IcIa6^6^IbIc6\\6^IdIc6[6]IeId6Z6]IeId6Z6\\IgIf64VIk54RJR7h5oHWJW7c5iH]J\\7^5dHbJ`7Z5`HgJc7U5^HjJd7T5\\HmJg7o4ZHQKh7l4XHTKk7i4UHWKo7e4RHZKR8a4oG_KU8]4kGcKX8Z4hGgKZ8W4eGiK_8S4bGmKa8o3`GPLd8l3]GSLf8j3ZGVLi8g3WGYLn8b3RG^LR9^3nFbLW9Z3hFfLa9Q3_FPMd9l2\\FTMe9k2ZFWMe9j2[FUMe9k2\\FUMc9k2]FUMc9k2]FUMc9l2\\FTMd9m2[FSMe9m2[FSMe9m2[FSMe9n2ZFRMf9n2WFPMM2l9n2ZFSMe9m2[FSMe9n2ZFRMf9o2ZFPMf9P3ZFPMf9P3ZFPMf9S3WFnLh9S3WFmLi9S3WFmLi9S3WFmLi9S3WFmLi9S3WFmLi9S3WFmLi9T3VFkLk9U3UFkLk9U3UFkLk9[3OO1000000000000000000O10UNlL`IT3_6QM]Io2d6VMVIi2k6ZMRIf2n6]MoHc2Q7bMjH]2W7RNZHn1f7YNSHg1m7j110000O100O10000O10000O100O100O100O101O0O101O1N101O0O2O1O1N101O001N1000000000O10O10000000000O101O1O1O1O100O2N1O1O1O100O1O1O1O1O1O010O1O010O00100O1O00100O10O010O010O010O01000O0100O010gL"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:rough"], "control_dims": "color, pattern", "answer": "The image features two elephants standing in a grassy field, with one of them appearing to be playfully biting the other's ear. The elephant on the left is larger and more prominent, while the one on the right is smaller and positioned behind the larger one. The elephants are facing each other, creating a sense of interaction and bonding between them."}, {"question_id": 411, "height": 426, "width": 640, "image": "000000291861.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [96.69, 78.5, 537.04, 346.54], "segmentation": {"size": [426, 640], "counts": "_YY14V=0O3N2N100000O10O1bHJg15XNLh14WNMi13hHH[57l11hHJW59P24lM0S2OlM1U2HQN8P2HoM8R2HmM<P2DoM=Q2CSIJV4n0f2XOUIIU4o0f2TOkH0e4N[KQ1T7UOSILR4S1k2QORIOo3R1o2oNRILJMT4[1P3jNnHNNOU4\\1n2gNoH2Q4Y1P3dNmH6R4X1P3aNoH72Hf3b1Y3^NQI3MM21d3d1[3\\NSI03O^3i1Z3WNWIO20[3m1]3TNUI022X3l1`3RNVI023V3m1a3PNXIO23Q3Q2f3mMWIN43i2X2l3gMQIO?2`2\\2P4fMTIK73b2a2Q4bMUIJ84_2c2S4`MTIK92^2e2U4gMVIFk0O`0h2b5gMRI^Oj07<g2i5iMiIC7k2o5bMiILMf2Z6]MhIP4X6gKQIHc0d4^6bKPIJa0e4_6aKPIIa0h4^6`KPIHa0i4_6gK`IZ4`6eK`I\\4`6bK`I_4b6cKZI^4f6bKXI_4i6aKWI^4j6ZKlHF;P5k6TKkHL=Q5i6YKVIh4j6XKVIh4j6XKQIm4n6XKkHk4S7f0O2O001N10001OXORIVKm6l4RITKk6d51O12N2M2O2O0O3L3M3O1N2O1O0O1001IiIZIX6l6000O0001000O1O1O1O10000O01000OfIWIT6j6lIVIS6j6nIVIR6g6:^O_ImI16c6R6\\InId6\\6O01O100N110M2N3@VIUJ05k6T6aIeIQ6[6oIeIQ6Z6?01gNRIQK2OOk0n6Y4RIjKP7X50N1QOoHaKOZOU7U5lH\\KO_OZ7V5fH^KZ7Z5OXOgH^KZ7a4hHQKNK100OY7U5hHkJO100000OY7U5hH]KY7c4fH^KZ7b4gHZK\\7e4iHmJJ0b7S5eHkJa7U5_HkJK0a7V5aHlJMO`21\\2U5RNiJo1W5R3[MoG1Q8e2O1RHhJh7X5500YMQHaM0]2o7i2O101O1O002N10O001O0000000O100000O10O0011O000001O0O100O2O00fMhJcLW5]3iJcLW5]3iJcLV5i5000O01000O10O100000000000001O0000000000000O20O00O10001O00010O0001O01O0001O001O1O001O00002O0O0010O00010O01O00100O1O0O2O1O1O001O001O1O0O2O1O1O1O1O1O001O100O1O01001N1000001O00001O0O101N3M002O2O1N0O101O001O1O1O3M2N4L1N2O002N0O1O2O1O003M0O3M2O1O1QKeHl3[7mKlHT4S7lKlHU4T7lKiHV4W7P13TJbHc5b7010O3N0O5MO00O1O2N2kHoIm6X6O010O1O1O10O02N1O1O001O02OO1O00010O1O010O000010O000010O1O0000001O010O00001O0001O01O00001O00000010O00O101O0000000000001O00000O100000001N100O10000O2O0000000001O1OLTImIi6S6XIRJc6l5^IUJa6j5`IXJ^6h5aI^JZ6a5fIaJY6_5gIfJT6Z5lIlJn5T5QJQKk5o4UJVKf5Y6N_N[J_Kd5`4]J`Kb5_4_JfK\\5Z4eJgKZ5W4gJiKY5W4fJkKY5T4hJlKY5S4gJnKX5Q4iJoKW5Q4iJoKX5o3hJRLX5m3iJSLW5m3jJRLV5m3kJSLU5m3kJSLU5l3kJTLV5l3jJULU5j3lJVLU5h3PKTLm4ZNfJ`5>VLl4ZNfJ`5?ULj4\\NgJ^5<ZLm4XNgJ^53cJ0g1V5XNgJ]53eJOg1W5XNfJ\\54eJOg1W5XNfJ\\54fJNf1X5XNfJ[55gJLg1Y5VNgJ[55hJKg1X5VNiJZ55iJIh1Z5UNgJY58iJGi1Z5UNgJY51gJ1Q2W5oMgJY50hJ2P2V5PNhJX50PMX5hMhJW51QMX5hMfJZ52kLX5U3gJeJ2U2W5V3fJRMZ5_3iJ]J<d0k4\\4fJVK4Ha0a0f4S5iJZJf0`0a4W5PLdJP4]5RL`Jn3k4eJ[K^1CcNIZ5X5gJ[K_1An3T5bJ]Ka1\\On3R6d12O2M2N2N2O0O4L2O0O3N3M1O2M4L3O2L5L4L1N2OO2OO01O00100O1O1O1O2N1O1O1O1O1O2N1O1O2N1O2N1O1O2N1O1O1O2N002N2M2GTImIR7c5nH^J23W7\\5iH`Ja7Z5<J5N2O2N1N4D:N2A`0H8J5I8F:M2M3K8G7J6M4K5J:@`0D9Cid2"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, color, texture", "answer": "The image features a zebra standing next to a large rock, possibly a boulder or a large stone. The zebra is positioned in the foreground, with its body facing the rock. The zebra appears to be looking at the rock, possibly curious about it or simply observing its surroundings. The zebra's stripes are visible, adding to the distinctive appearance of the animal."}, {"question_id": 412, "height": 360, "width": 640, "image": "000000508586.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [315.5, 152.7, 36.1, 38.5], "segmentation": {"size": [360, 640], "counts": "mX_31V;1N2O1O1O1O010O1WOK_F5`9MoEM87i9MnEL97i91XF0i9g000001O00O1O1O1O1011N3M00N2O1O2MDSFAk95cFJ[96gFIY96iFIW96kFIV93oFKQ91UGMl81WiT3"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:smooth/sleek"], "control_dims": "texture, color, state", "answer": "The image features a zebra standing in a grassy field, with its head turned to the side. The zebra is looking at something in the distance, possibly a deer or another animal. The zebra's body is covered in black and white stripes, which are a distinctive characteristic of its species. The zebra appears to be in a relaxed state, enjoying the open field and observing its surroundings."}, {"question_id": 413, "height": 478, "width": 640, "image": "000000109900.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [105.42, 136.68, 282.28, 95.41], "segmentation": {"size": [478, 640], "counts": "bea12k>2N2O0O10000011Mo`6NS_I2O1N2O00001O001_AG[>?O2N1N3N9G1O00000000O11O000000001OO1000001O00000000000000O2O1O1ON11XBPOa=Q1^BPOb=P1]BQOb=P1_BPO^=R1bBnN]=S1dBmN[=S1dBnN[=S1eBmN[=[1O100OH9O1000O10O100O1BZBAh=`0YB^Oh==XB\\O70c=d0=O1N2O001O1O1N2O1N2O100O1L]AMc>25O16J1O1O3L101N4M6J1O1N2N2O1O001O0O10000000000000000O100000O0N3M2J6001000000000000O1000O10000000ON3001kA@j=m0L1000O10O101O1O0O2O1O000O10N20O10H]BUOc=<_BH0Jb=>_BF1K`=?`BGLLd=<aBO_=1aBO_=1aBO_=0bB1]=OcB1]=NdB2\\=NdB3[=LgB3Y=MgB4GB\\=9mB;S=DnB9U=GkB7W=IiB7W=HjB8V=HjB9V=FkB:T=EmB;S=DnB<R=DnB<R=DnB;S=DnB;T=DlB<T=DlB<T=DlB<T=CmB;U=EkB9X=EiB:X=EiB9Y=GfB:Z=FfB9P>000O2O001O2M3gA^OR>g002N1O1N1000001O0O1000000O1000000O0100O1000O1000000O010000000O10O01N2N2O1N1O2N2N2O1N2M3N1O2O1O1N1O2O1O1N101O010000O1O1O2O0ASClNn<j0]CTOd<e0cCZO_<9nCES<1WDO\\=00O2NT\\f3"}}, "object_label": "airplane", "attribute_label": ["color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color, transparency, size, texture, pattern", "answer": "The airplane in the image is a small propeller plane, likely a twin-engine aircraft, parked on a dirt runway. It is surrounded by a group of people, including pilots and passengers, who are standing around it. The plane appears to be a small passenger plane, possibly used for short-haul flights or regional transportation. The people are gathered around the aircraft, possibly discussing or preparing for their journey."}, {"question_id": 414, "height": 480, "width": 640, "image": "000000125257.jpg", "category": "description", "question": "Describe the snowboard in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [336.97, 215.24, 72.16, 23.13], "segmentation": {"size": [480, 640], "counts": "kUn41m>4N0O2O0000000001O0001O01N2OO2O1O1O01IYA4j>O1O01O001O0001O01O001O0O101O01O1O000000N2O101O01O2N010O1O000O2OO4K3N1000G]A5h>O1O10O000000O101O000000000O2OfQ\\3"}}, "object_label": "snowboard", "attribute_label": ["color:blue", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "transparency, material, pose, pattern, texture, size, color", "answer": "The image features a snowboard with a person standing on it, likely preparing to snowboard down a snow-covered slope. The person is wearing a pair of black snow boots, which are visible on the snowboard. The snowboard is positioned horizontally across the image, with the person standing on it, ready to enjoy the winter sport."}, {"question_id": 415, "height": 375, "width": 500, "image": "000000410880.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [88.48, 75.84, 231.74, 298.32], "segmentation": {"size": [375, 500], "counts": "iZP1b03E3MX:X1M3M3M2N2M4M1O001O1O100O101O0001O000O011O2O0N010O1O10O0200N00100O000010000O010O001O001OTHeN]5Z1_JROZ5m0aJ\\O[5d0`JE]5:aJJ]56`J0^50_J3a5L]J8a5G_J<`5C^J`0a5@^Jc0`5]O^Jf0b5YO]Ji0c5VO\\Jl0c5TO]Jm0c5RO\\JP1c5PO\\JQ1d5oN[JT1c5lN\\JV1c5jN]JW1c5hN]JX1c5hN\\JZ1c5fN]J[1b5eN^J]1a5bN_Ja1^5_NaJf1\\5XNdJj1\\5UNdJk1\\5TNdJl1^5SN`Jo1_5RN`Jo1`5PNTJ^2k5bMmIh2FXLV6o0QJR3o5oLjI[3c0PL[4\\6L4L101N100O1O1O100O100O1O1O1IhHoKX7i3hHVL6LS7j3b0O1M3N2O1N2O1M3N101O1O001O000O001N1O2O100O11OO1001N2fMkLQLU3o3PMlKQ3S4RMiKQ3V4RMdKQ3\\4QM_KR3a4ZMmJm2R5\\MaJj2]5j1N4L1O001O0000001O0000YKaJV3_5hLeJV3[5gLjJW3V5hLmJV3S5hLPKW3P5gLSKX3m4gLVKW3i4iLYKV3g4hL[KY3d4fL^KY3b4dLbK[3]4eLeKZ3[4dLgK\\3Y4bLjK]3V4aLmK^3S4`LPL_3P4_LSL`3m3_LUL`3k3]LXLc3h3\\LZLb3g3]LZLa3h3]L[L_3h3`LZL^3g3bLYL]3i3bLXL]3Q60100O10O3N2M4M6J1N101N2O3L6K7oHiKR6n41O10O000100O01000O01O010O1O1O0O2O1N2N1O2N2O0O2M4\\Oc0I82MN3N2I7YOSI_LP7m38K6I7I6G:L5J5M3K5L3L5L4K6K4L5I9E=E7I9I8GdYQ2"}}, "object_label": "teddy bear", "attribute_label": ["color:pink", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, pose, pattern, material, color, texture", "answer": "The image features a large, brown teddy bear sitting on a bench outside a store. The teddy bear is positioned in such a way that it appears to be leaning against the doorway of the store. The bench is located on the sidewalk, and the teddy bear is the main focus of the scene."}, {"question_id": 416, "height": 640, "width": 425, "image": "000000004395.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity", "region_anno": {"bbox": [1.44, 1.44, 423.56, 637.12], "segmentation": {"size": [640, 425], "counts": "h`1l18VNJ601O0000?0@2JO150000000M32NN201N1Od09_1]8Z6]GkIc8i8O100O100O1O1000000O100N20000O1O10000O1000000O10000O1000000O1O100000000O1000000O1O100O100O100O10000000000O100O1O1O1000000O100O100O100O100O100O1000000O100O10000O1O1000000O100O1O100O1O10000O100000000]KaC[MOR4`<bNdCVM2T4\\<^N^CbM?m3U<WN\\CnM3K?1Cd3`<^M^C_OOB2NP10oNX3d<gMbCQOK20M20Y10dN5N00V2g<dNcCoNL20Nl14QN0OV2g<cNeGg0]8UOiGWO]K]1k<WOQHg0Q8WORHf0P8WOSHAmJR1S=ZOWHc0k7[OWHc0k7TO^Hk0c7TO^Hk0a=I7I2O0O2N2M3M300O101O1ObP30ccM0elf00_kWO20N10`^40_aK5Vi2KfXM2So7N^VN0`\\50joD0[_20f79eXM3G;Jl0RO6L201O0UBTN`9P2V42O1SCnMi7S2^HlM\\7U2cHlMRKOQ<U2a52N1WDkMe5V2S60aDiMjI4P;T2c61O0\\EPNX3P2QMfMjH0`0Om8\\2mMPNjHEY9\\2VNdMbH1W9[2bNgMSH2OKi8]2WOXNd0h1GdMcG11Ne8]21dMYG014W8Y2i0bMZO_2_1fMaM[2^2iM_MX2i2`MPFOR7b2n2jMYFCU6c2k3_MoE2U6_2W4gMeKZ2[4cMgK]2n:001N2N1O1O2N1O2N1O1O2N1L4O2O1N1O1N3N2O0ObLe_OZ3Y`07N3N2O0O1O2M3N2M2N2O1N3L4N1N2O2M3L4M2M4M3K5^KiJWJZ5T:3L4QGbJTOMUO4[Le5W5`JWOHQOV6d1XJXOBUM1D2WOV6e4XJRNJfMEj00A6SOU6j4VJmMEQM:a0@T14ZOj6Q4dIeMN\\Md0c1QOVOn6U4`IfM]O[M77KM2O1O4_11nNo6k3nHPL=Q4AVMP8f2WHoK9k1[O66]O1]N_7U4gHoK9l1YO79\\OL_Nb7R4hHoK8W4IQMc7g2]HPL8X4KlLc7g2\\I<ROlLd7a2_IeL\\N]3c0ZMc7c2[H[L51\\O45a3>ZMb7a2]H_L120c3_9IaFbL1O3d3\\9F_H9b7E`H:a7D`H<b7B^H>c7_O`H`0a7^O`Hb0b7\\O_HiMYMZOH^2a:=_HgMUMU2]:3QGWMdN0i0?WOW2\\:2QGWMEa0mNW2^:0[HjMSMY2d:KSGZM[O;mNh2f:BQG]M[O9nNh2g:AkFdM_O1POk2g:_OjFeM@0oNl2j:\\OhFgM@NPOo2j:ZOfFiMJn2c9VOjEfMWOO>9n0l2f9SOaEjM\\O47KL9f0FGV3f:oNdEPN]OLL8V1Q3R:fNYFUNBX3X:`NWFWN@Z3[:]NTFZN@Z3`:XN]DYNg01I7c0W3c:UNZD\\Nf01K7b0W3j:nMmDdNH5f0U3i:nMhDiN[OO55R1R3h:oMmCiNd04_OM47a0IHU3g;mMiCmN60N4J051O49HJ4;P3j;kMfCPOd04_ON454Ie0T3c;dM[CZOg00N0o0Q3T;bMXC\\Oi00M0n0R3Z;\\MSCAa112R3a;TMPDJXO1W1Q3e;oLmCOWO1X1P3n<nLlA1V1Q3n<nLlA1=OMP3j=QMiA2?NOn2k<RM]BO6132EO26i0ID0IOHm2c>TMhA1S10jNm2g`00O1ESMc_Om2\\?PM[A6XOj2\\?QM\\A5XOj2\\?QM]A4XOj2[?RM]A0RO16m2[?RM[A7YOg2d=RM^B0;OF132`06YOf2]?RM\\A7WOg2^`0UMe_Ok2h`00DSMe_Om2Y`0UMg_Ok2Y`0YMc_Og2W=RMhE7QMg2V=SMiE6QMg2U=TMcENWM82e2T=VMYCMCO`10cN1J93d2U=TMYCOi18iMe2m=RM`D1dMn2i`0N20O0ISM]_Ol2d`0UM[_Oj2f`0VMZ_Oi2f`0XMZ_Oh2c`0[M^_Od2o`0O1O10O01O01EYM]_Of2c`0]MZ_Od2f`0\\MZ_Oc2g`0]MY_Ob2h`0]MY_Oa2i`0^M[_O^2g`0aM[_Ob0DCO[1ca0cN]^O91G1[1da0cN_^O40K05LK1=3Ehd0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:adult/old/aged"], "control_dims": "face expression, maturity, gender, hair type", "answer": "The image features a young man wearing a yellow shirt and a brown tie. He is standing in a room, possibly in a restaurant, and appears to be looking at something. The man is wearing a white shirt, which complements his outfit. The room appears to be dimly lit, creating a somewhat mysterious atmosphere."}, {"question_id": 417, "height": 390, "width": 640, "image": "000000024021.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity", "region_anno": {"bbox": [581.86, 161.88, 56.8, 82.81], "segmentation": {"size": [390, 640], "counts": "jkm65k;7K5M4M2N2N1O10000O01O1OXO]OnEc0P:GiE8X:JeE7X:YOaEb054Z:2cEO\\:n0O1000001O000000100O102iEXNk9R2001\\NPFn0T:kNRFQ1S:jNoEU1b:O001O0O2O001O10O010O101O00010O2O01nNYE?Z;A`D3b;J^DN21i;602NFWD5V4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:straight", "maturity:young/baby"], "control_dims": "maturity, hair type", "answer": "The image features a young man wearing a suit and tie, standing in front of a group of people. He appears to be the center of attention, possibly posing for a picture. The young man is wearing a tie, which is visible on his neck.\n\nThere are several other people in the scene, some of whom are also wearing ties. They are standing around the young man, creating a sense of a formal gathering or event. The group of people is quite diverse, with individuals of different heights and positions, indicating a lively atmosphere."}, {"question_id": 418, "height": 423, "width": 640, "image": "000000334417.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, hair type, maturity", "region_anno": {"bbox": [100.45, 64.58, 497.0, 351.25], "segmentation": {"size": [423, 640], "counts": "hYY13S=1O1O1O100O1O1O1O100O1O1O1N200O1O1O100O1O1O1O1O1O1O1O100O1O1O1O1O1O1O1O1O1O1N2O1O1O1O1O100O1N2O1M3O1N2N2M3O1O100O100O1O100000UNjDe1V;ZNlDe1T;\\NkDd1V;62NO100O1N2O10000N2O1O100O100O1L4O1O1O1N2O1N2O1O1NcMbEU2\\:mMdES2Y:?M3M3N2N2L4N2M3L4N2L4M3LTOlFmMR9k1^GoM_8T2bGkM[8W2YG[MM>h8Y2XGWNe8m1YGTNc8k1]GYNb8i1^GWN]8l1cGWNW8k1lGiMMWOT8R3nGTNR8l1nGUNP8l1PHTNP8n1nGSNQ8a302O0OYNPHZNm7g1THZNj7g1VHYNj7f1WHZNh7c3NUNXH[Ng7c3N2O1N2O1O1NQNcHXN\\7h1eHXNZ7i1dHYN[7h1eHXNZ7i1fHWNX7k1hHUNX7k1hHTNW7n1iHRNV7P4O1O1O1O1O1O101N0010_MSIlLOX1m6j1WIjNi6T1XImNg6R1[InNe6P1]IPOb6o0`IQO`6l0bIUO]6i0fIWOZ6f0iIZOV6c0nI\\MYOD0g1i6W1PJ^MWOC1h1g6V1RJ`MVO_1h6m0VJEi5:YJFf59[JHe57\\JIc57^JhMmN^1e6\\O[I0T1VOlN^1d6i0aJiMkN^1d6i0`JjMlN@1h1_4VNaMh2TOjMkN@1j0O0_4WO_Mf2WOJg2gMXL3a1]2AId2]NdMo1HfMjNX1g3WOcMm1MdMiNX1e3YOaMn12aMhNX1b3]O`Mm15_MjNV1_3B\\Ml1<\\MiNV1^34bLd1W1RMjNU1[3m3kMoJlN4L1[3j2gLZL0l1V1lNkN2N2Y3j2mLUNQ1nNkNP1U3n1PMSNQ1oNjNP1T3m1SMTNn0QOjNn0T3n1mL\\LOf1V1SOjNm0S3o1lL^L0c1V1TOkNl0R3P2mL\\L1d1U1TOkNl0Q3P2oL\\L0d1T1VOlNi0P3R2RMWL0i1P1VOnNh0P3m1_MUNa0WOoNPOOe1Q3n1bMWN=WOQOnN13N?0:Q3h2bMXN;YOTOa0n2o1dMVN9[OTOa0o2n1dMWN7[OVO`0o2o1dMUN6]OWO?n2Q2eMSN4_OXO=n2S2eMQN4@YO<n2S2fMQN2@\\O:l2V2eMPN2B\\O8l2W2gMoMOC^OMOmNm2e3fMnMOD_OdNOi00\\O00m2d3gMoMND_O6k2X2hMnMND_O6j2Y2jMmMKF@4j2Z2kMlMH`1\\2f0lMiMFY1EUMi2i3lMjMCOHIh2_2QNhMXO40A0aNf2S4SN\\1l1gNSNEXOeMd2g2VNBVOgMc2h2WNBUOfMd2h2PNhKB[5]2nNZNQ1e1PO[N@SOdMa2m2]N^OSOdM_2o2`Nj0a1UOaN]OoNaM`2S3aN\\OoNbM^2S3cN[OoNZL0S1^2X3cN[OoNZL0S1]2Y3dN[OnNaM^2T3dNg0\\1ZOcN]OPOYM]2[3cN\\OQOXM\\2\\3cN\\OROWM[2]3dN[OROWMZ2^3dN\\OROTMLQO\\2`4eN[OSOTM[2a3bN[OSOTM[2a3bN\\OROSM\\2a3bN^OPORM\\2a3dN^OPOmLOVO[2`4eN=POSK[2`4eNb0[1_OdNa0\\1_OdNa0\\1_OdNASOgLY2i3bN<SORK\\2b4^N=WOQK[2b4fM[Kb0T5]OoJZ2d4fMYKc0Z5g1]OeM[K73OT5U2^OeMZK76NR5V2_OnM_KLR5V2@lM_KN]4KmK[2X4jMaKL]40hKZ2[4iM;OXKX2i9hMoEM0[2Q:hMoEM0[2Q:hMoEM0[2o9jMQFK0[2m9kMTFJO[2k9eMPF56KO[2k9eMQF27NM[2o9fMUFOL[2o9fMUFOL[2\\:eMdE[2f9eM[F13OL[2e9gM[F03NM[2d9mMVFK1N4O1\\2b9hMYFNO12M301\\2_9kM\\FKO0:NL\\2_9kM\\F08IM]2\\9gM^FO147JN\\2[9hM_FN147JN\\2[9hM_F97CO\\2[9YNfF[ON\\2\\9ZNdF[O0[2\\9[NcFZO1[2\\9[NbF[O2Y2]9XN_F^O113Y2]9XN`F^O003Y2^9YN^F_O1O3Y2^9]NaFZO1Y2^9]NaFZO1Y2^9_N_FXO3Y2^9_N_FXO3Y2^9_N_FXO3Y2^9]NaFZO1Y2^9]NaF[O0X2`9\\N`F[O1Y2_9]N`FYO1Z2`9]N^FYO2Z2a9VN[FA202Y2a9VN[FB1O3Y2b9\\NZF[O4Y2c9[NYF\\O4Z2d9XNXF_O3Y2g9TNXFC1Y2i9QNXFEO[2i9oMXFFO[2j9lMXFIO[2j9gMQFN7ON]2Z:cMfE^2Y:aMhE_2n9dMoE02]2m9lMSFU2T:dMkE]2V:aMjE`2U:`MkE`2V:_MjEb2U:]MmEc2Z:2aKhMmMX2Q2nMkMS2R2QNlMo1S2SNlMm1Q2VNoMk1n1WNRNi1l1YNTNg1j1[NVNe1h1^NWNc1e1`N[N`1c1bN[N`1c1bN]N^1a1dN_N\\1^1gNcNX1Z1lNeNT1Z1nNfNQ1Y1QOfNP1W1SOiNl0V1WOhNj0W1ZOeNf0Y1@cNa0\\1AbN?]1BcN>]1BcN?[1CdN>[1CdN=[1DeN=Z1DeN<Z1EfN<X1FgN;W1GhN:V1HiN9U1JiN7T1LkN5S1MlN5Q1MnN5n0NQO5j0OTO3i0OVO3g0OXO4c0O\\O3a0O^O3?NA4<NC3;OD291F073HNAWL\\Nn3S2M\\Oj0c0WOWOo0h0ROQOU1n0mNnNU1R1mNgNY1X1kN^N\\1a1gNXN]1h1eNRN`1m1bNgMaK2Q6W2j4O001O001O1O1O1O0000001O00001O00001O00001O0000001O0000001O0000001O00001O00001O0000001O001O00001O001O0000001O001O001O00001O001O00001O001O00001O00001O001O00001O0000001O001O001O001O0000001O001O00001O001O00001O00001O001O0000001O00001O001O1O1O1O1O1O1O2N1O2N3M2N3M3M4KZPc0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "hair type:curly/curled", "maturity:adult/old/aged"], "control_dims": "gender, hair type, face expression, maturity", "answer": "The image features a man wearing a suit and tie, standing in a room and eating a slice of pizza. He is holding the pizza in his hand, taking a bite. The man appears to be enjoying his meal, possibly during a break or a casual event. The scene captures a moment of relaxation and indulgence for the man in his suit."}, {"question_id": 419, "height": 427, "width": 640, "image": "000000018491.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "cleanliness, color, length, material, pose, texture, transparency", "region_anno": {"bbox": [0.0, 141.07, 223.94, 11.89], "segmentation": {"size": [427, 640], "counts": "d46U=000000000O10000000O1000000000000000000000000000000000O1000O10000000000000000000000000000000O1000000000O1000000000000O10001O000000``a0N__^O3O1000O1000000000O100001O00000000000000O101O0001N10000001N11N101N1000P`23m_M1O00O10000000000000000O100000000000000000000000000000O110O001O00000O010000O100000000000000000000000000O100000000000000000000000O100000000001O0Ong]5"}}, "object_label": "bench", "attribute_label": ["cleanliness:clean/neat", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, texture, pose, transparency, cleanliness, length", "answer": "The image features a bench situated in a grassy area, likely in a park or a similar outdoor setting. The bench is positioned near a fence, providing a comfortable spot for people to sit and enjoy the surroundings. The bench is empty at the moment, with no one sitting on it. The grassy area surrounding the bench adds to the serene and peaceful atmosphere of the scene."}, {"question_id": 420, "height": 640, "width": 640, "image": "000000233771.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "cleanliness, color, length, material, pose, texture, transparency", "region_anno": {"bbox": [1.07, 323.82, 62.21, 121.17], "segmentation": {"size": [640, 640], "counts": "T:a2_a01O2N3M100O00100O001O0001O0001O0a_OXMf?h2Z@YMf?g2Y@YMg?h2X@WMi?V3j_OiLW`0X3f_OhL\\`0X37N15K0001O01O000010O000000000011N00000001O0O1O1O1O2N1KW_ORMk`0c2V_O[MXa0a2;lN\\^O_Ooa03T^OL_b0VO_]O3mk];"}}, "object_label": "bus", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, color, material, transparency, length, texture, cleanliness", "answer": "The image features a large double-decker bus driving down a street. The bus is quite long and has two levels, making it a popular choice for public transportation in some cities. The bus is positioned in the middle of the street, and there are no other vehicles visible in the scene."}, {"question_id": 421, "height": 640, "width": 640, "image": "000000233771.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [526.99, 101.95, 13.03, 29.76], "segmentation": {"size": [640, 640], "counts": "\\_Y:<bc06J4N1N2N2O1O001O0001O1N3_OUim1"}}, "object_label": "clock", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:glass", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, size, transparency", "answer": "The image features a close-up view of a clock face, which is the front side of a clock. The clock is white and has a black background, making it stand out against the white wall. The clock face is positioned in the center of the image, with the time displayed prominently. The clock's design and placement create a visually appealing and functional display."}, {"question_id": 422, "height": 640, "width": 480, "image": "000000322844.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, length, material, pose, texture, transparency", "region_anno": {"bbox": [102.78, 95.54, 255.36, 352.73], "segmentation": {"size": [640, 480], "counts": "adP2=`c06I5L5L3cLWO_Cl0]<]O\\Ce0_<A]Cb0]<G^C:a<I]C8_<L_C5`<N]C4_<0_C2_<0_C1`<1^C1a<O_C1`<1^C0a<3\\COa<4]CNa<3^COa<2]COa<3_CN_<WNfAi1k10_<WNgAi1h12`<UNhAi1g14_<TNjAh1f16_<OaBVN1m1]=M_B]NOh1`=L_BaNNd1b=J`BfNK`1e=J\\BmNK[1h=Y1SBgNm=e31010O001O1O001O001O0000001O001O1O0O2VBkI\\31l6V6TIjIk6V6WIiIi6W6`31fEhIi6Y6^FhIA0X20h7Y6_FhI^O1[2Nh7Y6_FhI]O3b<V6RDnIm;S6SDeI\\O2b<Z6RDcI]O2b<[6QDcI^O1_<]6TDbIP<`6PD`IP<`6g0O2000O01O10O0001N1O2K5N1N3VOYBYKi=f4[BTKh=l4[BmJi=S5YBjJh=V5a0000O10000O1000O0100O10O1I]APKd4NX5o4P5\\MRA7o>IRAPN4c1k>=PAQN3d1m>j0PAXOP?l2]FTKR4l4nKUKP4l4PLUKP4j4PLWKo3i4QLXKm3i4VLTKj3g2gFXOn>g0TAXOm>i0PAXOP?l20001fFQKa3o4^LSKa3m4_LSKa3m4_LSKa3m4`LQKb3n4h5001O01O0010O1O000010OcEQKi5o4d400002O0OO10000100VEoJc6o4X4O2O1NXFVK\\4j4cKWK]4h4_5OaAWKg=i4iFYKe4f4\\KZKe4e4[K[Ke4e4[KZKg4e4Z501O1OhE]KS5c4U5001O0cE]K]5c4cJ]K]5c4P51O0O5LEo@hKP?W4QARLf>n3ZATLd>k3]AULa>m3_ARLb>l3^AnKLFo3Nk6\\4\\ERLf>m3XAfKL<n>l3WAVLk>g3WAXLj>g3WAXLk>f3VAZLj>e3WAoKJ5P?k3UA]Ll>a3PAeLN]OU30[8k3`DUMV1PO`02i9h3bDVMU1oNX<j3dBWMi>e2YA\\MQ1oN[<b3fB`Mn0nN_<]3dBjMi0iNc<Y3hBnMe0iNd<V3iBQNc0jNc<S3lBYN;eNi<n2nBgNBZNK3O0g=i2nBlN[OmNg=h1_BaMe0j1UOeN0Fi=g1WB_NX1m1lNlMi=X1TDe0oMTN4Oj=U1VDg0nMVNN1n=m0YDl0mMYNLI=0R=n0jDk0QN[NHL;0S=k0kDm0RNYNFO:1U=f0jDR1nMZNS>b0PDS1gMVNN7\\>?oCe1U<lM_A0^2S2U?F]^OWNca0j1\\^OWN4HYa0Q2e^O]N3Dm`0P2o^O^N1Do`0n1Q_OTNON4Nn`0P2n^OSN2M3On`0Q2m^O\\NZa0e1i^OWNWa0j1i^OUNXa0k1g^OUNYa0l1f^OUNYa0k1i^OSNWa0n1k^OQNKL5Ne`0T2\\_OQNJN3Of`0R2`_OUNJIg`0Q2a_OTNHKh`0Q2b_ORNDNk`0o1b_OZN^`0f1b_OZN^`0f1c_OWN_`0i1c_OTN^`0l1e_OPN]`0o1e_OnM\\`0R2j0O1O1O0SNQ^Oi1Pb0VNQ^Oi1Qb020O2O1O001N3N2N0O2_Nd]O\\1^b01102M2O003J4O2M4K3N5K3M9Gjj]2"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, cleanliness, pose, color, material, texture, length", "answer": "The teddy bear in the image is brown and has a red ribbon around its neck. It is sitting on a wooden bench, positioned next to a stuffed fish. The teddy bear appears to be looking at the fish, creating a playful and friendly atmosphere."}, {"question_id": 423, "height": 448, "width": 640, "image": "000000335427.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "cleanliness, color, length, material, pose, texture, transparency", "region_anno": {"bbox": [45.3, 116.78, 235.58, 326.19], "segmentation": {"size": [448, 640], "counts": "ZXd02o=002NO5NM1_k00`TO2O2N001O001O10O@LSC5l<LTC5j<LVC4h<MXC4g<MXC3h<NWC3i<LYC2h<OWC0j<OXCOX<KiC6O0V<LjC5OOV<NjC41LV<OiC51KV<2iC3OLX<1iC4NKZ<2fC41GZ<5eC42E[<7cC3j<NUC2k<NUC3j<NVC2i<NWC2j<NVC2i<OVC2i<NXC1h<OYC0h<1VC0i<0XCOh<1YCNg<2ZCOe<1ZCOf<1ZC0f<0ZC0i2Eh6;`FOg2Fj6<^FOg2Gi6:`FOc2EUM4h98aFMd2Kl68`FNa2GVM1j99_FO[2G]MO04h97aFOX2F`M1N3k96_F0\\2JYM0k97`FOS2OdMLj96^F0R2NeMNk95^FNQ2NgM2h92`FNT2KdM4j92^F0S2JdM6k9O_F1U24\\7M^FNU26^7K]F0T2MbM0k93`F0T25]7K^F0U26\\7K_FONJi1:k7L_FOL1e14P8M^FNK9K^Oc1?X8L_FOH=e1DU8O^Fk0`1TOR82_Fh0`1UOQ85aFe0Z1XOT83bFe0Y1QOZN3k96aFf0Z1POZN6k95_Fh0^1UOR83_Fh0_1kNXN8k94^Fg0`1lNXN:j95[Fe0KlNk19o76XFf0MlNl19P8a1nGUNWN9k9a1QH`NP8_1oGcNP8]1oGfNo7Y1SHfNn7Y1QHZNTN<j9Y1VHgNk7X1THjNk7V1UHjNl7U1YHgNg7Y1YHfNh7Y1XHgNh7Y1XHgNg7Z1XHiNg7V1XHjNj7V1TH^NPN;l9V1XHiNi7V1VH_NnM:k9X1[HfNh78WF7Q2Bb8;^GFb8:YGJh85WGMi83UGOk80WGOi81VG0j8OVG0l80TG0k80XGNh82WG_OPN;j:5ZGLf83VG1j80TG2k8OSG3l8NSG2n8MRG4n8KTG3l8ORG1o8NTG1j80UG0k80TG1m8NRG4m8MRG4n8LPG6o8JRG6n8JQG6o8KPG5Q9KnF6Q9JPG6P9JPG6o8KoF7Q9HPG7P9IPG7Q9ImF;P9EPG;P9FoF<P9DPG:Q9GnFJbNI`:=mFIeNK\\:=nFGhNK[:=nFEjNMX:?mFDlNKY:a0jFD_NI1M63a:d0hFJlNCX:c0kFHnNGV:a0lFFnNLV:>lFCTOKP:b0lFAVONm9c0kFZOcNOf0O[O3`:e0PGWOZO4g9e0lG\\OT8c0lG^OS8c0nFZO[O2g9f0kFXO_O1h9g0hFVOlN1<0Q:i0oFYOoNOR:i0mFWOROOT:j0iFVOSO0U:k0]GUOe8k0ZGTOg8m0WGSOj8m0UGSOl8n0aFQOeN141h:o0\\FPOfN11OO2o:o0XFPOiN07Oj:Q1nEoNPO7;Ig:R1PFUOWOJk:Q1nETOPOJ02S;Q1kESOQOK10U;S1iEQOPOK41S;U1gEoNYOKR;U1dESOVOHX;W1_EROVOI\\;W1[EUOf:l0YESOh:n0VEROk:o0UEoNm:Q1REnNo:S1PElNQ;V1mDiNT;W1kDdNBOc;^1RE_NP;c1f02N1O100O1O1O1O010O2M02O000O1O100O1O2N1O1O1O1O1N2O1O2M2O1O1O1O100O1O1O2N1O1O1O1O1O1O1O2N1N3N2M4Kh`m4"}}, "object_label": "fork", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, material, color, length, texture, pose, cleanliness", "answer": "The fork in the image is made of silver and is placed on a wooden table. It is positioned next to a spoon and a knife, all of which are arranged on a dining table. The fork is likely used for eating a meal, and it is placed near a bowl, which could be filled with soup or another dish. The presence of the fork, spoon, and knife suggests that the table is set for a meal, and the dining utensils are ready for use."}, {"question_id": 424, "height": 553, "width": 640, "image": "000000186624.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [31.03, 314.09, 45.3, 46.28], "segmentation": {"size": [553, 640], "counts": "lca05Pa05M1O100O2O1O2O1N2NG9O1L5N2MWa03g^OMo^O1Pa01310OO010l_OOR?0o@2n>OQA3m>KVA5h>MXA3h>MXA3h>MWA4j>Kf@1I5a?Kd@2J2d?L]@6NOe?L[@60Ne?MY@52Of?NT@45Oh?8P@@87i?8[@Hh?6V@Ho?6P@IT`05k_OKY`00i_OOY`00f_ON^`00Qj`9"}}, "object_label": "handbag", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "state:closed", "texture:smooth/sleek"], "control_dims": "texture, material, color, transparency", "answer": "The handbag in the image is black and has a strap. It is being carried by a woman who is wearing a white shirt."}, {"question_id": 425, "height": 640, "width": 480, "image": "000000224724.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [283.84, 514.39, 35.64, 57.68], "segmentation": {"size": [640, 480], "counts": "XXc5<dc0d0\\O?B2ON001O100O2N1O1O1O2N1O1O2N001O1O1O1O0O2O1O0O2O1O1O1O1J6Cc\\ON00ZZU3"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "state:closed", "texture:smooth/sleek"], "control_dims": "state, material, texture, color", "answer": "The image features a black car parked next to a brick wall. The car is positioned in a parking space, and it appears to be a small vehicle."}, {"question_id": 426, "height": 640, "width": 480, "image": "000000224724.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [285.0, 509.72, 136.21, 54.53], "segmentation": {"size": [640, 480], "counts": "nWc58hc02M3N00001O001O1O2N1O1O1O001O00000g\\O]OUc0i0N1O1O001O001O0000B[]OAeb0>?N2M300O11O001O00000000O11O1O1OM`\\OF`c0:a\\OE_c0;a\\OE_c0;a\\OE_c0;30`\\OFZc0:d\\OLXc0?O2N000000O1O1N2F:0000000001O00001MT\\4LQdK8`\\OIib09T]OIlb08R]OIPc06n\\OJSc06l\\OIVc06j\\OJYc0=1O1O1O1O01O00106I000100O010O0100O2O0O2N011N100O01O1O001N10000O1N3K4N2N1O2O2N100M3M4N100000Qd04k[O1O01OToT1"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "state, color, pattern, transparency, texture", "answer": "The car in the image is a small white car, parked on the side of the road."}, {"question_id": 427, "height": 438, "width": 500, "image": "000000451879.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [43.74, 128.94, 78.83, 58.82], "segmentation": {"size": [438, 500], "counts": "fj`0g0k<6J6L4M1O3M1O1O100O001O1O1O1O1O2O0O1O1O2O0O1O10000O11O00O2O0000001N101O1O100O10O001O1O000000001O00001O2M1O2O1N2N2O0O2N2N2N2N101N1O2N1O3M1O2N2SO\\Ce0l<O0O3N4L5K3M3MWWS5"}}, "object_label": "baseball glove", "attribute_label": ["color:black", "material:leather", "transparency:opaque", "pattern:plain", "state:dry", "texture:smooth/sleek"], "control_dims": "pattern, transparency, color, material", "answer": "The image features a baseball glove, likely a catcher's mitt, with a black leather exterior. The glove is being held by a person, possibly a baseball player, who is looking at the camera. The glove is positioned in front of the person, with the person's face partially visible in the background. The glove appears to be well-worn and is likely an essential piece of equipment for the player."}, {"question_id": 428, "height": 640, "width": 480, "image": "000000453040.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [0.0, 290.88, 480.0, 109.24], "segmentation": {"size": [640, 480], "counts": "f:e1[b00N3O0O10O010000O100O10O0O2O0O2O1O001O010O001O0100O101O0O2O1O1N101O1N2O1N2O001N2O1N1000jN[^O1da00`^OKaa04e^OG[a09h^OCXa0>j^O^OXa0b0i^O\\OWa0e0k^OWOWa0i0l^OROVa0n0m001000O100O_OV]OMkb01Y]OMgb01\\]ONdb01^]ONbb01_]OO`b01a]OO_b0Od]O1[b0Ng]O1Xb0Oi]O1Wb0Nk]O1Ub0Nl]O2Sb0Nn]O2Rb0LQ^O2Pb0MQ^O3oa0LR^O3na0MS^O3ma0KU^O5kb0O1O1000000O1000000000001O0OUk`5OlT_J3M2O1N1000001O001O1O002N2M2O1O1O0O3N00000000O1O100O100O100O10O01000000000O010GAP]O`0Pc0Bn\\O=Sc08000010O1O2O2M2o\\OSOkb0Q10001O10O01O00010O1O00100O1O2OO01O2O0O1O1O100O2N2O2M1O01O001O00010O01O01O01O010O0010O01O01O010O00010O00010OS^O\\N^a0d1b^O]NGO`a0e1f0O1iNg]OC1014O9V8"}}, "object_label": "dining table", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "state:covered", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The dining table in the image is adorned with a beautifully decorated cake, which is the main focus of the scene. The cake is placed on a plate, and it is surrounded by a few green leaves, adding a touch of elegance to the presentation. The table appears to be set for a special occasion or celebration, with the cake as the centerpiece."}, {"question_id": 429, "height": 480, "width": 640, "image": "000000007574.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [464.03, 312.24, 21.72, 67.58], "segmentation": {"size": [480, 640], "counts": "QWk6172Y>`0L6I8J4hBPOX<n1N1OO1O1@^CaNd<S1TCkNa=Q19J6K5K5K6KYjX2"}}, "object_label": "wine glass", "attribute_label": ["color:blue", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, color, texture, pattern, pose", "answer": "The wine glass in the image is a tall, blue glass vase that is placed on a table. It is positioned in the center of the scene, drawing attention to its unique and eye-catching design. The blue color of the vase adds a striking contrast to the surrounding environment, making it a focal point in the image."}, {"question_id": 430, "height": 400, "width": 600, "image": "000000009378.jpg", "category": "description", "question": "Describe the frisbee in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [190.5, 217.24, 169.17, 40.92], "segmentation": {"size": [400, 600], "counts": "Q^Z2:T<3N1O2O0O2O0O100O2O0000001N100000001O000000001O0000000000001O0000001O000000001O000000000000001O0000000001O01O000000000000001O000000N3J5O11O000000000001O0001O000000000001O0003M5K1O1O00000001O00001O0001O0000000000010O000000000001O000001O01O0000000000001O00000000010O00000000001O00001O000000001O000000001O00001O00001O001O001O0O2O1O1N1O2N5Iolm2"}}, "object_label": "frisbee", "attribute_label": ["color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, texture, color, transparency, pattern", "answer": "The image features a person holding a yellow frisbee in their hand. The frisbee is large and brightly colored, making it stand out against the background. The person is positioned in the center of the scene, with the frisbee held in their hand, ready to be thrown."}, {"question_id": 431, "height": 640, "width": 480, "image": "000000017899.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [122.71, 366.69, 50.72, 12.92], "segmentation": {"size": [640, 480], "counts": "dW]28gc0100000O1000O01000O10000O010O1001N1000000001O00O2O0O100O01000O100O10000000000O01000O1000O12Ma\\Q6"}}, "object_label": "knife", "attribute_label": ["color:black", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, pose, texture, transparency, color, material", "answer": "The knife in the image is a large, sharp, and long blade, likely used for cutting or slicing various materials. It is held by a person, who is standing on a sidewalk. The knife is positioned horizontally, with the blade facing the viewer. The person is holding the knife in their hand, and it appears to be a close-up shot of the knife and the person's hand."}, {"question_id": 432, "height": 640, "width": 480, "image": "000000017899.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, material, pose, size, texture", "region_anno": {"bbox": [204.72, 584.58, 14.54, 39.44], "segmentation": {"size": [640, 480], "counts": "kVn31oc00O1B1k\\OOTc04U]OK`b07^]OKbb05R]OI25nb00o\\OKO1M7Tc03l\\O3Sc0>O1O1O10HR]O[Oob0c08Ch\\O1fc0M2MTaR5"}}, "object_label": "bird", "attribute_label": ["color:black", "color:red", "material:paper/cardboard", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material, pose, size, color, texture", "answer": "The bird in the image is a colorful parrot with a red head. It is perched on a branch, surrounded by greenery. The parrot appears to be the main focus of the scene, with its vibrant colors and striking appearance."}, {"question_id": 433, "height": 640, "width": 427, "image": "000000025386.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 520.31, 138.36, 119.69], "segmentation": {"size": [640, 427], "counts": "d`0Q12VO:5ba0e0T^OVO:6_a0o0`^OUOVa0@e^O[15WOZa0k0d^OWOYa0Q1`^OaNO8`a0W1`^O^N5;Za0R1a^OcN:;Ua0R1Q_OmNo`0[1h^OgNWa0[1b^OkN^a0l1[_ObMf?^2Y@cMh?]2W@cMj?\\2V@dMj?l1`_O^Ne0Fl?k1__O`Ne0Dm?k1^_ObNd0AP`0m1[_OcN^a0P2001O4K2O0XO^^OQOca0m0]^OTOda0j0\\^OWOea0g0Z^OZOha0d0W^O]Ola0[12POQ^OJPb03Q^ONQb00n]O1Rb0Ko]O7Rb0l01hNl]Oa0Tb0^Ol]Oc0Wb0XOj]Oi0Xb0mNo]OT1Zb05O000e]OdNQb0]1o]OcNma0b1P^O`NPb0f12O002O0004L0001O00001O00001O001O1O001O001O001O1O001O00001O1O001O001O001O001O001O001O001O001O00001O1O001O001O00000000001O001O001O001O001O1O001O001O001O1O1O001O001O1O1O001O1O<^O\\\\O0k[h5"}}, "object_label": "chair", "attribute_label": ["color:blue", "color:gray", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, color, texture, pose, material, pattern", "answer": "The image features a blue denim chair with a blue and white striped cushion on it. The chair is positioned in a room, and it appears to be a comfortable and casual seating option."}, {"question_id": 434, "height": 426, "width": 640, "image": "000000063154.jpg", "category": "description", "question": "Describe the surfboard in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [243.87, 195.28, 106.12, 29.75], "segmentation": {"size": [426, 640], "counts": "^TV32W=2N100O10000O100O100O100O100O2N100001O0000000000O100O100O100O1001OO100O10O1000O1O100000O010000000O01O100O02O000000O010O10O10O1000O2O00001N2O1O0O1000000O100000O01O100O100O100ON3O00O2O10O11M2N2O11O0000O10001O00^^h3"}}, "object_label": "surfboard", "attribute_label": ["color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, material, transparency", "answer": "The surfboard in the image is white and appears to be a longboard. It is being ridden by a person who is lying on their stomach in the water. The surfer is wearing a wetsuit, which is a common attire for surfers to keep warm and protected in the water. The surfboard is floating on the water, and the surfer seems to be enjoying their time in the ocean."}, {"question_id": 435, "height": 426, "width": 640, "image": "000000063154.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [252.3, 137.12, 138.04, 79.44], "segmentation": {"size": [426, 640], "counts": "_TV31X=1O1O10000O100O100O1O2N1O011OISC1l<0UCOj<1WCOh<2XCNg<2ZCNe<3[CMd<4\\CLc<4^CLa<5^CLb<4_CK`<4bCL]<4dCL[<4fCLY<4hCLX<3iCMV<3kCMT<4lCKU<4kCMT<4lCLT<3nCLQ<4PDLP<4PDLo;4RDLn;4RDLn;3SDMl;4TDLl;4TDLl;3TDMl;4TDLl;4TDLl;4UDKk;5UDKj;6e0O10TCJc<7]CIc<7]CIc<6^CJa<7_CI21S<6VDIk;7TDIl;8SDIm;7SDIm;7SDIm;7SDIm;6SDKe;1mC5>Jc;`0VD^OK2m;b0XD\\OK1m;d0]D]Ob;e0]D[Oc;f0[D[Od;f0\\DZOd;g0[DXOf;h0ZDWOg;i0ZDVOg;j0XDVOh;j0XDVOh;j0XDVOh;j0=N10hCYOo;e0QD[OQ<c0oC]OQ<c0oC\\OR<d09]O]Ca0b<4O1O1O010O0100O100000000O010000000000001OF\\OnCd0Q<^OnCc0Q<^OnC6NMX<IjC90Nl;I]D9GNi;N]D5JN`;J\\D;5M0N];<bDF2MZ;?dDD3MR;;gDB753Lo::XEJJLm:9[EIKKk:;\\EIKJi:=TECH5j;1SDI:3J1k;1^D0HMk;3\\D1o;OoC3R<KmC7S<IkC9U<GjC9W<IfC7\\<;000K5O2K4O1N3N1000000000001O001O1O1NjXX3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "hair type:straight", "maturity:adult/old/aged", "pose:horizontal/lying"], "control_dims": "face expression, maturity, pose", "answer": "The image features a person wearing a black wetsuit, lying on a surfboard in the ocean. They are riding a wave, skillfully navigating the water. The surfer appears to be enjoying the thrill of the ride, as they maintain their balance on the surfboard. The scene captures the essence of surfing, showcasing the surfer's ability to ride the waves and the excitement of the sport."}, {"question_id": 436, "height": 427, "width": 640, "image": "000000064898.jpg", "category": "description", "question": "Describe the surfboard in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [457.56, 280.43, 104.16, 22.87], "segmentation": {"size": [427, 640], "counts": "lPS62X=100100NQ`21o_M2N1N10000O1000KmB1T=31O1O00000000LMPC3P=NnB3Q=4001OO1O00100O11O0000O0100000O0100000O1000000O101O0O1O100000000O1000000O100000O10O10000000O1000O010000O10000O1000000LTCIl<7TCIl<7TCHm<93O001L]eP1"}}, "object_label": "surfboard", "attribute_label": ["color:black", "color:blue", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, color, material, pose, pattern", "answer": "The surfboard in the image is black and white, and it is being used by a person who is lying on their stomach in the water. The surfer is wearing a blue shirt and appears to be enjoying their time in the water."}, {"question_id": 437, "height": 480, "width": 640, "image": "000000068387.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [336.03, 108.92, 9.5, 45.02], "segmentation": {"size": [480, 640], "counts": "_Rn4h0;]O[=W1N0000O1B?DmdZ4"}}, "object_label": "baseball bat", "attribute_label": ["color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern, transparency, color, pose", "answer": "The image features a close-up view of a baseball bat, which is white in color. The bat is positioned vertically, with its end pointing upwards. The bat appears to be made of wood and is quite long, extending from the bottom left corner of the image to the top right corner."}, {"question_id": 438, "height": 640, "width": 427, "image": "000000079837.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [114.2, 350.3, 92.7, 68.8], "segmentation": {"size": [640, 427], "counts": "RdW25Zc0d0L4K7I4J6L4M2O2N1O00000000001O0O100010O0000000001O000000000O10000001O0000O10000001O00O100000000000000000WNl]Of1Tb0YNm]Og1Sb03000aNl]OR1Tb0=00O1000000001O001O00001O00001O00000O10001OO100001O3M000M3G>jNa]O:VW\\4"}}, "object_label": "boat", "attribute_label": ["color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, texture", "answer": "The image features a large boat floating on a body of water, possibly a lake or a river. The boat is white and black in color, and it appears to be a ferry boat. It is equipped with a life ring, which is hanging on the side of the boat. The boat is surrounded by a few other boats, indicating that it is in a busy waterway or harbor. The scene is captured at night, giving the image a serene and peaceful atmosphere."}, {"question_id": 439, "height": 480, "width": 640, "image": "000000106389.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [50.58, 23.62, 266.91, 179.73], "segmentation": {"size": [480, 640], "counts": "hno01n>1O100000000O2O00000000000O2O0000001O0000001O0000001O01OO10001O00000O10001O000O10000O2O000O101N1O101O000\\OBfB>Z=FdBGH=c=4bBL^=2eBM\\=0fB0Z=OgB1Y=NhB3X=LhB4Y=JgB7Y=IgB7Y=HhB9X=DiB=W=AkB?V=@jBa0U=^OlBb0h=110O0000001O000000001O00001O00001O00001N10001O00O100N2N2O1N2O1O101N1000001O00000000000000VOCRC<k<HTC8j<LTC4k<MUC2k<0TC0k<1UCOj<2VCMk<3UCMj<4VCLj<4VCLi<5WCJj<6VCJi<7WCIi<7WCHj<8VCHi<9WCGi<9WCGi<9WCGi<9WCGi<9WCGj<7WCIi<7XCHh<8XCHh<8XCGi<9VCGk<9UCGk<9UCFl<;SCEm<:TCFl<:TCEm<:SCGn<8RCGo<:PCFP=:PCFP=:PCEQ=;oBDR=<nBCT=<mBCS=<h010O1000O100PCC\\;>YD0d;0WD7g;IUD<j;DTDa0i;^OSDZ1Z;fNeD\\1Y;eNgD\\1X;dNgD^1X;bNhD_1W;aNiD`1V;aNhDa1W;_NiDb1V;^NjDb1V;^NiDd1V;]NhDe1W;\\NhDf1U;]NhDe1W;_NcDd1\\;^NaDd1];Q1O1O1O2OO11N@eD\\M[;U3O1000001N100O100OQOjDUNV;j1jDXNT;h1lDYNS;k2O1O1N2N2O2N1O2N1N2O1N3M2O2M2O1N2ORNjESOT:o2N1M3O1N1N2O10O100iMWFWOi9i0WFWOj9h0UFYOk9g0UFYOk9g0UFYOl9f0TFZOm9e0SF[Om9e0RF\\Oo9j21O0O11N100O10000002N:Fn0]KiDY10j0j;`N_D`1b<Nd0\\Om0QOZfg4"}}, "object_label": "bed", "attribute_label": ["color:brown", "color:tan", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, material, pose, color", "answer": "The bed in the image is a large, comfortable bed with a white comforter. It is situated in a bedroom, and the cat is sitting on top of it."}, {"question_id": 440, "height": 640, "width": 480, "image": "000000115946.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [240.19, 503.07, 18.63, 16.04], "segmentation": {"size": [640, 480], "counts": "lSg49ec03M201N1000O10000O100000100O2N3M1MSdY4"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, transparency, pattern, material, pose", "answer": "The image features a car driving down a street, with its headlights on. The car is a large truck, and it appears to be in motion. The truck is positioned in the middle of the street, and its headlights are illuminating the road ahead."}, {"question_id": 441, "height": 429, "width": 640, "image": "000000121242.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [483.79, 191.29, 92.78, 73.5], "segmentation": {"size": [429, 640], "counts": "g[^63T=0mB3R=4001O001O1O1O00O10000O2O0O10010000O01iNKVD6`00Y;;dDE\\;;dDE];;bDE_;:aDF`;9`DH_;8aDH_;8`DI`;7`DI`;7`DJ_;6aDJa;4^DMc;3\\DMd;3\\DMd;3\\DMc;4]DMb;3^DLb;6]DIc;8]DHb;9^DGm:EXEf0KEl:HUEf0NAn:MnDe04]On:T1QEkNP;U1PEkNP;U1oDkNR;V1mDjNS;W1lDiNT;Z1iDfNW;h10000O01O1DfDdN\\;Y1gDbN];^1cDaN^;^1dDbN[;^1eDcN0LS;a1lDeNOKU;`1lDeNNLV;o1200000010O0000000000001O002QNeDh1d;K4@VDWOQ<JPD`01DX<;gCE[<f0d0[O100O2M2LXZi0"}}, "object_label": "car", "attribute_label": ["color:blue", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern, material, texture, transparency", "answer": "The car in the image is a black SUV, parked near a fence. It is positioned close to the horses, with one horse standing next to the car and the other horse standing further away."}, {"question_id": 442, "height": 427, "width": 640, "image": "000000126137.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [167.14, 329.39, 72.11, 97.53], "segmentation": {"size": [427, 640], "counts": "m^V26R=3M3M3M3N2M3N2O1N2M3N2O1N2N2M3O1M3J6M3K5L4G9O1O1O_NSEf0l:XOWEh0i:SO[En0e:nN^ES1b:kN`EU1`:kN_EV1a:jN_EV1c:iN[EX1i:eNUE\\1m:cNQE^1Q;`NnDa1S;`NkD`1V;`NhDa1Y;81O001O1O00001O0000001O0000001O00001O001N2N1N3N2M2N3N2M4K4M4L5I:DjjV5"}}, "object_label": "tennis racket", "attribute_label": ["color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a close-up of a tennis racket with a white handle and a black and orange head. The racket is held by a person, who is likely preparing to play a game of tennis. The tennis racket is positioned in such a way that the strings are visible, showcasing the mesh pattern and the orange ball that is resting on the strings."}, {"question_id": 443, "height": 480, "width": 640, "image": "000000127517.jpg", "category": "description", "question": "Describe the surfboard in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [3.39, 0.0, 131.01, 456.28], "segmentation": {"size": [480, 640], "counts": "U4Y5c99Bb0C9D?]O`0G8H:D:G:G7L4I8H8J6E;J5I8J5I7K4M3K6J6K5I7K4K6L3M4K3N3J7L2M4K5M4J4MXOZN\\Db1d<N2L3O3M1O1O2N1O1O2N002N2N2N1O001O000000000000000000001O00000000000000000000O100000000000001O00O10O100O1O3M1O2O3M3M2N3M2M5L4K3IXNQCm1k<7L4J5K9H3K5L8G:H5K6H8I9F8H8I9E9H<D;D:F<D:F?^O?E;Cb0\\O`0Ad0[OQ1jNS1eLjCS2_j]7"}}, "object_label": "surfboard", "attribute_label": ["color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose, color", "answer": "The surfboard in the image is a large, yellow, and old-looking board. It has a star design on it, which adds a unique touch to its appearance. The surfboard is placed on the sand, possibly at a beach or a surfing spot."}, {"question_id": 444, "height": 480, "width": 640, "image": "000000128675.jpg", "category": "description", "question": "Describe the surfboard in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [321.66, 343.17, 125.47, 58.1], "segmentation": {"size": [480, 640], "counts": "gPk42n>1O1O1O100O1O0001000O0101O0O1O01O10O3N00000O01O100O010O001M3N3NI\\A2d>N^A0c>N_A2g>0100O010000O010O01000O10O01O01O000OP?OYRO0a>2]AOb>2\\A1d>501O001O1O0011N101O0O010O010O010O010O010O010O010O01O01O010O0010O0001O01O0001O010O0000001O00001O000000001O000O10001N101NeRj2"}}, "object_label": "surfboard", "attribute_label": ["color:orange", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The surfboard in the image is red and white, and it is being held by a person standing in the water. The surfboard is positioned horizontally, with the red part on the top and the white part on the bottom. The person is wearing a black shirt and is standing in the water, likely preparing to surf or having just finished a surfing session."}, {"question_id": 445, "height": 640, "width": 491, "image": "000000128748.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [291.96, 449.08, 48.89, 145.26], "segmentation": {"size": [640, 491], "counts": "ZVe51mc03M2M4L3M3M3M4L3L5L3M4K4M3M4L3M3M2N3M2N0N200001N2O1O0O101O0O2O001O001N100O2O0O2N2N2O1M2O1O1O2N3L5Kc0_O^mm2"}}, "object_label": "baseball bat", "attribute_label": ["color:black", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, pose, texture, transparency, color, pattern", "answer": "The image features a baseball bat lying on the ground, with a person standing next to it. The bat is black and appears to be made of wood. It is positioned horizontally on the ground, with the person standing close to it. The scene suggests that the person might be a baseball player or a spectator at a baseball game."}, {"question_id": 446, "height": 361, "width": 640, "image": "000000133233.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [411.11, 204.15, 88.95, 23.24], "segmentation": {"size": [361, 640], "counts": "jcd4324Q;Md;MaD000m:3oD3REJe:>O0=CZ;0`D9L20O001O001OO1EK`E7^:;0O1O010O1O10000000001N2O1O1O1O2E[EMne04nD9F2O1O1000O10010O0010O2M2O001N10001O00000001@oR1LRmN0dE8Y:=00O100001O10O01[O`EM5:]:Gd0O10QS`1"}}, "object_label": "boat", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, transparency, pattern, pose", "answer": "The image features a large boat docked in a harbor, surrounded by several other boats. The boat is positioned in the middle of the scene, with other boats of varying sizes and shapes surrounding it. Some of the boats are closer to the foreground, while others are further away, creating a sense of depth in the scene. The harbor appears to be a popular location for boat owners, as there are numerous boats docked in the area."}, {"question_id": 447, "height": 427, "width": 640, "image": "000000135673.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [313.05, 200.47, 103.81, 46.39], "segmentation": {"size": [427, 640], "counts": "hTS44W=0O2O1O1N3TCH`<;]CFb<b00000000B]C3d<L^C3c<K^C4d<J]C6l<O10O0100O100000O01001YOJWD6i;KUD6k;KTD5l;LSD5l;LSD4m;MRD3o;MPD3P<MPD3Q<MnC3R<NmC2T<NjC3V<NiC2X<NgC26Gd;8UD16Hf;7SD16Ig;7QD26Hj;6oC26Ik;d0UD\\Ol;c0RD^Oo;b0PD_OQ<`0nC@T<?kCBU<j00O2O0O2O0O2O0O2O0O2O1O0O2N10\\C]O`<b0aC^O_<a0bC_O^<a0600001O00L[CBe<=\\CCd<<]CDc<<]CDc<;_CDa<<7O10O10O1O1000000000000000000O1000001O000O101O1O0O2O1Nihl2"}}, "object_label": "airplane", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, texture", "answer": "The image features a large white airplane flying through the sky, with a blue sky background. The airplane is positioned in the middle of the scene, and it appears to be a commercial jetliner. The airplane is quite large, occupying a significant portion of the image. The sky is clear, and there are no visible clouds or other objects in the background."}, {"question_id": 448, "height": 427, "width": 640, "image": "000000135872.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [191.05, 177.84, 33.46, 88.92], "segmentation": {"size": [427, 640], "counts": "hT^26U=2N3M3N2N102M102N2M2O0O1O11OO3N0O32L11N2NOO3YOoNeD\\1c;oNUDf0m;QORDO4Q1^<G2N1N2O1N200O1O0O3M2MQCGo<75M3Mfn[5"}}, "object_label": "tv", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, color, pattern, pose, material", "answer": "The image features a flat screen TV sitting on a wooden table. The TV is turned off and appears to be a small, modern model. The table is positioned in the center of the room, and the TV is the main focus of the scene."}, {"question_id": 449, "height": 427, "width": 640, "image": "000000135872.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pose, state, transparency", "region_anno": {"bbox": [389.27, 144.94, 149.08, 246.63], "segmentation": {"size": [427, 640], "counts": "inR51o<2VC4f<:N2N2O0gM\\OjGe0V8[OjGe0V8[OjGe0U8\\OkGd0T8]OlGb0Y7\\O[G2[1c0W7A[GL^1b0V7D]GI]1b0V7G\\GG]1<]7NUGG^19^71nFEC1Q28_72mFED0P29^73mFEENQ2:]73nFDj19Y72[INe62[IMe65ZIKf65YILg64YILg64YILg64XILi64iGDM8Z84gGFO6Z84fGG05Z85dGG24Z85QGCI6j03\\84QGCH:h0O_84PGDG=h0Ka84QGCE`0h0Ic84oFCFb0f0Eg86nFBFc0c0Ej85nFCEc0c0Fi84oFCFc0a0Fj84oFCEd0a0Fk83oFCCg0b0Cl84nFC_Oj0`0TOA;b94nFC\\Om0c0QOA;b94nFe0MnNC9c93mFg05VOn84lFf05WOo83lFf05VOP94kFf05VOP95jFe06VOQ94jFe05XOP93kFf03XOR93jFe04XOR93kFd03YOR93kFd02ZOS92lFc01[OT91kFd00\\OU90lFFZOf0e0CV91lFB@f0=Hh0Hj68aHBBc0<J;KPO1U85cHABb0<M0`0^7AcHAB`0>NIg0c7[OcH@D>=j1\\7WNcHBC=<l1^7VNbHBC;<o1_7UNnHLBP2`7UNnHJ@S2c7TNkHI[OZ2j7oMjHGVO_2P8lMiHe2T6eLoIh0Ke1DmMb6HnIg0K\\1OSNX6KmIg0KX13UNU6NmIf0ASOG=LQ1Q1gNP62kIg0_OXOD7`0`0n7ZO_Hh0_OVOD7b0=P8]O\\H5TO4:DE9b0;P8_O\\H3UO68CF8d0;m7A]H2UO67EE7f0:l7B_HOVO83FF6h0:j7CbHJVO<0GF5i0;i7CPI7iNDE7j0:i7CPI8gNDF7g0IYO?c8FoH7hNDF7g0>k7@PI8eN1`07k7AoH7lNK9>l7@PI6kNL9>l7@_H3RO3:M8I[O>a8GVHHYOc0NK?L8J\\O;a8HPHI^OX1;TO:H]O:`8ImGZ1EPOb0B]O:_8JjGV26cM^O33;^8IjGW27bM^O34:^8JgGY27bM_O169]8KeG[29`M_O169]8KdG\\2:_M^O199[8L^G_2`0_MH6[8f2mGTMI5Y8h2nGSMI5Y8h2mGTMK4U8j2PHRML3Q8m2THPMK3o7n2WHoLK2l7o2ZHPMJ1k7Q2mGfMU19fNG:9k7Q2_ISNeNLj7X2nGcM04j06]OLi7l2jHXMUOB69k7k2lH]MZOHi7k2mH]MZOHh7j2TIZMUOLe7i2ZIVMhNI98d7i2]IUMfNJ:8a7i2`IXMoNO`7h2dIXMmN0]7g2iIVMlN3Z7g2`JZM^5f2dJYM[5g2gJYMX5f2iJZMV5h2iJYMU5R1cH6X2gNU5Q1eH8W2fNS5R1hH4X2kNn4Q1kH3Y2kNl4Q1nHJ^2VOb4o0VIoNQ32g3o0TMROhKJh6S1bMROeKMg6Q1fM^OY2a0hM@V2?lMBR2;SNEl17XNIg16\\NId12bNM]1OiN0V1NSOLm01VONj02XOLh03[OKd06^OHb08@Fa08Y6O3H7MWW[1"}}, "object_label": "chair", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:empty"], "control_dims": "color, state, transparency, material, pose", "answer": "The image features a black office chair with wheels, placed in front of a desk. The chair is positioned in a corner of the room, and it appears to be empty. The desk is equipped with a computer, keyboard, and mouse, indicating that it is a workspace. There is also a cup placed on the desk, possibly for holding a beverage."}, {"question_id": 450, "height": 427, "width": 640, "image": "000000135872.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "color, material, state, texture", "region_anno": {"bbox": [185.48, 174.43, 110.34, 97.61], "segmentation": {"size": [427, 640], "counts": "[h]2<Q<IiD5W;0SE:U:HhE>T:DgEFUOe0S;FfEDYOg0Q;FbED]Og0Q;H^E^OB0Nk0R;G\\E^OCR1P;FUEXOKV1m:FWE^OJb0n:0XE]OJe0n:MdE3[:MiEOW:3gEO\\OYOf:f0mE8T:JiE6Y:KeE4]:M`E3d:LXE4l:MnD5S;Q11O00OPNnDi1R;VNQEh1Y;0;E4K4M2N1O3M0ON12001O00001O00O100001O00O1000000000000000O11O000000O100000000000O10000000000O1000O100000O10001O001O1O1O1O1N2O1O2N1O1O1O1N2O1O1O1O1O1O2M2O1O1O1O1N3NgP`4"}}, "object_label": "laptop", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "state:open", "texture:smooth/sleek"], "control_dims": "material, texture, color", "answer": "The image features a black laptop computer sitting on a wooden desk. The laptop is open and appears to be in use, with its keyboard and screen visible. The desk also has a telephone and a mouse placed nearby, indicating that the user might be working on multiple tasks or communicating with others. Additionally, there are several books scattered around the desk, suggesting that the user might be engaged in research or studying."}, {"question_id": 451, "height": 393, "width": 640, "image": "000000147725.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [71.91, 171.2, 77.95, 95.48], "segmentation": {"size": [393, 640], "counts": "eik0Z15UOU:V2ZO1OO1000000000000000000O10O10O1001O00O10000001O00O11O0000000000001OO100001O0000O10000000001O001N101O0O2O1N3N2O0O3M3M2N3M3N3L2N210N3M1N3N3L1O4L2O2L;E?\\O\\Vl5"}}, "object_label": "truck", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, texture, color, pattern, material, pose", "answer": "The image features a white Ford van driving down a street. The van is parked at a stop sign, waiting for the traffic light to change. There are two other cars in the scene, one behind the van and another one further down the street. The street appears to be a busy urban area with multiple vehicles and traffic lights."}, {"question_id": 452, "height": 427, "width": 640, "image": "000000153669.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [589.68, 303.71, 35.36, 43.21], "segmentation": {"size": [427, 640], "counts": "Vne72Q=9H8K4M3N2N3M2N2O1O1O1O1O10O01O1O100O010O10iNTDo0l;POVDn0l;POVDo0S<01N101N2N101L_C\\Od<1]C1Vc7"}}, "object_label": "baseball glove", "attribute_label": ["color:black", "material:leather", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, material, transparency", "answer": "The image features a baseball glove with a brown leather exterior, which is being worn by a baseball player. The glove is positioned on the player's hand, with the catcher's mitt facing upwards. The glove is designed to provide a secure and comfortable grip for the player, allowing them to catch and hold the ball effectively during the game."}, {"question_id": 453, "height": 427, "width": 640, "image": "000000153669.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [280.6, 102.04, 82.07, 199.63], "segmentation": {"size": [427, 640], "counts": "oof3<U3HZ6`0eIGR6<mIEn5?RJBk5`0TJBW5DTHn0e2^OU5U1jJkNT5V1lJkNR5W1nJ_NQM1Q8a1nJZNQM005Q8a1SKZNkL4S8b1SK`Nm4`1UK^Nk4b1UK]Nl4c1UK[Nl4b0PH8^;DiD8W;FgD=[;^OgDc0P<1O1O101O0O101]ESOe8n0XGUOh8k0TGnNbN9`9GUGS1KUO36j8DWGQ1LVO18h8GVGl01ZOK9e8KYGb07\\OF=f8HZG?;kNA2O66h0a8I[G=c0jN\\O86i0]8T1lGkMA1085k0[8Q1oG^NFc0W8P1SHaNBb0W8n0VHbNAc0e0gNg6T2SI=EfMV7m1UI`0AgMW7i1WIT1g6lNYIT1g6lNYIT1g6lNYIT1g6lNXIU1h6kNXIV1g6jNYIX1f6gNZIY1f6gNZIZ1e6fN[IZ1f6eNYI\\1h6cNXI^1h6aNXI_1i6`NXI_1j6oLjHl0;V2m6jLjHP19V2`7jM_HV2a7jM_HV2a7jM_HV2b7iM^H`1KcMg7m0]H_13^Ma7S1\\H^15]Ma7T1ZH^1_8bNaG]1`8cN`G[1b8eN^GY1e8fN[GZ1e8fN[GX1h8gNXGX1j8lMSG53n1d9oM\\FP2g9nMYFQ2i9nMYFn1i9QNZFJDe1W:`NbFm0o9QOUF=g;IUgc3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, face expression, maturity, gender", "answer": "The image features a baseball player wearing a red and white uniform, sitting on a bench in the dugout. He is holding a baseball glove, likely preparing for the game or taking a break. There are several other people in the scene, some of them sitting on the bench as well. One person is sitting next to the baseball player, while others are scattered around the dugout. The scene captures the atmosphere of a baseball game, with players and spectators gathered in the dugout."}, {"question_id": 454, "height": 425, "width": 640, "image": "000000156278.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [437.93, 41.84, 44.65, 44.65], "segmentation": {"size": [425, 640], "counts": "ghc57n<601^OEeC34MN9V<NjC;U<_OjCh0U<7FoN\\DQ1a;QO_Do0a;PO^DQ1b;oN]DS1b;mN]DU1b;kN]DV1c;jN]DW1b;iN]DY1b;gN^DY1b;gN^DZ1a;fN^D[1b;eN]D\\1c;dN\\D]1c;dN]D\\1c;6O00000O10000001N1000001O000O1`N[D\\1e;dN[D[1f;eN[DZ1e;fN[DY1f;gN[DX1e;hN[DW1f;jNYDU1h;5100O2eNWDS1R<L3M3M5K5I;Cbko1"}}, "object_label": "clock", "attribute_label": ["color:brown", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern, pose", "answer": "The image features a white and blue clock with a wooden frame, which is placed on a white background. The clock has a simple design and is positioned in the center of the scene. The clock face displays the time as 11:11, with the hands pointing to the numbers. The clock's wooden frame adds a touch of warmth and elegance to the overall appearance."}, {"question_id": 455, "height": 612, "width": 612, "image": "000000175251.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [300.7, 351.98, 214.94, 57.25], "segmentation": {"size": [612, 612], "counts": "`km51Qc02000N20000000O101OO0100O10O1000O1N2E;0O010O1O1O10000O00100O1O1O100O1000O0100000O1O01000O100O0100000O10O1000O10000O1000O0010O01000000000O100O10000O10O10O2O0O1O100O10000O10001N100O100000000O100000O010000O10O0100000O10O10O10000O100O10000O010O1000000O010000O100O10O100000O2O00000O10O10000000O1000O10000000O10O100000000O1000O100000O10O100000000O0100000O0100000O1000O010000O1001N10001O2N5J3N1O2N2N2M2O^Pi1"}}, "object_label": "toothbrush", "attribute_label": ["color:green", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, material, color", "answer": "The toothbrush in the image is green and has a blue and white design. It is being used by a young child, who is brushing their teeth with the toothbrush."}, {"question_id": 456, "height": 640, "width": 478, "image": "000000175535.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 517.9, 166.8, 122.1], "segmentation": {"size": [640, 478], "counts": "o`0`0=FD42ONm0m`0]OW_Og1h`0i000O1000000000000O100000000O100000000000000O10000000000O1000000000000O10000000TN[_O=e`0C[_O=d`0D^_O:b`0G[_O;e`0`1000000O1000000000000O1000000000000O10000000000O100000000O10000000000O1000000000000O10000000_Nb_O@^`0Q200O10000000000O1000000000_Nd_OaN09[`0V1f_OaNO9[`0k1e_OUN[`0h20SOe_OUN[`0k1f_OTNY`0l1h_OTNX`0l1h_OkMNFZ`0c1h_OoN0GNGZ`0l1g_O]N29W`0Y1h_O^N0:X`0X1h_OTNO110N:Z`0S3O1000Gg_OkLY`0R2h_OfN1WOW`0S2i_OeN0XOW`0P2h_OkM11Nh02[OW`0Q2g_OlM2k01XOU`0P2h_OnM2`00D1NU`0P2h_ObN5@MOV`0W3h_OjLX`0_300O10XOi_OgMW`0Q30TOk_OmMU`0S2j_OnMV`0n2O100000000000000001O001O1O1O1O2N6J>B?A:F9G9G7I7I6J9G=CYXT6"}}, "object_label": "bowl", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, pattern, material", "answer": "The image features a white bowl filled with a red sauce, likely tomato-based, placed on a dining table. The bowl is positioned in the center of the table, and its contents are visible, giving a clear view of the sauce. The bowl appears to be empty, with no other food items or utensils visible in the scene."}, {"question_id": 457, "height": 426, "width": 640, "image": "000000179265.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [286.23, 150.3, 152.21, 110.09], "segmentation": {"size": [426, 640], "counts": "Pcg3c0[<=I7E:E<J5K5N3O1N4N0O4L0000000000000000000O2O001O001O001O1O0010O01O00[MaE`2^:`MbE`2^:601O1O2NWMgEg2T:9N1O000001O000002N2N00001O0000O100O101O000000001O001O000000001O00000000000000001O000000000000000000001O01N10000001O00000010O00000001O01O000001O1O101N2O0O0000001M2O101O0O110O1O0000000O2O0010O000000000001O0000000]O[E^Ni:n0XERO5Dk:X1R1jN_DNZWd2"}}, "object_label": "bus", "attribute_label": ["color:black", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a large yellow bus driving down a street, possibly in a city. The bus is positioned in the middle of the street, and it appears to be a tour bus. There are several people visible in the scene, with some standing near the bus and others walking along the street.\n\nIn addition to the bus, there are two cars in the image. One car is located on the left side of the bus, while the other car is parked further down the street. The presence of multiple people and vehicles suggests that this is a busy urban area."}, {"question_id": 458, "height": 426, "width": 640, "image": "000000179265.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [462.06, 157.64, 57.18, 34.91], "segmentation": {"size": [426, 640], "counts": "Wno5283^<3bCL\\<6dCILN\\<9hCH^<9aCF`<:`CF`<:dCGW<9gCLV<4kCLT<4mCKS<5nCKQ<6oCIQ<7oCIQ<7oCIQ<7oCIQ<7nCJR<6nCJR<7mCIS<7mCIS<7mCIS<7mCDX<<hCDL0U<<oCDL0U<<VDDj;<VDDj;<b0000]CDX<<;000000000000001O00014K=C00O11O000001O01002N1N3M2N1N3L4Lfbb1"}}, "object_label": "truck", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "color, pattern, transparency, texture, material", "answer": "The image features a white truck driving down a road, possibly a highway. The truck is positioned in the middle of the scene, and it appears to be a large vehicle."}, {"question_id": 459, "height": 640, "width": 480, "image": "000000182611.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [372.06, 356.27, 99.43, 60.89], "segmentation": {"size": [640, 480], "counts": "l[V76ic011O1NGOg\\OOYc01;0WT3NkkL0F264_\\OJTc08h\\OKVc09h\\OJ:J[b0h0d]OYO[b0c0Z]O_O90Zb0?b]O@41Yb0b0`]O]O71Xb0d0a]O[O0ON4ab0c0g]OAYb0b0b]OXONNbb0l0_]OUOgb0l0W]OUOib0Q1^]OlNWb0U1i]OkNWb0V1h]OjNXb0V1f]OkNZb0W1c]OkN]b0[11001O0O01O1O1000000001N100000001O000000010O000001O01O000001O000000001O01O00O101O00001O0O2O0000001O000O2O1O0O2O1N1000001N1O2O1N2O1N1O3M2N2N3L5KRd4"}}, "object_label": "bowl", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, pattern, material, color, texture", "answer": "The image features a large silver bowl filled with a brown liquid, possibly chocolate or a sauce. The bowl is placed on a table, and it appears to be the main focus of the scene."}, {"question_id": 460, "height": 640, "width": 480, "image": "000000182611.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [136.4, 537.44, 49.27, 43.9], "segmentation": {"size": [640, 480], "counts": "^ae21kc07J6K4M3M1O1O1O1O100O00100O10000O1000000O100000001O0000001O01O01O0010O010O010O01000000000O2M3La0[O`jg5"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "texture, transparency, cleanliness, pattern, pose, size, color, material", "answer": "The bowl in the image is white and has a slightly curved shape. It is placed on a table, and it appears to be empty."}, {"question_id": 461, "height": 480, "width": 640, "image": "000000185472.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [542.01, 151.5, 24.6, 18.36], "segmentation": {"size": [480, 640], "counts": "ken77h>:F100000O10000000O1001O00O100000O10=BlmS1"}}, "object_label": "stop sign", "attribute_label": ["color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The stop sign in the image is red and white, with a red circle around the word \"Danger.\" It is placed on a pole, and the pole is located near a tree. The sign is positioned in front of a building, and there is a street sign above it. The stop sign is clearly visible and serves as a warning for drivers and pedestrians to be cautious in the area."}, {"question_id": 462, "height": 480, "width": 640, "image": "000000194724.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [96.79, 273.76, 61.31, 58.78], "segmentation": {"size": [480, 640], "counts": "W\\\\17h>1O2N1O1O1O1O1O2N10O01O000010IfAGZ>97N110O1O001O0001O010O1O00100O00100O001O010O0010O01O1O0O2N1O2M2O2M2O1O1O20O2N0010ON3N3N1N2M4M301O1E^A2kUQ7"}}, "object_label": "fork", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material, pattern, pose", "answer": "The fork in the image is made of plastic and is placed inside a foil container. It is positioned next to a piece of cake, which is also inside the foil container. The fork is partially covered by the cake, indicating that it has been used to eat the cake. The fork is placed on the right side of the container, and the cake is on the left side."}, {"question_id": 463, "height": 480, "width": 640, "image": "000000194724.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [339.81, 2.76, 17.78, 48.59], "segmentation": {"size": [480, 640], "counts": "Z^n45i>`0^A@e=Q1J5N101O001O0000O100001O00000003K7^OUVT4"}}, "object_label": "bottle", "attribute_label": ["color:blue", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, transparency, material, pattern, texture, pose", "answer": "The image features a bottle with a blue and white label, which is placed on a table. The bottle appears to be a beverage bottle, possibly containing a drink like water or soda. The bottle is tall and slender, with a clear glass body that allows the viewer to see the liquid inside. The blue and white label on the bottle adds a touch of color and contrast to the overall scene."}, {"question_id": 464, "height": 480, "width": 640, "image": "000000220732.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [193.61, 260.32, 120.46, 17.69], "segmentation": {"size": [480, 640], "counts": "bVk23l>1N2O1O100O100O100O1000000O10000000000O10000000000O10000000000000000000000O10000O1000000000000000000000000000000000000000000000000000000000000000000000000000000001O00001O0000001O001O001O001O001O00001O1O001O001O001O001O1O00oi20PVM11O10O0]Tg4"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, material, pose", "answer": "The image features a car parked on a street, with its hood up. The car is positioned in the middle of the scene, and it appears to be a small vehicle."}, {"question_id": 465, "height": 480, "width": 640, "image": "000000230450.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [301.1, 247.68, 73.53, 15.42], "segmentation": {"size": [480, 640], "counts": "TW_42n>0000000O1000000000000O1O1O1O001O101N1O10000O10000000000000000000000000000000000000000O10000O10001O0O10000000O100O100O1O1N2O1N2O1O1O1O2O0OYok3"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, color, pattern, transparency, pose, material", "answer": "The image features a large black car parked on the side of a road. The car is positioned next to a curb, and there is a person standing near it. The car appears to be a stretched-out SUV, and it is parked in front of a building."}, {"question_id": 466, "height": 480, "width": 640, "image": "000000230450.jpg", "category": "description", "question": "Describe the parking meter in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [182.08, 228.18, 78.41, 175.76], "segmentation": {"size": [480, 640], "counts": "Xbe2=^>9J6ZC\\Og:j0nDCk:a0lDIo:;hDOS;7cD3W;OeD5Y;ObD4\\;j1M3N2N2C>L3L4M3M3M3M3M3M2N2N2N3M101O2N1O0O1000000000000000O0100001O000000000O2O0O101N2N1O2N2O1N2N2M3M3M3L6K7I5J4jMPE8R;ERE7Q;FTE6o:GWE2l:KZE1h:K^EOe:O`EJd:4cE^Of:>Q2M2N2M5JRla5"}}, "object_label": "parking meter", "attribute_label": ["color:gray", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "pattern, material", "answer": "The image features a parking meter on the side of a street, with a sticker on it that says \"Kumata.\" The parking meter is located near a building, and there is another parking meter visible in the background. The parking meter is positioned on the sidewalk, and it appears to be a coin-operated device."}, {"question_id": 467, "height": 480, "width": 640, "image": "000000230450.jpg", "category": "description", "question": "Describe the parking meter in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [103.48, 238.84, 15.04, 45.1], "segmentation": {"size": [480, 640], "counts": "f``188OP>d0L4L3L3N3M2O1O0O1000A_B_Oa=L^BI<0i=5Tnd7"}}, "object_label": "parking meter", "attribute_label": ["color:gray", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The image features a yellow parking meter with a yellow and black design. It is located on the side of a building, possibly in a parking lot. The parking meter is positioned next to a wall, and it appears to be a large, prominent object in the scene."}, {"question_id": 468, "height": 640, "width": 480, "image": "000000246436.jpg", "category": "description", "question": "Describe the microwave in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [221.05, 318.25, 119.06, 42.86], "segmentation": {"size": [640, 480], "counts": "P^Z42mc02O1O001O1O1O001N2O001O01O101N0010O010O0001O01O001O010O00001O001O3M:F3M1O1O1O1O1O001O1O001O1O1O00O10000O1O1N110O100O100O10000O10O1000O100000000O010000000O010000000000O10O1000O10000000O100000001O00000O2L3N2N2N3N1O100O101O001O00001O9Fb]h2"}}, "object_label": "microwave", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a microwave oven placed on a countertop. The microwave is white and appears to be in a kitchen setting."}, {"question_id": 469, "height": 640, "width": 634, "image": "000000270677.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [417.95, 496.76, 77.17, 143.24], "segmentation": {"size": [640, 634], "counts": "f[V87fc05L4N101O1O0010O01O1001O2M1O100O1000O01O01O1O1O010O012M1O1N2L6G:N1M401M3L3K5L2N3L3MTNQ^Oj1ma0UNT^Ol1ja0TNX^On1ka036RNn]O_1Qb0]NT^Oc1Vb000002hN]Nk_Oa1T`0aNR@X1n?iNS@U1i?gNP_O6X1P1h?RO\\@l0f?QO_@k0a?UOb@h0^?XOd@f0\\?ZOg@c0W?^On@>n>FUA7k>IXA4g>M\\A0d>0^ANb>1bAL^>LY_ONN1X21b>L\\_O0K3Z2Nn>3`2O13NOW\\OK41Zc03b\\OL41\\c00h\\OOfUh2"}}, "object_label": "skateboard", "attribute_label": ["color:gray", "color:yellow", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, transparency, texture, pose, material", "answer": "The image features a person holding a skateboard with yellow wheels. The skateboard is positioned in the foreground, and the person's hand is visible on the side of the board. The skateboard appears to be a longboard, which is a type of skateboard designed for cruising and downhill riding. The yellow wheels give the skateboard a distinctive appearance, making it stand out in the scene."}, {"question_id": 470, "height": 480, "width": 640, "image": "000000279145.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [332.56, 82.6, 65.65, 55.16], "segmentation": {"size": [480, 640], "counts": "Qno44k>4M2N4L3M2M4M3M3L4M2N3M2N1O1N1000000000O010000000001N10000000O10000000000001O001OO100000000000001O2eN\\BV1i=N1O0N6G9AfAKSXb3"}}, "object_label": "potted plant", "attribute_label": ["color:brown", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern, transparency, material, color", "answer": "The potted plant in the image is a small tree with green leaves, placed in a brown pot. The plant is positioned on a table, and it appears to be a houseplant."}, {"question_id": 471, "height": 481, "width": 640, "image": "000000281693.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 136.28, 67.2, 106.62], "segmentation": {"size": [481, 640], "counts": "^T19f>5L1O1N101N2O1N2O1N2O1N2O1N2O1N200O0011L4M3GOEa06_ABW>[1YO2N2M3N1N2O1O1N2N2O1N2O1O1N2O1O1N3N2M3M200O10O1N2D_CTNe<j1:L4McCYNf;d1]D\\Nc;`1Q1N2M3K5J6K5K5L4K5L5Kfa\\8"}}, "object_label": "airplane", "attribute_label": ["color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, material, pattern, color, pose", "answer": "The image features a large airplane with a distinctive red, white, and blue tail. The tail is painted with the British flag, which is a symbol of the United Kingdom. The airplane is parked on the tarmac, and its tail is visible in the foreground of the image."}, {"question_id": 472, "height": 504, "width": 640, "image": "000000297022.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [80.26, 125.06, 500.6, 225.54], "segmentation": {"size": [504, 640], "counts": "[a\\13c?3L3N2M3POCbBa0\\=C]Ba0b=@[Bc0e=_OYBb0f=h0O010O1O1M300O10O1000N2KZNWBg1h=5O1000UN[Bc1e=[N]Be1c=^NZBb1f=_NYBa1_=ZNdBo1l<g0NO21O005Jd0]O6K1O0UDZLc;h3[D\\L`;j2aDRN\\;m1iDRNV;n1hDTNW;m1fDXNX;h1fDZNV;g1jD\\NV;`1nDZNKoN1LQ;0oDe25aNJnN1LQ;OQEd24jN0bNf:0WEb23POKeNf:I\\E\\29ZNC40@g:F^E[28jMCN=U1^:S1aEPN1n0^:S1_EPNID4Z1c:Q1`EQN3o0\\:o0aERN5JAl0i:W1aETN6FC2Mg0g:^1bESN6HCo0d:V1bEVNJA60I01T1c:T1eESN?j0k9n0RFmM72WOk0_:Q1XGTNYNk0_:P1nEXNb0NoNk0a:n0oE[NDHc0Q1ZOoNa:k1QF[N=g0k9n0SGnNP9Q1QGnNP9R1mEVN3g0Q:o0nD\\Nm0OVOO?0Ff0l:o0lD]Nn0NI1@d0e:[O[Ed1J^Ng10]Nc0g:[O[Ee1I]Nh11\\Na0i:\\OZEi1`1ZN^Na0Q;U1lDWNa12bNc0Q;T1aFYN^Nb0R;U1`FXN_Nb0R;V1hFiNY9W1gFiNY9X1fFgNR9@TEl1h1dNT9@TEn1g1aNT9CTEm1h1XNTNMP;MUEn1g1XNTNLR;MSEP2e1XNXNHQ;0RET2a1YN]9BTEY2Y1WNb9@UE^2T1SNf9_OVE`2Q1SNh9]OWEc2n0TNg9ZOZEd2l0TNnNXOh:0]Eg2i0WNi9RO]Ej2h0XNg9nNbEk2d0XNj9mNbEl2c0WNk9lNdEn2>XNV:j1eEYN[:h1dEXN\\:i1cEXN[:i1eEgMBDa:BeET37fMCDa:BeET3;WMF7Z:^OdEe2K]M37=H@585II`:LdEk2L^Mb0c0]OXOa:MbEl2M\\M;HJP1]:oNaEX3b0mL[O>1@d:U3SFkL\\ONN9i:`2VEaMW1Md9b2VE`MV10b9`2YEXMM3X1LhN6k:X2XEdM2OL2R1LPO0T;\\2\\EhM`0NX:Y2XEhM`01X:V2YEhM?2S:MlDY22fM<0d03Q:0kDT2\\1iM`:[2aEeM_:Z2bEfMjN1Z;1^DS2^1lMiN0_;T2iDnM:O^OO`;S2iDnM:NX;T2hFmMl7R2bEmMS27Z8i1[ERNc00U1:m8d1[ERN<OH7f0O_O<[:]1\\ERNc0663WO>d:Z1PFVN4m0l9l0RFVNIHHU1^:n0oEVNKIET1a:m0oEVNJKER1a:n0PFUNKIET1\\:S1SFPN3m0i9U1cEeM<:8l0c9jNkE\\2=nM5k0b9nNkEY2?mM3l0d9nNjEh22[Md0k0a9POjEn2P1lMlNVOc:n2dFhMa9X2_FgMa9Y2aERMb0d0P:X2\\FgMf9X2_F[Mj9d2lDUMe<l2ZCTMf<l2ZCTMf<l2YCVMf<n202N100QDmLC0\\;S3oDnLDO^;V3jDmLFM`;[3dDjLHL6OW;[3kDnLLIZ;X3jDoLKI\\;X3gDRMME[;Y3fDUMa;j2[D[Me;d2\\D[Me;d2\\DZMf;f2ZDXMh;h2XDXMh;h2WDYMi;f2WD[Mi;e2WDZMj;f2UD[Mk;Z3O0000TOWDiMj;R1UDWO0Hl;o0VDWOOJl;m0VDYONJk;R2VDnMh;T2WDmMe;WOZDl20nMe;XOZD51H2U10lNNm1c;VN\\D3:MLLMa05IHY1V1bNm8Y4eFnKY9]4VFlKh9R5O1O1O1M3M3N101O1N101O1OYKbFU3_9b10O000O2XK^FY3b9hL^FU3e9kL[FS3g9aLYFh3j9XLVF_3S:aLmEA0C030W123W::gEN1LS:MlEeN0b10YN0b1Q:U4JkMVFbNe9k0`FoLL6OQ21hM_9R3`FPM0O16NW2`9i0aFjL1g2]9d0bF\\O^9_3O100000000000O1bLaFc0_9j2100O1O1\\ObFhJd9Y5[FfJf9_5WF`Jh9`5YF`Jf9a5[F\\Jf9d5ZF\\Jf9b59G801001O0000001O2N1O6J4L1O6J5L1N2N1O1O001O001O00001O000000001O01O0000000001O001O001O0000102M2N1O1O1O010O001O000010O00000000001O000O101O00000O1N201O0O101N1O100N3N1O101N1O1O2N2N1O2K5N1M4O100M3N2N2O1L5M1M3kJaE41c4\\:]KbEM7c4W:bKUFo3Q:QLXFg3f9YL[Fk3a9PLdFP4\\9PLbE0n0P4`9PLbE0o0o3_9PLcE1n0m3h:O1O10000001O000000O100001O001O00000000001O10O0001O00000000001O001O011N5K001O0000O1000001M2O1O10000N2N3O0001O00O2O00000001ZDTL^;l3aDVL_;h3bDYL^;f3bD[L^;d3bD\\L^;d3bD]L^;b3cD]L^;a3cD`L];_3cDaL^;_3_DeL`;j30O1O1O3N4K4L6J4L10N101O01O0O101N10001O01O00M4M2M4M2M3O2M2L5M2O2O001N1O2O1M2O2O1O1N3ZO_BQOc=h0bBXO`=a0eB_Ob=9_BGi>0000000000O1000000000O1000O10000000O10O10000000000O10000O011O0O3Lmgm0"}}, "object_label": "truck", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, transparency", "answer": "The image features an old-fashioned truck parked in a grassy field. The truck is an antique, possibly a vintage fire truck, and it is surrounded by several men. There are at least five people in the scene, with some standing closer to the truck and others further away. The men appear to be gathered around the truck, possibly discussing or admiring it. The truck is parked in the middle of the field, and the overall atmosphere suggests a sense of nostalgia and appreciation for the historical vehicle."}, {"question_id": 473, "height": 640, "width": 427, "image": "000000322864.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [12.54, 351.71, 60.54, 47.63], "segmentation": {"size": [640, 427], "counts": "V_84kc04L3N1N6K2M102m\\O[Ogb0f0W]O[Ohb0P1O1O8H1O001O0O10000000O1000O1000O1B_]O^O`b0b0`]O^O`b03b]OJO3`b04`]OIO3ab05_]OH03ab0P10XOe]OKZb07e]OEKEab0X14M3L4J6N2O1O1O1O100O1O1Hf\\OG]c08g\\OEYc0<52N10L3L4O1O1O2O0O1OPam6"}}, "object_label": "car", "attribute_label": ["color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern, texture, material, color, transparency, pose", "answer": "The image features a busy city street with several cars, including a yellow taxi cab. The taxi is parked on the side of the road, and there are other cars in the vicinity, some of which are also yellow. The street is filled with traffic, and the taxi is positioned in front of a black car. The scene captures the hustle and bustle of city life, with various vehicles navigating the streets."}, {"question_id": 474, "height": 480, "width": 640, "image": "000000327890.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [619.51, 203.13, 20.46, 10.76], "segmentation": {"size": [480, 640], "counts": "]WT99g>00O01O10001O0000000000000000000eI"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, pose, pattern", "answer": "The image features a large white car with a blue stripe on the side, driving down a road. The car is positioned in the middle of the scene, and it appears to be a semi-truck. The truck is driving on a highway, and there are other vehicles in the background, including a bus and a train. The scene captures the essence of a busy road with various types of vehicles sharing the space."}, {"question_id": 475, "height": 480, "width": 640, "image": "000000350023.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [119.14, 394.44, 8.94, 24.47], "segmentation": {"size": [480, 640], "counts": "jdh16Z>b0M100001O000Ogc_7"}}, "object_label": "traffic light", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The traffic light in the image is a black and white photo, featuring a person standing next to it. The traffic light is located on the side of a road, and it appears to be a stoplight. The person standing next to the traffic light is positioned on the left side of the image, and their presence suggests that they might be waiting to cross the street or observing the traffic."}, {"question_id": 476, "height": 335, "width": 500, "image": "000000356387.jpg", "category": "description", "question": "Describe the bicycle in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [45.29, 262.82, 183.32, 69.02], "segmentation": {"size": [335, 500], "counts": "b\\>2\\:1O100O1O1N20000O1O100O100O10000000000GHZF9e9KXF5g9LYF4g9:O10000O10000000000000000000000000000000000jNZOcHf0\\7]ObHc0]7YOdG3m0d0f7[OXHe0h7\\OWHd0a7XOdG;j0=b7G\\H8d7KZH5e7MZH4d7_OkG2`0?e7^OnG2:b0g7]OPH08d0h7\\ORHO4f0i7\\OTHNOi0m7RO[HU1@QOU8KZHT1AQOU8KZHT1BPOT8K[Hf0^OF3IT8K[Hf0^OG3GS8M\\HU1ClNQ8O]HT1ClNQ8N]H0@7N?3[O\\9c081\\F[O]9e0bF[O`9e051OO0100OGYFKf95ZFKe9`00000000000000000000O10000001O01O000J\\F@e9>^FAb9=802O000001O2N1O2N1O2N001O00001O000000000000OZOZOeGf0R9001OO100000000001O00000000000mN[O\\He0d7[O\\He0e7ZO[Hf0f7ZOYHf0g7[OXHe0h7[OXHe0h7[OXHe0i7ZOWHf0i7ZOWHf0j7YOVHg0j7YOVHg0i80POZOWHf0i7ZOWHf0i7ZOWHf0i7ZOWHf0i7ZOWHf0i7ZOWHf0j7YOVHg0j7YOVHg0j7YOVHg0j7YOVHg0j7ZOVHe0j7[OVHe0j7_ORHa0n7AQH>o7BQH>P90001O00O10_OXF;h9EYF:g9FZF9g972@UF8S:N1O001O001O1O1O1O1O1O001NeZh2"}}, "object_label": "bicycle", "attribute_label": ["color:black", "color:orange", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pattern, color, material, transparency", "answer": "The image features a row of bicycles parked next to each other in a parking lot. There are three bicycles in total, with one being red and the other two being black. The red bicycle is positioned in the middle of the row, while the two black bicycles are on either side of it. The bicycles are parked close to each other, creating a neat and organized appearance."}, {"question_id": 477, "height": 480, "width": 640, "image": "000000357748.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [53.09, 1.9, 586.91, 422.57], "segmentation": {"size": [480, 640], "counts": "^Pi05_1MbN5c<S1_CjN:f0_;]OWDR3S;VMkDn2Q;b0M3M3N101N1O2N1O100O101O001N2O2N3L2O00002N2N2N000PFSKm9h4RF[K0Nm9h4TF]Kl9b4WFZKj9g4UFYKk9h4TFWKm9i4500001O0O2O001O000000001N10001O0O2O1O0O101N10001N2O0O101NjLgFg0Y9YOhFg0W9YOdFjM03Nb2^9i201N100O2O0O2O0O2O0O2O001N100O2O0O2O0O101O1N10000O2O0O2O001N1O2O0O2O0O101N10001N101O0O2O0O2O000O2O000O2N101N101N2O000O101O0O2O1N100O2O001N10001N10001N101N2O0O101N101O0O101N10001N101O1N100O2O000O101O2M5L7H6K2N4K4M1N3N1O1N2O1N2O1O1N2O1N2O001N101O0O2O2N0O100O101O0O10O010000O100O10O10O10O10O010O10000O01O1O0FUK_Fm4_9:10000O2dJ`FV5e9ONkJ[FU5e930O100O10001N101O0O101N2O00000O2O0O10000O2O1N10001N2O000O101N101O0O2O0O2O001O0O10001N101N101N101O000O2O0O101O0O2O001N10001N101O0O1O2O00001N10001N101N101N10001O0O101O0O2O0O2O001N10000O2O001N101N101O001N100O2O001N100O2O00001N2O0O101N101O001N100O2O000O2O0O100O2O000O2O0O1000001N10000O10001O0O10001O0000000000001O0000000000001O00000000000000001O00000001O00001O001O1O3M00001O1O1O1O001O1O1O1O1O000O100^CeM_<_2O0O1000O1001N10001O0O101N1000000O101O0O101O0O1000000O2O0O2O001O000O10000O2O000O2O000O100O1000000O2O0O2O000O1000000O2O000O2O1O0O10000O100O102N1N101N1000000O2O000O100O10001O0O2O001N101O1N2O000O100O101O1N1O10000O10001N100O2O00001O0O10000O2O1N100O100^IXKl2h4TMXKk2j4TMVKl2j4TMVKl2j4TMVKl2j4TMVKk2k4UMVKj2k4UMUKj2l4VMTKj2m4UMRKk2P5TMPKk2R5TMnJl2R5TMnJl2R5TMnJl2R5TMnJk2S5UMmJk2T5TMlJl2T5SMmJm2S5TMlJk2V5TMkJk2U5UMkJk2U5UMlJj2T5VMlJj2U5_3101N101N1O101N10000O10000O2XG^JB2R8a5\\H^JA1S8_3"}}, "object_label": "bus", "attribute_label": ["color:black", "color:pink", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, material, pattern, color, pose, transparency", "answer": "The image features a large pink bus parked on a city street. The bus is advertising a shopping center, and it is likely a tour bus or a city bus. The bus is parked near a sidewalk, and there are several people walking around the area. Some of them are carrying handbags, indicating that they might be shopping or going about their daily activities. The presence of multiple people and handbags suggests that the bus is in a busy urban area with a shopping center nearby."}, {"question_id": 478, "height": 427, "width": 640, "image": "000000457848.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [189.03, 49.9, 448.11, 372.3], "segmentation": {"size": [427, 640], "counts": "`ca21T27e8JYE0o1:f8HZENo1;f8H\\G:b8F]G<V6@RJ7D?W6\\ORJ7F>X6[OoI:I;X6[OnI;I<X6YOoI;H>XNUOk05P6KVK<Di0^NFj8VOTG4f1R2S7mMWG2d1R2T7nMWG0e1R2Q7QNWIP2g4hM^IOd1<4P2i4hM\\IMe1>3o1l4eM^IMb1?5o1k4eM^IM`1`08n1Q5bMfJ`09o1Q5aMdJb0:n1b6hMhGNf1Z2a6kMhGJg1[2a6kMhGKe1[2b6eMoIZ2b2eMXNLPM5W2Z2^2iMYN3YOT2]2kMWN3[OS2]2kMWN3\\OR2^2jMUN5\\OR2a2fMRN:[OR2h2_MlM`0\\OQ2i2^MjMb0\\OQ2j2]MiMc0\\OQ2j2]MiM:`MCn1f2i2]MgM;HOeMD3o1i4SNfM<HEeMN2O8o1b4SNeM>JCfMM108o1a4TNeM>JCkMM5n1`4VNWKJ20R2d05AgM1:i1^4aNXM78HiMA6n1a4bNVM99HiM_O77H^1i4lNTM9;GRN^1_4bNRM;<FRN^1`4eNlLNbN^OQ2a0jM@0o1g4hNfLLS1M^Mg1j4`NcLMU1B^MJ2OOX2h4aNdLLU1FdMm1c4aNdLIdN]O^2?gMj1c4aNcLJU1LeMi1c4aNbLKT1McM_OOX2g4TNXKN[1;S1IbMC20NW2h4aNbLMS1AcM30S2i4\\N`LHgNA\\25eMc2g4QN`LDkNAX29fMa2`4\\N_LiNRO7h2<VM@0[2_4lNbKfNj02WO3g2`0WM^O0[2^4mNbKfNk02UO00Ng2f0YM\\O1Z2]4QO\\LjNXOHe2l0ZMa1[4TO]LgNYOHd2h0ZM[O1Z2X4WO_LdNQ2b0WMYO0Z2Y4XO]LbNU2d0UMXO0Z2Y4XO\\LcNV2c0UMg1Y4SOXL\\N@6k2X3\\1WNXL\\NA5k2:TMG0Z2X4TORLkNd2ORMH1N0R2W4_OPLkN=A`1;lMI1KN01V2W4_OhKZN4b0j2MRMG2J00OW2W4CiKgNP3NoLH1I5W2S4:fNWNRMXO10O2OP2\\4=dNWNPM\\O1N011P2[4=cNXNPM\\O0O101P2[4=cNXNPM@2JOR2\\4<cNXNPM@2P2[48cNXNQM_O1Q2[48cNkMQMO0JOO1V2\\4fNcKTO1Y10eNl27WM1MJ1OOW2[49eK_Mk28XM0NI4W2S4<gK]Ml26YM1MI4W2R4=hNaMUM2LJ1N1W2R4a0lN^MSM2MKOO20NQ2k3oMYLg2P3[MoL6MI0O2OOS2g3QNYLf2R3YMoL8NK2Q2f3k0ZOQMQMa00b1a3Z1SOeLZM7OJ2P2b3_1nNlL^MA000O1V2b3UO^LTO4o0[2SOaM^O011OO2OP2c3[O]LSO5o0[2SOaM^O011OO2OP2b3NdL_O[2hN_M00K0O3NN3OP2`32bL^O^2oN`MA0O2OO10Q2^3j1QOeL`MA0O2OO11Q2\\3o1nN_LdMB0O2OO11Q2\\3Q2lNnKfM`00A1N02OQ2k2QNbM\\1ClN0e1Y2oMjMi0M_1_3m1hNkKlMi0M_1h2gMmM^4Z1dKSN9N20F0Q2g2nMnM]4GPLd0CSO8MN0K000Q2h2lMnMa4CoKg0ATO9LN0K000Q2h2lMnMb4BoKh0_OTO:LN000l1a3_2_L_K1`00^OQ1;nNM001k1`3\\3`MmJoNG00000O2Q2b3Z3[MPKQOF00000O2P2c3Z3ZMRKQOE00050k1e3V3\\LgJn0W3j2R2UMnMl2kNVLV1l0iLWOn2i3kNZL_1m0_MmN[1m3JUL\\1Q1_MmN[1P4U3RMfMn2jNSLe1l0[MQO\\1R4]OVLS2a0SMWO]1S4\\OVLMHg0g0YNXOK0l1S4]OULS2`0YO[3eNPL^NNe3f0YO]3cNSLU2<ZOc3^NSLX23@k3WNSLY20Am3WNPLZ23hMF5V4MmKW27gMK0Q4NRLZ22hMG4V4HZLT2IaMFS1W4VNiKb00VOa0^3ImLF50A0l1W4]OXLU2MdMDj0W4^ORLcNIb3:oMD2V4KWLU2NlME6S4K\\LU2IjMHcN2]1Q41^LT2FkMJbN1^1R41XLX2KgMJbN0_1T4OTL\\2NcMN3T4JTL]2InLJ02n0W4FYL^2@dLNL050J2]1X4EXL_2@_LNL000O20N10O230`1X4DXL_2@_LN10J20N53f1W4\\OULb2EZLM16KJ63e1W4\\OTLiNAh32gL0O1]1Z4hNeKJa0[3]O\\M2h0[4fNfKFe0`3XO\\M1i0\\4eNgKFc0`3YO]O]4^MfKF;GBm30XO]4_MdKEe0h6g3nI\\LQ6e3lI^Lj3UO_M]4gN^LS6b3nIeKTO=NAQ7_4jI[LV6f3_I_KHl0h6e3`I`KFl0R6SOkI043N]4<aKF0Ig0^6YOcI0114^4;`KK?HCZ63dIM3_4<`KFj0[6VO`I13^4<gK_Og0a6SOaI22]4=hLP6hNaI3NN1_4`0gK_Og0b6RO`I32^4<dKCd0MYOb6O_I23]4>dKAe0MXO^6OeI1N15\\4=gL[5lN^J1E0005Z4?dK]OQ1d5A\\JFOJ5Y4`0eK@7K44F`5a0^JFNJ5T4KkKP10UO81G^5b0^JEOK4R4P1SLjN45F`5a0^JFNJ5Q4Q1iL^4H]JH4e3o0oKmNl0c5TO]J`00M3c3U1lL_4DYJM3c3U1hLhNXOg5?YJO3b3V1hLeNYOe5U1_Jj2n0PLYOh0T5d0dJd2n0TLXOc05ZO^4^1VKb2n0QL[Od05ZO\\4^1VKd2]1\\LeNDW5_1gJb2m0nK]O?DD`0LY4b1XKc23kKb07@b07YO[4`1YKd20mKd04\\OJ1i06VOI4f4^1ZKj2d0kKBIJd0<_O[4_1YKk2c0hKI9EBb00Q4W1[KSO0V4b0aKMc03^OQ4b1]KS3d0XLLSOS4b1]KT3c0WLMSOS4b1]KT3d0ULNTOQ4]6QLcI]O1Ob04]O80W4^6fKaINn0LSO50_4`6_KbIOQ1NSOc4\\6^KcIMo01SOd4\\1ZKY34YKMo01ROe4\\6^KaINQ1MQOi4^6ZKaI0U1i4[5VK`I11Nh0e4XOZKa60_I30Ng0f4R6YKXI2N1e0f4U6WKYI1M2d0f4j6YKTIi4m6UKQIn4o6RKPIk4h71O1KH;J7J[JgKg2X4V30K6N2O1N2N2L3O2SJYK^M0041JR5l4VMTKiMe0N\\Oo4m4aMjK\\2Y4eMfKY2\\4jMnJ\\M?h4f4oMZKo1h4PNYKn1i4PNYKn1i4QNXKl1k4PNYKn1j4mM[Kn1i4lM]KS2d4hMaKU2b4gMbKW2`4dMeKX2_4]MlKa2V4[MnKd2T4WMPLg2R4WMPLd2W4VMmKg2]4kLjKR3Y7O1M3N2M3M3N2N2L4K5K5N2N2N2L4LgGoM`5Q2WJPN_M5Y8k1UJ\\Nk5d1QJ`No5_1kIoMlMf0Y8\\1RHPNW1i0g6W1RHPNV1j0h6U1RHRNV1i0h6V1QHPNT1m0m6R1ZISOh6m0VIUOj6k0RIXOo6h0gHoMnN1NY1]8g0nGSN1e1Q89bGPN39Og1[84eG<[8Z2000003M1N1000:F10O0000000O10000OmHgJV6Y5jIgJV6Y5jIgJV6Y5n0000000001O0000001O00000jNeJ\\J[5d5eJ\\JZ5c5hJ]JX5c5hJ]JW5e5iJZJV5c5iJ[I1R1T5i5kJXJU5h5kJXJU5mNjJg62\\JS5nNkJg61[JS5oNlJf61[JR5ROPK_6M_JU5POoJl0Lh5Q5XIRK31m0Lh5P5YITK10n0Mg5m4\\IVKO05L`02o5k4^I`Kl0Df5n4]I]Ke7d4[H]Kd7`4YHUK1<f7]4[HiKd7V4^HkK`7V4_HkKNZOd05o5`4`I[K0e0L^O0O:8Z6[4_I]KOm00QO3;_6Y4`IbLMjN3;a6S4[IfK5Q1KmN2:c6Q4hIQMIdN_6W4[IhK>\\1KcN\\6Y4\\IgK>]1IdN\\6V4PJVMDdN\\6U4PJYMBbN_6S4QJ\\M^O`Nc6T4oI]M]O`Nc6S4PJ\\M]ObNc6R4PJ[M^OdNa6Q4PJZMBdN^6R4hIaML\\N\\6S4gIbMN[NZ6S4hI_M1^NW6R4iI`M0^NW6S4eIaM6[NU6Y4_I]MR7d2lH]MT7d2kH\\MY6ZN`JS6U5mIZJ0a0R6]600N2001O00001O000000OTJPJ_4o5`KTJ_4l5bKSJ^4m5bKSJ^4m5`KVJiNJb5P6cK^J[4c5cK`JoN_OV5Q6kK`JoN_Od1Oi1R6dM`JoN^Oe13e1o5gM`J[4^5hKbJKAU3m5QMaJYO_OM5h3k5RMXJhNOa0II7n3i5PMXJiNN`0JI6o3j5nLbJXO@J5P4i5mLdJWO_OL6n3g5nLeJWO_OM6m3g5nLdJWOAL1S4j5jLdJWOALOU4l5iLcJVOBJ1W4i5jLdJVOAH4W4g5lLUJjN6<IG5W4g5lLUJjN6<IG4X4h5kLVJjN4<JG3Y4j5iLfJRO_OI2]4j5fLhJPOI[4_5dLaK\\3_4dL`K]3`4cL_K^3b4bLiJPOC^4e5bLeJSOFZ4h5aL`JVOHY4h5gKjI`0g0_OF[4i5fKkI?g0_OALFa4X6dKjI>j0_O_Ob4n5aKhI>\\1P4m4aKgI>]1Q4l4`KiI>Y1T4n4^KjI=W1V4o4^KhI>X1T4R5TLgIWO808e4j5TLdIGa0V4l5RLcIH?X4o5oKbIAOHc0i4n5kKbIAb0I\\Ol4b6gKaJZ4_5fKaJZ4`5dK_J^4a5bK^J_4b5aK^JAnNj4d6fK^J^OoNl4d6eK`J[4`5eKXJc4h5]KWJd4i5[KXJe4h5[KXJb3SOoLe6PO\\I41Ml0o3UOnLb6QOgI1a0R4UOlLQ7ROfI1WOR42jLR7ROfI1VOT40jLS8W400L4L4O02OM3N2O100001OK5O10000O100LYJdHg5\\74O1M3O1O100N2O1O100O1O1N2O1M3N2O1J^IaId6]66N200dI"}}, "object_label": "motorcycle", "attribute_label": ["color:blue", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, material, transparency, texture, pattern", "answer": "The image features a row of motorcycles parked next to each other on a street. There are at least six motorcycles visible in the scene, with some of them being parked closer to the foreground and others further back. The motorcycles are of various sizes and styles, showcasing a diverse collection of bikes.\n\nIn addition to the motorcycles, there are several people in the scene, some of them standing near the motorcycles, possibly admiring or discussing them. A car can also be seen parked in the background, adding to the urban setting of the image."}, {"question_id": 479, "height": 427, "width": 640, "image": "000000463037.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [611.47, 243.24, 28.53, 16.28], "segmentation": {"size": [427, 640], "counts": "R^o75V=7H100000000000000000000000O11N1000O2OO1000001O00001O0\\H"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The image features a white car parked on a street at night. The car is positioned in the middle of the scene, with its headlights on, illuminating the surrounding area. The car appears to be a small vehicle, possibly a compact car or a sports car. The nighttime setting and the car's headlights create a sense of depth and contrast in the image."}, {"question_id": 480, "height": 612, "width": 612, "image": "000000492937.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [423.59, 82.52, 165.03, 221.42], "segmentation": {"size": [612, 612], "counts": "Wik7j0Ub0h0]O5K2N01O001O01O001O00O11N2O0O1M4M2]OVNh_On1V`0a0O1WO_Ma@N2g2W?jMf@X2W?m0N1O2O0O2HQLWAR4h>oKVAR4i>oKWAR4h>nKWAS4i>mKXAS4g>mKYAT4f>lKZAT4f>lKYAU4g>4O2O00001N1000001O002M2O0O101O1O001O000O2O001O0000001O001N101O1O001N101O001O0O2O1O00001N10001O000O2O001O001N2O1O00000O2O001O001O1O001N1000001O0O2O001O001O000O10001O1O001O000O10001O1O00TJSCb5l<^JTCc5k<;00100O01O001N1O10001O0O1O10002N1O0O101O00001O001O0O2O1O00001N0102N4L4dI[CP6``0ZLYa="}}, "object_label": "train", "attribute_label": ["color:blue", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color", "answer": "The image features a train station with a train on the tracks. The train is positioned on the left side of the image, and it appears to be a passenger train. There is a person standing near the train, possibly waiting to board or just observing the scene. The train station has a platform, and the person is standing close to it. The scene captures the essence of a typical train station, with the train and the person waiting for their journey to begin."}, {"question_id": 481, "height": 640, "width": 427, "image": "000000496571.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [193.87, 102.52, 33.41, 77.76], "segmentation": {"size": [640, 427], "counts": "W[i31nc04M2O2O1O2M03N1N101N0O3MkT3O\\WL3^c0=K6]OZOc]Og0Qc0J;E1OO100O02O0O1O2N`^m3"}}, "object_label": "fork", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The fork in the image is a plastic fork, and it is being used to pick up food from a plate. The person holding the fork is in the process of eating a salad, as evidenced by the presence of a salad bowl and a variety of vegetables on the plate. The fork is being used to pick up a piece of broccoli, which is a part of the salad."}, {"question_id": 482, "height": 640, "width": 427, "image": "000000496571.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [372.67, 230.97, 54.23, 72.44], "segmentation": {"size": [640, 427], "counts": "^\\Y72hc0=C9H7K4M4L3N3L3N[Og]OFWb0;k]ODSb0<P^OCna06[^OJca05`^OK^a04e^OK[a04h^OKVa06k^OJTa05n^OJQa06P_OKo`04S_OKl`06U_OJj`05X_OJg`07Y_OJf`06[_OIe`06\\_OKb`06__OIa`07`_OH``07a_OI_`06c_OJ\\`03h_OLX`02j_ONV`02j_ONV`03i_OMW`04h_OLX`05g_OKY`06g_OIY`08f_OHZ`09e_OG[`0;c_OE]`0<b_OD^`0>`_OB``0?__OAb`0?]_O@d`0d0X_O\\Oh`0d0X_O\\Oh`0`0X^O@j0OPa0b0T^O_Ol0OPa0h0Z^OSO`04Xa0h0W^OWO>2\\a0g0U^OWO?1]a0j0R^OUOa01]a0R1b^OmN`a0W1Z^OjNga0a0R^OF:GW:"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, state", "answer": "The bowl in the image is white and filled with green beans. The beans are arranged in a way that they are partially submerged in the bowl, with some of them sticking out. The bowl is placed on a table, and the beans are the main focus of the scene."}, {"question_id": 483, "height": 360, "width": 640, "image": "000000496722.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [394.74, 147.06, 23.46, 10.35], "segmentation": {"size": [360, 640], "counts": "inY43n:NWE4i:NTE2l:51O00Z;IkD7K0001Naf0LcYO1O20Mbf00_YO3N1OO2O000O2O[V]2"}}, "object_label": "car", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, pattern, material, color", "answer": "The image features a car with graffiti on its side, which is parked in a parking lot. The graffiti is visible on the side of the car, adding a unique and artistic touch to the vehicle. The car is parked next to a building, and the overall scene appears to be a casual, urban setting."}, {"question_id": 484, "height": 640, "width": 480, "image": "000000523100.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [0.0, 80.36, 417.0, 168.84], "segmentation": {"size": [640, 480], "counts": "]36n0MX20h;1VA>h0AZ20f;V1dAjN^1NUN02312M2NLj>Z1aAfNG130N[2g>POaAaNH502MX2l>SO`AcNF2ON2O2OO1O2M20=m>Q1\\A]NJ30MQ1OnN40<m>U1`A_NDNQ1NnN31<m>W1^A^NCOh0L]OO15L<m>Y1_AbNb0IQO10;n>[1^A`NDD01?0B5Mf0o>R1^AbNDC5N11JS1n>m0\\A]NEE5N0c03Fh>i1^A]NEGM<:Ff>l1]A\\NDA0e0>[Oc>Y2^ARNCHN8e?n1l@PNAEM134MNg?Z2j@cMBO?5_OOf?\\2Y@`MW11iN121e?b2SA[MXO115MNg?f2m@]M]O79Em>i2ZAmMI^Oi>i2`AQM_O=8Ii>k2cA\\MDIi>n2aAQM\\OO93j>R3fAhLA6i>T3QBmLo=[3iAeLW>]3PA\\L?8`>e3_A[La>n3UARLl>o3SAQLm>P4QAQLo>P4PAPLP?P4o@PLR?P4n@PLR?o3n@RLR?o3m@QLS?^40@l@TLS?l3n@SLS?m3m@SLS?f3l@RL18S?\\3l@_L1J0=S?Z3l@^L2KN=U?Y3m@^L49o>W3]AiLc>P3l@dLa0=c>o2l@cLa0?c>n2k@eL6L2a0n>V3m@[LNO1a0T?V3k@[L0N1a0T?W3k@XL6a0o>W3UAiLk>V3UAjLl>`0i@a18SNo>;o@]12XNo>;o@\\13YNn>=l@mNNT20nM:d0l>>i@]17VNo>R3l@QMU?o2j@RMV?l2l@TMT?k2m@UMS?k2l@VMT?i2j@ZMV?a1k@\\NNVO2m0U?b1j@fM10N06i0Q?d0i@dN0K0:1D61JO11OO5n0R?j1k@_MMO4j0T?^2j@dMV?\\2i@eMW?[2i@eMW?Y2k@gMU?Y2k@gMU?Y2i@iMW?^1[A_M_OR1W?\\1]AaM\\OT1W?[1i@`M6OO2JU1X?VOg@f11nM7O00JW1W?VOj@i12lM2NKW1W?UOk@l1NoM4Q1S?TOl@l1MjMOO5W1S?TOl@l1MjMON6X1R?TOk@m1NiM6X1Q?SOh@H0g10VN4N2\\1R?WOn@U1<Df>WOPAR1:Hf>VOQAP1G^N?[1j>VOQAV1LXNNZ1W?YOPAV1HXN0W1[?WOc@A:j1GWN0V1^?\\Ok@X1FVN0V1`?\\Oi@Y1HTNOV1a?]Oh@Y1LZO\\?]Oh@Y1KZO^?]Og@Y1KYO_?^Of@Z1HZOb?VO[@G;i1HZOa?^Oe@X1J[Oa?B_@T1OZOc?e1]@[Nc?[O[@b15SO`?ZO]@b13TO1jNU?h2i@^Nb?B`@m0JEg?^O`@l0ICj?A^@f0HcN0U1k?C\\@GI:1UO1U1i?HY@EL=17j?IV@g0O_Ol?d1T@[Nm?8S@U1m?kNS@kN0P2m?UOT@jNOQ2m?SOW@iNNT2k?ROY@hNMV2j?ROX@hNOV2i?SOV@gNONOX2k?_OU@`0l?j100000dNT@dNl?h20000000000000O1000000O1O1L4L5oMh_O3^`0Ed_OdNO5OU1c`0I]_OlN1160JO1Y1e`02Y_O>h`0=Z_ORNN8h`0d1\\_OSNK:k`0b1Y_OgNi`0c0V_ORO1;k`0b0R_OTO39n`0T1R_OlNo`0?P_OXO0BMa0]a01c^OF4630Za02`^OG3LL484]a0?_^OD4Lba0=Y^OCMF89ea0<V^OEMF=3la04n]O2\\c0E^\\O8fc0O001IZ\\O1dfR42RmmK4J6FEj\\O>Wc0Ah\\O`0Xc0400O1001O00001O1O00001O00000000008H2NO1O1M2010N21O10Ijha1"}}, "object_label": "oven", "attribute_label": ["color:gray", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "color, material", "answer": "The oven in the image is white and located in a kitchen. It is positioned next to a sink, and there are several oranges placed on the countertop in front of it. The oranges are being sliced and prepared, possibly for a recipe or a snack. The scene suggests that the person is in the process of preparing food or beverages using the oven and the oranges."}, {"question_id": 485, "height": 438, "width": 640, "image": "000000531495.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [241.23, 151.1, 58.77, 98.37], "segmentation": {"size": [438, 640], "counts": "\\UX363OT=;N2O01O0000O10000N2O100O10OPOBjD>P;KlD6P;Z1K5>VNfD<[<O1O000O100000000^OPC>P=CoB=Q=40_OoB=Q=BPC>P=BQC=o<DoB<R=4001^OQC;U=01O00HFTC:l<GRC:g<>;D101O001OO010001O1N2O2M3MYVa4"}}, "object_label": "boat", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, transparency", "answer": "The image features a white boat docked at a pier in a harbor. The boat is positioned near the center of the scene, and it appears to be a small sailboat. The harbor is filled with several other boats of various sizes, creating a lively atmosphere. Some of the boats are docked closer to the foreground, while others are situated further back in the scene. The presence of multiple boats in the harbor suggests that it is a popular location for boating enthusiasts."}, {"question_id": 486, "height": 426, "width": 640, "image": "000000549738.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [504.65, 416.19, 31.52, 9.81], "segmentation": {"size": [426, 640], "counts": "RXa64T=2001O000000O10000O100O100O10000000000000000000000000000001O001OgX[1"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, color, pattern, transparency", "answer": "The image features a car with its hood open, parked on a street. The car is positioned in the middle of the scene, and its hood is visible, indicating that it might be undergoing maintenance or repairs. The car appears to be a small vehicle, and the hood is red in color."}, {"question_id": 487, "height": 427, "width": 640, "image": "000000552842.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [364.5, 246.6, 22.62, 20.57], "segmentation": {"size": [427, 640], "counts": "a^h43W=2M2N3M3N10001O01O00001O00001O00001O0O1O1M3MijX3"}}, "object_label": "baseball glove", "attribute_label": ["color:brown", "material:leather", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, transparency, color, pattern", "answer": "The image features a baseball glove with a red and white color scheme. The glove is placed on a grassy field, and it appears to be a catcher's mitt. The mitt is positioned in the foreground, with a close-up view of the glove, showcasing its design and texture."}, {"question_id": 488, "height": 333, "width": 500, "image": "000000553511.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [79.1, 12.8, 26.1, 62.8], "segmentation": {"size": [333, 500], "counts": "fej03a0N`03a76hGo0S8VOjGk0Y8oNjGQ1W8mNjGT1V8kNjGU1W8jNiGV1Y8hNgGX1Y8hNgGX1Z8gNfGX1h80O10000000001O1NBRG@n8MUG020i8OXGO00j80WGO0Ok8OYGN0Oj81TTP4"}}, "object_label": "traffic light", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The traffic light in the image is a black and silver color, hanging from a pole. It is located near a building, possibly a tall building, and is positioned above a street. The traffic light is currently displaying a green light, indicating that vehicles can proceed through the intersection."}, {"question_id": 489, "height": 428, "width": 640, "image": "000000054123.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [187.82, 108.49, 81.53, 41.5], "segmentation": {"size": [428, 640], "counts": "Sg^28P=4M2N3O1NN1200O2N2O1O01J5100O1N101M3O101^CXO_<g030100O03M00LaC]O]<b0eC]O[<c0dC^O[<c0eC]O[<d05100O100O3N1N101N10O10O10O10O01N2O1N2E`CHc<7]CJb<6_CIa<7`CH`<7bCG_<9aCG_<8bCG_<9aCG_<9aCG_<9aCG_<9`CGa<9_CGa<:^CEd<:\\CEe<;[CFe<9[CGe<9[CGf<8YCIh<7WCIi<7VCIl<:10100O1O2N1O1O1O1O1N3Nh`j4"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, texture", "answer": "The image features a zebra with its head down, grazing on the grass. The zebra's mane is standing up, giving it a unique and distinctive appearance. The zebra is standing in a grassy field, surrounded by a lush green environment."}, {"question_id": 490, "height": 428, "width": 640, "image": "000000054123.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, state, texture", "region_anno": {"bbox": [102.41, 113.76, 443.46, 288.88], "segmentation": {"size": [428, 640], "counts": "hY[13X=3L2O3M3M;F0OIbCB^<=81O1OMYCCg<<ZCDf<<ZCDe<=[CC]<4bC83B\\<6aCO2Kd<6]CNf<3ZCNc<2[C3d<N\\C3\\<GdCf0Y<:^DZOY:<PEH0B3i0d:NYEo0d:RO]Eo0`:U1H10hNfE_O4mNn9d1nE_O3nNn9l2RFVMj9l2VFTMh9n2VFSMi9o2VFQMk9X3ZFaL]9`3cFgLU9W1fFS1X9iNhFhN170n1T9SOlFhN143S2k8SOPGfN241V2k8UOTGdN2X2h8_OUGk0b8V2H6L3M2N3L2O1O1O0O3M1N3N2N2L3N2N11O0O1001O0O2O1O100000000O10O100O1O0K0WJjHb5[7`JcH\\5a726YNbHUMh7g2_HnLj7m2\\HnLg7o2`HiLa7Y3W111O3M2O2N1O1O1OHiL^FU3c9jL^FT3d9lL^F5Ge2W:72N1O100O1O0N3N3O0000IZMgEh2V:8ORMlEf2T:ZMlEf2U:XMjEj2Z:2lNRMjGo2T8RMlGn2T8RMkGP3T8PMlGP3W92N1O2N1O2N100O2O0N2O2PO`LRH`3l8101N1SO]LPHd3P8\\LoGe3Q8[LoGe3Q8[LoGe3Q8[LnGg3i82JZLeFh3Z9ULiFm3Z92M2N4M2YOiKUHZ4h7fKXH\\4[84I7K6L7I6I6K5J5K2N1eI\\Jk4k5iJ_JS5m60000000001O00O2O000O1O1O1N3M2bL`JPO`5o0eJlN\\5T1gJiNY5W1jJfNW5Y1lJdNT5\\1PK_NQ5a1TKYNl4h1XKTNh4m1[KoMe4Q2QLXMP4h2WLQMi3o2\\LlLd3T3cLdL^3]3eL^L\\3b3X3O01O000O101O000000001O0000001O0000001O0000000000000000001N10000\\OoKmGQ4S8oKmGQ4S8PLkGQ4U8oKkGQ4U8oKkGQ4U8oKkGQ4U8oKkGQ4U8oKkGQ4U8oKkGQ4U8oKkGQ4U8oKjGR4V8nKjGR4V8nKjGR4h8000O10000O1000O1000O100000O100000O10O10O1000O10000O100O010O01000O10O0100O10O0100O100O010O10O01O001O00100N2O1O100O1O1N20O01N200O1O10WF`Lf9h3K1OCaFoL]9b3N2M4M3M2O1N3MQOSGdMh8\\2XGgMe8Y2[GjMb8d3K2O3M0hGPKT8U50O000O1I7HeG_K\\8`4dGaK\\8i4bGTKX8P4iGaL0EV8j3jG]L5CJ2V8n3kGSL2O91h7n3lGTLd0La7Y4i002N00mGgKT7W4mHiKS7T4gHkKYO21OP8Q4hHoKVO21NQ8T4iHmKUO1R8R4lHnKT7R4iHQLX7o3bHYL\\7g3bH[L]7f3cHVL]ODQ8W4aHTLc7m3m02N2O0O1O2O1N100O101O0O2O0O10001O1N2O1N101OmMPHkNn7m0]HQOa7j0fHWOX7d0oHZOQ7a0TI@k6:[IGd63cI1X6KlI9P6CUJ<l5[O^Jb0c5WOdJh0^5QOiJm0X5POlJn0W5oNjJP1W5POiJo0Y5QOfJm0^5SO`Jl0b5TO]Jj0f5VOZJg0j5XOWJc0m5_OP410N1O1N101NUCGe<7ZCLg<>00O10O010OO2N4MO04M0O0100O10OO1001O01O1N2O011M2O000O101N10O0100O002OO010O04L1GRC2o<LRC5R=02O1J\\\\Z1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "state:dry", "texture:smooth/sleek"], "control_dims": "texture, pattern, state, maturity, color", "answer": "The image features a herd of zebras grazing in a grassy field. There are at least six zebras visible in the scene, with one zebra standing out as it is eating grass. The other zebras are scattered throughout the field, some closer to the foreground and others further in the background. The zebras are all focused on grazing, enjoying the lush green grass in their natural habitat."}, {"question_id": 491, "height": 427, "width": 640, "image": "000000055072.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [49.24, 46.17, 462.67, 380.83], "segmentation": {"size": [427, 640], "counts": "\\ee04U=2K6ONQ=JnB;I9JO11@0oCFQ<k0M20O2kNSDh0h;WOVDN015;MGf;OXD0302<JEe;:_DD3c0\\;F]DG`0<Y;DWD52I`0<R;K^DJO11Na0;l:7aD@2N?<m:;WE_O[OLa;f0P100]O_C30Oa<MaC20LNOm<1VCOo<0PC5m<5VOK\\D1_OJT<7SDHO0Y<5jCNKN\\<1mCNcZ19bmNIcG4h1OA`0\\67XHYOj15VOd0`66`J^OeNb0f63eJZ1W5cNnJ_1n4eNnJ_1P5cNmJ`1P5cNkJa1T5bNRI`Nd1P3Y5mNSITNS1R3j5UOlId0]6Q33M4E;K4M4O1N200N1N31O2O1N2N3M3M3M4M3M3L3L5L5K5K5K5K5K5L3L4L5LlMiJULU5k3PKRLn4l3VKSLj4j3\\KSLd4j3bKSL]4l3jKoKV4P4nKmKR4R4RLkKn3S4YLhKg3W4^LeKb3Y4cLdK]3[4hLaKX3^4nL[KT3d4j2O1N101N2O1N2N101O1O1O1N2O1N2O0O2O1O1N2O1O1O1N101O1O1M3O100O04M1O001O000O2O00000O101O0O1000000O10000O10000O10000O1O100YJPLcL0X5Q4nMWLiLHY5Q4jM[LlLEY5Q4_MlL`2U3ZMQMe2P3WMQMk2P3lLWMU3i2dL]M]3d2^L`Mb3a2YLcMg3^2WL]M]N[N^5X4SL^MR4c2lKWM[4j2cKVM^4j2`KXM`4i2]KUMf4l2WKUMk4l2SKSMn4n2mJVMS5l2iJVMX5k2dJXM]5g2bJYM_5h2]JZMd5g2XJ[Mj5d2TJ\\Mn5e2oIZMU6e2hI\\MZ6h2_IXMe6c43O2N2M2N2O2N1N3M2O2L4O0O2N1O2N101N2O1002N8G`0A=C7I<C3N3M3M4K7J6J5K6I8I6J3M0O1000O1RM[LlJA3V4[4\\MoJnN<e3_4oNWKR1d4m3K5K5L4O0O2L4M3O1N1O2O001M201dNoF\\NS9b1RGYNP9d1UGXNm8f1WGUNl8j1WGRNj8n1\\GiMh8U2X1O001O1O1O001O001O001O1O010O1O1O010O1O001O1O10O010O01O1O010O1O010O1O100O00100O001O010O00010O010O1O0010O01O100O001O10O01O1O0010O01O10O010O01O001O010O00010O0010O01O10O01O010O00100O001O010O1O0100O01O001O00010O10O01O100O0010O01O010O0010O010O01O001O01O010O010O0001O00100O010O01O1L3M4N110000O2O1O001O001O1O1O0O1000O100O1O2AiNhDW1W;lNeDV1[;>0O100O1O01O01O2N3N1N3N1N1O1O0000000010O000001O1O1O2N2N2O1N2N1O1O100O10000O1000001N101N100O1O1O2N1O1O2N2N4KXSf1"}}, "object_label": "giraffe", "attribute_label": ["color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, texture", "answer": "The image features a giraffe standing in a grassy field with trees in the background. The giraffe is positioned towards the center of the scene, and its long neck and legs are clearly visible. The giraffe appears to be looking at the camera, possibly curious about its surroundings. The field is spacious, providing ample room for the giraffe to roam and graze."}, {"question_id": 492, "height": 466, "width": 640, "image": "000000058384.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [304.15, 203.57, 33.26, 66.45], "segmentation": {"size": [466, 640], "counts": "hQ[44Y>6K4XOh0N2N2NL4L31O4M;F3M1O1O1O3N2N0O100O100001M2O101D`CbNe<V1`0I8H7K8A_?NeXX4"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:young/baby", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "texture, pattern", "answer": "The image features a group of elephants walking together in a line. There are three elephants in total, with one being the main focus and the other two positioned behind it. The main elephant is walking in front of the other two, creating a sense of depth and movement in the scene. The elephants are walking on a dirt road, which adds to the natural setting of the image."}, {"question_id": 493, "height": 640, "width": 427, "image": "000000059386.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [266.01, 237.12, 122.2, 236.71], "segmentation": {"size": [640, 427], "counts": "^lZ5<9FI0Qc0=T]OH2K]b0=d]OJJ0\\b06k]O9Sb0Fm]O<Rb0Dn]O?na0CQ^OGJ<la0AS^O=7EN<ea0DT^O<8EO=ba0CW^O<5H0:ba0CY^O;4J0:aa0A[^O;5JM;ba05c^O;Za0TOa^O35j0Xa0TOf^OO2m0Wa0TOi^ON1n0Ta0WOk^OI0R1Sa0VOQ_OEHY1Ua0TOV_O@B_1Wa0QO\\_Oo0a`0SO__Om0``0TOd_Oi0Y`0ZOf_Og0X`0]Oe_Oc0[`0C[_Ob0d`0^1O0010O0QMU_Oi2Va0L2M3M2O1N2N3N2N1N5K7Jc0\\O7J1O000O3O0O000O100010O0100O0010O0O2Oh0XO3M002M104K10JR^OYNma0g1T^O[Nja0l11L50`_ORNl>o1RARNn>o1QARNn>o1QAPNQ?P2_1104K2h^OPN\\`0U2[_OSNa`0S3DO0ROd_OXN\\`0^1d_OnM1d0Z`0^1f_OmMOe0\\`0^1f_OiMOi0^`0Y1`@kMRO3a`0o1[1O1O100010O3M1O2O000OeN_^Oa0Xa0XOm^On0GoN``0N]@Y1Wa0N4LB^N_^O1E0OV1]b08JaNk]O`1cb0jN\\]O?Tc0N2N4M2M4L9EfUi0"}}, "object_label": "giraffe", "attribute_label": ["color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, state", "answer": "The image features a group of giraffes standing together in a grassy field. There are five giraffes in total, with one of them being the most prominent and visible. The other four giraffes are positioned behind the main giraffe, forming a line. They are all standing close to each other, possibly enjoying each other's company or grazing on the grass. The scene captures the beauty and social nature of these majestic animals."}, {"question_id": 494, "height": 640, "width": 427, "image": "000000059386.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "color, pose, state, texture", "region_anno": {"bbox": [339.46, 179.88, 14.81, 24.81], "segmentation": {"size": [640, 427], "counts": "mQd68_c0=L22M1O1N1O1O1N2O001O2M3LmQ^1"}}, "object_label": "giraffe", "attribute_label": ["color:brown", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose", "answer": "The image features a giraffe standing in a grassy field, with its head and neck prominently visible. The giraffe appears to be walking or running through the grass, possibly in a park or a natural habitat. The scene captures the giraffe's unique features, such as its long neck and legs, which are characteristic of this species. The giraffe's presence in the field suggests that it is in a comfortable and open environment, possibly enjoying the sunshine and the surrounding greenery."}, {"question_id": 495, "height": 332, "width": 500, "image": "000000064359.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [214.1, 114.07, 132.85, 126.94], "segmentation": {"size": [332, 500], "counts": "VkU26U:3K4M3M2N1M4O1O1OOKYOiFg0T9802O1000OPIoNg4P1XKSOg4l0YKUOg4k0VKXOj4h0UKYOl4f0SK[Om4h0nJZOR5g0kJ[OU5g0gJUO`5l0[JVOf5k0SJYOQ6g0kIYOX6i0cITOb6R1WImNl6V1oHjNT7V1hHjN[7W1aHiNb7W1\\HiNe7X1YHgNi7Z1THgNn7Z1oGfNR8i11O1O2N2N10100002M2001OO2M\\OiGVOT8h0RHUO?_Og6Z1oHWO4Am6W1RIYOLBR7U1WIVO@JY7Q1cIWO]6i0fITOZ6l0gIROZ6o0fIiNoNN\\7X1a1O10000001O0000O101O0000^HhNo5Y1PJiNo5W1PJjNP6V1nIlNR6T1mImNS6S1lInNT6Q1kIQOU6o0jIQOW6o0gIoN]6R1`IoNa6S1[IoNe6U1VIkNj6]1mHcNU7c1_HaNc7S21N2N2N2N2N2O1N2O1[OSHjNn7U1e0O1O100O10000O2N11O4L102M101O1O]OXGBf8;[GId84^GNa81`G0_8OaG3^8E`GB2m0h0QOf6?`HC2OMm0f0UOl6`0nH6O]OV7:mHo0W7mNlHP1W7nNjHP1X7QOhHl0\\7QOfHJH5BLR86XIIkNNQ89j103NM0PFJl9<2L[Rb1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pose, maturity, state, color, pattern", "answer": "The image features a zebra walking on a dirt road, surrounded by other zebras. The zebra is the main focus of the scene, and it appears to be walking in front of the other zebras. The zebra is positioned towards the left side of the image, while the other zebras are scattered around it, with some closer to the right side and others further back. The zebras are all standing on the dirt road, creating a sense of movement and togetherness."}, {"question_id": 496, "height": 313, "width": 500, "image": "000000068933.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [6.32, 58.95, 134.04, 206.33], "segmentation": {"size": [313, 500], "counts": "ed5>9Cb8d0\\G^O]8i0bGYOX8k0hGWOR8o0kGlNN5R8W1nGnNj7f1I8I4KVOiHZOR7i0oH_NOc0n6o0TI]NOe0h6R1XIXN1h0b6Y1^IjN]6Y1aIkNZ6V1hIlNT6W1jImNP6j2C=E2M5lJZKk4l4VKUKc4R5O0O01I]KXKb4f4:O0BSKfK33MMl4Y4\\KiKh4W4YKgKg4Z4<3L4Le0\\O3L2L3O2N6IMUL\\Jj3d551O1O010VLZJ`3g5900VMQLJn30QL]M4a21[Mc3g2YL\\M3b2k31TL\\M1a2m34[LZNDUO0O1d0OXOS4f2ZLXNDVO1M<:i3\\2VLWNDVO2L26L4V4]2VLWNDVO2L26L5T4\\2VLZNb0[OW3[2QLXMNS1h0TOUOO0JQ4i2YLbN1gNG?Q4W2UL_NHQO7`0l3n1WLXNHVOa0>d3T2TLUNEVO41`0?c3U2TLXNISOg07_3_2mKYMId02C2Kg0Ne3k2bKmM1^O0MZ5`3jJ`LO0W5`3jJ_L01U5a3kJ_LO0V5`3mJjLS5V3mJiLT5W3kJ]LI141K5T5]3PK]LN13>5AX4k3^KYL1l0_4j2bKZLN903`4Y3dKiLNM1@X4j3jKWLN22M78GHX4k3iKWL`5c3eJ^L[5a3fJ_Lf0Oa3a3kK^La04d3]3mK^L<7h3[3c10000O1000kIeLm5Z3RJRMc5m3E4L5L3L>CO1O0O1O2M2D]K^Kg4\\4?L3I8G9L4N2L4M3G8E<M3M3N3L3M3M4L5J5K6K8F<ROgGEV`^3"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pose", "answer": "The image features a zebra standing in a field, grazing on grass. The zebra is the main focus of the scene, and it appears to be eating hay or grass. The zebra is positioned in the middle of the field, with its head down, and its body is facing the camera. The field is relatively open, providing ample space for the zebra to graze and move around."}, {"question_id": 497, "height": 334, "width": 500, "image": "000000069106.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [207.16, 116.11, 102.82, 132.1], "segmentation": {"size": [334, 500], "counts": "WdS2;R:3jFHR88hGOZ8NcG7^8F_G?`8BZGc0k0@Y6V1XI]Ob6d0TIaNHT1m6:YIdNIX1i64\\IgNIW1j61]I^ONHc6k0^IWO>@]OJg6_1^IiNOJg7_1YHhN1Fc7h1[HcNm7]1SHcNn7\\1SHdNV1EfNOe6c1^IjNT1GhNLg6b1]IlNR1GjNKg6b1^InNl0Ig5X1^IQOd0Kn5U1]I7d6K[I4f6MYI0j6aNWIT1N9l6bN\\IQ1H1W7oNRIo0GOZ7QOQIQ2T7oMmHj1Y7VNhHd1^7[NcH_1Z8K4N201O000001O0000000000000O1000000000O1000000000O1000000000O10000O10000O1O001O100N200003M5K2N2^H^NT6d1cIcN]6_1`I_Nc6c1ZI^Nf6d1WI]Nj6d1QI^NP7d1lH^NT7d1gH^N[7f1\\H]Ne7T23M2M4L4M\\HkMS7S2mHoMBL_7S2kHYNV7e1cHcN]7Q27N2O1N2dNXHJo72WHGn76WH@Q8=SH\\OT8>V1DVUm1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color", "answer": "The image features a zebra standing in a dirt area, possibly a zoo enclosure. The zebra is the main focus of the scene, and it appears to be looking at the camera. The zebra is standing next to a wall, which adds to the enclosure-like setting. There are two other zebras in the background, one on the left side and another on the right side of the main zebra. The presence of multiple zebras suggests that this could be a group or a herd."}, {"question_id": 498, "height": 480, "width": 640, "image": "000000091921.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [72.41, 295.97, 160.88, 96.73], "segmentation": {"size": [480, 640], "counts": "R`S1:a>8J5L4oAYOc=S1N3M2N2N2O1O2ROfNSD[1m;gNoC[1P<hNmCY1R<iNlCX1S<kNiCW1V<kNhCV1W<j00001O1000O10O001O0O1000001O0O1000000000000O2O000001O0O100000000010O000001N1000001O1O2N1O2`MbCZ2^<eMdC62g1`<XNaCg1_<YNaCg1_<XNbCh1^<XNbCh1^<XNbCh1_<WN`Cj1a<TN`Cl1j<0000000000000000000001N100000001O0O11O0000000001O000000001N101O0O2O0O2JgBbN[=a11O00100O1N3N1O1B[B_Og=?YBAh=m00O2N3GSBWO\\>:fAE\\>:cAE_>9bAF`>8`AHb>6^AJc>5]AKg>0ZA0k>000l`[6"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:sitting/sit", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, pose, texture, maturity, color, state", "answer": "The image features a zebra lying down on the sand, possibly in a zoo enclosure. The zebra is positioned in a way that it appears to be sleeping or resting. The zebra's body is covered in stripes, which are a distinctive characteristic of its species. The scene captures the zebra in a relaxed state, enjoying its time on the sandy ground."}, {"question_id": 499, "height": 480, "width": 640, "image": "000000091921.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, size, state", "region_anno": {"bbox": [313.61, 223.04, 288.11, 194.05], "segmentation": {"size": [480, 640], "counts": "_ab41o>1M200O10000O100O001O10000O010O10O01000O0010000O1000O1000000O1O0001O1O001O001O000010O0000001OO11N100O1O1D<N3L4O2N5K3M4L3M4M2M3M5lC`NPOl0S:g0iFLU99fFHZ9<aFE^9?]FE`9?\\FDa9b0XFDd9m2N0010O01O101N2^FgJ[9`5N10dNiFoLV9j2ZGnLf8a2RHWMn7h2VHRM_NB\\9Z3ZHQMZNE[9Z3_HQMa7n2eHkL]7T3X2O1N2O1O1N2O1N2O1N2N2N2O1O1O2M2O1N3N100001O001O1O1O1O010O001O001O00010O001O00000010O00000000000010O0000000001O000000001O000000000000001OQFeMX7\\2fHjMV7V2hHlMX7T2dHPN\\7o1cHSN]7m1PH`MhNi0W9h1jGlNV8T1gGjN^8V1]GlNf8T1mFoN]9Q1TFWOS:j0iESO]:e23O001O1N2L4H8H8M3K5M3M3M3N2N3M2N3O000O2O001O0O101O100001O0O3N8H3M4L3M6K5K0O2M3K6K<H5I2N01nMoEROQ:h0ZFTOe9g0fFoMROh0Y:W1XGjNa8U1eGeN\\8Z1hGbNZ8]1fGcN[8\\1WFRNl0>o8^1kEdNT1JR9c1eEiNY1\\OeNO`:g2iFZMhNNa:g2hFXMiN1_:g2mFXMV9f2jFZMX9e2b1010O2N100O101N00<C3N1O00O00101N1O1O2N2N4K5L1N2N1O2N1\\OeCbN\\<j0`DlNb;2cC?j=@[B7i=JXB3i=MXB0j=0c01O01O001N100001O01O0O11O3N0O0010N1000000O100N2OPkc0"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry"], "control_dims": "maturity, pose, size, state, pattern", "answer": "The image features a zebra standing in a grassy field, with its head down and its nose close to the ground. The zebra appears to be grazing or sniffing the ground, possibly searching for food. The zebra is the main focus of the scene, and it is positioned in the center of the image."}, {"question_id": 500, "height": 375, "width": 500, "image": "000000129054.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [308.6, 191.18, 35.49, 46.14], "segmentation": {"size": [375, 500], "counts": "\\\\a33Z;:OL2NGLYE1j:1TEMm::52lDLa:5[EOd:b00H8YOSEa0P;_OQE=V;O01O100O2O=BM4I41O6REXOe:S1I20E:M3GVEDm:9;OO2O08H2MbYi1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, pattern", "answer": "The image features two zebras standing in a grassy field. One zebra is positioned towards the left side of the image, while the other is on the right side. Both zebras are facing the camera, and their distinctive black and white stripes are clearly visible. The zebras appear to be walking or standing in the grass, possibly grazing or exploring their surroundings."}, {"question_id": 501, "height": 512, "width": 640, "image": "000000132622.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [11.43, 3.67, 559.21, 508.33], "segmentation": {"size": [512, 640], "counts": "mY84o>S1H8H5I6J6M<C;F2QFYMiL0d9m2]I[M]6m2ZI[M`6S3QIYMb6Q3UITMg6R3mHWMR7l2iHWMU7o2bHVMY7^3oGlLn7d5N2M3M3N2O1O2N1O1N6J3M2O0NO22M@cHcHOBX7i7QIVHH7X7b7h01O2O2EVH]Hk7c79O1N3O0O1O1N2N3L4N1O101O0N3K5N2M4L4M2N3L3iJ]FmN3n4`9PLiFn3Y9PLiFn3Z9lKWF[O`0h4[9jKkFT4W9iKlFU4V9hKmFV4V9cKoF\\4Z:O2N10000O2OLdKeD]4Y;500001O00M3001O1oKiDX3X;gLiDY3W;dLjD]3f:]L[E5O^3g:aLVE04]3h:dLRE06Z3k:XLQEi03o2R;RMiDn2c;ZL_DR4l;oKUDd3U<N2N4M1bLbCW3f<M1O1N2O1O1O1O1OOOL4111OO11N200O3L101O1O2O0O2M2O1O2M3M10010O100O100O01000000O0101N2N100O10O00001O001O01000N10100O10O01O11O0000O100O10000O1O001000O10000O1000N2000O103M001N10000O00101N101O001N2O003L3N1N2M4M2N6K00O1N1O2N2N2O1N1O2N2M201N]NSBK2Q1i=UOVBI2R1f=VOVBK5n0c=YOYBG7m0_=]O`BA0S1^=XORCh0m<XOSCh0l<XOVCh0h<XOZCh0e<VO^Ci0a<VObCj0\\<WOfCh0X<YOiCg0V<YOkCg0S<YOoCg0o;ZORDg0l;YOSDi0i;XOYDi0f;WOYD9lNFj<OVDb0RO]Of<1YDd0TOWOc<5XDe0ZOPO^<?RDd0]<ASCBEn0V=a1M3ObMlBR2R=PNmBP2R=PNPCn1R=oMQCl1R=TNQCk1m<VNSCl1l<TNSCo1j<RNUCQ2h<oMZCP2d<PN^CP2a<QN`Cn1^<QNfCo1X<PNjCo1U<RNmCm1R<QNRDn1m;SNSDm1l;UNTDi1l;YNSDg1l;ZNUDf1i;\\NWDc1i;UNaCLf0o1g;UNhCGd0S2b;VNjDg1V;XNnDe1Q;ZNUEb1l:_NUE^1k:dNUEZ1k:gNdCG_1_1m:hN[EV1e:jN]EU1b:lN^E_1W:]NmEd1R:[NoEf1o9[NQFf1m9[N]DI\\1n1U:YNUFh1j9XNVEI0o1j:UNXDMf00_O0MOg0o1n:TNUEM9o1a:TNWEM8o1`:TN`Fl1`9SN^E2Jk1h:RNQEOE5b0j1h:RN^E4Jj1h:RN_E3Ik1h:QN`E4Gm1h:oMbE4Do1Q<VNUCHb0S2T;mM^E<YOh1X;mM`E>TOf1[;lM[Ei0TO\\1a;kMUE[3a;cLiC`3\\<O00]OdL\\Dc3b;aLZD`3f;aLYDZ3Q<cLlCX3[<6001O10O001O1M20_OmCTMS<m2oCPMQ<Q34jLkCX3V;WMfD@O82R3T;mMkDT2P;fLnDV12T2o:hLnDN120h04a2l:gMXE\\2h:bMZE_2f:ZMQEVO;`3g:VM_Ej2a:TMaEk2`:SMaEn2^:RMbEo2^:nLdES3`:gLaEZ3_:_LgEa3Z:^LgEa3Z:aLcE_3^:aLbE]3`:cLdD0e0\\3i:jLWEU3k:cLaD3b0Z3V;dLhD\\3X;dLiD[3X;dLhD\\3o;O\\OeLcD[3\\;iLaDV3`;kL_DV3c;gL^DX3d;fL\\DZ3d;fL\\DZ3c;hLYD\\3f;dLZD]3e;bL[D`3d;`L\\Da3c;_L\\Db3d;`LZD`3f;aLXD`3h;_LYDb3f;^LYDc3g;]LXDd3h;]LVDd3j;\\LUDg3i;ZLVDh3i;WLWDj3g;9O0002OO3N1M100O2N100O1O11O0006I2O0M30000O100001OO2L3O10000O1KPKZEP5f:50kJ[Eo4d:QK_Em4_:UKaEl4]:VKaEk4^:VKaEl4^:SKdEl4\\:RKgEm4Y:RKgEP5Y:nJhER5b:11O10O1N2O010O001O1O10O12N0O0010O10O0010O10O10O100O0010O010O020O001N1000O0101N1000001O0O1O101O0N2O1O1O1O00001O00010O00001O010O010O1O010O00000010O0100O1O1O1N3N3L4N3L>A6K3M1O1O2M2O1O1O2^GeH[8b7N3L3N1O2O0N2O2N2N3N1N1N2O1O010N2]HhG\\7_8O2N1O2N2M3N4L2N2M2O1O1O3N3L2M2O2N100O3mIXF22Z5g9bJ[FN3^5b9cJ]FM5]5`9cJkFZ5Q:M2oJYEe4V;K2N2O1N2N8VL]Dh2i;fLVDO6Z3Z<01O1O2M101O0O2N1O2O3L8G4M3K6I9QNYBT1o=gNcBf0`>K4EVdQ1"}}, "object_label": "bear", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, maturity, pattern, state, pose, texture", "answer": "The image features a large brown bear walking through a grassy field. The bear is standing on its hind legs, with its front paws on the ground, and appears to be looking at the camera. The bear's fur is wet, possibly from the surrounding environment or water. The bear's size and presence in the field suggest that it might be a grizzly bear, which is known for its strength and adaptability to various habitats."}, {"question_id": 502, "height": 478, "width": 640, "image": "000000140583.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [427.31, 283.98, 20.05, 46.1], "segmentation": {"size": [478, 640], "counts": "`TW63i>3N1O2O1WBJh<8SCLl<6oBNP=4kB0T=4eB0Z=j00000000O2O1N2N1O2M3C=K5IoZi2"}}, "object_label": "sheep", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, pose, pattern, maturity, color", "answer": "The image features a group of sheep standing together in a field. There are at least five sheep visible in the scene, with some of them standing closer to the foreground and others further in the background. The sheep are of various sizes, indicating a mix of ages and stages of development. They are all standing in a line, possibly grazing or resting in the field."}, {"question_id": 503, "height": 478, "width": 640, "image": "000000140583.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [385.28, 292.42, 23.42, 51.0], "segmentation": {"size": [478, 640], "counts": "^_d5;`>8I6J5L2O3L8H2N20O00010O0O1N3K4N2N3K5L5M3K6ISa[3"}}, "object_label": "sheep", "attribute_label": ["color:black", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose, maturity, state", "answer": "The image features a group of sheep standing together in a field. There are at least 13 sheep visible in the scene, with some of them standing closer to the foreground and others further in the background. The sheep are of various sizes, indicating a mix of adult and younger animals. They are all facing the same direction, possibly indicating that they are grazing or following a leader. The scene captures the essence of a typical herd of sheep in a natural environment."}, {"question_id": 504, "height": 640, "width": 480, "image": "000000150726.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [56.09, 204.22, 211.42, 258.88], "segmentation": {"size": [640, 480], "counts": "f[Q13lc01N3N1O1O2N2M2O001N100O2M2O2N101O001N2M3N1L5O10O101N105J2O0O100O100O1000O010O2O0O101OUOo\\Og0Vc00O1O100O02O00000000O1000000O10000O11O0000O1000000O100O10000000000O100O10O010001N10O01000OW@WO[<j0bCZO]<f0`C]O`<c0^C@`<`0^CCb<=\\CEc<<[CFe<;WCIg<7XCLg<4WCNi<2SC3k<NRC6m<JPC^OUNLj>g0nB^O\\NJe>h0fAmN8b0AH_>j0bATO8<JF[>k0\\A[O:43FU>n0UA_O`0N8FR>m1aA^Na0Dn=o1\\A_Nj0Ah=T2VA^NS1Ae=P3^BPM`=n2dBRMZ=m2jBRMT=l2PCTMo<j2SCVMl<h2WCXMi<f2ZCYMf<e2]CZMb<c2bC^M\\<a2fCbMW<[2mCfMP<Y2RDhMl;X2VDgMj;W2ZDfMf;X2\\DgMe;Y2\\DeMe;Z2\\DeMf;Z2[DbMh;_2XD^Mj;b2WD[Mk;f2g2011O0O3M3N2M2O3L5L4L5K:F4cAPLa<R4VCULj<n3PCTLQ=S4dBPL]=[4RBjKo=S51dLfAP1[>mN]B=c=CfB4[=KhCQOZ<o0PDdNS<[1nC^NY<a1fC^N\\<b1bC^Na<a1^C^Nd<b1ZC^Nh<b1VC_Nl<`1RC`NP=`1mBaNV=^1hB`N\\=`1bB`Na=`1\\B`Nf=a1VB_Nn=c1mA]NU>e1gA[N[>i1^AWNf>n1PAUNQ?W2]@mMf?T32M3N3N1N2N3N1N2O2N1O1N2O1O2SOc_OTN^`0j1m0N3L4L3O2O0100O2O000000000O10O0O2N2M3M3M3M5J9G4L7Jo]O@RO0\\a05T@Lia062Lc\\OLXc0Oi\\O2bc03NJZkR4"}}, "object_label": "giraffe", "attribute_label": ["color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, texture, maturity, state", "answer": "The image features two giraffes walking together in a grassy field. One giraffe is positioned towards the left side of the image, while the other is on the right side. Both giraffes are walking in the same direction, with their heads close to each other. The scene appears to be a sunny day, as the giraffes are enjoying their time in the open field."}, {"question_id": 505, "height": 428, "width": 640, "image": "000000155571.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [13.48, 7.53, 401.72, 415.4], "segmentation": {"size": [428, 640], "counts": "V`62W=4L102O000N2M201O01OO2OO012O00L4N1O11O0O20YNMTF4d9g0iEYOT:P1gEoNW:[1aEeN^:U2N3M3M5KMjEYMQ:h2PF[Mk9Z3H6K4J6KlNlFWNo8Y3I6K7H5L6I5K4M3K5L5L4L4K4L5L3K5M3M2M4M3M3M3M3bMlH_NX7Z1mHdNW7X1jHgN]7Q1fHmN_7n0bHQOc7j0^HUOg7e0[HZOS87oGHX8VObGWO;a1h:O1O0O200O1O1O1O1O2N1O1O100O1O100O100O101N10000O10000O01000O2OfLZOmIf0g5f0ZIZO`6W1UIiNe6f1RIYNl5WO]IT3;eMX6\\3bIdL^6b3\\I]Lf6c3YI]Lg6d3XI[Li6f3VIYLk6i3SIWLm6j3QIVLP7k3nHULS7o3fHTLZ7n41O100O1O1O100O00100O010O1O100O100O2O0000000[NbH[M`7_2hH^MY7Y2QIeMP7o1\\IPNf6i1_IWNc6c1bI\\N`6`1cI_N`6]1bIbN_6Z1dIfN^6V1dIjN^6Q1fInN[6o0gIQO[6j0iIVOV6g0mIYOT6b0PJ^OQ6;VJDn53WJMk5K[J5f5YOkJg0n8O00000010O001O0001O01O00001O01O01O000O1010O0001O00001gNoNUFQ1a9^OZFb0\\9L_F6[92bFNY9;cFEX9a0gF@T9d0kF]On8;kFcN5R1g8`0\\GZNLX1a8b0hGUNEY1]8g0oGUN]OV1a8g0WHBe7`0\\H@a7c0`H\\O^7f0eHWOZ7i0hHVOW7k0jHTOT7n0mHQOQ7P1QIoNm6R1UImNh6U1ZIjNe6W1\\IhNc6X1_IgN_6[1aIeN^6\\1cIbN]6_1eI_NY6b1hI^NV6d1kI[NS6g1nIWNR6h1PJXNn5j1SJUNm5j1TJVNk5j1VJVNi5j1XJUNh5l1XJTNf5m1[JSNh5i1YJWNg5g1[JXNg5f1YJZNh5e1YJ[Nh5`1[JaNf5[1]JeNd5X1]JiNe5Q1_JnNc5l0bJTO`5`0iJAY52RKMT5SOfKn0\\80O001N2N2J5M4M3N1M4N1O2O1O1N101O1O1N10hNgDZO3n0U;ETE:j:FYE8g:IZE7d:I]E7a:J`E6a:GaE9b:C^E>h:VO^Ej0b;01O0001O00000O10000010O01O001O000000000XKZOjLf0Q3HfL8V31eLOT3>fLBU3g0gLYOU3Q1eLoNW3\\1bLeN[3d1^L\\N^3Q2XLPNe3W2WLjMe3\\2XLdMd3f2VLZMg3R3PLnLm3T4TKlKi4\\4RKeKk4_4SKaKi4e4UK[Kh4j4VKWKg4l4XKTKe4P5ZKPKc4T5\\KlJa4X5^KhJ`4\\5^KdJ^4`5cK_JZ4e5eK[JX4i5gKWJU4o5iKQJV4Q6iKoIU4T6jKlIU4U6kKjIV4X6hKhIX4Y6fKhIZ4e71N100000001O000O101O001O00103L:F1O1O1O1O101N3M2N10O06J2O0O2N6K3L4M4K4L3N3L5K4L4M2M4M3L3M2N2N2N3N6I9H9F4L4M1N1O100O2O0O01000O01O001O1O1O1O1O2N2M3N3M3L?A6UM]JbMf5YOgJ4g02e4CPKES1?o3GZKUOZ1k0_3LjNGZ16oN@U1=XOROP1j0k5M3N2N2I8K5Iknm2"}}, "object_label": "elephant", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "state, color, pose, maturity", "answer": "The image features a large elephant walking across a grassy field. The elephant is the main focus of the scene, and it appears to be the only animal in the image. The elephant's trunk is raised, possibly indicating curiosity or a sense of exploration. The elephant's size and presence in the field create a sense of majesty and power."}, {"question_id": 506, "height": 333, "width": 500, "image": "000000159311.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [48.44, 1.73, 298.4, 224.02], "segmentation": {"size": [333, 500], "counts": "ijc02[:1O000000001O00001O000000001O001O00000000001O00001O1O00001O0000001O000000000000001O001O001O0000001O0000000000000000000000001O0000000000O11O001O001O0000O100001O1O000000001O001O001XH\\Oe5e0UJ[OYN20N[7e0aJ\\OTN2Y7b0\\JYO^N4L5W7?YJ3f5MYJ5f5MVJ7h5IXJYOeN2;9d6=ZJAPO4e6;YJFkN_O0a0k6;WJKmNJ0_Oj6n0TJ8ROoN0Kj6n0SJ9TOmN2Mc6m0UJ<UOiN4Mc6P1RJQOWO[1n6FhIoN\\OZ1l6GgIPO\\O[1l6FfIPO\\O_1k6AUImNb01@e1e6@jIkN_Oh1f6]OlIg0R6YOnIh0Q6ZOmIc0@VNc6X1iIh0W6YOgIh0Y6XOdIk0\\6WOaIf0NnMa6]1_If02oM[6\\1aIf03PN[6a3eI\\L]6g33000000001O0000O100000000003M1O1O001O00001O0000002N1O1O1O1O01000O0010YMkIU1T6kNlIV1S6fNTJW1m5iNRJX1n5gNRJZ1n5eNRJ[1n5gNPJZ1P6eNoI]1Q6cNnI^1R6aNoI^1Q6bNPJ_1o5aNPJ`1P6_NPJb1o5_NoIb1Q6]1N3K6N02SMUJbNO[2P6mNTJfNL]2S6iNRJhNKc2Q6fNSJgNLd2o5fNTJgNMe2k5hNUJ_1j5Y1XJoKf5Q4ZJQLc5P4\\JRLa5^1`JS1_5mNcJR1]5oNbJR1]5nNcJZNMe2\\5ROfJYN0Z2NlM7Gi49PK]14ZNLW22VNNF26_4NbK^13c0MZN0I\\4EaK15a14g0IXN2_OL9j4W1_KdNHW2OiMb02V4[1aKcNHV2m0jMh3_1`KbNJV2n0jMg3_1`Ko0j0bMc3a1bKn0n0dMY3_1iK_NLU2S1oMU3^1kKXNN026Mk1S1ZNT3`1iKTN76Jm1U1WNo2e1RLWNJOOh1Y1VNo2m1mKWNLNOh1`1VNa2n1SL;0eMX14c2l1TLSN1n1a1RN\\2R2TLM4mMV10`2V2VLMd1QNS2R2YLLe1TNP2o1\\LPNK0O_1k1^NR2R2XLRNOKM`1O`N140LO02O`00S4T2`KnMKO50L`13cN2LL0W5T2kJQN4^1KaNc5Q2]JQN5[1i5c0RJRNOJ32LN0X1Q6l0PJQN7NKU1o5kNoIj1OUN;1FNOT1[6h0UJCBgNNKP10SON[4m1RLhNFMJO;HE6\\4`1SLfNHLJK>`0l3T1lKPNLf0OZO0b0OI9EIf0L]O[47hKZ13\\NO>LE9m09QO]O723X4NjKc11VNK74H8m0EROd01]OO49S4OkKd14`NKE9m0EROc02G7n3LmKg12_NME71Dm0d0UO^ON38a4c1`K`Nb0m0@iNIO0O33L2e4g1aKZNJMj0V1^OhNI00022N1d4i1_K^Ng0n0XOgN32KO22NNg4m1[K\\Nh0Q1WOfN22MO11NOg4n1\\KYNh0l1UOnMf4n1]KVNi0o0TOG1TOf4[2WLHSOlMg4[2WLHm36TLcNQO[OOb0o4^1RLeNROZOM80GT5S2jKmMROb01@O>W5a1eKPNTOa01^OP6P2iJQNXOK21M91FR6U2cJWNCMP6k1\\JYNZ6h1bI[N`6e1]I\\Nc6e1ZI_NI[Oc6c30003N0OO2K4I7O00002N1O1O2N1O1O2O1N2N1O001N3N1O0dNbHHa73fHI[71PIIQ75UIFk69ZIBi6;^I\\Of6b0d1N2M4N1O1N3N2N2N1M]Xd1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose, texture, pattern, maturity", "answer": "The image features two zebras grazing on grass in a field. One zebra is positioned towards the left side of the image, while the other is on the right side. They are both focused on eating the grass, with their heads down. The zebras are standing close to each other, creating a sense of companionship and togetherness."}, {"question_id": 507, "height": 360, "width": 640, "image": "000000162543.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [463.67, 135.24, 56.33, 89.79], "segmentation": {"size": [360, 640], "counts": "gVR5:8G\\:k0E;G4K<F9F2O3M1O1O1OO010WOQGXOP9f0^GnNb8R1dGgN\\8Z1i000002N1O000jFjN[8S2O00O1O00001N2]O_G]Na8\\1j0FZFmNi9;UFF`Uc1"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "pose, color, texture, state, maturity, pattern", "answer": "The image features a large elephant standing in an enclosure, which is surrounded by a fence. The elephant is positioned near the fence, possibly leaning against it. The enclosure is filled with rocks, providing a natural and interesting environment for the elephant. The elephant appears to be enjoying its time in the enclosure, possibly exploring or interacting with the rocks."}, {"question_id": 508, "height": 640, "width": 480, "image": "000000163290.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [253.44, 285.55, 59.35, 229.48], "segmentation": {"size": [640, 480], "counts": "`hT59dc07J:V_OXOk=o0jAWOS>R1dAPOZ>]1UAiNi=MPAh1Q1`NU<]OkCOTOl2g0kMY<\\OdBNT13SOm2>PNf<WOhCn4W<TKhCl4W<ZKjBAd0U5a<dKRCZOKQ5P=iKTCWOKo4Q=kKTCVOKQ4N`LW=9SCSOGn3`0XLj<g0lBQONQ4<WLj<g0cB]O1n38ULT=T61M000XMoBaNQ=Z1XCkLIg0P=\\2bDYM^;h2cD_LoMc0_=k2nDoLS;Q3`BaL_22aM1`=b3SE[LP;f3bBoLL\\O`?Y3_@hM`?\\3O5KeKl@o3a0RL[=OYBX5\\=gJhBX5W=fJmBW5V=fJmBW5T=gJnBX5Q>WNVATNm>g0aARN1n0`>h0iBQOY=g0SCSOo<g0VCXOk<e0YCYOi<b0]CYOh<b0]CUOm<9gCA_`0N^TY3"}}, "object_label": "giraffe", "attribute_label": ["color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state, pattern, maturity, pose, texture", "answer": "The image features a giraffe standing in a fenced-in area, possibly a zoo enclosure. The giraffe is positioned near a wire fence, and it appears to be looking over the fence. The giraffe is standing on a dirt ground, which is typical for a zoo setting. The scene captures the giraffe's unique features, such as its long neck and legs, making it an interesting sight for visitors."}, {"question_id": 509, "height": 500, "width": 332, "image": "000000206135.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [232.28, 297.15, 68.59, 138.53], "segmentation": {"size": [500, 332], "counts": "cbb3b0m>:I5J5M7H6J5E:M3M4L4M5J6gC[MY;h2_D]Ma;[3000cNSDSOm;m0UDROj;o0YDmNg;T1nDVNR;j1QERNP;Q2X18G8I;XCdMb;W300O10000O1OTOhD^MX;n1`E`MSO7];[2_1003M00O1N3N1O24K7I1O10O000O010M4O06K3L4Mc0]O8IN2N1VN^D@d;6bEmN_:h0lEVOU:a0VF\\Ol9FYD0]25^9GTG6W<N3M2Nlf>"}}, "object_label": "cow", "attribute_label": ["color:brown", "color:white", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, pose, maturity, texture", "answer": "The image features a brown and white cow standing in a dirt lot. The cow is positioned in the center of the scene, with its back facing the camera. It appears to be a large cow, possibly a dairy cow, as it is standing next to a smaller cow. The dirt lot provides a natural environment for the cows, and they seem to be enjoying their time together."}, {"question_id": 510, "height": 427, "width": 640, "image": "000000209613.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [179.72, 246.99, 94.7, 63.85], "segmentation": {"size": [427, 640], "counts": "Pb\\23W=2N1O1O2O0O2N100O2O1N2O2M5K2N100000XObCc0^<]OcCb0]<^OdCa0\\<71O0001O01O1O00001O1O001OO100O0010O0100O1O0010O010O01000000000O10000O10000O10001N101N101O100O001O2N1O1O1O1O2N1O000O10000N3N100Ohkj4"}}, "object_label": "sheep", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, pattern, pose, color, state, texture", "answer": "The image features a group of sheep standing together in a grassy field. There are at least five sheep visible in the scene, with some of them appearing to be looking at the camera. The sheep are of various sizes, indicating a mix of ages and stages of development. They are all standing close to each other, forming a small herd. The field provides a natural and open environment for the sheep to graze and interact with one another."}, {"question_id": 511, "height": 427, "width": 640, "image": "000000209613.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [48.88, 273.68, 71.01, 104.21], "segmentation": {"size": [427, 640], "counts": "Xgd06S=3M3M2N2O2N1`C_OJ0W<b0jCLo;l0LYOSD5i;LWD7e;l0K2N101N100O2O00000bESN_9l1^FXNb9h1iESN7;o9d2O00O10OM4SOk0101O1O10[NlDS19bNZ:;_ER10kN`:6\\EQ11kNb:Y2000eM]E_2Q:`MTF]2l9a0000POaFTN_9k1eFQN]9m1Q10000O10000O101N101M2O2O00100>B0000[OTEiNn:Q1ZEjNh:R1l0N3L3M5Jk0TOUnh6"}}, "object_label": "sheep", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pattern, maturity, pose", "answer": "The image features a large, woolly sheep standing on a rocky hillside. The sheep has a black face and is wearing a pair of black socks. It appears to be looking at the camera, possibly posing for a picture. The sheep is standing on a rocky surface, surrounded by a few rocks, and is positioned in the middle of the scene."}, {"question_id": 512, "height": 427, "width": 640, "image": "000000209613.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [108.06, 247.49, 67.64, 95.78], "segmentation": {"size": [427, 640], "counts": "]\\_14V=3M2M3M2M4N001H_OeCa0\\<_OaCd0Y<[OjC2Lf0V<ZOmCT1i;lNWDX1e;hN[D\\1a;dN_D_1^;bNaD_1_;aN_Df1\\;6N2N101O0O001O1O0010O001O0O2O104K4N1OO01O1O1OO01YNaDa1g;M1N1K6O0O1O10O1000O101O2M`0^O7K6I`XS6"}}, "object_label": "sheep", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a group of sheep standing together on a rocky hillside. There are at least four sheep visible in the scene, with one of them being a black-faced sheep. The sheep are standing close to each other, possibly grazing or resting on the rocky terrain. The scene captures the natural environment of the sheep, showcasing their adaptability to different terrains."}, {"question_id": 513, "height": 427, "width": 640, "image": "000000209613.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [130.74, 182.29, 31.13, 34.68], "segmentation": {"size": [427, 640], "counts": "c\\f19P=3N1O1O2VCCc<d0O001O00001O1O001O0010O1O001O10O010O11O0O2OO_O`CK25^<OiC1V<LnC3f<00O2MXfV6"}}, "object_label": "dog", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a black and white dog lying on the ground, possibly in a dirt field or a muddy area. The dog appears to be relaxed and enjoying its time outdoors."}, {"question_id": 514, "height": 528, "width": 640, "image": "000000212559.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [585.26, 119.55, 54.74, 76.61], "segmentation": {"size": [528, 640], "counts": "[Y^99U1Ke=>TBDi=a0SBBi=c0TB^Ok=g0oA[OP>i0kAYOT>`1100N3L3104L3L6K1O1N10EoAXNP>c1a0L4H82M2O1O1O0010O00000000000000000O10000O2O000O10000101N002N1O01O00XAeN[>[1eAeN_:"}}, "object_label": "sheep", "attribute_label": ["color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state", "answer": "The image features a group of sheep standing together in a grassy field. There are at least four sheep visible in the scene, with one of them being a large sheep standing out from the rest. The other sheep are smaller and scattered around the large sheep, creating a sense of a herd. The sheep are all standing on a grassy field, which provides them with a natural environment to graze and interact with each other."}, {"question_id": 515, "height": 528, "width": 640, "image": "000000212559.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [276.47, 154.1, 87.79, 61.65], "segmentation": {"size": [528, 640], "counts": "o_^41Y`07K5N2N2O1N101N2N3N1O0O2O1O2N2M104L1O001N01O12N0O10O0010O0010O1O010000000O1O1O01000O1O1M300O0100000O01000O01O1O1N2O1O100O100O1O1000O1O1N2O100O1O1O1M4M2N3M2O110O1O6K0O2N1O2N2LeT^4"}}, "object_label": "sheep", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:sitting/sit", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, texture, pose, maturity, state, pattern", "answer": "The image features a group of sheep, with one of them standing out from the rest. The sheep are standing in a grassy area, and there is a wooden fence nearby. The sheep are of various sizes, with one large sheep standing in the foreground and the others scattered around it. The large sheep appears to be looking at the camera, while the others are grazing or standing in the background."}, {"question_id": 516, "height": 427, "width": 640, "image": "000000229997.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [220.17, 40.48, 97.53, 89.94], "segmentation": {"size": [427, 640], "counts": "_Vl22Y=0O2N1O1O3QCLb<f0I3L3N2N1O2O3L3N2N20O7I01N1O000O2O0O100O2O0O010\\DgNT;h10O2H7O100011YDaN^;f10I8N1O1O1N3N1O10001O0O2O0O2O00001O1N101O0010O01O10O01O001O10O01O0O2O001N2O001N2N1O2O001O1O001O001O010O0O2N1HUCNn<0YkW4"}}, "object_label": "bird", "attribute_label": ["color:black", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color", "answer": "The image features a large black bird standing in a grassy field. The bird appears to be a vulture, which is characterized by its long neck and sharp beak. It is standing on one leg, possibly resting or observing its surroundings. The bird is surrounded by a lush green field, which provides a natural habitat for it."}, {"question_id": 517, "height": 480, "width": 640, "image": "000000267191.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [0.0, 265.95, 235.91, 214.05], "segmentation": {"size": [480, 640], "counts": "gk15g>6D;H7K5]OROhBZ1U<Z1J6K5K5J6iNdLeFa3[9_LaFe3`9\\L\\Ff3d9ZL[Fg3]9WLSF2?h3f9XLZFh3g9WLZFh3_:0VOWL^F2WOb3Z:]LdF;TOg2X:nLiFOXOQ3d;N`0@BcMQD10]2o;bMoCg2Q<aMoCH1Z2];eMSE2AM9X2Q;RNfDF52f0h1^:PObEP1\\:ROeEm0Z:WOiDQOh0f1^:^ObEROWOW1W;I`EkN@NLW1S;4lDgN;3FM0U1S;<TEkNHi0S;?SEbNIJ3R1Q;f0SEWNf0O\\O0n:S2lDmM^<Y213_CeMY<b2N3J6N4K3oDnLP:W3j01ORM\\Dd2a;]M_Dd2_;`0N2M3M5L2N1aEYL@Ko9P4`FRLCMl9R4k01O3N0O4L2N2N3oE_K^9d4`F\\K_9f4=1N2N3N1N2N2N2O1N2M3N2N1O1O2O1N1O2N2O1N100O110O000O1N200O1001O00001O1O2N00O_KjFZ3Q9aKQGU1OY3o8mLPGT3P9^1O]KQGW3n8^10000OZKSG[3m8cLUG]3k8cLUG]3k8cLUG]3j8]100OSKUGg3k8W1O1O100O10mJYGm3f8SL\\Gl3c8Y100OdJ[G_4e8aK[G_4d8aK]G_4c8aK]G_4b8`K^Gb4a8^K`Gb4`8^K`Gb4_8[K`GYO1\\5_8ZKaGZOO]5_8XKbGn4]8nJgGS5Y8mJfGT5Z8iJiGW5V8iJjGX5V8gJjGZ5V8bJnG^5R8bJnG^5R8aJdGG7h5T8cJdGE7i5U8bJnG^5R8bJnG^5R8bJnG^5R8bJgGE0j5Z8`JeGG1i5Z8`JeGG1i5Z8`JdGH3g5Z8`JcGI3g5Z8`JcGI3g5Z8`JcGI3g5Z8`JbGK3e5\\8_JaGM1e5^8^J`GN2d5_8eJbGZ5^8fJbGZ5^8fJbGZ5^8fJbGZ5_8dJbG\\5_8cJbG\\5^8cJcGd1Jh1c8cLdGa11h1\\8eLeG^1;e1P8mLeG[1`0dNXOh2c8YMfGX1c0dNVOj2b8ZMeGU1f0eNTOl2a8[MdGR1Q1c1\\7[McGo0S1f1Z7[MdGl0T1i1Y7ZMcGl0T1k1Z7XMcGk0U1l1Y7YMaGh0Y1o1V7VMWGM;g0_1U2P7YMaG`0a1W2o6WMcG=a1\\2l6UMfG<c0EnN0?j2[8SMgG8d04XOb2b:`M]E`2`:eM^E[2b:hMTE[O1m2g:U1N4NI^ESLY:T4gEmKU:U4mElKP:U4PFlKo9T4PFiKK0T:W4nElK0LS:X4lEmKOLW:U4iEVLV:T4jEaKY:\\4_OaKnFk3ZOfLb:R4J0001N1O1O2N00QOfK`FMf0Y4k8lK]FMh0V4l8lK\\FNi0V4l8jK[F0k0U4m8kKTGT4l8lKUGS4l8lKUGS4n9N2NZOPLkE1;o3f9_LWF_3k9`LjED9i3Y:ULnEj3f:N2N3M2N1O4L2N5K4L3LY2hMhkm5"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "texture, maturity", "answer": "The image features a large elephant with a man riding on its back. The man is sitting on a bench or a chair, which is placed on the elephant's back. The elephant is walking through a forest, surrounded by trees. The scene captures the unique experience of riding an elephant and the connection between humans and these majestic animals."}, {"question_id": 518, "height": 480, "width": 640, "image": "000000267434.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [401.5, 203.86, 92.02, 150.79], "segmentation": {"size": [480, 640], "counts": "\\el5<b>7J3M;E5K3M4fBdNk0:\\:U2lDnMS;P3OFcDSM\\;n2cDSM];f1bDoN6TOJ7^;f1cD`N^<`1`010100O001O00100UCoMd<^2CeMfCh2m;b0C7J1N2O1SEZL^:U4O00000001N100ULXEm26PMd:2UEl2^;83WOjDeMY;Y2i0M1011M2N2O2M2O3M8IM210000000O1O10O2Ob0_O6I9G=D1N10O10000O1^NbFaMa9X2fFdM[9OaEKNd1_1^NQ92oES1T<nNQDg0U<ROTC2l0e0R<ZORC1T16P<JlB0d>0]AOc>1]AOc>0^A0a>2]AOc>1]AOc>61O101N1O1O3LXdU2"}}, "object_label": "cow", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color, pattern, pose, state", "answer": "The image features a group of cows standing in a grassy field. One of the cows is wearing a hat, which is quite unusual for cows. The cow with the hat is standing in the foreground, while the other cows are positioned behind it. The cows are all facing the same direction, possibly looking at something or someone. The scene captures the unique and playful aspect of the cow wearing a hat."}, {"question_id": 519, "height": 424, "width": 640, "image": "000000268375.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [155.91, 82.71, 264.29, 257.63], "segmentation": {"size": [424, 640], "counts": "e[R22T=8I?A7J<D:UE@QOmNT9d1eGLX85eGNZ83cGO\\85_GMa87YGKg88TGIl8;PGFP9Y20O0O2N2O1O1O10OO200N101O1O1000O010O10O100O010O10000O1000O1000000O01000000000O0100000O010000O10O01000000000000O100000hI[Lm2e3UMYLk2f3VM\\Lh2d3^300OiI[Lm2e3RM\\Ln2d3RM\\LWM0U5d3m3000001O00000O1000000O2O000000001O000000000000001O000001O0000000000001O0001O000001O000000001O00001N101O001O001N101O000O2O0O\\MhF[1W9[101N101O1O0O2O0O2N2N2N2N1O2N2N2O1N2O0O3N1O1L4N4M2N3M1O3M4L2N6J8Hb0^O6J:mIWIS5R7cJRINGW5Q4oJkNJcMW5Y3ZKFf47dKB\\4;iKCW4<lKBT4=ULgNdNYNV5o2ZLeN`NVN0GV5^3`LnNZNdMV5]3jLfNPNmMV5]3lLdNoMnMU5^3UM[NgMVNT5^3XM`Nh2_1aMYN_2g1bMXN^2h1eMUN[2k1eMPNWMbNT5^3eMoMYMbNR5a3`MeL[MQ1\\5Z2XMfL]MI4a0LH[5X3XMfL]MK3?LH\\5W3TMaLaM60L2O08NM[5X3[MgLQNOYO1\\5X3cLmL]OHeN5W5V3eLnLBFeN2T5Z3dLgLLMXNN03X5\\3cLfLMNVNN21Z5\\3bLbL;0U3^3[40^FbLY9^3fFbL[9^3dFbL]9^3`FdLW1On6b3cH]L^O8m7^3nG\\L40K413U8m3jGPL12W8l3iGmK64U8T4kGjKX8V4>O0105K02OO2M10O1014L3[G[K\\8h41O3N2NcG\\KY8`4dGcKd7MSIc4l6^KXI]4WOcKZ70aI[4TOiKX7LjIV4nNoKV7JQJj3gN[L30g8`3VG`L1KO3n8^3RGcL1M10o8^3nFfL1M1OV9Y3gFRM1I:Me8k3PG[Lb97bF`2o:]NmDXOY;Y17I4L4J5L3L4M6J7H5K\\Ym2"}}, "object_label": "elephant", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "pattern, texture, maturity, pose, color, state", "answer": "The image features a group of elephants, including a baby elephant, standing together in a dirt field. The elephants are of various sizes, with one being a baby elephant and the others being adult elephants. They are standing close to each other, possibly in a line, and appear to be enjoying their time together. The scene is set in a natural environment, with trees in the background and a fence nearby."}, {"question_id": 520, "height": 480, "width": 640, "image": "000000268729.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [330.58, 303.92, 258.95, 171.55], "segmentation": {"size": [480, 640], "counts": "jeX5i05C_=S1L2[NbNdEb1S:SO^EP1\\:WO_El0]:[O]Ef0b:\\OZEh0e:[OTEOOWOl:m0TEEl;f11N201N1O10001O0O2O02O8G4M2M3N1O2M5L2N2N1N2O4LIhDgLW;f2oDZM11m:b2bEaM]:[2fEgMY:V2kEjMT:S2^1LSEeM]9W2h1J502K4O1N2O1001O1O1O1O011N1O001O001O00001O001O000010O01O00001O0001O00000000001O00000001OO1000000000001O0000000O011O0O0100O10O1000`DTNk9m1PFYNo9f1bEjN^:V1_ElNb:S1[EPOf:P1UESOm:m0QETOP;l0jDYOW;g0gDXO[;j0dDPNLm0e;T1^DmNe;U22N2J6N1N2N3O0O2O11O5J9H4L9G3L7J?A2N1N2O1N4M00`NgESMa0<g9X2XG[Mi8_2^G`Ma8^2R2L4N2O1O001O2M101N2N2O1N2N2N101O1O1O100O100O1O1O100O010O1O00100O00100O1O1O010O100O01000O01000001N2O1O1O1O001O00010O001O10O01000O10OeNhBo0W=POlBn0S=SOnBm0Q=RORCl0k<VOWCj0h<UOZCj0f<TO]Cm0]=N4L1O1N2N1O2O0N3N1N3M3L4Mi_h0"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture, pose, maturity", "answer": "The image features a group of zebras standing together in a dirt area. There are three zebras in total, with one zebra standing in the foreground and the other two zebras positioned behind it. The zebras are standing close to each other, possibly forming a small herd. The zebras are facing different directions, with one zebra looking to the left, another looking to the right, and the third one looking straight ahead."}, {"question_id": 521, "height": 480, "width": 640, "image": "000000268729.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "maturity, pattern, pose, state, texture", "region_anno": {"bbox": [273.11, 112.2, 45.7, 169.47], "segmentation": {"size": [480, 640], "counts": "ebQ43d>b0@;J5K5L4L4K9Hi0oB`MQ<i2N2N1N02O0000O2SNQMaF3?m2P9QM^F5?k2T9SMXF3d0k2T9UMRF3h0j2U9dMjF]2T9fMhF^2X9aMfFa2[9_M[Fk2e9TMVFR3k9Q11O000000O0O20QLeFX2^9]MPG^2R9XMYGd2l8UMWGm1kN_Nf;\\1bDXNi;`1S1F:E9GVhf4"}}, "object_label": "giraffe", "attribute_label": ["maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, state, texture, pose", "answer": "The image features a giraffe standing next to a zebra in a zoo enclosure. The giraffe is positioned on the left side of the image, while the zebra is on the right side. The giraffe is looking up, possibly observing the zebra or something else in the enclosure. The scene captures the unique interaction between these two different species in a shared environment."}, {"question_id": 522, "height": 424, "width": 640, "image": "000000321887.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [0.0, 44.68, 486.0, 374.76], "segmentation": {"size": [424, 640], "counts": "`3f9b3000010O1O2M200O1O1O2N00001O001O001O0000000000000000000000000O20O0001N2O1O1O3M1O0000001O0000O2O00000O011N100O100O1000000O10000N2N200O1O1O1O1N2N2O1O1O1O1O1O1O1N20000O100O10000O10000000000O100O10000O10O1001N100O1O100O100O1000000O10000O10000O100O1O10000O1000O10000000O10000000000O1000000000001O00000O10O1001O000000000000O0100001O0000000O001L4M3EUMXFl2j981NO2K5K4L5O1O1N1O2N10010O01O100O1O2N10O1O00001O0O011M2O110O01OO1N2O2O00100O10000000001O0000000O100000O10O10O100O100O1O1O1O0000010O10mLPLnLP4P3TLmLl3T3TLkLm3U3SLkLl3V3RLlLn3T3PLmLQ4U60O1O1O001N2N3N100O1O0010O1N2M300000O10000O2O001N100O010000O0100001OO100O10000000O100000O1O2N10001O2M2O0010OO2O1N2O4K101N10001O1N5K2O0O1O1O1O1O2O0O0K6M21O001N1O20O10O0100O1O2O001N101O0O2O001N100000001O00001OO10000O1O10000O1000000001O001O1O1O1O2N1O1O1O2N001O1O1O5K1O1O1O1O1O1mJYIc3g6\\L\\Ib3d6]L^Ic3a6[LbId3^6[LdId3]6YLfIg3Z6dKaIH8c4Y6bKbIH6f4Y6_K\\J`4W700O101N101O0O100O1O100O011N100O1O100O1O100O1O1O1O2N100O1O1O1O1O1O1O2N1O2N1O1O1O1O1O2N1O1N2O1O1O2N1N2O2N1N2O1N2O1O2M2O0O2O1N2N2O0O2N2N3M2N1N3N2L5K4M3N2O1N2O1N1O2N2N2M3N2N2N2M4G9L3M3N3L6H[[P2"}}, "object_label": "sheep", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pose, pattern, color, state, maturity", "answer": "The image features a large, fluffy white sheep with a thick coat of wool. It is standing in a room, possibly a museum, and appears to be looking at the camera. The sheep is positioned in the center of the scene, and its woolly appearance makes it stand out."}, {"question_id": 523, "height": 428, "width": 640, "image": "000000360325.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [188.69, 42.34, 132.54, 85.6], "segmentation": {"size": [428, 640], "counts": "dR_25U=4L3N4K3O0O2O0O1000001N100O100O010O5hCSOi;Y1O1O0O101N2M2H9M2O2N1O1O100O100ON3M3O1O1O1N101N101O0000001O01O01O1N2O001O010O2O5J2N1O2O1N101O0O2O0O100O2O000O2O001O1N2O1O0_O^C8b<FaC9k<N2M3N2LWm20kRM1O10O1OX_c4"}}, "object_label": "sheep", "attribute_label": ["color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, pose, color, pattern, state, texture", "answer": "The image features a large herd of sheep standing together in a group. The sheep are of various sizes and colors, with some appearing to be white and others black. They are all gathered in a pen, possibly on a farm or in a rural setting. The sheep are standing close to each other, creating a sense of unity and togetherness within the herd."}, {"question_id": 524, "height": 428, "width": 640, "image": "000000360325.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [336.84, 112.28, 114.51, 95.61], "segmentation": {"size": [428, 640], "counts": "XaZ45V=1N2O1N2N2N2O1O1N2N2N2N101N2O100000O2O000010O001O000000001N100O100O1N2N2N2O1M3L4]Oc0L4K5M4M2O1N2N2N2N2N1O2O1O1N200O10000000000001N100O1N2O101N100000000O2I[EdMf:[26O1O2N1O1N2O1N2N2N2N2N3M2N2N3N1N2J6M3O1O2NJlNVDR1l;nNTDQ1m;oNSDP1n;POSDn0n;RORDm0o;SOQDk0Q<UOoCj0R<WOmCi0S<XOlCg0U<YOkCg0U<XOlCg0U<YOkCf0V<[OjCb0Y<^OfCa0[<_OeCa0\\<]OeCb0\\<^OdCb0\\<^OdCa0]<@bC?g<O0M4N1O1O1O2O0O1NMNPC1\\n[2"}}, "object_label": "sheep", "attribute_label": ["color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, pose, color, pattern, state, texture", "answer": "The image features a group of sheep, with one of them looking directly at the camera. The sheep are standing close to each other, creating a sense of togetherness. The sheep in the foreground is looking at the camera, while the others are looking away. The sheep are of various sizes, indicating a mix of ages and stages of development. The scene captures the essence of a herd of sheep, showcasing their social nature and the bond they share."}, {"question_id": 525, "height": 428, "width": 640, "image": "000000360325.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [138.36, 192.32, 320.08, 235.68], "segmentation": {"size": [428, 640], "counts": "ooi1<m<4L4H9aCTOn;`1I9F<E4L7I5J;E6F7N3M3M3M3N2N2N9F6K3N2M3M7^GWKT8R5N1O1O2M2O1O1O100O1N2O10O01O2N1O1O1O1O1N101O2N1N2O1N2O1O1O1O1O1O1O1N2O1O1O1O1O100N2O1O1O100O100O1N2O100O1O1O1O1O100O1O1O10000O1000000000000000000O1O1K5001O000000001O001O0000000000000000O100O10000001O0^LnIJR6h31O00000000O100O100O10000000000O1000000001O1O000000000000001O0000O100000000001O00001O00001O001O0000001O001O001O00001O00001O001O1O1O00001O001O0000000000000O1000O1O100000N2M2O2N2O1O1O1O1O1O1TJVIV5j6jJUIV5k6e01N2O1N2K5M4N1O1L4O1O100O100O1O2N1M3O1L4N1O2kNmGPMT8P3mGnLT8R3kGnLV8P3kGmLY8S3gGjL\\8V3dGeLa8[3^GdLd8\\3\\G[Lm8P420000O100O01000000001O001O001O1O010O1N2O1O1O1O100O100O2O0O1JbF[La9Y3_FlLh9S3WFnLi9[313NL2O01000FVFoLl9h2UFUM4Oh9k2VFTM31g9j0ZFm0JZN4Oi9h0]Fc0EQO4Dj9g0bF`0@UO4Dk9f0cF>@QONM4Nk9d0gF>\\OSONL5Ok9a0jF?WO[O2Gn9:oFc0PO\\O3ENNP:7WGg0iN_O2DO0Q:OZGm0eNXO1L62Y;?^DE<JM2Z;>]DF3NOM70\\;=[DH20NM8L`;>XDI27OCo;:PDL170DP<8oCM1N10OMS<5lC10L32MLV<c0nC@LMW<2iC42J32KNX<1mCO70F1V<NcD2h;MPD2o;OmC0B1a<0cC1N0c<2ZC21Le<;[CEm<OSCOVU\\2"}}, "object_label": "sheep", "attribute_label": ["color:white", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, state, pose, texture", "answer": "The image features a group of sheep standing together in a field. One of the sheep is particularly noticeable, as it has a unique appearance with a combination of black and white fur. This sheep stands out from the rest of the herd, which consists of other sheep with various shades of black and white fur. The sheep are all gathered together, forming a small herd in the field."}, {"question_id": 526, "height": 360, "width": 640, "image": "000000559099.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [171.63, 163.94, 40.19, 26.68], "segmentation": {"size": [360, 640], "counts": "Zdl13P;6N1000003^EDS:i0O00K4M400O12N6J1OG:L4O02N1O0000000000O100O1O1O11O1O1O8H1O@cE4_:IR\\g4"}}, "object_label": "cow", "attribute_label": ["color:black", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, maturity, color, pose", "answer": "The image features a large black cow standing in a grassy field. The cow is positioned in the center of the scene, with its head slightly tilted to the left. The cow appears to be walking or standing still in the field, surrounded by a lush green environment."}, {"question_id": 527, "height": 360, "width": 640, "image": "000000559099.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [273.83, 165.89, 27.42, 32.49], "segmentation": {"size": [360, 640], "counts": "ekP32U;2O1M6L1N1L4L3L21M400103`E[OV:m0OGnE[OS:c0:O02O9GO1G90000100^E^O]:h0^Pg3"}}, "object_label": "cow", "attribute_label": ["color:black", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a black cow standing in a grassy field. The cow is positioned in the center of the scene, with its head slightly turned to the left. The cow appears to be looking at something, possibly a person or another animal. The field is lush and green, providing a natural environment for the cow to graze and roam."}, {"question_id": 528, "height": 453, "width": 640, "image": "000000575357.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [247.56, 159.86, 366.49, 199.85], "segmentation": {"size": [453, 640], "counts": "lS`38k=4N1N2N1O101N1O101N101eB\\OR=m0N2O0O2O001N1O1O1N2L4O1N2O1O00100O00100O00100N2N1N3O1O10000000001O0000000000001N101O1O1O1O1O1O0000O01000000O10001O001O1O001N2O2N1O1O2N1O2N6K20N1O4K4M0O0100cEgMl8Z2PGjMP9V2mFmMS9U2hFmMX9T2eFnM[9U2`FmMa9T2[FmMf9T2YFlMh9U2TFmMl9T2RFmMn9U2oElMP:T310N11O100O1O2N1O2N1O1102MWLgEh3[:1O0O100O10O10N1O2N100011N0001O01O1O2O1N000001O0001O000O2O00000O2O000O100ZObEeM^:Z2dEdM]:\\2cEcM_:\\2bEcM^:]2bEbM`:]2aEbM`:]2bE`M_:a2`E^Mb:a2_E]Mc:b2^E\\Mc:d2^EYMd:g2>O0001N11O010O10O0100O1O100O1O1O1O1O10O01N10002N1O001N1000000O2O00000001O000O20O00010O0001O0000000001O0O10O0100O100000O100O1000001O001O1O1O1O1O1O10O01O1O001O001O1O1O1O1O1O010O001O1O001N2N2O1O1N2O1O001N2O1O001O0O101M2J7M2O1O101N1O1O1O2N1N2N3K4N2O2N1O1O1ObMaF8_9HbF7]9JdF5[9LfF3h8oM[Go1N1g8`0YG@g8`0YG@g89UGbM6T2e88YGaM3W2e82TGhM`0U2\\82VGgM`0V2Z84UGgM`0U2[89eGF[84lGKT81UGkM:21P2`82dGmMNo1^8K`H3`7LcH1_7NbH1^7KRG\\Nb1i1[7JUG\\Na13`N`1i81UG\\Nk1e1m61UI0j60VI0k6OVI1i6NXI3g6K[I4f6J\\I6e6FWGeNT2d1g6HZI6m6DUI:l6dNQGf0U2d0l6bNTGg0R2e0[7VOhHg0[7WOeHk0Y7TOhHk0[7QOfHo0^7kNeHT1V:01O1_OUCFk<:UCFl<i00@WCAm<>WCZOm<f09001O01O01O001O2O1N101N2O1O0O5L2ON1O2M3N1O2M3N2N2N3M1O9BYg:"}}, "object_label": "dog", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pattern, maturity, pose, color, state", "answer": "The image features a large, brown dog running through a grassy field, possibly a farm or a pasture. The dog appears to be energetic and enjoying its time outdoors. It is wearing a collar, which suggests that it might be a pet or a working dog. The dog is running towards a wire fence, possibly indicating that it is chasing something or exploring its surroundings. The scene captures the dog's playful and active nature."}, {"question_id": 529, "height": 425, "width": 640, "image": "000000273232.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [39.84, 41.49, 34.85, 22.58], "segmentation": {"size": [425, 640], "counts": "bW`06P=5M3M2N2N1O010ON3N101O1O1O1O100O1O1O10001N101O0010O0100001O2N1O2N11M3MT^Z7"}}, "object_label": "kite", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "texture, pattern, transparency", "answer": "The image features a large, colorful kite flying high in the sky. The kite is shaped like a parachute and has a distinctive orange and white color scheme. It appears to be a sunny day, as the kite is soaring through the clear blue sky. The kite's design and vibrant colors make it an eye-catching sight in the sky."}, {"question_id": 530, "height": 480, "width": 640, "image": "000000314251.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [147.2, 331.4, 41.6, 65.82], "segmentation": {"size": [480, 640], "counts": "ebW23j>4hALF<R=LVCIE?R=3PC]OLb0S=5UC[OJ6P=`0VCZOK6n<`0XCXOK<h<<^CXOJ=f<<jCET<<lCDT<<lCDS<=nCBQ<?nCBQ<>gCSOF`0d<=eCGC\\Oj<m0bCEc<;^CDc<<\\C@j<?VCXOS=i0lBVOT=k0lBUOT=k0lBTOT=m0jBVOU=l0fBYOLGX=Q1iB]OY=P16N2jN`Bg0c=WO^Bf0e=WO^Bg0e=VO]Bd0S>N1I8M3Looc6"}}, "object_label": "motorcycle", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size, pattern, color, pose, material, texture", "answer": "The image features a man riding a motorcycle down a street. The motorcycle is a moped, which is a type of motorcycle designed for short-distance travel and urban environments. The man is sitting on the moped, and it appears to be a two-wheeled vehicle. The street is busy, with other vehicles such as cars and a truck visible in the background. The scene captures the man navigating through the traffic on his moped."}, {"question_id": 531, "height": 480, "width": 640, "image": "000000326627.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [290.78, 397.44, 54.19, 39.78], "segmentation": {"size": [480, 640], "counts": "VYY47e>;F3M300O1O1N10N20O2O1N2O2N100O2O00000000O10000000O100000000000001O1O001O000000N2M3O2O1O1100OO2N4L4K5JQ[Z4"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, texture, color, pattern, transparency, size, material", "answer": "The image features a silver car parked on the side of a street. The car is positioned next to a red fire hydrant, which is located on the left side of the car. The car is parked in front of a building, and there is another car parked behind it. The scene also includes a traffic light, which is visible in the background, and a person standing near the right side of the image."}, {"question_id": 532, "height": 427, "width": 640, "image": "000000563702.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [268.67, 168.72, 345.44, 148.73], "segmentation": {"size": [427, 640], "counts": "kj[31mb41U]K6S<o0^OlN^Db1a;4O3N5K001O1O1O000OQNkDj1U;VNkDj1U;7N01OGRNWEn1h:;M20O0100O3N2O0O01000O10O001O1001OO1O001O1O1I7[O\\EZNm:e1=O1O1O1O1O1O1000O10001O0O10MZDaNf;^1[DbNn02c9\\1_EbNm03d9\\1^EaNm05d9Z1^EcNl06d9[1YFkNc9V1\\FlNc9U1\\FlNc9T1iEfN46S:f1kE[NK_OU:Y2mE]NR:_2OQOnEbNOYOR:U2oEaN1YOP:V2nEaNX:Y2000000O10O100000010O000000O1N200O1000001O0000001O00000000000O1000000000001O002M^MSFi1l9WNTFi1l9WNTFi1k9XNUFi1j9WNVFi1j9k01O02O001O1O1O2N1O0OWM]Fn1a9RN_Fo1`9QN`Fo1`9QN`Fo1`9o0O0O100000000000000000000000000000000000O01000N2O1O10O0100001O2N2N001O0O1000001O00000000000O100O101OO1000O10000000000000O10O10O1000ON3000gFQLV9R4000MjFQLV9o3300000O1000000000000000001O0O10000001N10001O1O1O00010O00000000O0100000000O100O1O2N100O2O2N0O101N3M2O1O00001N2NSFkLg9U3WFlLk9X32K6oMPFkN20KY1W:I\\F5d9K\\F5e9ROgE<d0b0f9POjE;`0e0T:[OlEe0U:[O[E^O8W1]:[O[E^O8W1]:[O[E^O8:D?k:GiEf0^:SOcEk0_:TOaEl0`:SOaEl0_:SObE1[OJNb0U;CbE2ZOIOb0\\:\\O[F70m0d9oNZF24o0b9nN[F25n0[:ROfEl0b9QOXF3CL8k0a9AoEIc02AM0M13N5S:?iEYO7104L:0D1OY:h0VFYOA<OEN5W:a0fF=W9EiF]OSOd0P:5oEPO00c00Am0j9=nFhNVOh0f9DXF9l0\\OUOg0h9CWFK3JMNg0OZO40h0g9SOXFi03[OMNa0?_O<k9LWF\\ON<1JOi0l9CWF]OO<NL1h0j9CYF\\ON=NL2g0i9XOUFM?NAO251h0d9mNZFh05YO03Mk1b9mN_FXO9l1V9WOjFi0W9mN^FXO;k1W9lN`FXO:k1V9hNfF[O4n1V9fNgF\\O3n1V9`N]FA<O3o1U9_N`Ga1`8^NaGb1_8^NaGb1`8\\N_F2>b1U9XN_F73h1a9nMgF0GS2c9kMjFNDW2h:0001WNQET1Q;jNmDX1X;dNgD\\1[;90O2O0000000O100000000O1000000N2M4M30001VObDCf<02FmB3gj03\\B10O13MO1N3M3Mff9"}}, "object_label": "truck", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, transparency, texture, cleanliness, color, pattern, material", "answer": "The image features a large red fire truck parked on a street, with a hose connected to it. The fire truck is positioned in front of a building, and there are several people around it, possibly firefighters or bystanders. The fire truck is equipped with a ladder, which is extended and ready for use. The scene suggests that the fire truck is responding to an emergency or conducting a training exercise."}, {"question_id": 533, "height": 640, "width": 478, "image": "000000017379.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [145.26, 214.29, 165.39, 107.87], "segmentation": {"size": [640, 478], "counts": "lZm2=cc06h\\OBbb0U1U]OVO21N4e`0e2O0001O00000O100000000000000000000000000000000O10010O0000000000000O1O11O0000000000000000000000000000O100000001O00000000000000000000000000000000000000000O10001O0000000000000000000000000000000000000O10000000000000000O100000001O00000000000O100000000001O0000O1000000000000000000000000000000000000O2O00000000000000odZ3"}}, "object_label": "tv", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a large flat-screen TV mounted on the wall in a bathroom. The TV is displaying a football game, with two teams playing against each other. The players are wearing their uniforms, and the game is in progress. The TV is positioned in the upper part of the bathroom, making it a focal point for the space."}, {"question_id": 534, "height": 500, "width": 375, "image": "000000025096.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [27.84, 280.68, 78.84, 40.46], "segmentation": {"size": [500, 375], "counts": "PXf02b?1N3M4L3N1O2N2N1N2O2N2N1O2N1O1O1O2N100O2N101N0000000001O0000000O10001O000O2O000O2O000O2O1N101O1N101N2O0O2N2N101N2N3L5J^aS4"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "material, pose, texture, transparency, cleanliness", "answer": "The bowl in the image is white and made of ceramic. It is placed on a wooden table, and a person is using a knife to cut it. The person is cutting the bowl in half, possibly to use it for a specific purpose or to serve food. The knife is positioned on the table, and the person's hand is holding it, guiding the cutting process."}, {"question_id": 535, "height": 500, "width": 375, "image": "000000025096.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, material, pattern, pose, state, texture", "region_anno": {"bbox": [224.14, 471.05, 50.03, 28.95], "segmentation": {"size": [500, 375], "counts": "ck]31b?1O1OO110O01O1O4M0O1O1O1O01O01O001DE]A<d>E[A;e>FXA;i>FUA;k>70000000000000001O001O@UA:h>D\\A:f>C[A=o>O1O1O00001O001O001O001O0O2N3LT[`1"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "pattern:striped/lined/pinstriped", "pose:horizontal/lying", "state:dry", "texture:smooth/sleek"], "control_dims": "state, color, material, texture, pose, pattern", "answer": "The image features a zebra with its back facing the viewer. The zebra is depicted in a stylized manner, giving it a unique and artistic appearance. The zebra's body is covered in a pattern of stripes, which are a distinctive characteristic of the animal. The zebra's back is prominently displayed, showcasing its unique stripe pattern."}, {"question_id": 536, "height": 449, "width": 640, "image": "000000030213.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [21.24, 193.15, 154.72, 113.26], "segmentation": {"size": [449, 640], "counts": "h_<5g=;[BA[=e0fBCl<m0L<D6J1Nc0^O1O4L2N1O001O1O0O2O000000000O100000O10000O1mMgD^1Y;bNgD^1Y;bNgD^1X;e01O1000000O01000000O010000O100O100000O10O100000O01000000000O010000O100O1000G_MQEe1KUOT;VOQEa2X;0O10O100000000O1000O01O100O02O0000000O1000000000O10000O1000O100000O1000O010000O100O1000O10O010000O0100O100O100000IdMiD[2X;fMgDZ2Y;fMgDY2`;10VO`DSO`;l0bDSO^;l0eDRO[;n0fDPO[;o0fDQO[;n0fDQOZ;n0gDROY;n0hDQO];j0dDTOj;FhCd0c0@Y<1YP]6"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:green", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color, transparency, cleanliness, texture, pose", "answer": "The oven in the image is white and is placed on a table. It is an old-fashioned, vintage-style oven, which adds a nostalgic touch to the scene."}, {"question_id": 537, "height": 449, "width": 640, "image": "000000030213.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [160.52, 218.1, 250.56, 230.9], "segmentation": {"size": [449, 640], "counts": "hbX27j=000O003N1O1N2O1Oe0[Oc0]O3M`0@=C<D`0@>B`0A11M1N1O2ROnFiLT9U3n0hMbEi0`:VOUF4m9L]FJd95fF@[9a0R200001O0000001O00001O00001O001N101O1O00000O2O001O00001N10kN`Ci0`<VObCj0^<ROfC0Ke0l<[OTCf0l<YOUCf0k<ZOUCf0k<ZOVCe0k<[OSCg0l<YOSCi0l<WOTCj0k<6000POUCj0j<WOWCh0g<ZOZCd0h<[OXCg0g<YOYCf0g<[OWCf0h<;O01O01O001O001O00001OoN]Cd0c<]O]Cb0c<_O\\Cb0c<>oNfN\\EZ1b:gN^EY1c:fN\\E`1WO^N04h:NQF`1SOWOb:XO[Fa1SOYO`;f0cDYONWOZ;_1jD]OV;d0hD]O_:ROUFb1[O]O_:QOUFc1]O[OS;h0nDWOR;i0QESO\\:WOoEf1GPO[:\\OlEe0A5`0]OX:HhEe1i;ZNfCc1]<O010O2`NaC10U1h<O001O0mNWCo0i<POWCP1i<5O00lNXCo0h<POYCP1g<6OmNYCl0g<TOYCM1k0e<]OZCc0e<^O\\Ca0]<VOcC[1o;eNXDa1g;`NYDa1f;_NZDa1f;^N[Db1e;]N\\Dd1\\;\\N]D18b1[;_N[DO:b1Z;`N\\DN:b1Z;eNfD\\1Y;dNgD\\1\\;`NfDa1Y;^NgD]2^:cMbEV3e9jL\\Fj3o8ULRGc4W8[KkG_5n7cMgGSOX8h0RHSOn7k0WHROi7l0ZHSOf7l0_HPOa7o0aHPO`7m0eHPO[7o0hHoNd6_NeHa2k0mN`6cNeH^2l0oN_6cNeH^2m0nN^6dNeH]2n0oN]6dNeH]2n0oN^6cNdH]2Q1nN[6eNeHZ16jNP1T1U6hNeHX1X2gNWMT1m7mNdHX1W3nNV4JcHX1_;hNaDX1`;gN`DY1b:gNhE0EY1d:gNgE0EY1d:gNgE0EY1b;gN^DX1c;iN\\DV1e;jN[D6Be0U<SOYD7Ce0V<TOXD5Bg0e<[O[Ce0e<\\OZCd0f<]OYCd0f<]OZCc0f<]O[Cb0Y<TOPD:Ga0\\;VO]E2]O8K>\\;XOkD052I8K=i;XOdD4G6M>Z<[OhC8M=\\<[OgC7M?j;XOcD2E8N=k;YObD2D9O<k;YObD2D80=j;YObDb0E3j;\\OaD`0D5k;]O_DY1b;hN]DX1d;gN]D:D=o;XO^D;CDOd0Q<]O]D;B<R<YO\\DW1e;hN[DW1f;hN[DX1f;gNZDY1f;gNYDY1h;gNWDY1j;hNUDW1l;iNTDV1m;jNSDV1m;jNRDV1o;jNQDV1o;kNPDU1P<jNQDU1P<kNoCV1Q<jNoCV1R<iNlCX1^<10O100O1TOXC>i<BXC=h<BYC>g<BYC>:XOn;;hC>0GNG2J];OdD=Md1Z;f0N001OO101O0000000kMgDb1Y;\\NiDc1X;]NjDEL23K90F0R<=]100O101N1O100O2N2O001O0O1OamU3"}}, "object_label": "dining table", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, cleanliness, color", "answer": "The dining table in the image is a small, white, and wooden table with a floral pattern. It is set up with various items, including a bowl, a bucket, and a couple of bottles. The table is surrounded by chairs, with one chair on the left side and another on the right side. The table appears to be in a kitchen setting, possibly in a museum or a display."}, {"question_id": 538, "height": 449, "width": 640, "image": "000000030213.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [280.75, 181.48, 30.57, 55.68], "segmentation": {"size": [449, 640], "counts": "Qkk3i0V=3N2M2G:^CgNY<[1fCfNY<Z1fChNX<Y1hCgNX<Y1hCgNX<Y1hCgNX<Z1fChNY<X1gChNY<W1hCiNX<V1iCiNX<V1jCiNV<V1mChNS<X1:0101O000O10001N3kNZCk0P=N2N3LQR`4"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:empty", "texture:smooth/sleek"], "control_dims": "length, state, material, texture, cleanliness, transparency", "answer": "The image features a clear glass jar or bottle, which is placed on a table. The jar is filled with a liquid, possibly water or another type of liquid, and it appears to be empty. The jar is sitting on a table next to a bowl, and there is a spoon nearby. The scene suggests that the jar might be used for serving the liquid or for holding the spoon."}, {"question_id": 539, "height": 333, "width": 500, "image": "000000040083.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [156.55, 281.1, 23.36, 21.63], "segmentation": {"size": [333, 500], "counts": "Xfb15X:0M3I7O2N100O0100000O1O10O1000000000001O0O3HTFJP:0eSX3"}}, "object_label": "bottle", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "state:cracked", "texture:rough"], "control_dims": "cleanliness, color, texture, pose, material, state, transparency", "answer": "The image features a close-up of a bottle, possibly a wine bottle, with a cork in it. The bottle is placed on a table, and the cork is visible in the middle of the bottle. The bottle appears to be empty, and the cork is the only remaining item inside the bottle."}, {"question_id": 540, "height": 640, "width": 427, "image": "000000040471.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [0.6, 342.38, 74.66, 22.62], "segmentation": {"size": [640, 427], "counts": "h:f0Zc00000000000O100000O10001O0001N010001O0000000000000000000000000000000000000000000000000001O00O10000001O0000000O1001O0000000000000000O100O1O1O1O1N3N1N3M3N2MVii6"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, transparency, state, material", "answer": "The sink in the image is a small, white sink located in a bathroom. It is positioned under a mirror, which is mounted on the wall above the sink. The sink appears to be clean and ready for use."}, {"question_id": 541, "height": 426, "width": 640, "image": "000000041872.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [178.32, 139.08, 46.24, 56.35], "segmentation": {"size": [426, 640], "counts": "gVZ27n<:H7I5M2M4L3N3M1O2N3N0O2N101N101O0O10001O0000000000O101O0O10001O0O2N2N1O3M2O1M3N3M2M5K4L6HTm\\5"}}, "object_label": "clock", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, cleanliness, transparency, color, texture, material", "answer": "The image features a round clock with a black face, prominently displayed on a wall. The clock is positioned at the top of the wall, making it easily visible. The clock's hands are pointing to the numbers 12 and 1, indicating that it is almost 12 o'clock. The clock's design and placement on the wall create a sense of elegance and functionality in the space."}, {"question_id": 542, "height": 477, "width": 640, "image": "000000193926.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [370.05, 94.76, 245.99, 130.48], "segmentation": {"size": [477, 640], "counts": "Pa\\54T>:PBm0j<d0I3[CPNc<g1^CYNk<]1=NfBfNZ=Z1hBdNX=[14FeB\\OT=c0nB^Oo<a0TC@j<a0VC_Oh<c0WC]Oi<d0WCRONLk<S1XCnN51Y<S1TDmNl;Q1WDnNh;R1ZDmNc;V1]DkNa;l0`CYOR1K[;l0eCVOR1NX;U1iDiNX;V1W100010O1^BjN]=R1aBoN10^=Q1aBoNd=U1XDkNg9U1lEjNkN3X;P1]FPOb9Q1TElNa04[:l0XEPO=4[:i0bFYO^9d0\\EUOL0_O;Y;?]EVO5;^:>WFWObN;W;<YFYO_N<X;9hE\\OoN06=R;8hE]OlN43;Y;4hE]OmN23=V;5mEYOlN31`0U;4XF\\O`Nc0];KTFC]Nc0`;IoEd0Q:[OnEBaNP1S;oNWE>U1DaNONm0U;ROWE>U1D`NP1S;oNXE<S1HaNn0R;QOYE8T1o0c9jNXE6V1P1`9mNYE3W1P1`9mNYE2X1Q1^9nNZE0Y1R1[9lNSEJ3017_1S1Z9oNWEF08_1S1Z9oNXEGL8b1R1Z9mN[EHJ8`1T1Y9hNVEN<2W1[1V9dNXEN=1U1^1V9hN_EII3`1]1W9hN_EJI2_1]1Y9gN_EJH2a1\\1Y9cNXEL65^1]1T9aNcE3X1\\1U9bNXEL6:Y1X1X9cNXEL79X1Y1[9^NYEO4:W1Z1m9`NXFa1c9aN_F`1a9gNXFY1h9gNXFY1h9cNiDI^1e1j9]NmDLZ1g1i9]N^Fc1a9_N^Fa1b9`N]Fa1b9\\N^FM\\Ng1W;ZN]Fj1d9UN\\Fk1e9UNZFk1f9[NSFf1P:SNTFl1_;000O10000O100O100000000O10000O100000000O10O110O00000O20O00000000000000000O10000N2O13M001O0000000000001O00000000000001O00O11O01O00O10000000000001O00000000000000000000000000001O000000001O00000001O00000000O10000000000000000000000000O10O100001kNTNVEm1j:SNVEm1j:SNVEm1j:SNVEm1j:SNUEn1k:RNUEn1k:RNUEn1k:RNTEo1l:QNTEn1m:RNSEo1h:oM^D1i0Q2i:oM]DOk0R2g:PN^DNj0S2g:PN_DMj0S2]:mMnD5ILj0T2]:oMmD6c0m1_:^N`Ec1`:]N^Ei0\\O\\OV;K]Eh0@\\OS;M[Ef1d:[NUEl1k:TNTEm1k:TNUEl1k:UNTEk1k:VNUEj1j:XNTEi1k:YNTEg1l:[NREe1l:^NSEb1m:W1001O001O0O3N1O1N2O2hLoD_2\\<YM[CO2N^_;"}}, "object_label": "backpack", "attribute_label": ["cleanliness:clean/neat", "color:blue", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness", "answer": "The backpack in the image is black and has a large orange piece of luggage attached to it. The orange luggage is placed on top of the backpack, covering a significant portion of its surface. The backpack appears to be a piece of sports equipment, possibly a skateboard or a snowboard, given the presence of the orange luggage."}, {"question_id": 543, "height": 425, "width": 640, "image": "000000199771.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [256.13, 391.31, 45.17, 33.69], "segmentation": {"size": [425, 640], "counts": "jQ[37P=5L3N2M4L5L3L100O100O10000O100000000O1000000000000000000001O0000001O00001O1O0O2B?HeT]4"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "state, transparency, cleanliness", "answer": "The image features a white cup sitting on a table. The cup is placed on a wooden surface, and it appears to be empty. The cup is positioned in the center of the image, occupying a significant portion of the frame. The wooden table beneath the cup provides a contrasting background, emphasizing the cup's shape and color."}, {"question_id": 544, "height": 480, "width": 640, "image": "000000211825.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [458.38, 55.68, 181.62, 221.62], "segmentation": {"size": [480, 640], "counts": "ghf6;25[=V1I5L5M1O10000000000000000nFoMVL`0\\8a1XKQN[Lc0]8\\1nJSOQ5m0eJ^OZ5b0bIZNZNe1S8MfGUNc1m2f6nNgGUNb1n2g6mNgGUNg0N0S3a7nNWIU1g6kNXIX1f6hNYIZ1f6fNYI[1g6eNYI[1g6eNYI[1g6eNZIZ1f6fNZIZ1f6bNmGUN]1Y3f6bNmGUN]1Y3f6gNYIY1g6gNYIZ1f6fNZITNdNn2R8nNZIZ1f6fNZIZ1g6eNYI[1g6eNYI[1g6fNYIY1g6gNXIZ1h6fNXIZ1h6fNXIZ1h6fNXIZ1h6fNXITNfNm2R8oNXIZ1h6gNWIY1i6gNWIY1i6fNXIZ1h6fNYIY1g6gNXIRNeNR3S8lNXIRNeNR3S8lNYIQNdNS3S8lNYIQNfNQ3Q8nNZIPNfNQ3P8oNYIQNgNP3P8oNYIQNeNR3R8mNYIQNeNR3S8lNYIQNeNR3R8mNYIPNeNT3R8lNZIoMdNU3R8lNZIoMdNV3Q8kN[IoMdNV3Q8kN[IoMeNV3o7kN\\IoMfNb2MnMQ8a1\\IoMeNd2MlMR8a1\\IoMdNW3P8jN\\IoMdN:1^2o7YOaIXNcNIJ_2R8@aIXNmNHG0Ng0L_OOL0=R8a1`IYNnNIEn1m70`IYNnNKCl1o70aIXNmNIJ1FS10ZOR8a1cIVNkNI13_OO1j0ODS8`1cIVN]OLoNOO2Od00IS8a1aIVN[OJROU1OZOS8a1`IWN[Oe1U74`IWNmNHMl1f75aIVNbNI206k1e76aIWNaNI2O8?AI0:0IS8f1_IYNdNHOO7k1g75^IZNfNHM13i1l74_IYN\\Ob1U75aIVN@JRO1LN020OOi0R8W1bIUN_OJTO1N101J:0IS8k1bIUN_OKnNO11O0O110Nh0S8W1aIVNlNI17@1Ol0S8m0aIVNlNI17@LOV1S8g0bIWNaNI2182AN0106Og0S8Q1bIWNaNI2182EOM5N10=S8[1aIXNcNH00:7@X1Q8a0aIZNdNH1O46EX1Q8b0aIWNAJRO4Ko0Q8l0cIUNIJjN1N1LOO?R8a1dISNGLjN001N?m7a1cITNHKjN001J0O?R8a1aIVNJIeN00001O1N01>R8a1aIVN@JSO0KO020OO2O00=S8a1aIVN_OKSO000LOO2Oc0R8[1bIVNlNI12E000LOO2Oc0R8[1bHoM:84KSO4L1Oc0R8V1aHPN:8[OGa05ZO1N2Oc0R8V1bIVNJMeN3Nd0Q8V1eISN1M^N1K1O>R8`1fIQN1N^N2KOO?R8a1eIQN1O]N2J00>R8`1bIoM^N3\\1MiN2J00i0Q8V1iHoML1ZO2]1NdN0O101Oh0R8V1hHPNM0ZO2S1NRO1LOO11OOj0Q8V1hHPNM6<KSO1KN011ON30b0R8[1gHQNM7=HoNO07O1Oc0R8V1gHRNK8CEc05XO2N10c0R8V1hHPNL8g0LeN2Od0Q8V1iHoM03c0NhN101J0050OS8i1hHPN02d0OgN100LOO2OO15R8i1hHPN03c0NhN101J0050OS8i1hHPNL1ZO3[1NjN0K006O00OS8i1hHPNL8<HTO2O1Jm0S8P1hHPNK93G_O1N101Kl0R8Q1hHPNJ:4F^O2O001Kl0R8Q1hHPNI;>HSO4Ln0R8k0hHPNI<CDb05ZOY1P8b0_IZNKGdN01T1Q8k0`IXNKHjN1Nk0l7T1bIWNJIjN1N2Jd0R8Y1^IPNaN9\\1GjN2Kn0P8P1]I]NNCjNU1l7k0[I_NDBPOb1Q8=ZI_NfNFd0f1[75[I`NdNG0L9MIl1o74[IQOkNQ1j7OYIUOiN8LTOR8_1ZIVOdN90ROR8^1\\I\\1d6dN\\I\\1d6dNiIo0W6ROjIVNXNNN^1NnNS8`1WJRNjM_1LPOR8_1ZJPNhM>LC2N61J0O10001O:R8d1bJWN]MJj0OWO0O2O:R8d1dJUN\\MK0Oe01ZO10`0Q8_1eJTN[ML0O`00A1N2O?S8^1kKWNRL;S8Y1mGXNP3MlM2TO10`0R8W1oGXNP3NjM3UO00`0R8X1nGWNQ3NjM3UO00?S8]1nJQNfM1ZO2OO1?S8^1lJSNRMO0000O10;OK0J1OT8j1kGWNP30QMT1OmN6Mo7j1lGYNc2MdMW1HkN2N]8k1aGXNo2n0m5o0oIQNVMo0l8k0SGXNo2?RM_OV9i1jFXNP30oL52I[9j1dFXNP3OQM0d9j1ZFWNQ3Oj6o1TIRNl6m1T3LRCUNo<j140000GlBeNV=Y1kBfNV=V1jBeN14V=W1hBgN11X=a11GfBhN0OZ=Y1gBeN_=[1300000001OO10O2O000POhB7Y=EQC1S=LR1ORN"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "texture, color, transparency, cleanliness", "answer": "The oven in the image is a white, modern-looking stove top oven. It is located in a kitchen, and the door is open."}, {"question_id": 545, "height": 480, "width": 640, "image": "000000361238.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture, transparency", "region_anno": {"bbox": [3.02, 299.04, 72.91, 93.45], "segmentation": {"size": [480, 640], "counts": "c9822Y>0fA0Z>;O2N1O2O[OlA>T>@nAa0Q>_OoAa0P>@PBa0n=@PBc0o=?H`0@^NhBd1o<\\NSCi1g<VNZCR2]<oMcCX2V<hMjCZ2T<eMlC`2P<`MPDb2n;]MSDd2k;\\MVDe2j;YMWDh2o;10000O100GVM\\Dj2d;VM\\Dj2m;001N1000O01000O100dNmCKS<2RDLn;3YDGf;:^DAc;>_DAa;?bD^O^;>hD_OX;`0lD^OT;=TE@l:>WEAi:=[EAe:>^E@b:?cE\\O^:b0eE]O[:b0gE]OY:a0jE]OV:b0U2O1N2N2N2O100O1O1O1OHGkA8_>O1O1O1O1O1N20dPY8"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:red", "material:ceramic/brick/porcelain", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness, state, texture, color, transparency, material, pose", "answer": "The cup in the image is a red plastic cup, which is placed on a table. It is filled with a drink, possibly water or juice, and is accompanied by a pastry, which appears to be a donut. The cup and the pastry are the main focus of the image, creating a visually appealing and appetizing scene."}, {"question_id": 546, "height": 361, "width": 500, "image": "000000061333.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "cleanliness, color, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.81, 136.15, 496.48, 219.85], "segmentation": {"size": [361, 500], "counts": "]5j12SO0h03]N;a0n4X1dJROOi02^N<`0V4^ORLl1[OjNOP10^N>>U4_OTLj1ZOd0OeM6LNc0^4\\O[Lo0SO\\20iL7MLd0^4\\O]Lm0ROb28bLId0_4\\O^Ll0ROb28bLId0_4\\O^Ll0ROa28cLIe0^4^O\\Lj0UOJ0k18]MIg0^4]O\\Lj0UO`28bLIg0^4]O\\L[4]O`KJh0]4]O\\Lk0VO^O7V23VNT4[O\\Lk0WOVO`0W2M]No3\\O]Lk0WOSOZ1`1SOVOo3\\O]Ll0XOnNc1\\1iN^Oo3\\O\\Lk0X16\\NDP4[O\\Li0^13WNIo3[O[Li0b11SNLP4ZOZLi0f1OPNNP4ZOYLe0m13iMNQ4YOXLg0P2NZMWO:n0T4VOVLg0U2MWMXO;m0S4VOVLg0X20_M3S4VOWLd0Z2OQM[O:l0U4TOXLd0Y21PM[O:l0U4TOXLc0Z22oL[O:l0U4SOZLb0Y24nL[O:l0T4TO]L<[28jL\\O9m0U4SO_L9Z2;iL\\O8n0W5ZOiM<hL\\O8n0\\4POVL8_2>gL[O9o0Z4QOWL6a2>eL]O8n0Z4QOYL6a2=dL^O8n0Y4QO[L4c2>aL_O7o0X4RO^L0c2`0`L_O7o0X4SO]LNe2a0_L^O8OHo0_4UO]LMf2a0`L^O60In0^4WO1a0kK8T4XO0>mK;T4VO0<mK?R4VO1;mK?R4VO1:nK`0P4VO3:mK`0P4VO3:lKa0Q4UO3:lKa0Q4TO4<jK`0R4TO4=iK?S4SO5>hK?S4SO5:]KD;o0R4TO78\\KE:P1S4TO67]KE:P1S4TO67]KE:P1R4UO76]KE:P1R4VO65^KE:P1R4VOjKHT4=fKE1N6R1U4WOhKIU4;gKE0O6R1V4XOeKJV48iKE0O6R1V4@KJiKE0O7Q1U4ALIhKF1N5S1V4@LIhKF1N5S1V4_OMJhKE8R1R4@NIhKE8R1R4_OOJfKF9Q1R4^O0KeKF9Q1R4^O1JdKG9Q1R4^O1JdKG9Q1R4]O2KcKG8R1S4\\O2KcKG8R1S4[O3LbKG8R1S4[O3LbKG8R1T4YO3NaKG8R1T4XO4O`KG8R1T4XO4O`KG3N0T1Y4XO4O`KG3N0T1Y4XO52gKf0S4XO71hKf0Q4YO71hKf0Q4XO82gKf0P4YO92gKd0P4ZO92gKd0P4YO:3fKd0P4XO;4eKd0P4XO;3fKe0o3WO=3dKf0o3WO=3dKf0o3VO>4cKf0o3UO?6XKC6R1S4UO?6XKC6R1S4TO`07WKC6R1S4TOa06VKD6R1S4TOa06VKD6R1S4TOa06VKD6R1S4TOb05UKE6R1T4SOa06UKE6R1T4SOa06TKF7Q1T4SOa09[Kd0T4SOa08\\Ke0S4ROb09[Ke0S4QOd09YKf0T4oNd0;XKf0T4oNd0;XKf0T4oNd0<WKe0Y9[OfFe0Z9[OfFe0Z9]OdFc0]9ZOeFf0\\9XO`FF1R1_9XO`FF2Q1^9YO`FF2Q1_9YO^FF3Q1`9TO\\FM1O0O0P1d9XO\\FI0O0P1e9QOZF31L4P1c9QOXF09o0c9PO]FP1b9QO^Fo0b9QO^Fo0c9POZF0KP1k9POXF2Mn0k9QOWF1Nn0k9QOWF1Om0j9QOXF2Nm0j9QOXF2Nm0j9QOXF2Ol0i9ROXF3Nk0P:UOoEl0Q:UOnEk0R:TOoEl0Q:TOoEl0R:SOmEn0S:QOnEo0R:QOnEo0R:QOnEo0R:QOnEo0R:ROmEn0S:ROnEm0R:SOmEn0S:ROmEn0S:ROmEn0S:ROmEn0S:ROnEm0R:ROoEn0Q:ROoEn0Q:ROoEn0R:QOnEo0U:11O000000001O0000000000000O1000000001O0MFjEGV:7kEJi9D`Fb0FKW:c00QOiEl0W:TOjEk0V:UOjEk0V:UOjEk0j9TO_F1G4O`0j9\\O`F0G40?h9_O`FNI20a0g9@XFL41N00c0f9@WFM503d0_9[OYF75K1d0a9ZOYF75J2e0c9]OVFN6O0g0a9YOZF65J0g0`9ZO[F55J0g0a9YOZF65JOh0d9\\OWFM6ONi0c9WOYF76INi0c9WOYF85HOi0e9^O]FINi0f9]OaFd0^9]ObFc0^9]ObFc0^9]ObFc0_9\\OaFd0^9]ObFc0^9\\OcFd0^9YOdFg0\\9XOeFh0Z9YOfFg0Z9YOfFg0n900000000000000000000000000000O1XOUOPG0\\Ok0d9UOPG0]Oj0b9WOPG1]Oh0c9WOPG2]Of0d9XOnF2_Oe0b9ZOoF1_Oe0a9[OPG1^O=0D]8KcH0QO3a0k0c7SOPHOj03QOOa0m0d7VOkGLo02QOOb0l0d7YOiHLQON`0OBm0T8[OhHKIj0^7\\OlGGh01WO0g0>YONU80bHHO;ZOMU82`HF0k0a7\\O`HHZOLc0R1e7POiGN10e03ZOM504S1n7[OZHHDJ3T1o7\\OoG@M0L67J1U1Q8lNkG8;M1o0S8SOkGM3LB7M<c8_O^GO9NG6?KDm0_8TObGO3OH7?KEl0_8YO]GJ;36NCl0_8YO]GJ1O7391Ak0a8[O^GFm03UOl0`8YO_GJk01SON0n0e8UO]GLO1l02WOk0i8ROTG10011a01Bj0U9UOXG1Cj0g8TO_G26T1Z8TOUGJa0R1T8iN^G?NB0O=W1\\8_OdGa0]8WOZGB9W1S8iNiG0L0c0W1W90cNiNhHW1e80TOjNeGV1S8iNYG2d0U1R8mNVG0g0S1V8POkGP1Y6iNiJ5oNR1W8mNhGS1[8mNbGS1b8lN\\GS1e8mNZGS1^90001OBkNiFT1S7lNQKT1o4lNQKT1c7O00000000cKnNmKO^N0^2S1W3mNlK0T1R1m2POPLNS1R1k2SOQLKU1Q1f2XOULHV1n0e2YOSOf0l0[OTOe0l0ZOUOf0b0ROSK7\\4g0i0ZOWOf0i0YOWOh0h0ZOVOg0j0YOQOIeKn0Z5XOROm0m0TOSOl0l0UOTOk0l0UOTOk0l0UOTOk0l0UOTOk0k0SOXOm0h0SORLHj1U1S2TOSLHkN0K0g2U1`2SO[LKU1R1`2ROjKL[O11Li1U1Q3QOlKJO1S1U1Q3oNSMMUNMV1W1b3nNTMNJT1m2iNQK6Y2OgMNh1T1U3kNSK4Z2LiMOf1V1R3lNVK2`4S18lNYK1[2KCX1h2mNZK0[2M@V1l2lNYK2^4R19jNUKN35a4S1`0lN@V1>kNoJK`4Z1a0kNoJLZ3OhMZ1o3kNoJLZ3OhMY1P4lNnJL^4Z1c0jNoJL^4Z1]5000O10000O1_LeNTM[1l2hNlILm2\\1]3cNiL^1a6O10O2O000O01000O1O100bN`NRIa1Z810000O1O100O1O100XN[NkIf1V6YNjIg1U3XNMh1j40M3O10000N2O1O11O6JBYNPGO7h1e8]NTGK7h1f8`NSGH3h1m8`NSG`1j8cNVG]1n8^NRGc1Y9100O1O11O00N2O100O100000RNjFi1V9VNkFj1U9VNkFj1U9VNkFj1U9WNjFi1U9XNkFh1U9XNkFh1V9VNkFj1U9VNkFj1U9UNmFj1S9VNnFi1R9WNoF0Jf1b9O0000O[NaFb1^9_NcF`1]9`NcF`1c901O1O1O001O0000001O2N0jNSFP1m9POWFl0j9RO]Fh0_6WO_IOm2i0d3XOYIO>3U2f0S4ZOWI03M49]2`0o3>TL]Of3j0ZLUOe3l0[LTOe3l0\\LSOc3n0^LQOb3o0^LQOb3P1YJfNW1:`4P1VJkNX15b4Q1SJROW1Kf4S1RJUOW1Gh4T1oIYOV1^O_NJ\\6_1nI^OT1]Om4W1mI_OU1YOn4[1hI_OY1VOP5g2nJYMR5i2lJWMT5k2jJUMV5m2gJTMY5o2^JWMb5n2RJYMm5R4001OO1001O000000000000001O0000001O00000000000000000000001O00000000001O0000000000001O0000001O00000000000000000000000000001O0000000000000000^I"}}, "object_label": "bed", "attribute_label": ["cleanliness:clean/neat", "color:white", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:covered", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, state", "answer": "The bed in the image is a small, cozy space with a white blanket and a green and white comforter. The cat is lying on top of the blanket, which is placed on the bed. The bed is surrounded by numerous books, indicating that it might be a reading or relaxation area. The cat appears to be resting comfortably on the bed, enjoying the warmth and coziness of the space."}, {"question_id": 547, "height": 393, "width": 640, "image": "000000270883.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "cleanliness, color, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [5.31, 2.66, 634.69, 390.34], "segmentation": {"size": [393, 640], "counts": "m8l1]:001N2N100O1OO20O0010O001O00aKSNcNm1^1SNaNm1`1SN`Nm1n5O00iKSNSNm1U60O1\\KTNkNl1h50000010]KSNjNm1W1RNhNo1h510O01O1`KoMhNP2Y1PNfNQ2Z1oMfNQ2k0oMfK0n2Q2\\1PNQK0NO02c3o1_2oMbMQ2Z6010O1O100O1O010O100O10O0101N010O001VKiMBX2V51O10001O0OVOWFWOg9f0^FYOa9g0aFXO_9g0cFYO[9h0eFXOZ9f0iF[OV9c0lF]OT9c0lF^OR9a0PG@o8?RGAm8?TGAk8?VGAj8>WGBh8>YGBf8?ZGAf8>[GBd8>]GBc8>]GBb8?^GBa8>_GC_8=bGD\\8=dGD[8<eGEY8:jGFU8:kGFU8:kGGS8:mGGQ8:oGGP89PHGo7:QHFo7:QHFm7<VHBj3POTO^1TM@g7?]HcNkNi0h8d0_H]O_7d0bH\\O\\7e0eH[OY7e0hH[OR3VOH_1WMZOP3XOI^1WMZOQ3WOG`1XMZOT7g0lH[OR7e0oH[OP7e0PI[OP7e0PI\\Oo6d0QI]Ol6e0TI]Oi6d0WI]Oh6c0XI^Og6b0YI^Of6c0ZI]Oe6d0ZI^Oe6b0[I_Oc6a0^I@a6`0^IB`6?`IA_6`0aIA^6?aIC]6>dIBZ6?fIBY6>fIDY6<gIEX6;hIFW6:iIGV69jIHU68kIHT69lIHR66dHXNY1d1R67nIKP65PJMm54SJMk51lHVNY1j1i51nHUNY1k1h53XJMh53WJOg52YJOm1QNa0Q2bMOk1RNb0o1cM0k1oMb0Q2dM1`5O`J1_5ObJ2\\5OdJ2[5NeJ3Z5LgJ4Y5LgJ5X5JiJ7U5JkJ7S5JmJ7R5InJ8P5IPK7o4IQK8n4IRK8m4HSK8l4ITK7l4HUK8j4IVK7i4IXK7h4IWK8i4GXK9g4HYK8g4GZK9e4H[K8e4G\\K9d4G\\K9d4G\\K9d4G\\K9b4I^K7`4K`K4`4M_K4a4K`K5`4K`K5`4JaK7^4IbK7]4JcK6]4JcK6]4IdK7[4JeK5[4KfK5Y4LgK4Y4LgK4X4LiK4W4LiK4V4MjK4T4MlK3T4MlK3R4OnK0R40oK0Q40oK0Q40oK0Q40oK0P40QL0n31RLOm32SLNm31TLOk32ULNk31VLOi32WLNi32WLNh33XLMg34YLLf35ZLKe36[LJd36]LJc36]LJb37^LIa38_LH`39`LG`39`LG_3:aLF_3:aLF^3;bLE^3:cLF]3:cLF\\3;dLE\\3;dLE[3<eLDY3=hLCW3>iLBW3>iLBW3>iLBW3>iLBV3?jLAV3?jLAU3`0kL@U3`0kL@T3`0mL@S3`0mL@R3a0nL_OR3a0nL_OQ3b0oL^OQ3a0PM_Oo2b0QM^On2c0RM]On2c0QM^On2c0RM]Om2d0SM\\Ol2d0UM\\Ok2d0UM\\Ok2d0UM\\Oj2d0VM]Oi2d0WM\\Oi2c0XM]Og2c0ZM]Oe2d0[M\\Oe2c0\\M]Oc2d0]M\\Oc2d0\\M]Oc2c0^M]Oa2d0_M\\Oa2c0`M]O_2c0bM]O]2b0dM_O[2b0eM^O[2b0eM^OZ2b0gM^OY2a0gM@Y2?hMAX2>iMBW2=jMCS2^MgKo2V2BT2_MgKm2U2FW28kMHU27lMIT26mMJo1]MhKi2Y2Jo1]MhKh2Y2Lo1]MgKf2[2Mn1]MgKe2\\2NR20nM1R2NoM2Q2NoM2Q2LPN5P2JQN6o1IQN8o1GRN9n1FSN:m1FRN;n1CTN=l1BUN>k1AVN?j1_OWNb0i1\\OYNd0g1[OZNe0e1[O\\Ne0n0WMlLT2V2e0e1YO[Nh0e1VO\\Nk0e1SO\\Nm0d1SO\\Nm0d1SO\\Nl0f1RO[No0d1PO]NP1d1oN\\NQ1d1nN]NR1c1mN^NS1b1lN_NT1a1lN^NU1c1jN]NV1c1iN^NW1b1iN^NV1c1iN^NX1a1gN`NY1`1fNaNZ1_1eNbN[1^1eNbN[1^1eNbN[1_1cNaN^1_1`NcN`1]1`NcN`1^1_NbNa1^1^NcNb1]1]NdNc1]1\\NcNd1]1\\NcNd1]1[NdNe1\\1[NdNe1\\1[NdNe1]1ZNbNh1]1WNdNh1]1XNcNh1]1WNdNi1]1UNdNk1\\1UNdNk1\\1TNeNl1[1TNeNl1[1TNeNl1[1TNeNl1\\1SNdNm1\\1RNeNn1[1RNeNn1[1RNeNn1\\1QNcNP2]1PNcNP2]1PNcNP2]1PNcNP2]1oMdNQ2]1nMbNS2^1mMbNS2^1mMaNT2_1lMaNT2`1jMaNV2_1jMaNV2_1jM`NW2`1iM`NX2_1hMaNX2`1gM_NZ2a1eM`N[2`1eM`N[2`1dMaN[2`1eM`N[2`1eM_N\\2b1cM^N]2c1cM\\N]2d1cM[N^2e1bM[N^2f1aMZN_2f1aMYN`2g1`MYN`2h1_MWNb2i1^MWNc2h1]MXNc2i1\\MVNe2j1[MVNe2j1[MVNe2j1[MVNe2j1[MUNf2l1YMSNh2n1WMQNi2P2WMPNi2Q2VMnMk2S2SMnMm2U2gLiJ1R3Y3\\2gLdMY3]2fLcMZ3]2fLbM[3_2dLaM\\3_2dL`M]3`2aLaM`3c5100O10000O100O1O1O1O10000O1N2O100O1O1O100O1O1O1O1N2O1O1O1N2O1O1O1N2N2O1M4N001O1O100O100O10000O1O1O10000O100O1000000O1O1000000O10000O100O10000000000O100O10001O0O01000000000O10001O00O011O01O01O000O02N001O10000O2O0O100O10000O010O2N100O10000N2O100N200O1O10000O1M3N200O100O10000000000001O0000001O0000001O000000001O00000ZOlIWKU6c4TJYKl5e4XJYKh5g4XJYKh5f4ZJYKg5e4[JZKe5e4]JZKd5d4^J[Kb5e4^J[Kb5e4mIYK32P6e4^J[Kc5d4^J[Kb5e4^J[Kb5e4^J[Kb5f4iIVK<4k5f4]JZKd5d4]J\\Kc5d4]J\\Kc5d4]J\\Kc5d4]J\\Kc5e4[J\\Ke5d4ZJ]Kf5d4YJ\\Kg5d4XJ]Kh5d4VJ]Kk5c4TJ\\Kn5e4mI]KT6d4jI]KV6d4dISKK8d6f4]I`Kc6`4]IYKk6c4^IVKc6g4aIXK_6g4YI[KNNi6g4WI^KNL5O]6f4`I^KOM4O]6j4\\IXK6Nh6j4RIXK6Ni6i4QIZK4Nk6d4UI_KM0m6a4RI[K141Nm6c4QI[K^7e4aH\\K^7h4000O0O20O1O1O1N101N1OGhHbKZ7\\48L6O11N11ON020O11O0OOO30VJdKh3\\4Q211O0N\\JfK^3Z4bLhK]3U4gLiKY3W4^2O1M2N2O001O2K4M3O2N2L3O1LXGfLj8X34O2L7H6UMcFd2b9O1O2L4N2M4L4hNQF1P:NRFAJ0P4"}}, "object_label": "bed", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, transparency", "answer": "The bed in the image is a large, white bed with a black headboard. It is covered with white sheets and pillows, creating a clean and elegant appearance."}, {"question_id": 548, "height": 480, "width": 640, "image": "000000208423.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [185.31, 430.89, 94.89, 48.61], "segmentation": {"size": [480, 640], "counts": "WSh22l>4L7J7H4J5L3O1O1N2O10000O10000000000O1000000000000O1000001O00000000000000O100003M2N1O0O1001OO2O0000O2OO01O2K4O100001O0001N10001O00001N110O1N2O1O1O1O00100O10O010O0001O1O00001N2N3M2KoWY5"}}, "object_label": "car", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "size:small/little/tiny", "state:closed", "texture:smooth/sleek"], "control_dims": "state, pose, size, material, cleanliness, color", "answer": "The image features a black car parked on the side of a road, with a white car parked behind it. The black car is a compact car, and it is parked next to a fence. The white car is positioned behind the black car, and both cars are parked in a parking lot."}, {"question_id": 549, "height": 640, "width": 480, "image": "000000250137.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "cleanliness, color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [145.59, 312.07, 286.84, 321.44], "segmentation": {"size": [640, 480], "counts": "ldm24jc03M3O1N2M2O001O1O1M4M5K3N1Y_OXOhMJ[`0o0c@VOEf0c?5`@n0_?SO]@Q1b?QOZ@R1e?oNW@U1h?lNV@V1i?mNQ@W1o?iNn_OZ1P`0hNP@X1P`0\\1O1O100O1000000O1O1O1O10000O1O100O10cLZ@`2e?aM[@_2d?o00000O10000000000000000N200O1O100O1000000O10000J_Km@a4S?`Kl@`4T?`Kl@`4`>`KnA0B`4Y>bKfAN>2B^4T=`KlBOm07BLA^4S=fKiC0CLA^4R=gKiC1ZOG04J]4T=aK_C6@10H53H]4j=jKXBN0I6f4a=dKYBNMJ9d4_=hKXB1:V4]=\\LgBa3U=iK^B:=ZOB`4b=mK_B9=YOCa4a=mK_B8>ZOC`4_=hLSCW3l<fL`BlN=0H^4Y=gLQCnNFZ4W=gKhB90J:0FU4U=jKlB51L72FS4T=lKoB20N43JP4P=PLRCO0OJH36NJ4Z4n<RLRCN03LJ0K2X4m<VLSCK1=N[O3U4g<\\LVC_O1000O:2G1S4`<hK\\Cg0?YOD5L70D451S4^<QLcCHJ1l08TOL2I261S4[<TLlCCb09^OGH54R4U<QLXEKRO2[OK2W4U<RL\\FJ]MO1U4T<SLgFGUMV4Q<QLmCIn2OUMW4n;SLWGm3g8VLXGj3a8]L_Gc3]8VL[DI\\3P4V8VLcDHX3R4S8YLcDF[3P4P8gLgDVOo2S4V8TMkGk2S8WMmGi2Q8XMPHh2o7gLmDZO]3o3g7dLPEZOZ3R4g7[LjDB1Oi3S4\\7[LkDBn3S4i6QL`E0KOQ4o3d6SL^E?h3^3j6TL\\E?K\\Ol3Q4h6RL^Ek0NSO[3NkL2NP4_:VM]EjNc31`Lo3\\:ZMaEfNb32aLn3\\:kLbECX3CjL12m3Y:^LbEBd06g25kLd3X:]L^FFWOMS3<RMc3V:ULoFNg17WMf3o9QLhE1^12c14ZMh3l9RLcJ4dKj3h9SL^J7lKf3e9QLlG2=8SNe3\\>XLhAh3X>ULkAk3n=SL[Bm3_;ULXE7WOc3a;WLRE:^O_3b;WLmD8Da3`;WLjD8Ga3`;WLgD3Of3[;XL`CJ109<o0a3X;XL^CM1O8;S1`3W;YL\\CM1086Y1d3S;ZLYCL3083\\1g3Q;XLZCL23NOo1k3h:VLbC9e1b3i:ULbC8f1c3j:TLSC=OBY2m3f:eL]E[3d:\\LPCI`2j3b:XLfEh3[:VLfEj3X=000O100000000O1000000O100oIPLQLQ4o3oKQLQ4o3oKPLR4n9100O1O1O1O1O1O1O1O1O1O1\\JcKdK^4\\4bKcK_4n9100O1O1kJ^KjJd4X:100O1N2O1O1000000PKYKhJf4X5ZKhJf4Y5ZKhJd4Y5[KeJg4]5[KWJMfKh4S:\\KUJMgK8LT4Y:fKSJOiK7LR4X:hKSJOiK7LR4Y:hKfEMX42mK8KQ4^:hKjINmKg4Y:[KjINlKh4\\:XKhI0lKh4h>XKYA9KQ4l>fKXAh4P?00000002N0[Km@]4T?aKn@^4X?2M3000]Kg@_4Y?bKh@\\4X?60eKf@P4[?:00^L]KgGc4l;O001O1O00001XLc@k2]?l01O001O001O001bL_@[2a?fM^@Z2c?fM]@Y2c?R11O1O1O001O1O001O1O1O1O001O1O1O1O1O1_Mn_OR1S`0mNo_OQ1R`0nNn_OR1S`0lNn_OT1S`0hNP@oNJT2W`0lNU@S1l?lNW@Q1k?nNU@Q1l?oNV@n0l?QOU@VO@]1\\`0[Ob_OVO?0F\\1Z`0[Oc_OYO=0JX1W`0]Oi@a0Y?\\On@>T?^OQA?P?_OTA>n>_OXA<j>BYA;j>AZA7kMDo`0OkeP1"}}, "object_label": "handbag", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:leather", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "state", "answer": "The handbag in the image is black and features a leather design. It is being carried by a woman who is wearing sunglasses and a black dress. The handbag is positioned close to the woman's body, and it appears to be a stylish accessory that complements her outfit."}, {"question_id": 550, "height": 480, "width": 640, "image": "000000298396.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [456.76, 148.03, 108.33, 118.18], "segmentation": {"size": [480, 640], "counts": "kjf6Q2`0TNA4m;k2N1O1N0101O0001O00000000O1000000000000000000000000000000000O1000000000001O000000000000000000000000000000SOYDaNg;a1XD^Nh;b1XD_Ng;]2000VOZDZNf;f1ZDZNf;e1[D[Ne;d1ZD^Nf;b1ZD^Nf;b1YD_Ng;]2000000O11O01N10O100000000001O000000000O1000000000000000O100001OO10000O2O0^MYD^O10o=MUB2gZU1"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "texture, pose, state, size, material", "answer": "The image features a stainless steel oven with a towel hanging out of the oven door. The oven is located in a kitchen, and it appears to be a modern and sleek appliance."}, {"question_id": 551, "height": 480, "width": 640, "image": "000000298396.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, length, pose, state, texture, transparency", "region_anno": {"bbox": [238.92, 323.78, 369.73, 149.19], "segmentation": {"size": [480, 640], "counts": "jT^35g>4M3M3M2N4M2N2N2O1O00O1N2N2N2010O001O100O2N3M3N5J3M3N0O1O1O100O1O1O100O100O1O1O1O100O100O1O1O100O1O1O100O1O1O100O1O100O1O1O100O1O100O1O1O1O100O100O1O100O1O1O100O1O100N200O100O1O100O1O1O100O1O100O1O100O1O1O1O100O100O100O1O1OTO`DZN_;d1fDZNZ;d1jDZNU;f1mDYNR;f1QEYNo:f1SEYNm:f1UEYNk:h0_DEh0Bj:f0bDEf0Dj:d0iD_O?Li:d0iD_O?Lh:d0kD^O?M]:3`D?i0]O;0\\:LiDc0e0^O82g:=^FBc9=]FCc9=^FBb9>_FAc9<a20[OEeB;[=DgB:Y=GgB9X=GiB7W=KjB3V=MlB1T=OmB1R=OoB2P=MQC3n<NSC1l<OUC1j<0VC0j<0VCOj<2WCMi<3WCMh<4XCLg<5ZCIf<8ZCHf<8P1001O100O1O1O100O1O100O011N1O1O1O1_B\\Of<d0j01O1O100O101N1O100O1O100O1O2N10001O0O10001O002N0000O10001O0001oBlNT<T1lCmNS<T1kCnNT<R1lCnNT<S1kCnNT<R1lCnNT<R1kCoNU<R1jCnNV<R1iCoNW<R1hCnNX<R1hCmNY<T1eCmN\\<S1bCnN^<S1`CnN`<U1\\CmNc<T1[CmNf<U1UCmNk<e1O1O1O1O1O000000TNZC^1f<^N`C`1a<^NaCb1^<]NdCb1\\<^NdCc1[<\\NgCd1i0YNW:3PEe1f0[NY:0REf1=aN4GZ91VFi19aN5F\\90VFj17bN6D]90WFj14dN6C`9MWFm1OgN7AW:i1]EjN9_OZ:i1YElN:\\O]:o2^ETMb:o2ZERMg:c30TMZE^1f:aN\\E^1d:bN]E]1d:aN_E]1a:bNaE]1_:cNaE]1_:bNcE]1]:cNdE\\1\\:cNeE]1\\:bNeE]1[:bNfE^1Z:bNgE]1Y:cNgE]1Y:bNiE]1W:cNiE]1W:cNiE]1W:bNkE]1U:cNkE]1U:cNkE]1V:aNlE^1T:bNlE^1T:bNmE]1S:cNmE]1S:cNmE]1S:cNnE\\1R:dNnE\\1R:cNoE]1Q:cNPF\\1P:dNPF\\1P:dNPF\\1P:dNPF\\1P:dNQF[1o9eNQF[1o9dNRF\\1n9dNRF\\1n9eNQF[1o9eNRFZ1n9eNSF[1m9eNSF[1m9eNTFZ1l9gNSFY1m9gNSFY1m9gNSFY1m9gNSFY1l9hNTFX1l9hNTFX1l9hNTFX1l9hNTFX1l9hNTFX1l9hNUFW1k9iNUFW1k9iNUFW1k9iNUFW1j9jNVFV1j9jNVFV1j9jNVFV1j9kNUFU1\\9QNlEk0h0T1[9SNlEi0i0T1[9TNjEi0k0S1[9TNjEi0k0S1[9UNiEi0l0Q1[9VNhEj0m0P1[9XNeEi0P1o0[9]OeFc0\\9\\OdFd0\\9]OcFc0]9]OcFc0]9]OcFc0]9]OcFc0]9]OcFc0^9]OaFc0_9]OaFc0_9]OaFc0_9]OaFc0_9^O`Fb0`9^O`Fb0`9^O_Fc0a9^O^Fb0b9^O^Fb0b9_O]Fa0d9^O\\Fb0d9_O[Fa0e9_O[Fa0e9@ZF`0f9@YFa0g9_OYFa0h9_OWFa0i9@VF`0j9@VF`0j9AUF?k9ATF`0l9ASF?m9ARF`0n9@RF`0n9AQF?o9BPF>P:BoE?Q:BmE?S:AmE?S:BkE?U:BjE>V:ChE>Y:BfE=[:DcE=^:D^E>b:P2001@ZEYL07f:Z3aE^LJ7e:[3^ElLc:l2ZEjLO=g:e3000000000O100M3J6M3I7K6K4N2IZDQMj;l26N3I7L6H6L4N2N3N1InB\\NW=a17L4M3M3L4K3O3J6K5K4JRc7"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:tan", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "state:covered", "texture:smooth/sleek"], "control_dims": "state, pose, cleanliness, texture, color, transparency", "answer": "The dining table in the image is set with a white bowl, a banana, and a few red plates. The table is surrounded by chairs, and there is a yellow tablecloth on the table. The table appears to be in a kitchen setting, and the overall atmosphere suggests a casual and inviting dining experience."}, {"question_id": 552, "height": 427, "width": 640, "image": "000000002157.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pose, state, texture, transparency", "region_anno": {"bbox": [230.11, 52.53, 61.5, 148.53], "segmentation": {"size": [427, 640], "counts": "m\\P34n<?D=F:F6K5K6K2jFUNj6l1TIVNj6l1TIUNl6l1SIUNk6n1RISNn6n1QIRNo6o1bHnMhN5d8P2aHmMjN3e8Q2_HnMjN3f8o1`HnMjN4e8o1`HnMjN3e8Q2`HlMjN5e8P2_HlMlN5d8P2_HkMmN6c8P2_HkMmN6c8Q2^HiMoN7b8Q2^H]Nb7d1]H]Nb7f1ZH[Ne7f300001O000000000000001kM]GmM3CNW1b8R2]GmMc8^3000hM_GFa88jG_OW8?SHXOm7f0^HQOb7n0bH\\NiNNf8e1cH\\NgNOf8d1eH\\NeN0f8c1fH\\NeN0f8c1fH]NeNOe8b1iH]NcN1d8`1kH_NaN0e8_1mH_N_N2d8]1oHaN^N0e8MXGR1h1QO[NOf8MYGo0j1TOXNOe8OXGk0o1VOUNNe84YGG17X2OjMMf85ZJMSMIf89YJMU62mIKU66jIIV6;^3N3M2Mln^4"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness", "answer": "The wine glass in the image is a clear glass, placed on a red tablecloth. It is filled with water, and there are some strawberries on the table near the glass. The glass is positioned between two other wine glasses, creating a visually appealing arrangement."}, {"question_id": 553, "height": 427, "width": 640, "image": "000000013923.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "cleanliness, material, pose, state, texture, transparency", "region_anno": {"bbox": [381.51, 331.81, 20.28, 36.2], "segmentation": {"size": [427, 640], "counts": "QWo47l<;H7L2N3L33M0010O01O0000000000O0107I3L7HjlR3"}}, "object_label": "vase", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, state, transparency, pose", "answer": "The image features a vase filled with water and a single rose. The vase is placed on a table, and the rose is positioned in the middle of the vase, creating a beautiful and elegant display. The rose appears to be a green one, adding a touch of color to the scene. The vase itself is white, which complements the rose and creates a harmonious and visually appealing arrangement."}, {"question_id": 554, "height": 480, "width": 640, "image": "000000025593.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [163.0, 193.3, 319.0, 110.4], "segmentation": {"size": [480, 640], "counts": "Uc]2o0^=e0G8M3M3M3N2N2N2N1O101N100O100O2N10000O1000000O100000000O01000000000000000000O1000O100000000000000O0100000000000000O100000000000O100000000000O100000O1000000000O100000O1000000000O1000000000O100000O1000000000O10000000O1000000000O1000O1000000000000O010000000000000000O100000O10000000000O10O100000O100000O1000O10000000000O100000000000000O1000O100000000000O11O0O100000O10O10000000O1000O1000O100000000000000O010000000000000000000O10000O01000O1000000000000O1O100001N100000000000000000000O100000000000000000000000000O100000000000000000O10000000000000000000000000000000O1001O000O10000000001O00000O2O0O101O1O0O2N2O1O1N2N2OgCQNd;k1n0J<D7I5K5K8E7M2N4KRjY2"}}, "object_label": "stop sign", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "size:small/little/tiny", "state:dry", "texture:smooth/sleek"], "control_dims": "size, length, cleanliness, pose, state, pattern", "answer": "The stop sign in the image is located on a pole, and it is written in a foreign language. The sign is positioned on the side of the road, and it is surrounded by trees. The stop sign is clearly visible, and it is placed in a way that it can be easily seen by drivers and pedestrians."}, {"question_id": 555, "height": 428, "width": 640, "image": "000000138550.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [167.35, 45.2, 150.04, 198.13], "segmentation": {"size": [428, 640], "counts": "hXV24W=4M2N1O2N2N1O2N2N002N2N001O0000000000000000000000000000001TGXOR5m0dJYO[5h0dJWO]5k0`JTOb5m0]JROd5o0ZJoNi5R1VJlNl5U1U3DmCAQ<>QDBn;>SDBl;>UDCh;>ZD@f;`0\\D@b;`0_D@`;`0aDA];?dDA[;?fDAY;?hDAW;?jDBT;>mDBR;>PEAo:?REAm:>VEBh:>YECe:=\\EBe:=\\ECc:=]EEa:;aED^:<dEC[:<fEFo0DY7f0iGGNCK7Z8`0oGDe0L\\7a0PHDa0K`7a0QHC9Oh7>PHC6Nl7`0nGB11R8=nGAO0V8?lGAM0W8?mGCF0^8<oGD@0b8<oGE\\O0e8;PHFbNCb0:P9=nGHoNLT9<nGGnNMT9<nGGmNLW9=lGHlNIZ9?kGGjNJ\\9?nGDcNMa9?mGD`NMd9?lGE_NKf9`0bGXOiN>MJi9`0aGYOhN>MFm9c0^G]OdN:0EP:d0TGXOPOi0K[OQ:d0TGXOPO20NK<1ER:g0PGZO@9e9=jF[OG2_9b0kF\\OV:c0gE_O\\:?dEA]:?bEB]:`0_ECa:?\\EBHOo9`0XFAI0JMb9a0jFBJN0M[9c0jFAL00LX9d0kF@K24JU9d0jFAL26KR9b0kF@N29Ll8b0kFA00>Kf8d0kFAO2a0Kc8b0kFA30b0L`8c0jFA5Oc0M]8c0iFA5IA4U10[8b0jF@53j0JU8c0jFA80k0NQ8`0lFB7OR1Mj7b0kFB81U1Kg7b0kFA:2V1Je7c0jFA<OY1La7Q1VGTO\\1I^7R1VGSOa1IY7S1VGTOn:j0REWOo:h0QEWOQ;h0nDYOS;e0nDZOT;c0nD\\OT;c0lD]OU;b0lD\\OV;c0dDYOH0h;f0`D_Od;`0\\D@d;`0\\D_Od;b0\\D^Od;b0[D^Of;c0VD^Ol;c0QD^OP<n01O1O1N2O1O1N2N2N200O101O1O1O1O1O1O1O1O1O1O1N2O1NcXU4"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The dining table in the image is a small, black iron table with a metal top. It is placed on a sidewalk, surrounded by a metal fence."}, {"question_id": 556, "height": 428, "width": 640, "image": "000000138550.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [95.15, 40.36, 123.71, 198.44], "segmentation": {"size": [428, 640], "counts": "^UX16S=6M2N2N03N000DTC=l<0O2N1O1O2N0110O6J010O3M11N002N2N002N001OO20O100OO1O2O011HSCJY=Olj02PUO2O2N02O01\\DJo97oEJQ:6lELU:4iEMW:4fEN[:3aENa:2]EMe:4XEKl:5SEHS;7jDJW;6gDJ[;6cDJ_;6^DJGLa;;fDHJNb;9cDGL0d;8[DK1Me;9YDHY<8cCJ7Lj;9mCKe<<2O2M4L1IPC2V=M7OJ4L3N2O1O1M3N2N2NC[C6c<JaC5Y<LkC4R<LQD4n;KSD7^;D`D376X;GaD297a;GcD:k:GfD3a05h:HeD4f04c:GhD4`0M[O7];HhD3i05^:HeD5P12_:OcE0_:LdE4\\:JeE7HIk:7SEKW<0N2OO4NW=1dB4OOO3M20O101O1000024L1N01N2O00O1O1O002MnT`5"}}, "object_label": "chair", "attribute_label": ["color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "pose, pattern, state, transparency", "answer": "The chair in the image is a metal chair with a black seat, placed on a sidewalk. It is positioned next to a metal fence and a table. The chair appears to be old and rusted, giving it a vintage appearance."}, {"question_id": 557, "height": 428, "width": 640, "image": "000000138550.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture", "region_anno": {"bbox": [264.49, 121.03, 103.88, 222.17], "segmentation": {"size": [428, 640], "counts": "mS^3=n<5H6M3L3M4N2M2N2YFROm6o0QITOn6m0oHVOo6l0PITOo6n0PISOn6n0QITOn6l0RIVOl6k0RIXOk6i0UIXOj6i0UIWOj6j0VIWOi6i0WIZOf6f0ZI^Oa6c0^I^Ob6b0^I^Oa6d0eH6Z7KaGY1^8l1H8I6I8L3D<K5L4N3O0O101N10000O2O001O00000000000N2K5O1000000000000001O5K1O1O000000000000001O1O0O2O00001N2O3AoH\\JV7_5f0cMZI`MS7R1oIoNg67[IJe65\\IJd66\\IJd66]IIc67]IHd68]IBbM]OU9P1YIAk6?VI_Ok6a0UI^Om6a0TI^Om6`0TI@l6`0WI\\Oj6d0P3N101N1N4M3L4M4M1N1O2O3Jid`3"}}, "object_label": "fire hydrant", "attribute_label": ["color:orange", "color:white", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:on", "texture:smooth/sleek"], "control_dims": "length, size, state, texture, material, pattern, color", "answer": "The image features a red fire hydrant with a silver top, located on a sidewalk. The hydrant is situated next to a metal fence, and it appears to be old and rusted. The hydrant is positioned on the side of the road, making it easily accessible for emergency services."}, {"question_id": 558, "height": 427, "width": 640, "image": "000000378139.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [114.24, 228.1, 372.66, 94.32], "segmentation": {"size": [427, 640], "counts": "ld`13U=7K4L2N2N2N2O1N2N101O0O101N101O0O1000000000O11O00000O10O01O1O100O1O2N1O1O1O2N3M3M2N2N1O1O1O1O1O1N2O1O2N100O1OoNjDQO2h0T;7iDRO4f0R;=nDCR;=nDCQ;:kDPO4f0Q;:kDPO4f0Q;:kDPO4f0Q;>oDAR;;jDQO3d0R;<lDPO1d0S;;nDPOOe0S;;TEEl:;TEEk:=mDmN2g0Q;\\110O10000000O10000000001O0O100000000O100000000O1000000O1000000000000000000UOfDD[;<eDD[;V100O1000O100mNoDLQ;3QELo:4QELo:5fDVO6e0T;4QELo:4PEMP;3PELQ;4oDLQ;4oDLQ;9iDHW;U110O10000000O10000000000O1000000000O10O100000000O100000000O100000000O010000000O1000000000000O10000000000O1000000000O0101O0000O01000000O100000000000000O1000000O1000000000000O1000O10O010000000O100000O100000O1000000O100000O10O1000000O100000O01000000O100000O01000000000000000000O100000O01000000O1000000000000O10O100000O1000001N1000O10000000O1000000O010000000O10000O100000O10O1000001O000000000O1000000O10000000000O10000O10000O100000000O100O2O000IgC[O[<c070001N1O2O2M101N1000001N10001N100O2O1N101N2NRjP2"}}, "object_label": "boat", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:horizontal/lying", "size:big/large/giant/huge", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, pose, transparency, texture, pattern, length, material, size", "answer": "The image features a large boat, possibly a ferry or a paddle boat, traveling down a river. The boat is filled with passengers, who are enjoying their time on the water. There are several people visible on the boat, some of them standing and others sitting, spread across the vessel.\n\nIn addition to the passengers, there are a few bicycles on the boat, likely belonging to some of the passengers. The boat appears to be a popular mode of transportation for people to travel and enjoy the scenic views of the river."}, {"question_id": 559, "height": 640, "width": 457, "image": "000000002431.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [307.3, 0.0, 126.89, 215.19], "segmentation": {"size": [640, 457], "counts": "nin53kc04L2XJf0hF]OU9k0dFWO[9m0aFTO^9o0^FROb9o0]FROb9Q1ZFQOe9S1WFnNh9T1UFnNj9T1TFlNl9U1SFlNl9U1RFmNm9U1QFkNo9V1PFjNP:W1nEkNQ:V1nEjNR:Y1kEgNU:Z1jEfNV:[1iEfNV:[1_BkMV3k0[:^1dEbN\\:^1dEcN[:_1cEaN]:b1`E^N`:d1^E\\Nb:d1^E]Na:e1]E[Nc:f1\\EZNd:f1\\EZNd:f1\\EZNd:g1[EYNe:g1ZEZNf:h1XEXNh:i1WEWNi:i1WEXNh:i1WEWNi:j1UEWNk:j1SEXNl:i1REXNn:i1PEYNo:h1oDZNP;g1nDZNR;g1lDZNT;g1jDZNV;f1gD]NY;d1^DdNb;]1RDmNo;W1gCoNY<T1kBhL;W2j<Y400000001O000000bMPCkK7]1i<c2mCYMS<e2QDYMo;b2WD]Mi;[2`DdM`;X2eDgM[;V2iDiMW;U2kDkMU;R2oDmMQ;P2TEnMl:Q2VEnMj:P2YEoMg:Q2YEoMg:P2ZEoMg:Q2WEQNi:n1YEQNg:o1ZEPNf:P2ZEPNf:o1[EPNf:o1[EQNe:n1\\ERNd:m1]ESNc:l1^ESNc:l1^ETNb:k1_E[MTMf0]=o1_EUNa:j1aEUN_:k1aEUN_:j1cETN^:k1cETN^:k1dETN\\:j1gETNZ:k1gETNZ:l1gERNZ:n1fEQN[:n1fERNZ:n1iEnMX:R2iElMX:S2jEkMW:T2kEjMV:T2nEhMT:U2m3N20000O1L4O10000M3N2N2O100N2M3M3M3O1L4L4N2H8N2KUl`0"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, pattern, texture", "answer": "The wine glass in the image is filled with red wine, and it is placed on a wooden table. The glass is positioned in the center of the table, and it appears to be empty, with no wine left in it."}, {"question_id": 560, "height": 480, "width": 640, "image": "000000145781.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [0.0, 166.45, 96.82, 138.03], "segmentation": {"size": [480, 640], "counts": "W5Z4f:0O10000000O10000000O100000O10O1000000O1000000000000000O10000000000O100O1O100000001O0O10000O100O1O1O1M3N2O1O2N1O1O100O2O0O100O1O2N1O100O2N1O2N101N2O1N101O1N101O1N2O1N2O2M2O2M4M3L3N4K8Hc0\\O`0\\O<_OeA0kVo7"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a clear glass bottle with a green top, sitting on a table. The bottle appears to be empty, and it is placed next to a small animal, possibly a mouse or a cat. The bottle is positioned in the foreground, while the animal is in the background, creating a contrast between the two objects."}, {"question_id": 561, "height": 427, "width": 640, "image": "000000405691.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [110.35, 54.53, 93.07, 204.39], "segmentation": {"size": [427, 640], "counts": "lV_1h0]<:G8I7I6J6H7M5L2M3N3M2O1O1O2N2M2O2N1N10001O1N2O002N001O001O0O103M00001O2N8H:F6Id0jGZKa6k4lHXKK0W7i5N1O00001O01O0PNRIcMn6W2TJmLl5i2kJiLV5V3lJiLT5V3nJiLR5W3nJbLjM3X7[3SKdLm4[3b2JTFlLm9T35O100O1N200N2N3L30001O001N1N3N1O2N4L4K4M4L3L5K5L4K5K5J7J;]OPof5"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, transparency, texture, material", "answer": "The wine glass in the image is filled with red wine, and it is placed on a dining table. The glass is positioned in the center of the table, and it appears to be empty, with no wine left in it."}, {"question_id": 562, "height": 427, "width": 640, "image": "000000581482.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, size, texture, transparency", "region_anno": {"bbox": [404.93, 205.18, 103.63, 100.76], "segmentation": {"size": [427, 640], "counts": "oXX51Z=0T>1aA1RC93F\\<d0bC]O[<m0J6L2N2N1O4L4M3M1O2M3M3N2N1O2N2N2O1N2O0O1O2N2N101N2O0K]MbEc2^:^M`Ec2`:]M`Ed2`:311N1O000O10000000QNbEQ1^:jNgEW1W:iNkEV1U:jNmE^OG_1\\:UOnEXOHb1Z:WOfEVO9a1R:ZOcEWO;_1Q:AfEnN5^1U:JlE3S:LQF2o9MgEmN7S1S:8lEGT:>lE]OT:d0eE\\N4o0W:j0iESOX:n0jEoNV:S1lEiNT:\\1jEaNV:`1kE^NU:o1cEkM^:T2eEjM[:c21N1O101O0O10001N101O0O2N1O101N1O2N2O001N2N2O0O2N2N3M2M3M3N2N3L3L6K4L4K6K7GVWg1"}}, "object_label": "clock", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pattern, texture, length, transparency", "answer": "The image features a large, old-fashioned clock with Roman numerals on its face. The clock is prominently displayed in the scene, occupying a significant portion of the image. The clock's face is white, and it has a black background, making it stand out against the background. The clock's hands are visible, indicating the time of 12:00. The clock's design and size suggest that it is a prominent and functional timepiece in the space where it is located."}, {"question_id": 563, "height": 612, "width": 612, "image": "000000127624.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, pattern, texture, transparency", "region_anno": {"bbox": [100.4, 418.09, 511.6, 147.15], "segmentation": {"size": [612, 612], "counts": "`oj11Qc03N:F2\\]OC_b0h0I2N00001O3M1O0O2O4L2N0Y^OhNba0T1]^OlN12aa0Q1^^OnNO8]a0i0e^O_OWa0a0i^OXO^a0g0c^OYO]a0X1O00O1YOa^OVOO`0`a0:e^ODNBXa0a1f^OcNWa0m1HXNP_O\\1Pa0cNQ_O]1o`0dNP_O\\1Pa0XOQ_O3o`0KT_OVOLj0Pa00T_OVOLj0Pa01S_OUOMj0Pa02R_O3m`0R10eNR_O`0o`0QOP_O^1Pa0bNP_O_1n`0bNR_O^1n`0<000VNS_O30i0n`0TOR_O30i0o`0CQ_O>n`0AS_O?a0jNf?h0h_O?a0iNg?R1g_OKc0SOf?S2Y@mMg?T2W@mMi?S2W@mMi?R2X@mMi?i0f_O=o`0l002`_OlMl?W2Q@jMo?S2S@nMl?R2T@nMk?T2T@lMl?U2S@kMm?V2R@jMn?U2S@iMo?W2Q@iMo?V2`00000O2OO1[_OjM\\`0R2g_OoMY`0R2<1OLR_OSNm`0`1X_O_N01h`0Z1f_OfNZ`0m0S_O[Od0FZ`0i0T_OXON42Kca0i0i^OYOWa0g0h^OZO64U`0a0g_OZO46T`0a0g_OYO:0P`0g0g_OXO;On?i0\\_OXO22<N\\`0g0R_OYO0`0>D]`0b0Y_O8MUOk`03T_O65h0h`0ROS_O65f0j`0EU_O;k`0ET_O;m`0ET_O9m`0HR_O7Pa0GQ_O9o`0FR_O;m`0^OY_Oc0g`0AU_O?k`0TOn^O66e0l`0DT_O<l`0CU_O=k`0DU_O=i`0DV_O<j`0DV_O;k`0EU_O=i`0[O__Of0``0ZOU_OA5V1g`0_OW_O=JPOo`0d0V_O<LoNn`0d0W_O=JPOo`0a0Y_Oc0g`0[O[_Oe0e`0POQ_O41F6Q1JPOn`05Q_O32G5o0LROl`0>^_Of0b`0ZO^_OCCo0o`0CY_O9HYOo`0`0V_O70UOj`0d0V_O70UOj`0b0X_O:LUOl`0=]_O=GVOl`0<^_O=GWOk`09a_O?FWOi`04R_O1:e0LTOi`01P_O149Me0Xa0QOh^O03T1NPOWa0Lh^O01_1Wa0aNh^O1O_1Ya080Mg^O\\NXa0h10O100Ei^OiNWa0=i^O09]OIOn`0d0Q_OO3]OXa0h0d^OLO^O\\a0f0f^OLM^O7Nm`0h0P_OKL_O]a0g0h^OCKF10\\a0f0h^OMZa01f^O0Ya01g^OILC]a0h0c^OB6CWa0[19ZO^^OKaa0FZ^O673OAXa0d0h^O1J\\O^a0b0h^O_OKb0]a0Nh^O@Mb0Za0Nc^O@6d0Ya0Ka^OA6d0Xa00i^O[OIa0^a03m^OJEC]a0b0n^OLEA^a0c0l^OCG0OJ_a0>a^OB;6F3^a04Q_O6n`0JS_O5m`0KS_O5m`0KS_O5m`0KS_O5l`0MS_O3m`0NR_OIBG11Za0>S_OOCB\\a0=Q_O3AA^a0<Q_ONXa01i^OK@IV12W?9U@K^OJ:O70F3ONn?;`@MAL:MG1ONP`0;_@:_O@OM4OKN11T`0>W@m0IfNX`0d0c_O[OO_14cNY`0Y2g_OgMZ`01b_OQ24nM[`00b_OR22oM;L_?\\2U@iMNN9Oa?[2V@jM002Nh?X2V@SN2Fh?R3000FX@SMm?Z2R@lM0O1Jn?d0Q@c1T`0lMk_O:2l1Q`0jMm_O;1j1R`04m_OTN2@n?\\2P@TN2Am?m2S@SMm?R30I7_Ol_OkMOKX`0Y2j_OkMOLW`03g_OQ22PN0LX`02f_OS21UNW`0Q2h_OkM0L0OT`0Z2l_OkM1OS`0_2l_ObMU`0f20O0@k_OkM0OU`0U2m_OjM0MONU`0Z2m_OjMONONU`0Z2m_OjMO2S`0T2m_OlMO1R`0T2n_OlM1IW`0\\2g_OkM]`0^2Q@]M^?c2`@cM[?]2e010O2O0000O100001N010iMj_On0IkN00]`07j_On0JfNOO16]`08g_Om05jNT`0:f_Ol06fNF0]`0?g_Ok0MjN00\\`0>d_Oh00jNO1]`0=d_Oh01iNN2]`0;f_Ok0NiNNM1O]`0`0f_Ol0MlN0H]`0`0f_OT1L]N2N\\`0>b_OD3c1N\\Nb`0`0`_OS1O\\Nb`0a0^_OT10[Nb`0Q2]_OUNf`0c1Y_O^N1O6JW`0i1b_O^N104JY`0[2h_OdMX`0\\28SN[_OC0b1f`0`N[_O16m0JRO0NNOh`03Z_O17l0ISO0Mk`02W_O14U1JiNj`01Y_O12V1JhNj`02V_O36k0IUO1N2K``04]_O47j0IUO1O1KO0]`0=i_Om0IlN1LON^`0=j_OCIg1^`0fNg_O[1KWN_`03`_Oi11VNPa0i1R_OUNo`0k1Q_OUNPa0k1n^OWNl`0OT_Ok1OYNj`0NV_OR22lM0O\\`0[2c_OgM0O1OW`0b2g_O_M2OW`0d2j_O\\MV`0a2m_O_MS`0Q1i_OUOOc05YO0OR`0g0j_O]O2NNN50KO02N07N10P`0R1h_OTO2K41LN02OO6O\\`0^1c_OdNLNO3O05O1NU`0^1h_OfNOi0Z`0YOd_On02RONh0i?ROi@f2V?ZMf@0D7NW10_O1SOd?0i@0D7OU2OfMd?Nj@0D60V2OdMd?1h@OF1N011ON6m1KSNc?0]@080I1N010:0Dh12WNc?0]@080I1N0100O10O2O5O50f01nNd?0]@1<4DL5OL0O7N01J2ONQ1c?PO\\@1>191ZO21J9P1X?UOk@N91ZON0O1O:2Ek0_?UOQA342[OJe01[Ok0_?UOc@O5OK2OO100O1000O2N02OO16N01Jk0^?VOm@NG1M21M70K0O2N11N01>0Bk0]?WOQA21JB9a0o0h>mNSA12JC8NI6OOf0JKZ?DTA12JB7NO3J46Il0Z?SOSA2DJ;OF2N0142K35Ko0U?POWA1EK60M3N10N21M;N21@U?4XANDNN160L4O10O5KL5O10J1005OL0O1000O0b>4kANF010M3O10O5KL5O10J65J103b>KkALC0114OK011N015O02KN001195DL7NL0O16b>K^AM71JO02O00N21N10O01050KO020N01000O1001M12O5OK1005c>OdAKJ0O1000O10O1Oi00e02dN3N_>3eAMG71d20TM105O\\>6dAMIV31hL016N\\>6aAJM205O01j21QMb>4`AJM205O01:Om12dMb>3cAKL5O10OO21m1OmM105O\\>5cALL500OLO02400O1O0010O010O1K0O100O10`>5fA4IL0:1d1NnM10j>2TAO2OO105O01K00O10O1o1OQN114N`>0hA0D6O01K00O10O1S20oMk>LgA6]O333Ng10nM011Nf>0lA6^O01ONM1R2OmM011N10`>0PB6]O12I02O40W2OdMh>OkA5^ONOO2OO1040\\2e>^MmA3A03MN5M2Nm10mMh>OmA0C0O1LON21ON160LON21U10iN100Of>0mA0C0O1K0O11ON160LN02OQ10oN0O100Of>0gB7aNO21NY16`NM0e>0kA0_O1000000O011N1041KO1041P12jN3O`>0jB0aN2131KO100O1OU16iN]a0R1]^OPO7O\\a0T1d^OkN]a0V1FjNR_O0F7Nd00WOZa0NT_OV1CjNXa00n^O1K1N104190B0O100Om`00X_O1KW1OiN10e`0O\\_O0O2OO11N01W12iN^`0Oa_O0O011N11OO01_11`Nk?0d@2D:NIMl00QO0O1Oj?4b@NI71GLQ1MQO0O1O2OO0`?5j@0G74DN^1f?gNa@1ELO93F35Kn0OnN2Nc?2i@2FMN6<X1Q`0bNh_OOL0O15OO3Kb0OB1K0O2OX`01l_OOL000O10O52Jc00A1KO02OO0f`00[_O27T1FPOY`0Ki_O0O11N02OO02ON200W1NnN2LY`0Nl_O1J2O81k0Wa0ZOh^Oh0l>hNYC0nMj1i>VNWC1nM00h1]`0WNi_O100I1150W1Sa0cNn^Oi1^`0VNQ@0B6MS10nN``0IQ@1@j1]`0VNm_OOKn1X`0SNb_O12N020NOn1]`0XNm_Ok1T`0QNb_OO:X1ESO0K^`05f_Of1Y`0UNc_OO2l1_?RNb@M4O07IM43Lb1a?dNm@KCH62KNO3O5090K1J`?7m@FCN;OG0O100O10:OG091J`?7m@J8U1[OjN`?7m@IMJG100Oc1Y?oNYA@KNDO0d1W?nNi@_O>2:^1]O_Ni>h0_A[O7M]Oi0M^O145Fj>h0`AXO41^O`13_Nk>i0QAVO62JOb03^O`10^NP?\\1o@cN5010Jm1P?2SANORNi>P2WAO0QN00e>S481SAnKf>b2ZAgN0eNi>d2WA]NOQO0O2OO0e>d2[A]NOQO001Ni>S4VAnKj>V4OBbAXL^>e3fAZLZ>f3b00e@[L50i>e3RA\\L0O00n>e3QAaLS?h3000005K4L0000000XAiKc>W4\\AjKd>[401O1OM3K50WAjKd>V4ZAnKd>R4601O11O000000001[AhK\\>X4cAiK]>X4700001XAiKa>_4N00001O0000M3L41ZAeKa>a4N1OK5O11O3MM3O1001\\AbK`>b4OO1NbAaK[>_4eAbK[>\\4dAdKOO\\>]4eAcK00[>]4800000]AdK^>\\4bAeK]>\\4dAaK]>`43000000O1O10000O001O1O100O100001XAeKe>^4N0100001O00N2001O1O000O1001O000O1001O000000001O]O^AdLb>\\3^AcLc>]3]AcLc>]3]AcLc>]3]AcLc>P4O1O1O0000O1O100A_A[La>e3_A[L`>f3`A\\L^>V4O00_ObA\\L^>c3cA]L]>c3dA\\L\\>d3dAYLOE]>R4cAZL`>f3`AZL`>f3`AZL0D]>S4bA\\L^>U40000001LbA`K^>m3aA[L5I^>l3^ASL20i>m3VASLo>m3QASLn>o3QAQLo>S40O0LQARLP?]2QAfNNROX?U2UAhMG5NLa?X2h@jME>`?o1`@fNV?e2N100m@ULn>P40000lB"}}, "object_label": "train", "attribute_label": ["color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "length, pattern, transparency", "answer": "The image features a train traveling down the tracks, with a large blue circle of light in the middle of the scene. The train appears to be a subway train, and the circle of light is likely a light on the train itself. The train is moving through a tunnel, and the scene is captured in a black and white photo."}, {"question_id": 564, "height": 424, "width": 640, "image": "000000015079.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [203.36, 8.25, 273.4, 214.84], "segmentation": {"size": [424, 640], "counts": "^Td27o<5L:G2N1O2M2N2N2N2N101N1O2O0O2M2N2O1O2N1O1O2N1O1N3N1O1O1O1O1O1O1O1O2N1O1O2N1O1O1O1O1N2O2N1O1O2N1O1O2N1O1O1O100O2N1O1O1N3O0O1N3O1N1O2N1O2N2O0O1O2N101O0O2O000O100O2O001O0O2O1O1N2O001O001N2O1O0O2O001O001N2O001O001O001O1O1O00001O1O001O000001O01O01O01O001O001O1O001O1O1O3M3L4lGlJ8O]7W5:001O0\\HiJV7X5fHmJZ7S5eHiJK0`7W5cHiJc7X5\\HgJe7Y552N10OXHdJd7\\5[HfJd7_505K000001O000000001O0001O01O0000001O01O010O002N2O2M3M3M4L5oHiIg6_6NO000J[IhIg6W6ZIhIf6X6ZIgIh6X6XIhIh6W65O2N1O2O0012M1O100O01N1N2000010O0000001N1000001O0O2O001O0O101O001O1O1O001O1O001N2O1N2N3K4M3M3N2N3M2M3K5N3L3N2M3L4M4M3M2N3L3O1N3M3N2N2N2M2O3CRFXMR:c2h0Bf0YO7I7I6F8J6BWSW2"}}, "object_label": "sandwich", "attribute_label": ["color:brown", "color:tan", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state", "answer": "The image features a close-up view of a sandwich cut in half, revealing its contents. The sandwich is filled with meat and jelly, making it a delicious and hearty meal. The sandwich is placed on a dining table, and a fork can be seen nearby, ready to be used for enjoying the meal. The sandwich appears to be a delicious and satisfying meal option."}, {"question_id": 565, "height": 400, "width": 500, "image": "000000046463.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [25.28, 66.59, 418.1, 265.46], "segmentation": {"size": [400, 500], "counts": "`g<331k;0TD:[;CjD0Ne0W;\\OkDj0T;VOlDn0KSOh:N\\E2N[1_:eNbE0N\\1^:nNdEQ1Y:ROcEA2]1X:UOiEl0U:TOlEl0T:hNhEO0M1N1^1U:iNiE21G1^1U:TOnEl0R:TORFh0o9gNiE0O20N1O`0Q1i9QOfEO051J`0f0_OC[:3fED?j0@\\O[:NfE10K`0i0@\\OZ:KfE100O11Na01^O`01@22[:NcE0000Od01\\O<OE31\\:MbE10O10b01_O?0Cc:M\\E0h0;XOEm:0oE0SO100U;OhE0SO50Ko:0QE0l09TOGR;0oE4T:LoE1Z9Oo12YDNZi01PVO003o9LlG1UN<n9C_F0m0b0j5^OoH2OOV20_Od0S5NWI_OV2O@d0XN\\Oc6O^Ie01\\OV22_O`0ZN_O^6k0SJSOV130?XNA_6j0nKTOYOf0k47mKROWN1\\O0<OE0000h0_66lKSOXN0\\O0;0FO01Nh0a65lKSOgM193NMF0Ok0`61gKROoM00075DK1032KR1]6JiKTOoMNM00373HK0O42LR1[6JjKTOTNOG193GK1023LR1\\6IjKTOTN0F0:7GHO91F02Of0]65kKSOnM0N386EHO91F0i00WO\\6m0kKSOnM0O27g0EWO0i0_64hKSOmM1O28f0DXO1h0_64hKSOmM1O37e0E4`60hKSOnM0L1N100;<Ej0]6EkKSORN1F01484GT1\\6@lKSOlM012K770IT1\\6_OmKTOkM01=3KHU1\\6_OmKTORN3G181HX1[6^OmKUOlM0M31O72GY1[6]OnKVOkM0M4O17OHZ1\\6\\OnKVOkM0M4O26`1T6TOoKVOkM0L40MN57_1U6UOSLVOcM0040MN66`1T6RO_LYO[M72_1S6POaL[OYM64^1S6nN]L[O^M1O1N09b1n5QOVL[OfM1O1O10N9b1m5ROnI\\On1OPN2M200007`1o5QOoI^Ol1MRN1M4O0O28]1P6QOnI_OJM2Og00`00iN1N015O27]1P6POPJ^OJM[24eM1046\\1o5POQJ^OLMQ21PN0O4N56[1n5PORJ]Oa22ZM46_1k5mNUJ^OT2NjM0O1MOO57c1j5lNVJ^OS2OiM1O1161`1m5jNUJALLj00YO0h01VO1O1073_1k5iNVJCT2KgM0O1130LO;2_1m5hNVJDJK6OO1O11NM0O11Og00]O1KO02OO2OO1080b1n5fNXJE`0M]OM22m0NoN001NO:9Gb1n5eNXJ@K1;OH01000O1W10nN9Ga1n5eN\\JBl27jLc1m5dN^JAl27hLf1m5aNfMB_L7Nf1m5aNfMB_L7Nf1m5aNYJBK0O0W38jLe1j5bNZJFKKW30jL41h1j5bNZJHR3JjL30j1i5`N]JDHO^33eLi1h5aN\\JC[34bLg1f5cN\\JCNOW35iLf1f5aN]JEMOV37jLc1f5bN]JEL0W37iLc1f5aN^JIIK\\39dLb1i5aN^JIIK\\3;dL]1j5eN]JHX34bL_1i5eN]JDJO^39cL^1h5fN\\JDKOO0\\3OdL84_1f5hN[JCLN01Z3;iLZ1f5iN[JCN0W3;jLY1f5jN[J@O2V3<iLX1h5iN^JBG0i0Od10dM>1X1i5kN\\J_OK0g00d10dM>1X1i5lN]J^OS3a0gLT1i5mN]J_Oa03b1=hMS1h5oN]J^O=8f17hMS1h5RO[J\\O?8e19hMQ1i5SOZJ[Ob06e0I_Od0VOo0j5SOUK@Z1>fMo0k5TOUK^OQOKW2W2d3aNmJYOZO4NKX2V2d3bNkJYOZO5[2o1`3cNoJ^OVONU2P2g3dNlJ\\OZO2S29jMR1m5WOlJ]OWO3R2ImM?1P1n5YOjJGZ13nMm0n5YOjJGZ15mMj0P6ZOiJF]13kMl0o5\\OhJD_14kMk0n5]OhJCa14iMl0n5^OhJBZOCR2a0oMl0l5^OkJYOVO12LQ2`0QNk0l5_OiJAWOIP2=SNj0m5@hJGV12TNh0m5@hJFX11SNi0m5AfJRO]O=NDo1c0SNj0l5@iJ@ZOCo1b0PNm0n5^OiJSOYO92Go1S2l3kNmJYOZOIl1e0QNf0l5CnJXOYOJl1d0RNh0j5CnJWOZOJk1f0RNf0k5DmJ^OS1;TNc0k5FnJ[OU1j1l3kNPKoNWO6n1IQNS2j5oNQKoNUO6o1P2j3lNQKnNVO5Q2P2h3nN]MPOjL=0k0h5JbLiN_N5WO<1m0f5IbLjN_NY2o4nNbLhN_N[2n4mN^MAmLf0d5J^M@nLg0c5I`M_OnLh0a5IaM_OnLh0`5JaM_OoLg0`5JaM@nLg0`5ZO_JBR3>oLf0a5YO^JCR3>oLf0a5YO^JDR3<oLh0`5I`M_OPMh0a5I^MhNPMb01m0a5J]M_OQMg0c5VO]JZO29m2FQM10d01i0c5XO\\J\\O19m2b0RMb0c5\\O^JAj2c0UM`0d5VO\\J^O0:k2S2i2SN_J]OM`0k2@VM\\2b5WN_J1i2]OUM[2b5XN_J@O;l2ATM\\2`5YNaJ0k2k1c2WNcJLi2AUMW2]5UO^MR1b2nNdJ_Nf2e2d2VNeJNg2k1c2XNfJMg2XOZM`2X5VO_MYNZMa2U5YO_MXNZM_2W5\\NjJLe2\\OZMZ2V5ZNkJXO4`0LAe23ZMZ2V5_NmJDNA0M`2g2e2XNkJSOO=0I`2`2d2VNnJRO2i0\\2XO`Mc2T5ZNnJRO3h0[2YOdM`2o4\\NnJWO0g0_2VObMb2o4[NPKVO0;OL`2EbMc2o4[NPKUO2;NKe2`0[Mn0o4YOPKQO51L0O126a2c0^Mk0o4^OQKTO0I18^2d0aMj0m4_ORKRO1I0:_2a0aMl0l4XOSKQO00060;b26_MQ1k4_OTKoN0<a25aMP1j4^OTKRO1JO=`29bMQ1i4]OUKRO2IN>`2:aMP1j4[OUKQO0M7;Z2H_M<2W1i4DWKcN5<IEa2i0aMo0i4EVKcN5?JAX2o0iMi0i4GVK`N6d0R2<iMj0h4\\OWKlN00006c0V26eMo0h4\\OWKUO5;V25fMP1g4\\OYKnN0L4e0U26gMo0g4[OZKnN0M4d0U27eMo0h4ZOlK^Of1]OhMl0Nn0h4[OmK]Oc1@iMg2g4\\NmK^Ob1\\2`2VNmK@b1^OjMg2f4XN[KoNc0d0`1\\OPN1Ld2f4[N[KQOd0b0f1V2[2WNZKQOf0b0d1W2\\2VNZKROf0`0e1<eMj0f4VO[KUOf0=^1@kM10m00j0f4]OQL\\O]1d0lMd0f4\\OPL\\O]1e0mMc0e4]OiKjNGa0o1`2a2XN]KfN51Na0o1_OmMm2d4[N[KiN8OMa0Q2^OkMm2d4[N\\KjN3OM04a0Q2_OjMl2e4aNbKcNNa0o1d0lMd0e4DbKcNO`0n1e0lMd0e4ClKTOc1e0lMd0e4BmKUOa1f0mMc0e4@nKXOa1`2a2XNnKXOa1_OmMm2d4\\NnKXOb1_2`2RN\\KPOc0?b1_OjMP10i0e4VOYLAW1d0kMe0d4TO]LBT1f0kMd0e4QO^LF^O_OP1V1_Nd0e4QO^LG]O^OQ1V1_Nd0e4PO_LI[O]OR11_No2d4jM]KWOo0b0_O^OQ10aNn2c4oM\\LE^O^OU1S1]Nh0c4nNaLIo0_2a2`MiLOg0a2a2^MiL1e0b2c2WMmL8?a2e2UMmL:>b2d2QMZKKe1b0=b2d2QMZKKe1b0>a2c2VMnL8`0a2b2oLZK1h1?<a2f2nLoL<?HhMi2e6_MVKD`NS3[6XMTKG]NOIR3f6ZMZICg10dNS3[6]M]Kc2c4^M]Kb2b4^M^K@mMo2e6]M[IDT2Q3b4XMVKF^N5Fh2f6]MVKF^NT3]6VMTKG^NS3^6[M[Ke2e4\\MZKAoMQ3f6^M[Kh0oMc0g6dN[KCnMQ10h0g6_NZIGR2V1nMb0h6_N`Kn0hMc0i6^N^KP1iMb0i6^N^KP1iMb0i6dNWKDoMT11d0i6gNTKASN8O`01P1i6gNWKe0PNd0j6fNUKg0RNb0j6^NUILR2T1oMb0j6^NZKR1lM`0j6^N[KQ1kMa0j6cNTIEn10RNW12a0j6gNQKBSNU11b0k6gNQKAUN1N41e00o0j6gNSKISNa01o0i6fNTKJRNa01o0j6aNXKHlM31d01o0k6^NTIJS23lM30c02o0k6bNSIGP2U1RNb0k6fNRKh0SNb0k6gNSKAQN6Oc02o0k6gNSKARN4O?OA2d1l6fNWK;kM[O2d1l6fNVKb0nMh0l6]NSIKY2P1hMh0l6\\N\\KMfMP11h0m6]NXKP1kMc0m6eNQKg0RNd0k4WNUM>1HnMc01P1k4WNUM?1a0oMi0n6fNmJAYNo0Lj0o6dNmJCWNP1Nh0n6ZNRINT20lM4Oe01o0o6YNWK1jMn00h0l4XNTM60P1PNb0P7cNkJGUNn0Oi0Q7cNlJDTN1OO0i00P1Q7dNkJCUN13f0MR1Q7cNjJDVN12e0MS1R7^NlHJn1OTN4Od01Q1R7\\NoJKoM5Nc01Q1T7\\NmJo0oMe0U7[NkJP1QNe0T7`NkHHg12YNj01m0T7dNcJBYN5N?4V1R7dNcJBZNi02Q1R7cNaJD[Nh02Q1R7bNhJGRNb02U1T7ZNkHLP24oMb01T1U7ZNjHM00g1P1\\Ni0S7cNaJGXNe04Q1T7dNdJ:ZNR1R7dNdJCUNO0:0H7h1Q7dNdJ2TNA7i1Q7dNcJ7\\NU1Q7cNVJEcN2Nc08S1R7`NWJi0gNg0R7aNVJe0kNj0P7bNSJc0nNk0o6cNWJD^N109c0`1h6cNVJC`NO15NMd0i1h6bNVJF`N20Kb0k1h6bNVJG_N6a0b1k6_NQJEdN5O7?`1m6[NUJJ_N4O7`0`1n6^NdHFY11gN??]1m6^NbHG_12cN3?h1l6bNQJAdNNf0P2e6aNPK`1Q5_NnJa1S5_NQJ@YOS2e6\\NlHAj03BQ2i6ZNjHCk02AR2j6ZNiHBl00CT2h6ZNiJf1X5[NfJf1Z5ZNfJf1[5YNeJg1[5YNeJg1[5XNeJi1[5XNdJh1\\5YNcJg1]5YNbJh1_5XN^Jj1b5VN^Jj1b5WN^Jg1d5YN]Je1c5]NdH_O\\1S2Q6]NcH@\\1S2Q6]NdH_OZ1U2R6]NYJc1g5]NYJc1h5\\NXJd1h5\\NXJc1j5]NVJb1h3lMZLb0WN_ON0X1R2Y4mM[La0WN_OM1X1R2Y4mM[Lb0VN^O]1T2U6_NSJa1m5`NRJ`1n5aNQJ_1P6`NQJ_1o5`NRJ`1n5`NSJ_1n5\\NVJc1k5\\NVJd1k5TN\\Jm1d5PN^JP2R8O1OdNRNVHn1k7QNVHm1W901O00001OdKUNSNk1l1VNTNj1l1VNUNi1l1VNTNj1l1VNUNi1k1WNUNi1l1VNUNi1[6N1O1N1O2O0M4M201O101N0N2K5O1O1O2L4N101M2O1M3O2N1BQD:P<ERD5NOT<0lCNV<150O1lWl0"}}, "object_label": "sandwich", "attribute_label": ["color:green", "color:white", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a close-up view of a sandwich held in a person's hand. The sandwich is cut in half, revealing its contents, which include lettuce, tomato, and cheese. The sandwich appears to be a delicious and appetizing meal, with the ingredients well-balanced and arranged. The person holding the sandwich is likely enjoying a tasty and satisfying snack or meal."}, {"question_id": 566, "height": 424, "width": 640, "image": "000000091406.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [106.54, 317.0, 50.6, 23.64], "segmentation": {"size": [424, 640], "counts": "Xd\\12T=2O2N1O100O1O1O1O1O1O2OO0CXC<g<EZC:f<FZC:g<EXC<g<3O10000O2O0O1001O1N10001N100O2O001N100O2O2M2O000O101NoTZ6"}}, "object_label": "pizza", "attribute_label": ["color:red", "color:yellow", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state, texture", "answer": "The image features a close-up view of a pizza with various toppings, including pepperoni and cheese. The pizza is placed on a table, and it appears to be a slice of pizza. The toppings are distributed evenly across the pizza, making it visually appealing and appetizing."}, {"question_id": 567, "height": 424, "width": 640, "image": "000000091406.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, length, material, texture, transparency", "region_anno": {"bbox": [0.0, 184.47, 155.01, 60.53], "segmentation": {"size": [424, 640], "counts": "[_82U=2O1N3N000000O1000O100000000ZCI[<6fCKY<5fCLY<6fCJZ<7bCL^<?000000O10O100000O2O00O010000000001N01000000O100000O100000O10O0100000O3N1O0O10MfCXOZ<h0eCYO[<k0O1O1N1000O100O100O1IjC\\OU<d0lC\\OT<d0lC\\OT<d0lC\\OT<d0jC^OU<c0kC]OU<c0jC]OW<c0iC]OW<c0iC]OW<b0kC\\OV<c0kC]OU<c0kC]OU<c0kC]OU<c0kC]OT<d0lC\\OT<d0kC]OU<c0hC@X<`0iC^OX<b0hC^OX<b0hC]OY<b0fC@Z<`0fC@[<?eCA[<>gCAY<`0eCA[<e0100HdCD\\<<dCD\\<;fCDZ<<fCC\\<;eCE[<;eCE[<;dCF\\<:dCE]<;aCG`<7aCI_<7bCH^<8cCG]<9cCF^<:bCE_<:aCF`<:`CF`<:`CFa<9_CGa<9^CHb<7_CIa<7_CIa<7_CHc<8ZCJf<=O000001O0O10nCIS;7nDIQ;MYD2h00o:N]E0lNLd;2cEOjNOc;2_10002NTdX6"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color", "answer": "The dining table in the image is long and wooden, with a brown surface. It is set up with several chairs, some of which are empty. The table is located in a classroom setting, and there is a book on the table. The chairs are arranged in rows, and the table is positioned in the center of the room."}, {"question_id": 568, "height": 640, "width": 480, "image": "000000108253.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [114.31, 270.66, 102.41, 49.33], "segmentation": {"size": [640, 480], "counts": "SQZ23lc02O1N3N1N10000O101O001O0O101O001O001O001O0O2O0O2O0O2O1O001O1O0O101O001O001N101O00001O0O2O001O00001N10001O001O0O10O10O01O1O1O10O01O1O1O1O1O1O1O1N2O1O100O1O1O1O1O1O1O1O001O1O001O1N2O100O1O1O1O1O2O0N_ST5"}}, "object_label": "pizza", "attribute_label": ["color:brown", "color:yellow", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a close-up view of a pizza with a crispy crust, topped with cheese and possibly some other ingredients. The pizza is cut into slices and is placed on a white plate. The plate is positioned on a dining table, and there are two forks nearby, one on the left side and the other on the right side of the plate. The forks are likely used for eating the pizza slices."}, {"question_id": 569, "height": 640, "width": 480, "image": "000000108253.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [420.12, 241.38, 59.88, 101.44], "segmentation": {"size": [640, 480], "counts": "o[W86ic03c\\Oi0la0ZOn]Om06XOj`0Nm^Oj1o`0e0O2N100O1000000O100000000O10000000000O1000000000000000000000000000000000000000000O11O00002N1O0001OO0001O1O15G^H"}}, "object_label": "bottle", "attribute_label": ["length:short", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a glass jar or bottle filled with a green substance, likely herbs or spices. The jar is placed on a table, and it appears to be a small glass container. The green substance inside the jar is visible, and it seems to be the main focus of the image."}, {"question_id": 570, "height": 424, "width": 640, "image": "000000122962.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [318.87, 291.52, 26.88, 16.76], "segmentation": {"size": [424, 640], "counts": "]aS41U=3O1O2N10O1O01O010O1O1O001O10O01O01O00001N001O0O1O1N4Ncki3"}}, "object_label": "pizza", "attribute_label": ["color:red", "color:yellow", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, texture, state", "answer": "The image features a slice of pizza on a blue plate, which is placed on a dining table. The pizza slice is topped with cheese and appears to be a pepperoni pizza. The plate is positioned in the center of the image, and the pizza slice is the main focus of the scene."}, {"question_id": 571, "height": 424, "width": 640, "image": "000000122962.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [313.61, 206.13, 26.86, 16.02], "segmentation": {"size": [424, 640], "counts": "nVR44T=1O010O2OO0100O100O101O0O0001O0O2O00000O1O101O0O2OXPl3"}}, "object_label": "pizza", "attribute_label": ["color:red", "color:yellow", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture", "answer": "The image features a slice of pizza on a blue plate, which is placed on a dining table. The pizza slice is cut into a triangular shape, with a few pieces missing, leaving a gap in the middle. The plate is positioned on the table, and the pizza slice is the main focus of the scene."}, {"question_id": 572, "height": 426, "width": 640, "image": "000000140640.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [477.81, 364.56, 115.61, 60.41], "segmentation": {"size": [426, 640], "counts": "_lX64U=2O1N1O2UCHa<<51O4L2M1000J^CDa<c000000O00100001O001O001O10O100O6J5LO1M3jCC[;c0[DCe;Q1O1000000O100O1M3M3N200O10`NaDU1^;lNbDT1^;lNbDT1^;lNbDT1^;kNcDU1];kNcDU1];kNcDU1\\;nNbDR1^;oNaDQ1_;oNaDQ1_;mNcDS1];=00000XNdDb1\\;^NiD]1W;dNhD\\1X;fNeD[1Z;hNcDY1];:001O00000000000000000000001O0000000000000000001O000000001O001O2N2N1O3M5K4K3N8H7I3M4K3L]oc0"}}, "object_label": "cake", "attribute_label": ["color:green", "color:white", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color", "answer": "The image features a large, white cake with white frosting, placed on a dining table. The cake is adorned with a green leaf, adding a touch of color to its presentation. The cake is being cut into by a person using a knife, and there are several cupcakes surrounding the cake on the table. The scene appears to be a celebration or gathering, with the cake being the centerpiece of the event."}, {"question_id": 573, "height": 361, "width": 640, "image": "000000172571.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [490.61, 55.14, 127.46, 60.95], "segmentation": {"size": [361, 640], "counts": "`h[55R;6K1N3N1O2N10001N1O100O2O000000000010OoEYO`9g0_FZOa9f0_FZOa9f0_FZOa9g0_FXO`9i0<5L3O1ZFnNT9T1jFmNU9T1kFlNU9T1kFlNU9T1kFlNU9U1kFjNU9V1`0O0100O3N0OO2O0MPFmNQ:U12O0O1O2M3I:BUm3GUSL9J5K5N101M3O1N2N2N10100O1O1QFoNf9Q1YFQOe9P1[FQOd9o0\\FROb9n0_FROa9n0_FROa9n0^FTO`9m0`FSO`9m0_FTOa9l0_FTOa9Z1O10000O10000O01000O1000O2O0O2O0O1000O10O0001O1O01O100O1O000000001O1N2O1N2O1M4N2M3M3M4K5K4N3KWf7"}}, "object_label": "pizza", "attribute_label": ["color:red", "color:tan", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color, texture", "answer": "The image features a slice of pizza on a white plate, with a glass of wine placed next to it. The pizza appears to be a deep dish pizza, and it is topped with tomato sauce. The wine glass is filled with wine, and it is positioned close to the pizza, creating a visually appealing presentation."}, {"question_id": 574, "height": 361, "width": 640, "image": "000000172571.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pattern, size, texture, transparency", "region_anno": {"bbox": [86.96, 77.08, 553.04, 283.92], "segmentation": {"size": [361, 640], "counts": "nhP14j:<K4I7E;J6L4N200cL`NQM`1P3_NPMa1\\601O1O1O1O1O1O1O1O001O1O1O001OPKmNJS16mNLQ1AoNkK0INl4R1TO]OULEJLm4R1POETL^ONMn4o0iN=V1CcN>`LcNo4n0XNh0jLXNP5o0nMQ1V2oNdMX1\\2gNaM\\1`2cN_M]1c2bN]M]1d2cN[M^1f2aNZM_1f2aNZM^1h2aNXM^1i2bNWM^1j2aNVM^1l2aNTM^1m2bNSM^1n2aNRM_1n2aNRM^1P3aNPM_1P3aNPM_1Q3`NoL_1R3aNnL^1T3aNlL_1U3`NkL_1V3aNjL^1X3aNhL_1X3aNhL^1Y3bNfL_1[3`NeL`1\\3_NdL_1^3aNbL^1_3bNaL^1`3aN`L^1a3bN_L^1a3bN_L]1c3bN^L\\1d3cN[L]1f3cNZL\\1g3dNYL\\1g3dNYL\\1h3cNXL\\1i3dNWL]1h3cNXL]1i3bNWL_1i3`NWL_1j3aNVL_1k3`NUL_1m3`NSL`1m3`NSL_1n3aNRL^1o3bNQL[1R4eNnK[1S4dNmK\\1S4dNlK^1S4bNmK_1S4`NnK`1Q4`NnKa1R4_NnK`1S4`NmK`1T4^NmKb1S4^NnKa1S4^NPL^1Q4cNhLNaL>i6CQM8o2HTM1QLNk61UMORLNj63ZMMf23Y4O0000001Oohh01QlVO0_:d0J5M100O0100O001O1O001O001N^OZOdFe0\\9[OdFe0\\9\\OdFb0]9_ObFa0^9@bF?^9AcF=^9DaF<_9EaF:^9HaF8_9IaF5`9M_F2a9O^F1b90^FOb92^FLc95]FJc96^FIb97_FHa99^FGb99`FE`9<bFA^9`0bF_O^9b0d01O001N20O01N2O1O1O001SFBm8>TGBk8?VG[On8f0QGYOP9h0PGTO_O0`9l0QGSO@2^9k0WGSOj8n0_GQOX8o0hGQOX8P1fGQOZ8P1eGPO[8P1eGPO[8Q1dGoN\\8Q1eGnN[8R1eGnN[8S1dGnN[8R1eGmN\\8U1k02N001O0000001O001O2N001O00001O001O001N2O1O01OO2O1O000000N2L4O1N2N2N2L4N2M3O1L4L4O2M2M3O1K5M3N3Med42X[K5L3N2N2O1HCbE>[:EdE;Z:<L4M2M4N1L5L3N3M2M3N2N3M2M301O01O001O100O1O010O0010O01O00100O01O01O001O010O0010O1O10ObLSN`Mm1_2TNbMk1^2UNbMY1cLVOk5AbMY1cLVOk5BaMX1dLVOj5CcMh1]2XNcMi1\\2WNdMi1[2XNfMg1Z2YNfMh1Y2XNgMh1X2YNhMg1X2YNiMg1V2XNkMh1T2YNmMf1S2[NlMf1S2ZNnMe1Q2\\NoMd1Q2\\NoMc1R2]NnMb1R2_NPN^1Q2bNoM]1Q2dNPNW1T2iNmMU1S2lNmMR1U2nNlMP1U2POkMo0V2QOjMn0V2SOjMk0W2VOjMh0W2XOiMg0X2YOiMe0W2\\OiMc0X2]OiMb0V2_OjM`0W2@iM`0W2@jM?U2BkM>U2BkM>T2CmM<S2DmM<S2DnM;Q2FoM;P2EPN<n1ESN;l1ETN;k1FUN:k1FUN<h1EXN<g1DZN<d1E\\N<c1D]N=a1D`N<_1DaN=]1DcN<\\1EdN;\\1EdN;[1FeN9\\1GdN8\\1IeN6Z1KfN5Z1KfN5Y1LgN4Y1LgN5W1LjN3V1MjN3U1NkN3S1NmN3Q1NPO1o00QO0o00QO0n01ROOm02SOKP15POKo05SOJl07TOIk09TOFm09TOFl0;TODl0=TOAm0a0RO_Om0b0TO[Om0f0SOTOR1m0nNPOT1P1mNlNW1T1^42iLcN_L]1a3iNYLX1g3iNWLX1i3iNTLY1l3hNRLY1n3hNPLZ1P4gNmKZ1S4gNjK[1V4gNgKZ1X4hNfKY1Z4hNdKY1\\4iNaKW1`4jN^KW1b4kN[KV1g2YNQMc05U1b2eNTM85V1`2lNYMO2X1d2lNXMNOY1j2hNVM3JX1P3eNVM5FX1T3dNUM7BW1Y3bNUM>UOW1e3\\NUMb0hN[1S4SNUMc3l2]LTMc3l2]LTMc3l2]LTMd3k2\\LUMd3k2]LTMc3l2]LTMc3l2]LTMc3l2]LSMd3m2]LRMc3n2]LRMc3n2^LQMb3o2^LQMb3o2^LPMc3P3^LoLb3Q3^LoLb3Q3^LoLb3Q3_LmLb3R3`LmL`3S3`LlLa3T3`LkL`3U3`LkL`3U3aLjL_3V3aLjL_3V3aLiL`3W3aLhL_3X3bLgLfNVOc4S4gLfL_3Z3cLcL^3\\3dLcLkN[OS4R4SMaLkN]OR4R4TM_LlN^OP4S4UM]L[3d3fLZL[3e3gLXL[3h3gLSL]3l3bMoKd1Q4j2OfKoK^1Q4bNoK^1Q4m20]KoKn1Q4RNoKn1Q4e2O11O0bKoKd1P4k200000lKQLn0o3QOSLm0n3UOPLk0P4WOoKh0Q4XOPLg0P4XORLg0n3YOSLe0n3\\OQLe0n3[30TLoK`0Q4@oKa0o3@RL?n3BQL>o3^30VLQL:o3ERL;n3gMQL=2k1m3hMRLW4m3jKSLV4m3jKSLV4m3kKRLU4n3c1O1000oLSLfNm3[4000000O10000O1000aMUL`Mk3`2VL_Mi3b2WL^Mi3b2WL^K4]1K"}}, "object_label": "dining table", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color, texture, material, transparency, cleanliness", "answer": "The dining table in the image is set with a variety of items, including a pizza, a wine glass, a fork, a knife, and a cup. The pizza is placed on a plate, and it appears to be a deep dish pizza with a thick crust. The wine glass is positioned near the pizza, and the fork and knife are placed on the table, ready for use. The cup is also present on the table, likely for a beverage. The table is surrounded by chairs, indicating that it is a dining area."}, {"question_id": 575, "height": 427, "width": 640, "image": "000000180878.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [116.37, 37.99, 310.63, 306.78], "segmentation": {"size": [427, 640], "counts": "iVd1l0Y<8J9UDPOn:Q2dHeMU3`2gL_MY3i2a35K6Jb0]O7J=C<D9Fd0]O2N4L2N1N2O00O10000000O10O100O10O100001O00010OO2N101N3N2N3L3N1O1M3O0O010O1O10`I[IZ6l6O00O10O10OZJTIo4l6h000O110O00001O010O1O001O1ORJZIW5f6iJZIX5e6g00]LZIb0e6^O[Ib0e6^O[Ic0d6R3001O000]L[Ic0b6]O_IjMOm18]Mi5l2PJU1n5MSJTLNd2n5m0SJ]L4MLO0j2m5`0TJmL1J5OI1Oj2m5?VJjL>L@P3k5;VJnL9HGo2i5R1WJPL0m2j5^4O1O001N2MnL[JbNd5_1\\JaNQ5QM]KY4BlNb5_4HZHjJh7T5YHkJh7U5XHkJh7U5XHkJh7V5WHiJS4NTL2Q3W5hLhJ^4OlN]5GcJQM0m01`2\\5BcJQM0`4]5DcJlK0[3\\5EdJe1[5\\NeJd1[5\\NeJe1Z5PLfJ`10_2[5QLeJ`10_2Z5RLfJ_10_2Z5RLfJ_11iMOa4Z5WLfJ^12jMNa4Z5WLfJ_11^2X5TLgJ^10^2Z5_NfJa1Z5_NfJa1Z5_NfJa1Z5_NfJ`1[5`NeJRN1S2Z53eJbM0[2[54eJSM2T3Z5IdJQM4FNU3[54cJQM4GMT3\\53dJRM2IOo2\\56cJSMOJ0n2`54`Jl0a5`LaJR6_5mIaJS6`5mI`Jh2NIc5]M`Ji2MJc5^M`JS6Y5YIfJc02T6T5]IkJ>1T6T5_ImJ;OV6S5^IQK:Ml2KLW5kLVK<Hl2MKU5mLXK;Gj1JfN3ROMS3W5PMXK;Gj1KdN0\\2W5kLWK;Gj1LcNO\\2Y5kLVK:Gg1IoM1j00UOOR3\\5lLUK=Gf1HPN0m03T2l5YMZJe1GTO2m1n5YM[JT6e5lI]JQ6e5nI\\JQ6d5oI]Jo1Ad1S6\\LaJk1_Og1P6^LdJg1]Oj1P6_LgJb1VOS2S6[LiJT1SOlN0f3T6ZLlJQ1POJ2n1^5nLQK8b0P1nNK2m1]5QMQK8b0\\1nNPO1\\2^5QMPK7f0X1lNZ2^5WLPK7h0W1iNRO2`2_5PMmJ7k0j1lNl0]5SMlJ6m0j1jNm0^5RMkJ7n0i1hNn0`5RMjJ7P1W1aNnN4c2a5QMjJ8P1?aN;3m1c5QMiJ=k0:fN24XOOn2c5QMhJ?E@Q1g0mNZOOc06^OKo2f5oLgJe0h01jN44^2c5hLgJ9GKQ1`1lNd1f5hLfJm0`0g0TOd1f5iLeJP1>b0YOc1f5iLcJR1EnNf0W1ZOQO3n2T6kMeJ6SOQO3o2V6fMhJHnNC084f2W6jMhITOc0i0\\OYON33m2X6lMeIUOe0d0]O[OO55f2U6[N[J]O\\OL3\\2V6ZN\\J7]O_1X6YNgIfNa0b1^O`1Y6`NXJU3h5nLVJP3j5RMVJm2k5PMXJn2i5PMZJo2f5SMgI]N:1B[4]6YMcIbN9II1Nb02l2l5cL\\Jm10PNH2O=0A3^3g5iL_Ji1OQNI1N?7l2b5lLaJc13VNH`01k2c5mL`Je1ISN2O1f0Lf2h5nL`Jk1HjM7V4b5UL_Jo1Nk1\\1mKa29ULk1GlM8Q4\\1oKa28TLl1GlM5NLQ10QOOi2d1WMa28TLl1GlM9n0Gn1f1TM_28TLQ2OgMH30^3h1_L]28TLT2KbMO5N\\3h1aL]27SLV2O[NJP2h1XM\\28RLQ2HgM9e0LP2g1ZM[29QLV2K`M0j0Nl1l1\\MZ28QL\\2Mh0i1fLX26RL]2Le0d1oL`2NPL^2Ke0g1mL_20oKW2IeM0U3l1iLc25hKX2HcM5T3k1iLc27eK^2N?Q2nLU25lK^2O=Q2PMU24kK^20<c6VM]I]21;d6XM[I]2N]MKl2n6ZMYI]2N]MKi2Q2YMj24\\K]2M^MLe2S2]MRNO\\44fK]2N]MKe2_2\\MS25eK^20OZ2^MQ25eK^2L]MM`2Y7eMnH_2I_MO[2\\7fMmHQ5HlJ]73kHo4W2lJc25VKd2H]Oa2kM`24WKd2H\\Of7QNaHd2IUOl7WN[Hd2ITOm7XNZHd2ISOo7XNXHe2IQOR8YNUHe2JQOR8ZNTHW2IhM011f1S8ZNSHU2LhM00Oh1T8ZNQHX21fMJg1U8[NPHY20eMKf1W8[NnGZ20eMJf1Y8[NmGY20gMIe1[8[NlGX21hMHd1\\8\\NkGX23fMFf1\\8\\NkGP2HSN7KOe1Y8\\NiGo17QNEf1[8ZNiGm17UNEd1[8ZNiG3Hj00XO20c0O^Ob1]8ZNhG2Ji0OWO43?M@f1\\8XNhG2Kf01WO26NK:1Ei1]8VNhG2Le00XO27LK61H00k1`8RNhG4L=LB5O06LJ47Kg1j8TN[G17KL1N6KK3Z2g8fMaH2QOX2n9gMTFNBU2h8kMgH1gN0LY2a8lM\\GKQ1NA3@Y2\\1jM_52SIJf01_OO<1@[2Z1jMb50SIJf01_OO=a2d0jMf5CWI4i0MXO2:MGa2o0mMg5LoIIZO12NK21_2m0nMm5ITIHe01@1O7MZ2h0QNS6DTIId01@0OQ38lLLg0f6BSIIc03^O`0Oa3m6SLTIH<OF5N`0Oa3m6SLSIK0d5m6aJSIY11f2n6PLQIf5o6ZJQIf5o6:2O00000O101O0O2O000O2O0000001OO010001N1O1K5N3N1O2O0O2O001O0O1L4L4N2M3N3M3M2N6K>A>B<SNoFjNd9DnE5g01k;K5JVig2"}}, "object_label": "cake", "attribute_label": ["color:black", "color:white", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color, state", "answer": "The image features a large cake with a unique design, resembling a suitcase. The cake is placed on a table, and it is adorned with a pair of high heels and a cell phone. The cell phone is positioned on the right side of the cake, while the high heels are placed on the left side. The cake appears to be a birthday cake, and the decorations suggest a celebration of someone's special day."}, {"question_id": 576, "height": 427, "width": 640, "image": "000000180878.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [404.93, 203.26, 107.47, 109.39], "segmentation": {"size": [427, 640], "counts": "oSY52V=7L1N1000001TC2Y<NdCe0l;b0K2M4J4J5M4L3N2O2M2N2O1N3K4O1N2N3N1O1O2N100O1O2O0O1000001O00000000001O00000001O000000000000000000000000000000000O2O00000000000O10000O2O0O1O1O1O100O100O101N1O1O1O2N1N3N2M3^OUEaNm:^1TE`No:^1WEYNP;MWEU1l;I2O0O1O1O3Klif1"}}, "object_label": "cake", "attribute_label": ["color:black", "color:red", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, color, size", "answer": "The image features a red cake shaped like a car, likely a Citroen, with a license plate that reads \"Jaynee.\" The cake is placed on a table, and it appears to be a birthday cake. The car-shaped cake is the main focus of the image, and it is likely the centerpiece of a celebration."}, {"question_id": 577, "height": 334, "width": 500, "image": "000000189078.jpg", "category": "description", "question": "Describe the banana in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [21.27, 74.83, 177.24, 130.77], "segmentation": {"size": [334, 500], "counts": "b[74Y:4K3N2M3M3M3N1N2N2O1O1N2O001O1O1O1O1O1O1O1O1O\\OVGFj88\\GCd8;h0O2N1O1O2O00001O000010O000010O0100O001O010O1O100O010O1O1O1O10O01O100O1O1O100O100O1O100O100O1O1O100O100O100O1O10O010000O10O01O1000O00100O100O010O10O0100O010O10O10O1O1000O00100O10O010000000O100000000O1000001O00001O00000000000O010000OK_F^Ob9?7N3O00001O01O00000010O3N1CQF9T:NROIhG4V80jGNXOOc83VHNWONd83VHNS83SGO?M^85nF30He95YF:7DT91eF<5EU9c0hF]OY9d0eF]O[9j01O2O0JbF[O`9OcFc0]9\\OfF`0h9F]RS3"}}, "object_label": "banana", "attribute_label": ["color:black", "color:yellow", "state:full/whole", "texture:smooth/sleek"], "control_dims": "texture, state", "answer": "The banana in the image is yellow and appears to be overripe. It is placed next to a red pepper, which is also overripe. The banana is positioned on the left side of the image, while the red pepper is on the right side. The two fruits are placed on a table, and there are other fruits in the background, including a bunch of bananas and a bunch of apples."}, {"question_id": 578, "height": 640, "width": 480, "image": "000000226147.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [243.55, 351.04, 141.53, 48.3], "segmentation": {"size": [640, 480], "counts": "Z_i47`c0Jf\\O9Yc0Hf\\O9Xc0;M1O3M3M1O2N010O001N1010oNT]Ol0Pc01JSOX]Ol0hb0UOW]Ok0jb0SOW]On0Uc0H10O0B[Oa]Oe0`b0ZO`]Of0mb01O001O0LYOn\\Oh0Qc04GSO_]On0`b0RO`]On0`b0RO`]On0ib00O2N100010O000POT]Om0kb0SOW]Ok0ib0UOW]Ok0ib0UOW]Ok0ib0UOW]O<M1kb0DW]O95Ndb0IW]O96Nbb0JW]O87Nbb08^]OHbb09]]OGcb09]]O_OJ5hb0<b]OD^b0<b]OD_b0;]]OIdb07V]O@0;ib0h00000000AW]O^OO5ib0=X]O^OO5ib0=X]O]O14hb0`0W]O[O23hb0b0\\]O]Oeb0c0\\]O[Ofb0OS]Ob0\\c0O00f\\O@Wc0c010O01]Og\\O=`c0O^ODU]O01<hb0HT]O5N1nb0KR]O501mb0JS]O501mb0JS]Oc0mb08000FT]O@mb0LS]O=0Hlb0JV]O=NImb0HV]O>NJRc02n\\OF08Rc01S]OOnb00R]O0nb00S]O0lb01R]O0nb00P]O2Pc0Oo\\O1Qc0NP]O2Qc0MP]O2Pc0No\\O3Rc0Ln\\O4Rc0Ln\\O4Sc0Km\\O5Tc0Jl\\O6Uc0Ik\\O7Xc0Eh\\O<]c01O10000O2N10Ac\\O;]c0Ec\\O;\\c05O100000Ah\\O6ib0Fa]O4F6hb0H_]O5H3hb0I_]O5I2ib0H^]O6I2ib0H]]O7K0ib0HZ]O;KNkb0GY]Oi0ob00001@n\\O0Rc00m\\O1Sc0>1N101O1O000O3N1O3L3M1O3M2MPdk1"}}, "object_label": "sandwich", "attribute_label": ["color:brown", "color:white", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, state, texture", "answer": "The image features a white plate with a delicious sandwich on it. The sandwich consists of two slices of bread, each topped with a variety of ingredients. One slice of bread has eggs, bacon, and onions, while the other slice has eggs, bacon, and tomatoes. The sandwich is presented on a dining table, and a person's hand can be seen in the background, possibly preparing to pick up the plate or enjoying the meal."}, {"question_id": 579, "height": 640, "width": 480, "image": "000000226147.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "material, pattern, pose, texture, transparency", "region_anno": {"bbox": [32.78, 219.41, 54.65, 207.1], "segmentation": {"size": [640, 480], "counts": "bod0S1ib06L3L4M3L5M2M3M3L5K5QLkMlEY2S:TN\\EP2d:\\OmCh0R<MTC8l<_30O01O01O01O0000000000000000000000O100000O100000O1000000O01O0001fJQCH<P2d<aMeE[2T>K4L4K4L5J6K4[Oh]O[O^b0>g0H8M4K4M\\l`7"}}, "object_label": "vase", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern", "answer": "The image features a tall, clear glass vase filled with water and a single flower. The vase is placed on a table, and the flower is positioned towards the top of the vase. The vase appears to be a simple, elegant design, and the flower adds a touch of natural beauty to the scene."}, {"question_id": 580, "height": 480, "width": 640, "image": "000000227985.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [320.71, 110.36, 275.07, 319.42], "segmentation": {"size": [480, 640], "counts": "ijl44k>7J4L1O3TOj0J6K5H8F;G8E;J6K5H8PEaL[:b3>3N3M2N3L3L5L4]EfK[:b4VF_KP9e4oF[Km8j4RGVKk8n4a04M102M2N1O1O2N2N1N3N2N2O0O3M1DXJ_Gj5`8;O2O1O1N101N101O001O1N100O3N001O001O00001O0UHYI]7h6bHXI^7h6<2O0000001O01O01O001QHTIh7m6UHVIj7P700_HmHU7S7lHlHT7P7cHPIk7o630RHQIk7T7NjNVHWKi7h4^HSKa7m4cHQKFSO20Y7l5kHUJIP13oNZ7k5iHWJJo04oNX7l5jHZK\\7f4dH[K[7e4fHYJIi0b7m4eHZJIj0a7l4eHVJJ10n0`7l4jHTJHo0^7n4nHTKP7l4PIVKn6j4RIVKo6j4PIVKP7j4PIVKP7j4PIUKQ7k4oHUKQ7k4oHUKQ7l4nHUKQ7k4oHUKQ7k4oHUKQ7m4mHTKR7l4nHTKR7l4nHUKKnNl6l5YIXKGoNo6i5ZIcKe6\\4\\IeKc6[4^IdKb6\\4^IdKb6\\4^IdKc6\\4[IeKe6\\4YIeKg6[4YIdKh6]4VIcKj6]4VIdKj6[4UIgKk6Y4UIhKj6X4VIiKi6W4WIjKh6W4VIkKi6V601O0000O100O100000000001O002N2N100O1O1N2O001O1O1O001O10O01O00100O001O1OlMeIcK[6b6O1OlMgIbKW6_4jIaKU6_4kIbKT6e601O0O2O1O1O001O001O001OYOTJ[Hk5e7VJZHj5f7XJYHg5h7YJXHf5U6VJjJ3QOg5U6VJiJ5QOe5V6VJiJ5ROd5U6WJiJ5SOc5T6YJhJ5SOb5U6YJiJ5POc5W6XJiJ6mNd5Z6VJiJ8jNc5]6UJiJ8iNd5]6TJkJ9fNd5^6TJmJ8cNe5`6RJnJ`6R5`IoJ_6Q5aIoJ_6Q5aIPK^6P5bIPK^6P5bIQK]6o4bIRK^6n4bISK]6l4dITK\\6j4fIVKZ6j4gIVKX6k4hITKY6k4gIUKZ6j4fIUK[6k4fISK\\6m4cISK^6m4dIoJ^6S5dIoI0K^6W6_JfIb5T5aIhJK:S1Hb5S5hIdJDb0X1^O_5Y5`IkJEO0b0Y8^4VHnKk7h1gG\\O;QOn7S1fGiM2N9P22ZNCJ1`0Z8i1eGeM9o14XNEH1d0X8U4RHVK7e0h7Q4RH[K6d0j7m3jHRLY7G`Ge3[1aLY7BbGi3l0ULUO`0i8X3jGYL[Ol0j8h2mG^LXOj0l8e2mGbLSOL0m0P9a2jGaLZO5Ko0P9Z2lGcLWO[1n8m1^GjLKa1h8b1^GoLCe1P9W1kGTMRO^1V9W1lGZMPO^1V9o0TH`MeNa0O=]9XOeFOd0i0j0ROaN7OJ7:K2h::nF_OXNJ80I627m:D[G6lMHK805a=HdBKL7O6d=j02O1N6[OSBMo=LPBI3:o=KVB3l=LUB3n=JSB5]>NEKoA3`>ME0_?1m@01OVSg0"}}, "object_label": "sandwich", "attribute_label": ["color:brown", "color:white", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, texture", "answer": "The image features a sandwich cut in half, placed on a white plate. The sandwich is made with two slices of bread, and it appears to be a ham and cheese sandwich. The sandwich is served on a dining table, and there is a knife nearby, possibly used for cutting the sandwich. The plate is positioned on a wooden table, giving the scene a cozy and inviting atmosphere."}, {"question_id": 581, "height": 480, "width": 640, "image": "000000227985.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [542.78, 53.67, 97.22, 88.82], "segmentation": {"size": [480, 640], "counts": "fQo73m>1O1O1O100O001O100O1O100O002N010O1O010O1O100O10O01O100O100O010O100O10O0100O100O10000O01000O100O100O01001N01000O1O100O02O000000O1000000O1000O010000O1000000O1000000000000O010O10000O10000000000cL"}}, "object_label": "knife", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, pose, cleanliness, texture", "answer": "The image features a large, silver knife with a sharp tip, lying on a wooden table. The knife is positioned horizontally, with its blade facing upwards. The table appears to be made of wood, and the knife is the main focus of the scene."}, {"question_id": 582, "height": 480, "width": 640, "image": "000000227985.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, texture, transparency", "region_anno": {"bbox": [0.0, 1.08, 640.0, 473.53], "segmentation": {"size": [480, 640], "counts": "2k4^3g1gLXNZ3i1dLWN_3g1`LWNd3h1\\LVNh3h1YLTNn3h1RLVNR4h1nKVNW4g1hKWN^4f1cKXN_4g1bKVNb4h1^KWNe4g1[KWNh4h1WKVNo4g1QKXNR5f1oJ[KMi1W5k2lJ\\KMg1\\5j2gJ_KMe1`5j2cJaKMc1d5j2_JXNc5g1]JXNf5f1[JXNh5f1WJYNl5f1TJYNn5f1RJYNQ6e1oIYNV6d1jIZNY6e1gIZN[6e1eIZN^6d1bIZNa6e1_IZNd6d1\\I[Nf6d1ZI[Nh6d1XIZNk6e1UIZNm6e1SIZNP7d1PI[NS7c1mH\\NV7b1jH]NX7b1hH]NZ7b1fH]N\\7b1dH]N_7a1aH^N`7b1`H]Nc7a1]H^Nd7b1\\H]Ng7a1YH^Ni7a1WH^Nl7`1TH_Nn7`1RH_NP8`1PH_NR8`1nG`NT8^1lGaNU8_1jGaNX8^1iG`NZ8^1fGaN\\8^1dGaN^8^1bGbN_8]1aGaNb8^1^GaNc8_1]G`Ng8]1YGcNh8\\1XGcNi8]1VGdNk8[1VGcNl8\\1TGcNo8[1QGdNP9\\1PGcNR9\\1nFdNS9\\1lFcNV9[1kFdNW9[1iFdNY9[1gFdN[9[1eFdN\\9\\1dFdN^9Z1bFeN`9Z1`FfN`9Z1`FeNb9Z1^FfNc9Y1]FfNe9Y1[FgNf9X1ZFgNh9X1XFgNj9X1VFhNj9X1VFgNl9X1TFhNm9W1SFhNo9W1QFhNQ:W1oEhNS:W1mEhNT:X1lEhNU:W1kEhNW:W1iEiNX:V1hEjNX:V1hEiNZ:V1fEiN\\:V1dEjN]:U1cEjN_:U1aEjNa:U1_EkNa:U1_EjNc:U1]EkNd:T1\\ElNd:T1\\ElNe:S1[ElNg:S1YElNi:S1WEmNj:R1VEmNk:S1UElNm:S1SEmNn:R1REmNP;R1PEnNP;R1PEnNQ;Q1oDnNR;R1nDnNS;Q1mDnNU;Q1kDnNV;R1jDnNW;Q1iDnNX;R1hDnNY;Q1gDoNZ;P1fDoN[;Q1eDoN\\;P1dDPO];o0cDPO^;P1bDPO_;o0aDQO`;n0`DQOb;n0^DQOc;o0]DQOd;n0\\DQOf;n0ZDROf;n0ZDQOg;o0YDQOh;n0XDROh;n0WDSOj;l0VDTOk;k0VDSOk;m0UDSOl;l0TDSOm;m0SDSOn;l0QDUOo;k0QDTOP<l0PDTOQ<k0oCUOQ<k0oCTOT<j0lCVOT<j0lCUOV<j0kCUOU<k0kCUOV<j0iCWOW<i0iCVOY<i0gCWOY<i0gCVOZ<j0fCVO[<i0eCWO\\<h0dCXO\\<h0dCWO^<h0bCWO_<j0`CVOa<i0^CWOd<g0]CYOc<g0]CYOc<g0]CYOc<g0]CYOd<f0]CYOd<f0\\CZOd<f0\\CYOf<f0ZCZOf<f0YC[Oh<d0XC[Oi<e0WC[Oj<d0VC\\Oj<d0VC\\Oj<d0VC\\Ok<c0VC[Ok<e0UC[Ol<d0UC[Ok<e0UC[Ok<f0TCYOn<e0SC[On<d0QC]Oo<c0QC]Oo<c0QC]Oo<c0QC\\OQ=c0nB^OS=a0mB_OS=a0nB^OS=a0mB_OS=b0lB]OU=b0lB^OU=a0kB_OU=a0kB^OV=b0jB^OV=b0jB^OW=a0iB_OW=a0iB_OX=`0hB_OY=a0gB_OY=a0gB_OZ=`0fB@Z=`0fB_O\\=`0dB@\\=`0dB@\\=`0cBA^=?aBA_=?aBA`=>aBA_=?aBA_=?aB@a=?_BAa=?_BAb==^BDb==]BCc==]BCc==]BCd=<\\BDd=;]BEc=;]BDe=<ZBDf=<ZBDf=<ZBDg=;YBEg=;YBEg=;YBEg=;YBDi=;WBEi=;WBEi=;WBEi=;WBDk=;UBDl=;UBEl=:TBEm=;SBEm=<RBCP><PBBR>=oABS>=mABT>>lABT>>lABT>>lAAV>>jAAW>`0hA_OY>a0gA^OZ>b0201O001O0000000000001O0O2O01O0000000001O00001O00XLDlH<T7DlH<m:O0000000000PME\\G9e8G[G:d8F\\G:d8F\\G9g;OcKIkE31Ld38g6KaI5`6J`I6PLI_;O`G8QMK\\;NcG7QMK\\;OcG5QMM[;NdG5QMM[;NdG5QMNZ;LfG6PMNd:LoEO]27PM0b:JUI5YL2\\>OcA2[>OeA1\\>NdA3[>LfA4Z>LfA4Z>LfA4Z>MeA3a;FWG7XM4`;EYG5XM6f:GiH3aL6f:GiH4`L5Z>LfA4[>KeA5[>KeA5`;EYG6WM5_;GYG4XM6h:DlE3S23YM6^;GZG2XM7^;E\\G3WM8Z>HfA8Z>HfA8R8DSN4kI8Q8ETN3kI8a8DUM4ZJ8a8EXJO13VM:];C]G3VM:];C\\G4WM9c8CTJ033VM:V8CTH0Z53\\J:V8CTH1Y52]J:V8CTH0Z53\\J:c8CQM3\\J;Y>EgA;Y>EgA;Y>EgA;Y>EgA;Y>EgA;Y>EgA;Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>DfA<Z>CgA=Y>CgA>X>CgA=Y>CgA=Y>CgA=Y>CgA=Y>CgA=Y>CgA=Y>CgA<Z>CgA<[>CeA;]>EcA;\\>GcA7_>IaA6`>J`A5a>K_A4b>L^A3c>M]A3c>M]A2e>M[A3e>L\\A4d>L\\A3e>M[A3d>O[A1e>O[A0f>0ZA0f>0ZAOg>1YAOg>140000000000000UANh>2XAOg>1YAOg>1YA0e>1[A0d>0\\A0d>0\\A0d>0\\A1c>0\\A0d>0\\A0d>O]A1c>O]A1c>0\\A0d>0\\A1c>O]A1c>N^A3`>N`A3_>N`A2`>N`A3_>MaA3_>MaA4^>LbA4^>LbA4^>LbA5]>KcA6\\>JdA7[>IeA8Y>IgA7Y>IgA8X>HiA8V>HjA9U>GkA;S>EmA<R>DnA<Q>EoA<P>DPB=o=CQB=o=CQB=o=CQB>n=BRB>m=CSB>l=BTB`0j=@VBb0h=^OXBd0f=\\O[Bh0`=XO`Bi0_=VObBk0]=VOaBl0^=TOcBl0[=UOeBk0[=UOeBl0Z=TOfBl0Z=TOfBl0Z=TOfBm0Y=SOgBm0X=TOhBl0X=TOhBm0W=SOiBm0W=SOiBn0U=SOkBm0U=SOkBm0U=SOkBn0S=SOmBm0S=SOmBn0R=ROnBn0R=ROnBn0R=ROnBo0P=ROPCn0P=ROPCn0P=ROPCo0o<QOQCo0n<RORCo0m<QOSCo0m<QOSCP1l<POTCP1l<POTCQ1k<oNUCQ1k<oNUCR1i<oNWCQ1i<oNWCR1h<nNXCR1g<oNYCR1f<nNZCR1f<nNZCS1e<mN[CS1d<nN\\CS1c<mN]CS1c<mN]CS1b<nN^CS1a<lN`CT1`<lN`CT1_<mNaCT1^<lNbCU1]<kNcCU1]<kNcCV1[<kNeCU1[<kNeCV1Z<jNfCV1Z<jNfCW1X<jNhCV1X<kNgCV1X<jNhCW1W<iNiCW1W<iNiCX1U<iNkCX1T<hNlCX1S<iNmCW1S<iNmCX1R<hNnCX1Q<iNoCX1P<hNPDX1o;iNQDX1n;hNRDX1n;hNRDY1m;gNSDZ1k;gNUDY1j;hNVDY1i;gNWDY1i;gNWDZ1g;gNYDZ1f;fNZDZ1e;gN[DZ1d;fN\\D[1c;eN]D[1c;eN]D[1b;eN_D\\1_;eNaD\\1^;dNbD]1];cNcD]1\\;eNcD\\1\\;dNdD]1Z;dNfD\\1Z;dNfD]1X;dNhD\\1X;dNhD]1V;cNkD^1T;bNlD_1R;bNnD^1R;cNmD^1R;bNnD_1P;bNPE^1o:cNQE^1n:bNRE^1n:bNRE_1l:aNUE`1j:`NVEa1h:`NXEa1g:_NYEa1f:`NZEa1e:`NZEa1d:`N\\Ea1b:`N^Ea1a:_N_Ea1`:`N`Ea1_:_NaEa1^:_NcEb1[:_NeEb1Z:^NfEc1Y:]NgEd1W:^NhEc1V:^NjEb1V:^NjEc1T:^NlEc1S:]NmEd1Q:]NoEd1o9\\NRFd1m9]NSFd1k9]NUFN0Oj93VFN1Og94XFM3Nc96ZFL5M_98\\FK5N^97]FK5N^97]FL5N[97`FK7MW99bFJ7MV9:cFI8MT9:dFI8NR9:fFI8MP9;hFH:Ll8=jFG;Lj8=kFG<Lg8?lFE=Me8?nFD>Ld8?oFE>M_8`0SGC?M\\8a0UGB?N[8`0VGC?MY8b0WGAa0MV8c0YGAa0LU8c0ZGB`0LT8c0\\GAa0LQ8d0^GAa0Ko7e0`G@b0Kl7f0bG@b0Jj7g0dG_Oc0Jg7h0fG^Oc0Ke7h0hG^Oc0Jd7h0iG_Oc0Ja7h0lG_Oc0I_7i0nG^Od0I\\7j0PH^Od0HZ7k0RH]Od0JW7j0UH\\Oe0JT7k0WH\\Oe0IR7l0YH[Of0HP7n0ZHZOf0Jm6m0]HYOg0Jj6n0_HYOg0Jg6n0bHXOi0Ic6P1dHYOh0Gb6Q1fHXOh0I^6Q1jHWOh0H\\6R1lHWOh0GZ6S1nHVOi0HV6R1RIWOh0GT6S1TIWOg0GS6S1VIVOh0Ho5S1YIVOh0Gm5T1[IVOi0Fh5V1_ITOj0Fe5W1aITOi0Gc5V1dISOj0G`5W1fIROk0H[5X1jIPOl0IW5Y1lInNm0JT5Z1oImNm0IQ5\\1RJkNm0Km4\\1VJjNn0Ji4]1YJkNn0He4_1]JkNm0Gb4`1aJjNl0H_4`1eJiNl0G]4a1gJiNl0GY4b1kJgNm0HU4b1nJgNm0GS4c1PKfNm0Jm3c1VKcNn0Kh3d1ZKbNn0Lc3d1_K`NP1L]3f1cK`No0KZ3g1gK^No0MU3h1lK\\No0No2i1RLZNo0Nk2j1VLXNP10e2j1[LWNP10`2l1`LUNP12Y2l1gLSNo04U2k1lLRNo05n1m1SMoMP16g1m1YMnMP17`1o1`MjMQ1<U1n1jMgMP1?m0o1SNcMP1c0e0l1[NbMP1h06n1jN[MP1n0TORL7OEl50UMQ1e7oN\\HP1d7PO\\HR1b7nN`HQ1_7oNbHQ1]7oNcHR1\\7nNeHR1Y7oNgHQ1Y7mN"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:brown", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "cleanliness, color", "answer": "The dining table in the image is wooden and has a white plate with a sandwich cut in half on it. The sandwich is made with two slices of bread and is accompanied by a side of lettuce. There is also a knife placed on the table, likely used for cutting the sandwich. The table setting appears to be simple and focused on enjoying the sandwich."}, {"question_id": 583, "height": 428, "width": 640, "image": "000000289415.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [10.85, 127.04, 134.45, 24.06], "segmentation": {"size": [428, 640], "counts": "]W21Y=3M2O2O0O10000O2O000O100O10000O2O00000O1000000O100000000O1000000O100000000000000000000000000000000O1O100O1001O0O101O0001O0000O10000000O1000000000O100000001O00000000000000000000000000O1000000O10000000O10001O0000000000O10O1000000000000000O10O1000000O2O0O100O101N10001N1O100N3M[c_6"}}, "object_label": "pizza", "attribute_label": ["color:orange", "color:yellow", "state:full/whole", "texture:rough"], "control_dims": "texture, color", "answer": "The image features a close-up view of a pizza on a plate, with a slice missing. The pizza appears to be a thin crust pizza with a variety of toppings, including cheese and tomatoes. The plate is placed on a dining table, and the pizza is the main focus of the scene."}, {"question_id": 584, "height": 640, "width": 448, "image": "000000311950.jpg", "category": "description", "question": "Describe the hot dog in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [153.48, 170.07, 141.41, 286.77], "segmentation": {"size": [640, 448], "counts": "lhQ3T12SOVb0k1ZOP1UO?D>A:G:D<F6H;G8I5J8I6J5L4L4K6K3L5M2M4M2M3N2N3fCdHk;k7M2N2N2N2N100N2O10O1O001O1N1O20000O010001O01O0mIaDe3`;XLbD;IoM0[2g;[O`D;Ii0h;lN^D<Jh0i;lN\\Df3e;ZLYDg3h;YLVDj3j;TLVDm3j;YJUD`10Y4j;T21O010N01O1N1O2O001O00001O00000000000001O00001N101N2N2O0O2N2N2O3UJPDbN4P4d;]K[Do1LeN5o3c;_KcDe1EaNM27Y4d;`K_Dg1ImN2l3e;RLUDk01bN1i0Oj3g;RLYDi01X4e;QKYDg02ANd3g;TLYDg01BOc3f;b301O100000O01000O10000O101N1L41TDnGh;W8N1O1O10O010O1O0`L[DfNe;j41O002kIWDo3j;PLWDn3l;_KVDbN22=X1BmNLa3Q<SMaEDKP3l:lLfENHm2U?K3N2^M\\_Od1f`0XNh_O[1ca0K6K2]O]]OEhb02_]OI`c0J]bn2"}}, "object_label": "hot dog", "attribute_label": ["color:tan", "color:yellow", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state", "answer": "The image features a hot dog with mustard and ketchup on a bun, placed on a table. The hot dog is topped with yellow mustard and ketchup, and it appears to be a delicious and appetizing meal."}, {"question_id": 585, "height": 480, "width": 640, "image": "000000369370.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [224.43, 68.83, 414.5, 226.58], "segmentation": {"size": [480, 640], "counts": "jTa33m>1O0O2N4L2O1N3N1N3N0O2O1N1O2M2000000O2O00000O1O1O2O001O0O1gM[O^DOZ1g0W:MeE3[:0aDnNj0S1d:7[EIe:7[EJc:McDTO8J6U1o:NbDSO8K7T1o:NbDTO6K9S1n:9eDbNN3`0Q1m:9eDjN?l0k:;fDjN?k0j:;gDjN?k0i:<iDhN>l0i:<hDiN?k0i:;iDjN=l0i:;jDiN=J@m0Y;`0jDbNN2`0P1h::lDdNL2`0Q1g:;kDbN00>S1g:<jDaN2N>1_O11i0V;f0jDbNe0N[OO11Nf0W;k0jD`Ne0OZO11j0U;f0kDaNd04ZOf0W;e0kD^N02a00]O01k0V;e0kD^N03`0N_O11j0P;WOnD^17bN;N@001Nf0Q;\\OoD]1n0`NSO11j0o:XOQE[1m0gNROf0P;k0mE`NSOe0P;k0VEZN=5^Of0n:l0WEZN<0]O02j0n:k0XEZN<6\\Og0o:i0nEBR:>oEAQ:>PFbNQOf0o:WOQEZ1o0iNQOK0f0P;l0PFBP:?PF@o9<RE`Nn0V1o9nNSEn0X14e9mNTEn0X15d9mNTEn0X15d9mNTEn0X15d9mNTEn05POg0U1o9nNTEn04QOi0MRO10l0l:XOUEm02TOj0JSO01n0j:WOVEm03SOi00SOi0k:WOWEl02TOi0R1n9oNVEj06SOf02TOh0i:YOVEl09oNd0NTO110Ni0i:^OWEk0:nN61HNI11O0i0g:e0`EdN0ML240G02OOk0g:c0aEcNO1LO55Gj0h:>aEcNO1LN66Fj0g:_OZE<f0UOK0_O2On0g:^O[E=7TO4051_O2On0g:_O[E;7WOe00SOU1f:YOZE;9WOb01UOT1d:[O\\E8h0VOG3A0Oo0d:>TFcNGOCOOQ1c:=TFhN@JI11OO;08b:k0UFdNYON75JKO;08b:k0UFbNF5DKO<O7c:k0UFbNF5D;N3c:k0gFgNfNS1b:\\O_E2Z1i0W9cN`E:09Y1k0W9aNaE;O9g0ZOGa1R:TO_E1[1^OfNT1`:6UGGk89UGfNZNk0`:?VGfNZNk0`:?jFdNkN4Kj0_:>cFbN^O5@k0_:\\O`EL0>S1ZO^O6@5O8_:IaEK1?Q1\\O^O3Di0[:^OaEK1?Q1\\O^O3Al0_:ZO`EL1?Q1\\O^O2Bm0_:;bFdN_O3_Oo0`:;lFeNhNV1\\:5hFjNlNQ1[:5iFjNlNQ1[:5iFjNlNQ1Z:6jFiNkNS1Y:5nFeNjNW1W:4QGcNgNZ1X:3RGbNfN[1X:3RGaNfN^1W:1SGaNeN_1X:1RGaNeN^1Y:1mFaNjN00^1Y:cNeE[1W1dNjN10_1Y:`NhE[1U1eNjNe1]:GiFdNjN2O^1^:LiFdNjN2O^1^:LmFfNeN_1]:KnFfNeN_1^:KlF:T9GkF:S9HgFbNoNe1Z:J`FgNVO_1Z:K_F^NXO3Od1Z:KeF`NQOf1Z:JcFaNSOe1\\:I[FhNWOa1^:GXFjNZO_1^:JhEQ1X:k1O1OXMeEm0Z:TOiEgNL`1Z:IiEhNM_1Z:IiEhNM_1Z:IiEhNM`1Y:IgEiN3[1V:OhEbN3_1S:MlEeN0_1T:LlEdN1`1S:LlEdN2_1Q:OkEcN5]1P:d0PF]Oo9c0nE@S:?lEBT:?jECU:d21O01OhMlEDT:d20mMkE\\OU:c0kE]OU:g20001O01O0001O00010O0000010O00010O0000010O000010O01O001O001O00100O1O10O01N1000\\MTFeM3X2h93VFdM1Z2i91WFhMMW2m91UF6k9JTF6l9JSF7n9^2O01O0ZMSF9m9BRFmM220X2l9d2001000O0100O1O1[MRF7n9BoEPN7\\2k9IPF:Q:[2O02OO01O10OSMmEVNOb2U:mNnEaN7`2k9nN^FR1c9mNoEaN5c2l9lNnEdNMM3d2R:jNmEkNO\\2T:iNmEkNO\\2T:jNlEkNO\\2U:hNlEmNN[2V:hNlEgNOMOe2V:eNnEeN1OMf2T:eN^FZ1b9fN_FgN]O\\2S:mN_FjN\\OY2V:mN\\F\\1d9dNUFeNIh2R:aNUFhNIh2R:_NUFiNIh2R:_NVFiNGh2S:_NWFiNEi2T:]NXFiNDj2U:\\N_FlN\\O^2U:fNnEkN8OG`2S:gNlElNON15M[2X:eNjET2W:kMhEW2X:hMiEW2W:hMkEW2V:hMjEY2U:gMkESOMm2Y:oMjESONn2X:PNhESOO8OW2Y:^NiESON82V2W:Q20010O00_LhEZ2X:fMiEZ2V:fMjEZ2W:fMiEY2X:gMgEZ2Y:eMgE[2Y:W1O011N^LkEZ2T:fMmEY2T:hMjEY2U:iMiEW2W:Y1100O1O00100O1O1O00001O01O01O00010O0001O00VMhEZNN\\2[:ROcEcN`0X2l9[OTFd0l9\\OTFd0n9[OcE\\N;Y2R:]OoEc0Q:]OoEc0Q:[ORFd0o9ZORFg0m9ZOSFe0n9ZOSF]N@43e1[:IbF6_9IQF`N@07f1X:KPFeNG`1Z:KmEgNDGNh1b:JiEi0X:XOfEh0[:XO]E]N3[2a:WO[E`N44KM0j1f:J_E_NKM1i1f:J]EfN1NMo0f:=[EeN4NMn0f:?XEfN4MNl0i:Q1TElMO65l0j:a1UE^Nl:b1TE\\No:d1QEZNP;f1PEXNR;g1oDXNS;g1mDXNT;g1nDWNT;g1mDXNT;h1lDWNV;d1nD\\NR;e1mDZNU;f1kDYNV;f1kDXNV;h1jDWNW;m0^DZO;IX;i1hDUNY;k1gDUNY;l1fDTN[;k1fDSN[;n1dDQN^;n1bDQN`;Q2]DnMe;R2ZDnMg;Q2YDnMh;R2YDlMi;j1PDTN72j;i1`DUNb;h1`DWNb;i1]DUNe;k1[DTNg;l1YDSNh;n1hCSNf<S20KXCRNi<m15O2OPCSNn<l1RCTNn<l1RCTNo<l1210O000O2O00001O0O1O2M2N2O2O00001N2O0O2N1N3M2N3N2N2O0N3N2M2N3\\OgA=e>Ege1"}}, "object_label": "sandwich", "attribute_label": ["color:tan", "color:white", "state:piece/cut", "texture:rough"], "control_dims": "texture", "answer": "The image features a delicious sandwich cut in half, with the top half containing a generous amount of avocado. The sandwich is placed on a white plate, and there are a few oranges scattered around the plate, adding a touch of color and freshness to the presentation. The sandwich appears to be a combination of bread, meat, and avocado, making it a tasty and visually appealing meal."}, {"question_id": 586, "height": 500, "width": 375, "image": "000000376307.jpg", "category": "description", "question": "Describe the banana in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [219.48, 370.06, 28.65, 54.57], "segmentation": {"size": [500, 375], "counts": "gY[36[?5L4M3N3M4K4M5K3M3N0O1O2N3M2N0010O1O2N1N3N4K;@<Eabo1"}}, "object_label": "banana", "attribute_label": ["color:black", "color:yellow", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, state, texture", "answer": "The image features a bunch of bananas, with one of them being particularly noticeable due to its green and yellow color. This banana is located in the middle of the bunch, surrounded by other bananas. The bananas are placed in a pile, and some of them are slightly bruised. The overall scene showcases a variety of bananas, with some being ripe and others still in the process of ripening."}, {"question_id": 587, "height": 500, "width": 375, "image": "000000376307.jpg", "category": "description", "question": "Describe the banana in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [40.86, 302.5, 37.27, 31.06], "segmentation": {"size": [500, 375], "counts": "kYe09Z?2N1O1O10O0100O1O100O001O0100O010O010O00010O10O010O01O100O3N4K5JUfa4"}}, "object_label": "banana", "attribute_label": ["color:black", "color:yellow", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, texture", "answer": "The image features a bunch of bananas, with some of them being overripe and yellow. The bananas are placed on a table, and they are arranged in a way that they are partially covered by other bananas. The bananas are in various stages of ripeness, with some appearing ripe and ready to eat, while others are overripe and starting to turn brown. The bananas are spread across the table, with some closer to the front and others further back."}, {"question_id": 588, "height": 480, "width": 640, "image": "000000402783.jpg", "category": "description", "question": "Describe the orange in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [246.18, 266.55, 173.07, 170.57], "segmentation": {"size": [480, 640], "counts": "gec33j>9F5M3L4M3N2M3O0O2N2N2N2N2N1O2N2N2N2O1N2N2O1N2N101N2N2N1O2M3O1M3O1N2M201M3N2N2N2N1O2N2N2N2N2N2N1O2N2N1O2N2O0O2N2N2N1O2N2O0O2N101N2N1O1O100O2N1O1O001O1O001O1O010O001O1O001O0010O01N100000001O0O010000O101O00002O0O2M201N2N2N2N1O2N2O1N2N2O1N2N1O2N2N2N2N2O1N1O2O1N2N2N1O2N2M2O2N2N2N2N1O2M3M3M3N2M3M2O2M3M2N3M3M3M3N2N2L3N3M3M2O2N2N2M3N1O2M3M3M2N3MoVX3"}}, "object_label": "orange", "attribute_label": ["color:orange", "color:yellow", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, state, color", "answer": "The image features a close-up view of a fresh orange slice on a white plate. The orange slice is thinly sliced and has a slightly translucent appearance, likely due to the moisture content of the orange. The slice is placed on a dining table, and the overall scene is a close-up of the orange slice, highlighting its texture and freshness."}, {"question_id": 589, "height": 640, "width": 427, "image": "000000406570.jpg", "category": "description", "question": "Describe the apple in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [331.55, 366.49, 95.45, 63.41], "segmentation": {"size": [640, 427], "counts": "WUa64jc03M2N2N1O2N2N2O0O2O0O2O1N2N2O001O1O1O1N2O1O1O1O1O1O1O1O1O1O00100O1O100O1O100O100O100O100O10000O10000O10000O10000O1000000O100000000000000000000000O1000000000000000001O0000000001O0001O00_D"}}, "object_label": "apple", "attribute_label": ["color:red", "color:yellow", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, color", "answer": "The image features a close-up of a red apple with a green stem, sitting on top of a pile of other apples. The apple is prominently displayed in the foreground, while the other apples are in the background. The apples are arranged in a way that they are partially covered by the red apple, creating a visually appealing composition."}, {"question_id": 590, "height": 480, "width": 640, "image": "000000529762.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, state, texture", "region_anno": {"bbox": [284.31, 325.47, 64.54, 71.72], "segmentation": {"size": [480, 640], "counts": "^\\V43l>2O1N2N2O1N1O2O001O001O001O1O1N101O03N0OO1O2N2N2O001N20O01O1SCTOd;m0WDWOi;j0SDYOm;h0oC[OQ<f0jC^OV<e0bC@^<a11O000O2O001O00001O1N101O1N102N1N101O1N3M2N3M2PO^B?e=_O\\B`0i=XO[Bf0Q>M5KcbW4"}}, "object_label": "sandwich", "attribute_label": ["color:black", "color:brown", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state, texture", "answer": "The image features a delicious-looking sandwich, which appears to be a burger, served on a plate. The sandwich is accompanied by a side of potato chips, making it a complete and satisfying meal. The sandwich is placed on a dining table, and the chips are scattered around the plate, adding to the presentation of the meal."}, {"question_id": 591, "height": 478, "width": 640, "image": "000000121586.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [539.65, 332.09, 51.33, 15.05], "segmentation": {"size": [478, 640], "counts": "f\\l74i>3N0O10001O1O0001O0000001O010O000100O0100O00001O1O1O1O010O0O100000O10000000O1000000000000000O1O11OWPg0"}}, "object_label": "book", "attribute_label": ["material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, pose, texture", "answer": "The image features a book with a red cover, placed on a table. The book is open, revealing its contents. The book appears to be a paperback, and it is positioned in the center of the image. The table is a prominent element in the scene, occupying a significant portion of the image."}, {"question_id": 592, "height": 480, "width": 640, "image": "000000165831.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [519.9, 0.0, 120.1, 79.79], "segmentation": {"size": [480, 640], "counts": "ede73f>9I7K4L5M2N2N2O1O1O1O1O001O1O001O1O001O1O001O001O1O001O001O001O001O0010O1O01000O1000O0012M010O10O10O010O010O01O10O00010O010O0100O010O01000O010O010O010O0010O00100O010O001O010O1O0010O01O1O00000000000000001N10BfNVCZ1X=0ZOfNfCY1Y<jNfCV1Y<iNiCW1o;PORDo0m;SOSDl0n;oN^CKd0V1n;lNbCM?W1P<lN`CO?T1R<oN]CM`0T1T<oN\\CM`0T1T<"}}, "object_label": "bottle", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The image features a bottle of oil, possibly olive oil, sitting on a table. The bottle is filled with a yellowish substance, which is likely the oil. The bottle is placed on a wooden table, and there is a spider visible on the side of the bottle. The spider is located near the top of the bottle, adding a unique element to the scene."}, {"question_id": 593, "height": 425, "width": 640, "image": "000000167572.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [152.25, 357.49, 118.05, 67.51], "segmentation": {"size": [425, 640], "counts": "o_o11V=3N1O1O1O1O1O1O1O1O1N2O1O1O1O1O1O1O1O1O1N2O1N2O100O100O1O1O1O1O1O1O1O1O1O100000000O1O100O100O1N2N200O1O1O_N]D^1a;cN`D]1`;cN`D]1`;bNaD^1^;dNaD\\1^;QO`De0^;]ObDc0];e0O1O1N2O11O000kNiD8X;EkD:U;EmD:T;ElD;T;FhD\\ONm0Z;HgD\\ONl0\\;m00nNdD7\\;HfD7Z;IgD6Z;HgD8Y;FjD9V;FmD8T;GlD9T;FoD8R;GnD9R;FhDBMh0\\;EfDENe0\\;FfDEOd0[;GfDD1d0Y;HhDBOf0Y;MmD2S;OmD0T;OlD1T;OdD]O2c0Z;0cD_O2a0[;9eDF[;;eDD\\;;eDD[;3`DC59[;4_DD68\\;3^DE77[;4]DF0J6:];5_DJ50];5^DDO076\\;>]DZO:7Y;>nDAR;?PE_OQ;b0nD]OR;c0PEZOQ;f0PEYOQ;f0i0LbC]O_<b06L50O6NJh]j4"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, pose, texture", "answer": "The image features a glass cup filled with water, with a slice of orange placed on top of it. The orange slice is partially submerged in the water, creating a visually appealing and refreshing scene. The glass cup is placed on a table, and the orange slice adds a touch of color and freshness to the overall composition."}, {"question_id": 594, "height": 476, "width": 640, "image": "000000241319.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [106.73, 221.64, 69.37, 93.91], "segmentation": {"size": [476, 640], "counts": "XWf12i>100O1O2O00000O100000001O0000000O100_MH^F8a9M[F3d9OZF2f9OTF6l9JSF7m9ISF7m9ISDJ31]1<]:IRDLj1;T:DQDO24g19V:NlE4T:KgE;Y:CgE?Y:_OeEe0[:VOhEl0X:ROgEQ1m;5L4O1KdNiB]1V=eNhB\\1V=6O1O1N2M3K5L3KmM_CW2\\<8K3L5N2O1000N2N2M4J5C=_Ob0L6La0UOn`f6"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, transparency, texture, material", "answer": "The image features a glass cup filled with water, placed on a table. The cup is positioned in the center of the scene, and it appears to be empty. The cup is surrounded by a few other items, including a bottle, a spoon, and a cup of coffee. The spoon is located near the top of the cup, while the bottle is situated to the left of the cup. The cup of coffee is placed to the right of the main cup, creating a visually interesting arrangement of items on the table."}, {"question_id": 595, "height": 476, "width": 640, "image": "000000241319.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "color, material, pattern, pose, transparency", "region_anno": {"bbox": [428.83, 153.84, 56.82, 92.2], "segmentation": {"size": [476, 640], "counts": "cSW61j>3M3M2N2N2N2N2O3M1O10000001O000O2M2N2M3O2N100001O010O101O00000000100OO100006cA@P>?oABR>e00000O10O13M1N02M8H3M2N1O3M4LlgX2"}}, "object_label": "toothbrush", "attribute_label": ["color:blue", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "transparency, color, pattern, pose", "answer": "The image features a white toothbrush with a blue handle, which is placed on a countertop. The toothbrush is positioned in a way that it appears to be hanging from the wall, giving it a unique and interesting appearance."}, {"question_id": 596, "height": 480, "width": 640, "image": "000000316666.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [389.5, 264.07, 35.41, 47.5], "segmentation": {"size": [480, 640], "counts": "[ag54k>3M3N1O1O001OF_A6`>J`A7_>7N3M1O1O001XB[OS=f0jB]OU=W1000[OhBBX==f0O1N2N2N2O1O1O1G]A4d>40N2N101OioT3"}}, "object_label": "wine glass", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The wine glass in the image is tall and slender, with a stem and a bowl-shaped base. It is filled with wine, and the wine appears to be clear and visible. The glass is placed on a table, and it is positioned between two other wine glasses."}, {"question_id": 597, "height": 480, "width": 640, "image": "000000316666.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pose, texture, transparency", "region_anno": {"bbox": [536.63, 94.58, 28.36, 70.38], "segmentation": {"size": [480, 640], "counts": "P]k72j>5K5L3M3^NC\\Db0d;^OYDe0g;\\OTDi0k;WORDl0n;UOoCm0Q<ZObCl0^<k0O010000000ObN_C?a<@fC:Z<EiC9X<@oC?Q<]OUDa0l;]OXD`0l;ZOXDd0U=M4L2N4L3LSPS1"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, material, cleanliness", "answer": "The image features a wine glass hanging from a ceiling, with a stem and a glass bowl. The glass bowl is filled with water, and the stem is positioned at the top of the glass. The wine glass appears to be empty, and it is hanging from a metal hook or a similar support. The scene is set in a dark room, which adds a dramatic and mysterious atmosphere to the image."}, {"question_id": 598, "height": 333, "width": 500, "image": "000000340697.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [2.59, 75.25, 58.82, 111.58], "segmentation": {"size": [333, 500], "counts": "Q=6U:6K4L2N2OAZF:b9>K7I3L4M3M2M6K3M2N101N2N2OYNdG]1Z8cNfG^1Z8`NgGa1Y8;001N007KM13N0O101ON2O100O1O02N1N100O3N1O1N100O3NO1N23M010O0001O03L6J5I7I7I6J5L4Kic]4"}}, "object_label": "bottle", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "material, texture, pose", "answer": "The image features a close-up view of a bottle of soda, likely a cherry-flavored drink, with a red liquid inside. The bottle is placed on a table, surrounded by other bottles, creating a scene of various drinks. The bottle is positioned in the center of the image, with other bottles surrounding it on all sides. The bottles vary in size and shape, adding to the diverse collection of drinks in the scene."}, {"question_id": 599, "height": 480, "width": 640, "image": "000000357888.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pose, texture, transparency", "region_anno": {"bbox": [599.51, 67.05, 34.75, 25.35], "segmentation": {"size": [480, 640], "counts": "bkh83j>6L4M1O0OFeA1[>NgA0T>6mAHS>9lAGT>c0000O10O10000000O1000O1000O10000O101O0O100O1N2L4M4Mmg2"}}, "object_label": "cup", "attribute_label": ["material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose, material", "answer": "The image features a white cup sitting on a table, possibly on a wooden surface. The cup is positioned in the center of the frame, and it appears to be empty. The cup is placed on a table that is covered with a green cloth. The overall scene gives the impression of a cozy and inviting atmosphere."}, {"question_id": 600, "height": 478, "width": 640, "image": "000000058029.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [306.73, 414.71, 164.8, 63.29], "segmentation": {"size": [478, 640], "counts": "cV`4<`>5K4M3L4M2M3N2N2N3M102M2N2O1N101N101N100O10000O1000000O11O00000000000000O2O00000001O0000000000O1000000O1O100001O0000000000000000000000000000000O1000000010O000001O1O6JJ6O11O6J2N1O001O001O00001O001O00002N001O00001O001O1O001O001O001O001O1O1O00001O0O2O000001O000000000O10000O1N2N2000ON30000001O00100O0O2O1O1OBVOiBi0W=WOjBh0V=YOjBf0W=YOkBe0V=ZOkBe0V=YOmBe0U=[OjBd0V=\\OlBb0j=LRm^2"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "state:empty", "texture:smooth/sleek"], "control_dims": "pattern, cleanliness, material, texture, color", "answer": "The image features a white sink in a bathroom, with a silver faucet on the side. The sink is positioned under a mirror, which is located above the sink. The sink appears to be clean and ready for use."}, {"question_id": 601, "height": 480, "width": 640, "image": "000000206218.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [360.0, 101.08, 269.19, 216.22], "segmentation": {"size": [480, 640], "counts": "ekX5;5HW>n0B=De0ZOf0[CYMg;V3J<C9H3M8H1O2N3M3M2N2N3M3M2N2N2N5K1N2O2N4L3M1O3M2N3M1O1O3M3M2N1O1O1O1N2O00001O0000000000000O1000000000000000000ObM_G^Nb8P40000000O1001OO1cM]G]Nb8c1_G]Na8d1^G\\Nb8Q400000O100000000000000000OcM^G^Nb8P4000000000000000O01000000000000000000000O10000000000000O1000O10000000000000000O10000000O1000000000000000000000000O100000O10000000000O11O0000000O0100PM^GBb8?]GAc8^30UM^GXOb8h0^GXOb8h0^GXOb8g0_GYOa8b0_GgL0g2a8d0^GdL1g2b8e0]GdL1g2b8c300000000000000000O1QN[GcMf8\\2ZGdMf8\\2ZGdMg8Z43M6JZ1fN8kM_E[OQ;Q2e0\\O;XMnCl1d<O0000000O2O1O1O00001O2N1O001O1O0O2O1O1O1O1O1O1O001N2O001O1O1O1O1O001O1O1N2O001O2N1O1O001O2N1N2O001O1O1O1O1O1N2O001O2N001O001O1O1O1N2O1O1N2O1N1O2LUh6"}}, "object_label": "laptop", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "state:on", "texture:smooth/sleek"], "control_dims": "state, transparency", "answer": "The image features a silver laptop computer sitting on a wooden desk. The laptop is turned on and has a blue screen, which is displaying a picture of a sun. The laptop is positioned in the center of the desk, and there is a keyboard in front of it. \n\nIn addition to the laptop, there are two other objects on the desk. One is a mouse located to the right of the laptop, and the other is a cell phone placed near the top left corner of the desk."}, {"question_id": 602, "height": 350, "width": 500, "image": "000000209747.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [0.0, 147.8, 499.77, 202.2], "segmentation": {"size": [350, 500], "counts": "U7Y12mNW9d1I7J2M4M3L5L5K3N2M2N2N2N3N1N2N2N3M2O2M2N2O1O1N2N3M102M1O3N1N2O0O3M101N2O1N2O0O2N2O1N2O0O2O1N101O1O0O200O000010O01O01O00001O001O001O001O1O001O1O001O1O1O1O1O1O1O001O1O1O001O1O4L2N3M001O1O001O001O001O0000001O0^MmHY1S7gNmHY1T7fNlHZ1T7X100001O000000001O0bMjHT1V7lNjHT1V7lNjHT1V7lNjHT1V7lNjHT1V7lNkHS1U7nNkHQ1U7oNkHQ1U7POjHP1V7POjHP1V7POjHP1W7oNiHQ1W7oNiHQ1W7[11O00000fMhHn0X7ROhHn0X7ROhHn0X7ROhHn0X7ROhHn0X7ROhHn0W7SOiHm0X7\\11^LgH]3X7dLhHT10o0W7nMkHQ1NQ1W7PNmHk0LU1V7RNTIb0F\\1V7RNTIb0F\\1V7RNoHIMi0N\\1V7UNlHFOj0O[1U7PNkHO2i0NX1U7WNlHj2S7WMmHi2S7SMWIg2i6YMXI?E[1S7VNXI?E[1R7XNmHE9g0H\\1R7WNnHF:e0F^1R7TNmHI10;d0E_1R7WNnHF?a0@b1S7WNnHFb0>]Oe1R7XNhI0VOh1R7XNiIOVOh1Q7ZNiIMVOi1P7]NhIJXOi1P7VNPJ0POj1P7VNQJOoNk1o6XNQJMQOj1n6YNQJMQOj1n6UNXJNjNm1n6UNYJNhNm1n6VNZJMhNm1n6nMQI5Z10gNm1a8SN_Gm1a8SN_Gm1T8SNQH0Km1W8TNhG11k1X8\\NhGd1k6oM^J=gNd1e6VNcJ6hNd1d6XNeJ2hNe1b6[NeJ1hNd1a6^NfJNiNd1a6_NeJMjNd1_6bNeJKlNc1^6fNZJ0XOZ1X6lNSJSOMi0IW1W6nNnIXOOd0LV1V6SOhIVO5b0MU1V6@kI[OOU1V6a0iI_OW6a0iI_OW6a0iI_OV6a0kI_OU6a0kI_OU6a0lI^OT6c0jI^OV6b0jI^OV6b0jI^OU6c0lI\\OT6d0lI\\OT6c0mI]OS6c0nI\\OR6d0nI\\OR6e0lI\\OT6d0lI\\OV6TNRJe1HZN4m1[7lNoHS1a7SNPHOf0n1W8000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O1`LRNPNn1l1XNRNh1l1[NSNe1i1`NVN`1i1fNQN[1l1kNQNU1n1oNoMQ1o1TOnMl0Q2WOmMi0R2YOmMg0S2[OkMe0T2^OjMb0V2_OiMa0W2@hM`0X2AgM?Y2CeM=[2GaM9_2I_M7a2I_M7`2J`M6`27SMIm2<nLDR3>lLBT3?XKbM_1P2Y3a0gL_OY3b0fL^OZ3:XKgM0O_1P2Y3:XKfMb1Q2V3=iLCW3=iLCW3<jLDV3<jLDV3>hLBX3?gLAY3a0eL_O[3d0bL\\O^3i0]LWOc3l0ZLTOf3R1TLnNl3X1nKhNR4j1\\KVNd4k1ZKVNf4k1YKUNg4k1YKUNg4k1YKUNg4k1XKVNh4j1XKVNh4j1XKVNh4j1XKVNh4j1XKVNh4P4000jMXKVNh4j1XKVNh4P41O000hMWK[Ni4e1WK[Ni4e1XKZNh4f1XKZNh4f1WK[Ni4e1WK[Ni4e1WK[Ni4e1WK[Nj4d1VK\\Nj4c1WK]Ni4c1WK]Ni4c1WK]Ni4c1WK]Ni4l300000fMWK_Ni4a1WK_Nj4`1UKaNk4_1UKaNk4_1UKaNk4_1UKaNk4_1UKaNk4_1UKaNk4_1UKaNk4_1UKaNl4^1TKbNl4]1UKcNk4]1UKcNk4]1UKcNk4]1TKdNl4[1TKfNm4Y1SKgNm4Y1SKgNm4Y1SKgNm4Y1SKgNn4X1SKgNm4Y1RKhNn4W1SKiNm4X1RKhNn4d31O0bMRKlNn4T1QKmNo4S1QKmNo4S1QKmNo4a31O000000000`MPKROQ5m0oJSOQ5m0oJSOQ5m0oJSOQ5l0PKTOP5]30^MoJWOR5h0oJWOQ5i0nJXOR5h0nJXOR5h0nJXOR5h0nJXOR5Z31O0]MmJ[OS5d0nJ\\OR5d0nJ\\OS5c0lJ^OT5b0lJ^OT5b0mJ^OR5b0mJ_OT5?mJ@T5`0lJ@T5?mJAS5?lJBT5>kJCV5<jJDV5S3O01XMjJFV5:jJEW5Q300001WMhJJX56hJJX56hJJX56hJJY55gJKY54gJMY52gJOY51gJOY51gJOZ50fJ0Z50fJ0Z5OgJ1Y5OgJ1Y5OgJ1Z5NeJ3[5LfJ4[5KeJ5[5KeJ5[5KeJ5\\5JcJ7]5HdJ8\\5HcJ9]5GcJ9]5GcJ9^5EcJ:^5FbJ9`5F_J;a5`2100O2O0O1O1UMZJ>g5@ZJ?g5AYJ?g5AYJ>h5BWJ?i5Z22UMUJ`0l5@TJ?n5_OSJ`0n5@RJ?o5AQJ>P6AQJ?o5AoI`0S6_OmI`0T6U21N1O1\\MiI`0Y6R20O100O101N1O1]McIe0g0"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, transparency", "answer": "The sink in the image is a white porcelain sink, and it is filled with water. A small kitten is standing on the edge of the sink, looking at the camera. The kitten appears to be curious and is possibly exploring the sink."}, {"question_id": 603, "height": 350, "width": 500, "image": "000000209747.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "cleanliness, color, maturity, pose, size, state, texture", "region_anno": {"bbox": [170.88, 59.71, 170.13, 223.34], "segmentation": {"size": [350, 500], "counts": "Wmk1:b:5L5K3N2M3N1O2N2N3N1N2N1O101N2O2M2O1N2N:G2N1N2O0O1000001N2O1N2O1jGZND^OV7Z2oHROf0eNk4Z2ZJ_O8gNV5j4O00010N1O100O1O100O10000O1O100O100O10000O10000O100000000O100000000O100000000O100000000000000N2O1M3M3O1M3O1M3N2N2O1N2N2O1N2O1O100O1000000001O1O1O002N2N2N3M5J`0A4L3M2N3M;E2N1_LWJk1k5mM]JP2e5nM]JQ2d5mM`JP2b5kMcJS2_5gMhJV2[5cMmJY2W5^MPK`2i6N2N2N1O2N3L5L4L6J2M3N1O4L3M2aNcF<0H0LO02030f90\\T3OelL001VOOoE10O3>T:BmE6KKf:ObTh1"}}, "object_label": "cat", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:white", "maturity:young/baby", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, color, texture, state, cleanliness, size", "answer": "The image features a small kitten sitting in a bathroom sink, looking up at the camera. The kitten appears to be curious and attentive, possibly exploring its surroundings or seeking attention. The sink is white, and the kitten is positioned in the middle of it."}, {"question_id": 604, "height": 500, "width": 500, "image": "000000219283.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [57.66, 322.0, 117.04, 62.95], "segmentation": {"size": [500, 500], "counts": "Qdm04_?2N2[AKi=6bAJ;5P>Q1L7I2N2O0O10000O1O2O0O10000O10000O100000000000000O100000O100000000000000000000000000000000000000000000000000O010000000000000O10000N2O1N200O100000000O1000000000000000000O1001O0001O00000O2O2M2O001N10001O0O2N1FgAXO[>7i0O1O2N2O2LZkn4"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "state:closed", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a white bowl sitting on the ground, possibly in a grassy area. The bowl appears to be empty, and it is positioned in the foreground of the scene."}, {"question_id": 605, "height": 640, "width": 426, "image": "000000476514.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, texture, transparency", "region_anno": {"bbox": [300.67, 203.45, 24.34, 131.72], "segmentation": {"size": [640, 426], "counts": "djk52_c05e\\O1Vc04i\\OKTc0:k\\O@11Rc0a0Q]O_Omb0c0S]O]Oib0h0V]OXOgb0k0X]OVOh`00PAk0WNVOe`0:^ANlMJa`0d0jA[O]=Md@W1CiNRb02V^OX1JeNoa07P^Oj0`0PO]a0W1h0O001000001TOZ]O<hb0_O`]O;ab0Do0Maao1"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "state:folded/bend", "texture:smooth/sleek"], "control_dims": "cleanliness, pattern, transparency, material, color, texture, state", "answer": "The tie in the image is red and gold, which adds a pop of color to the man's outfit. It is worn by a young man dressed in a suit and tie, and it is positioned in the middle of his body, extending from the left side to the right side of his torso. The tie's design and color combination make it a stylish and eye-catching accessory for the man's formal attire."}, {"question_id": 606, "height": 375, "width": 500, "image": "000000003845.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [258.53, 189.71, 37.94, 72.35], "segmentation": {"size": [375, 500], "counts": "Zgn28\\;4M3N2M4M1O1jN\\OXGe0f8_OVGc0i8@SGb0d8UOiF;?b0g8UOjF;0HNh0Y9VOhFj1Y9VNfFj1Z9XNdFh1^971O1N2N3N1O1N2K5O1O1N2K6M3N2M2N3K9H202N2O1N3J5IgTZ2"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "size", "answer": "The carrot in the image is orange and appears to be cooked, possibly in a sauce. It is placed on top of a dish, which could be a plate or a bowl, and is surrounded by other food items. The carrot is positioned towards the center of the dish, and it is accompanied by broccoli, which is located on the left side of the dish. The combination of these vegetables and the sauce creates a visually appealing and appetizing meal."}, {"question_id": 607, "height": 375, "width": 500, "image": "000000003845.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pattern, pose, size, state, transparency", "region_anno": {"bbox": [105.92, 0.04, 77.11, 55.08], "segmentation": {"size": [375, 500], "counts": "RYX14c;3M3M3M4L2N3M3M3M2N2N3M2N2N2N2N1O2N1O2N001O0000001O1O1O001O0000001O000000O100000000000000000000O1000000000000O100O1O1O100O10000O10000O1O1N2N2L4H8H8Di[c3"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole"], "control_dims": "size", "answer": "The image features a glass cup sitting on a wooden table. The cup is filled with water, and it appears to be empty, with no ice or other contents. The glass is clear, allowing the viewer to see the water inside. The table is made of wood, and the cup is placed on top of it, creating a simple and clean scene."}, {"question_id": 608, "height": 480, "width": 640, "image": "000000050331.jpg", "category": "description", "question": "Describe the broccoli in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [366.51, 92.5, 138.06, 143.75], "segmentation": {"size": [480, 640], "counts": "lj`56h>3M6mAGU==eBIX=;bBI\\=P1M3M100O1000001N2O1O1O1N1O1O1O1O1O1O2N1O1O2O0O101O0000001O001O001O1O01O001O0001N1O3N1O1O1O001OO1O1OSE`M\\9`2cFaM]9_2cFaM\\9`2eF_M[9a2eF_MZ9]2XEdMZ<\\25002M2OO1O010O100O10O0100O1O1O1O1100O00100OO10001N1O10O101O001O100O000000100O0001O0O2M3O1N3K4O1O00000O2O1O2lNkB9U=FnB8S=FoB9Q=FPC:Q=DPC;R=DnB2NAU=;PC0^=MeB0]=Mo0KXQQ2"}}, "object_label": "broccoli", "attribute_label": ["color:green", "size:big/large/giant/huge", "state:full/whole", "texture:rough"], "control_dims": "state, color, texture", "answer": "The image features a large, fresh broccoli plant with a head of broccoli sitting on top of a stalk. The broccoli is surrounded by several leaves, which are green and appear to be healthy. The plant is situated in a dirt field, giving it a natural and organic appearance. The close-up view of the broccoli and its leaves highlights the vibrant colors and textures of the plant."}, {"question_id": 609, "height": 612, "width": 612, "image": "000000123321.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [48.71, 392.5, 24.59, 46.69], "segmentation": {"size": [612, 612], "counts": "mXn02Pc03N3M2N8H4L4L4L3N2M7J1O1O0OO2N3N1N2O2N2N2M4K6J4L5H`no9"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, texture", "answer": "The image features a close-up view of a carrot, which is a bright orange in color. The carrot is positioned in the center of the image, and it appears to be the main focus of the scene."}, {"question_id": 610, "height": 425, "width": 640, "image": "000000130613.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [433.31, 125.7, 183.19, 136.37], "segmentation": {"size": [425, 640], "counts": "RVe55Q=6J5K5L4M2M5K3N2N1O1O1O001O001O00001O010O00001O0001O00000010N11O01O01M2M4O0O101O00000010O0001O00001O0010O01O001O0001O0010O00010EjCBV<>lC@U<`0kC@T<b0jC^OW<b0iC^OV<c0jC\\OV<e0iC\\OV<l00O010JjCXOV<h0kCWOU<k0jCUOV<k0jCTOV<P100O100O010O00FlCAS<`0mC@R<l000OFoC^OP<c0PD]OP<m0010FPDZOQ<e0RDYOm;h0SDXOm;h0SDWOm;j0RDVOo;k0oCUOQ<R10O001000O01CoCAQ<`0oC@P<a0oC_OR<a0nC^OR<m000O0100GoCZOP<f0RDYOm;h0SDWOP<g0PDYOW<`0iC_O\\<e03L4M3L5Jll>LXSA5nBJl<=L1N1OH[COd<0]C0b<1^CNb<3^CMb<;2N2O1N2N2O2N1O001N10100O1O002NeU8"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "texture, state", "answer": "The carrot in the image is long and green, with a slightly curved shape. It is placed next to a piece of fish and a potato on a plate."}, {"question_id": 611, "height": 480, "width": 640, "image": "000000148957.jpg", "category": "description", "question": "Describe the donut in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [431.46, 237.2, 191.57, 196.53], "segmentation": {"size": [480, 640], "counts": "QmY65g>:G6K6J5J5K5L4J5J7J6H7I7K5K5L4L4L4L3L5K5M3K5L4M3M3M3N2N2N2N2N2N2N2N2N2N2N2N2O1N2N2N2N2O1N2N2O1O1N101N2O0O2N101N1O2N2N101N2O001N101O0O101N10`L[Ge0d8[O`Gc0_8]ObGb0^8]OfG`0Y8AjG<V8DlG:T8FmG9S8GnG8Q8IPH6P8JRH5m7KTH4l7LTH4k7MVH2j7NWH1i7OYHOg71ZHNf73ZHLf74ZHLf74[HKe75]HIb79]HGc7:\\HFd7;[HEe7;\\HDd7=[HCe7>ZHBf7?YHAg7`0WHAj7?THBl7`0PHBP8?mGCT8`0fGBZ8c0^G@b8_30000O10000001O0000001O00001O0O101O001O000O2O0O2O000O101N10001N101N10001O0O2O001N101N1O2O1N2N2N2N2O2M2N2N3M2N2O2M2M3N3N1N2N3M2N3M2N2M3N2M3N3M3M3M2O2M3M3L5L2N5K4K6I>A9H8G:Dc0\\O]Q9"}}, "object_label": "donut", "attribute_label": ["color:brown", "color:yellow", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, color, state, texture", "answer": "The image features a box filled with a variety of donuts, including a large glazed donut and a chocolate donut. The glazed donut is placed in the center of the box, while the chocolate donut is positioned towards the left side. There are also two other donuts in the box, one located on the left side and the other on the right side. The donuts are arranged in a visually appealing manner, showcasing their delicious appearance."}, {"question_id": 612, "height": 426, "width": 640, "image": "000000153510.jpg", "category": "description", "question": "Describe the broccoli in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [478.24, 229.13, 60.79, 72.05], "segmentation": {"size": [426, 640], "counts": "]TW62T=8AJ`C9^<J_C8_<;M2O1O2M2O1O1O1N2M3M3M3M4K4N2N2O1O0100000O10O10O10O10000O2O1O001N2NK_NdD^1^;bNbD\\1`;cNbD[1_;fN_DV1e;71O1O10000O1GWDQOl;m0RDSOP<S10O1M3O1O1O001N2N8G6JohY1"}}, "object_label": "broccoli", "attribute_label": ["color:green", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, state, size", "answer": "The image features a close-up view of a piece of broccoli, which is placed on top of a plate of food. The broccoli is surrounded by a sauce, giving it a moist and appetizing appearance. The broccoli is a prominent part of the dish, and its vibrant green color stands out against the other ingredients."}, {"question_id": 613, "height": 480, "width": 640, "image": "000000157390.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [74.0, 84.0, 192.0, 222.0], "segmentation": {"size": [480, 640], "counts": "_RW164M\\>?eAMa=n0K4M3M4L3M4M2M3M2K6M3[OeM`D]2\\;jMaDV2\\;mMcDU2[;lMdDU2Z;dM_D05]2Y;cMhDMNb2X;aMkDLLe2W;`MmDKLf2V;eMiDD1h2U;eMjDB1j2S;hMiD^O4k2R;kMmDW2Q;iMPEW2o:jMoDX2P;hMoDZ2P;fMoD\\2o:dMRE]2m:cMSE^2l:bMTE_2i:n0M201MiL]EU2b:lM^ET2b:lM_ET2^:cMaE_O3l2[:dMeEBNi2[:gMgEXOM40m2[:hMiEUOM7Nm2Y:iMTF\\2j9gMoEQOOV3Q:lMkERO3S3P:TNPFl1P:TNPFl1P:lMlERO4R3P:kMnERO2S3o9lMoE_2Q:bMnE^2R:bMnEPOOW3S:hMRFlN0Z3m9jM[FU2e9kM[FU2e9lMZFT2f9kM[FU2e9iM]FW2c9hM^FY2a9gM_FSO@P3Q:lMoERO=1Fo2n9RN]FmNFQ3m9RNSFnN:o2c9TNRFnN;m2d9TNoESO;i2f9TNoETO:h2g9SNPFTO9j2g9_MPFF1M208m2e9`MRFE0M2N6S3f9iMQFVO304Q3i9iMnEXO2162Hb2Q:UNnEUO5040HO0f2R:ZNTFoNN5NK1e2m9eMPF;6[ON40KOf2R:`MnE>1^OO48_2l9^MTF:IEO39`2]:gM\\EEM4;`2`:]M^ENG5=_2S;`MPE^2P;cMoDLA[2`;iMUEW2l:iMcDK6]2Y;fM`DO5\\2\\;eM^D03]2b;cMXDj2h;WMWDi2R<N9F1O11N101N1O2O0002M3L3M2OIfMjCZ2]<100O10O011O2N00000aN\\Ca0e<YOjC>Q<TOiDb0Z;]OhD=];_OhD?o<M4Koj2HXgL1WOO[>0kA0K4X>LmA0K6e>O0M3Oc<OV40U_OOZA3e>MZA5h>0]AMY>;4MNG`A7\\>IcA:`>03F_A0f>O60n>0Rno5"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "state", "answer": "The carrot in the image is long and orange, with a slightly curved shape. It is placed in a bowl filled with other vegetables, such as broccoli and carrots. The carrot is surrounded by a variety of other carrots and broccoli pieces, creating a colorful and appetizing display."}, {"question_id": 614, "height": 480, "width": 640, "image": "000000157390.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [91.69, 259.78, 116.49, 73.34], "segmentation": {"size": [480, 640], "counts": "XPZ15i>4L4L3N3L4L4M2N2N2N3N1N6J2O2M2N2O1N2O0O101N101N1O101N10001O0O100000000O100000000O10000O10000O100O010O10O10000O10O1000O10000000O010000O10O1000O1000000O10000O2O0O100O1000000O2O00000O100O2O00001N2O0O2O001N101N101O2N1N2O1N2O2M3M4M;D3M3M4KeeZ6"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "size, state, texture", "answer": "The image features a close-up view of a carrot, which is cut in half and placed on a plate. The carrot is orange in color and appears to be freshly sliced. It is accompanied by several pieces of broccoli, which are scattered around the carrot on the plate. The broccoli pieces vary in size and are placed in different positions, creating a visually appealing and healthy meal."}, {"question_id": 615, "height": 425, "width": 640, "image": "000000209142.jpg", "category": "description", "question": "Describe the broccoli in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [186.22, 134.41, 119.07, 122.73], "segmentation": {"size": [425, 640], "counts": "ama23\\<O\\D3b;6UDKj;6UDJk;7TDJk;6UDJk;6UDKj;5kCD:5k;7kCD;4j;8kCD;4j;8ZDHe;8[DId;7lCE>5d;;[DFc;:]DI`;8`DOX;3fDNZ;1fDOZ;1gDNY;3fDM[;2eDN[;2eDN[;2eDN[;6aDJ`;6`DI`;7`DI`;7`DI`;7aDH_;9aDF`;9aDF>EV:e0\\EG;FZ:c0[EG9I[:ITEd07N6Fc:;WE40Bl:7TE7OCm:5TE9MCP;3SE;LCP;2UE;JDQ;OVE?FDS;MXEo0i:POWEQ1i:oNVEQ1k:mNWES1l:eNXE\\1Z;000O1O100O110O1013L000O001000001cNWDW1n;1O0001O1O1O3MO1O000O101O001O00001N1L41O1O01O1O01O01O010O0010O1O3N000O1O01O1O01O002N1M:F6^Oc0ITW[4"}}, "object_label": "broccoli", "attribute_label": ["color:green", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "size, color, texture", "answer": "The image features a close-up view of a large head of broccoli, which is the main focus of the scene. The broccoli is surrounded by several pieces of carrot, which are scattered throughout the image. The carrots are of various sizes and are placed in different positions around the broccoli, creating a visually appealing and colorful arrangement."}, {"question_id": 616, "height": 480, "width": 640, "image": "000000226903.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [86.29, 194.44, 39.24, 32.49], "segmentation": {"size": [480, 640], "counts": "VoX17h>?B2N1O0O1000001O000O100000001O00000000O1O1O2WORB=oj17ScN3M100O11O1O0O2N2N7I[Va7"}}, "object_label": "cake", "attribute_label": ["color:brown", "color:yellow", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a piece of cheesecake sitting on a table, with a knife sticking out of it. The cheesecake appears to be a slice of a larger cake, and it is placed on a white plate. The knife is positioned in the middle of the cheesecake, indicating that it has been cut and is ready to be served. The overall presentation of the cheesecake and the knife suggests that it is a delicious dessert, likely served at a restaurant or a special occasion."}, {"question_id": 617, "height": 480, "width": 640, "image": "000000227765.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [145.54, 262.03, 155.76, 132.0], "segmentation": {"size": [480, 640], "counts": "SSW25i>4M3M1O1jAIb=7\\BN_<ITD9]O0[<KWD4]O5Y<HYD4]O6X<D^D7WO9X<]OdCMn0=UO;X<^OcD8RO<[<\\ObDW1\\;jNdDW1[;iNdDX1\\;hNUDJM`1m;cNjCK<3Lc1j;_N]DNIh1e;YNcDNIi1e;XNbDOHj1h;TNaD1Hk1Z<VNeCk1[<VNdCj1d;TNjD0Cj1`;[NUEh1k:ZNSEd1o:]NQEb1P;^NoDc1CUNl:9aEb1CUNl:9aEk1ZOlMT;9cEo1UOhMX;9cEU2[:kMeEV2Z:jMeEX2Z:hMdE\\2Z:`MmDLh0g2Z:aMeE]1YOZOQ;YOfE\\1\\OYOn:\\OeEZ1]O[Oo:\\OaEY1@[OP;]O_EX1@ZOS;^O\\EX1BYOT;_OYEW1CZOU;_OWEW1EYOV;@SEW1GZOW;^OQEX1IYOX;\\OQE[1GXOZ;\\OnD]1IVO[;VOaDO<d1IVOo;j0SDUOl;l0TDSOl;m0UDROi;Q1WDoNf;S1[DmNb;U1`DiN`;W1aDVNB?l;[1cDVNA?k;[1dDiN[;X1gDfNY;Y1jDeNV;Z1lDeNU;Y1lDfNV;Z1iD\\N[O2m;a1hDeN[;Z1eDeN];Z1cDgN];Y1cDgN\\;Z1eDeN[;Z1eDgN[;X1fDhNY;X1hDgNY;X1gDiNY;V1aD^NA;o;V1`DROa;l0^DUOc;k0\\DSOg;l0ZDSOg;m0YDSOg;l0ZDSO[;FTDW1b0nN_;]1bDbN^;]1UDXN6:d;]1UD[N87b;^1WD[N78a;[1mDeNS;[1mDeNS;Z1nDgNQ;X1QEgNo:V1TEjNl:P1QDiNU16j:P1^EnNb:R1bDgN97U;Q1TDjN72<5X;o0UDjN72<3@Ja;V1\\DlN80;3A1Z;P1`DoN9O;0A4Z;W1iDgN;0@3[;V1jDhN:`0k:i0cD_N499c0P;j0cDhN3e0[;e1aDnM^;j20000001N1aMaD]1`;aNaD^1a;aNaD[1b;dN_Dd0KUOh;6^Dc0LUOj;5\\DYOJV13XOj;7_D`0JUOk;7\\Dd0JROm;8[Dd0KPOm;:YDf0Y<YOgCg0Y<YOhCf0Y<XOiCf0X<ZOjCc0X<[OjCd0V<\\OjCc0W<]OjCb0W<\\OjCc0X<\\OjCa0Y<\\O]C0G`0c=B\\B=c=EZBKL=k=HYBLK;[>4K_OmAa0R>AjA`0X>03OOJgAI[>77000N2_AFZ>;gAFV>=iACV>d00O1O9_O`ANl>OU_P5"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "texture, state", "answer": "The carrot in the image is long and thin, with a slightly curved shape. It is placed in a bowl of soup, which is filled with a variety of vegetables. The carrot is surrounded by other ingredients, such as broccoli and possibly other vegetables, creating a colorful and appetizing dish."}, {"question_id": 618, "height": 427, "width": 640, "image": "000000260470.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [395.33, 235.81, 69.41, 34.06], "segmentation": {"size": [427, 640], "counts": "ViU57S=4L4L3M2N2N2N101N2O0O1O2O0O101O00001O000000000000001O0000000000000000000000000000O2O0000001O0O10001O000O10001N100O2N2N1O2N1M4N2M3MWbY2"}}, "object_label": "cake", "attribute_label": ["color:brown", "color:tan", "size:small/little/tiny", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, color, texture", "answer": "The image features a close-up view of a delicious-looking pastry, possibly a donut or a cake, with a white frosting. The pastry is placed on a table, and it appears to be a dessert or a sweet treat. The frosting is spread evenly across the pastry, giving it a mouth-watering appearance. The overall presentation of the pastry is visually appealing and inviting."}, {"question_id": 619, "height": 427, "width": 640, "image": "000000276434.jpg", "category": "description", "question": "Describe the orange in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [333.33, 257.46, 21.07, 25.5], "segmentation": {"size": [427, 640], "counts": "o`[41Y=3N1O002M3N4L9G0000000000O2N2N2M3O2M2N8H_bf3"}}, "object_label": "orange", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color", "answer": "The orange in the image is a slice of orange placed on a white surface, possibly a table or a piece of paper. The slice is cut in half, revealing the orange's interior. The orange appears to be fresh and juicy, with a vibrant color and a smooth texture."}, {"question_id": 620, "height": 480, "width": 640, "image": "000000308430.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [208.54, 293.27, 129.16, 64.16], "segmentation": {"size": [480, 640], "counts": "_gR32m>1XAOa>16N30nX30QgL101O00000iA0]=1^B6`=J_B8`=H^B<`=DVBN2a0f=BXBM1b0g=AXBMOe0h=^OYBMNf0i=]OYBMNg0h=[O[BNMg0h=[O[BNNf0g=[O\\BOMe0h=\\O[BOLf0h=]O\\Bf0d=\\OZBd0f=]OYBc0g=]OXBd0h=[O[Bd0d=YO`Bf0`=YObBf0^=[ObBNGb0g=AaBMIa0f=BfB>[=AeB?\\=@dB`0\\=AcB?]=BbB>^=BcB=]=EdB8\\=HdB8[=BYB2=<Y=C[BO=>Q>0O000001O00001O01O000001O0000000000O1O100O100O010O1OO01000001I6M4O1O1O010O0001O1O001O100O100O00100O100O100O100O100O1O100O100O1O2O000000000O101N1O2N1N3Mhe^4"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "state, texture", "answer": "The carrot in the image is long and orange, with a slightly curved shape. It is one of the many vegetables in the dish, which also includes peppers, onions, and other ingredients. The carrot is placed among the other vegetables, creating a colorful and appetizing presentation."}, {"question_id": 621, "height": 480, "width": 640, "image": "000000308430.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, pose, size, texture, transparency", "region_anno": {"bbox": [0.0, 201.97, 289.62, 278.03], "segmentation": {"size": [480, 640], "counts": "S=k1U=0SOYN\\Dl1S;RN`D1L4=m1U;oM^DOO15O8T2Q;\\NoDm1m:WNQEk1m:RNhD@6c2Q;jMhDC2O00Oe2W;hMjDCO2Oh2W;dMkDe2Q;nLmD90F3R3T;XMkDFOS3[:oLUFMB6OK0W3Y:lLVFLB7ML0V3Z:jLUFMHh3i9dL^FFGg3j9cL`FFAk3i9fLZF_O41Ij3f9gLjF^3R9eLnF\\3n8gLfFVO5U4T9eLhFVO3V4S9eLiFWO4T4R9fLjFUO5U4n8hLlFSO4Z4l8fLnFRO5Y4l8kLUGT3l8eLnFTO5X4l8eLoFSO5X4l8cLoFQO;\\4e8bLRGSO8[4e8bLSGSO7]4e8`LTGTO6]4f8_LSGUO6]4e8fL[G[3c8fLZG^3e8bL[G_3e8`L[Ga3e8_L[Ga3d8\\L`Gd3_8VLZGTO8]3FjMg8E[GUO6h4^8TL\\GTO6h4]8UL\\GTO6h4]8[LaGg3]8YLcGi3\\8WLdGj3\\8ULeGj3[8WLeGi3[8ULgGk3X8TLfGmNLo4]8TLhGnNJn4]8ULhGnNKl4^8VLgGo3W8SLhGm3X8SLfGo3Z8QLfGmNMm4]8VLgGmNLm4\\8VLiGn3X8PLjGP4U8PLlGP4S8PLjGlNMT5X8PLlGmNKR5Y8RLkGS4U8mKkGR4T8oKhGV4W8kKiGT4W8kKjGnNNQ5X8QLlGT4S8jKQH1Hl2W8SMmGlNOP1MSO0n3W8SMmGlNNX5U8lKmGnNMU5V8mKmGoNMT5U8mKoGX4P8jKmGX4S8hKmGX4T8gKmGY4S8fKnGY4Q8gKQHX4n7iKoGkNOe1NP2T8`MoGlNNZ5S8jKPHlNMY5T8iKPHPOKV5T8kKQH[4m7gKRHZ4n7eKQH\\4P8dKPH\\4o7eKQHZ4o7cKTH]4k7eKUHWOKY1Od1Q8lMRHlNN<Ob4R8VLQHAM]O0b4Q8aLQHANR4Q8[LSHDLP4Q8\\LSHEN^O0T4n7jLSHGM\\O0T4o7jLSH1NT3P8kLRH]4n7`KQHmN2X10n2k7nLXHHJVO151JO11i3l7ZMXH6JmN0d3n7YMTHlNOa5m7dKTH_4l7aKTH`4k7^KVHc4j7]KVHc4k7]KTHd4k7]KUHf0No1m7\\MTHa0Od11UMk7d0UHL0WOOL053o24UMe7h0WHo35YKd7h0WHlNMP59\\Kb7i0WHlNOm43UKM8j7i0XHnNNk42eKh7a0ZHoNLk41fKi7?_Hl3GeKj7?`Hk3F`K0G[9f4fFcKOG`9a4aFhKOEd9g1]FXOOa01kNOEg9^4ZFQLk9k3UFULo9g3PFYLS:e3mEZLW:c3hE^LZ:R43M3N5K1ULZEi21VMj:d33N4M2UOlDfMU;YOkDm21jMX;m22O2N2L3O3L2N3N2M2O1O2N1N3M4L2O1N2O2M102M3N2N1N2N2O2SORCDo<JQCMO8T=GUCDHj0S=ZOnBM>g0f<YOoB0>O_O>`=BWC=i<DWC;k<CVC<d<EeBOh0:d<GcB1l02b<MbB2b>O]A1d>5002O0OkAJB0i=4lBLT=1YBOf>2KNZA1f>1YAOh>5UDJj87UGIk87UGIm85SGKn84RGLP92PGNQ90PGOmh10ScN100ZV_6"}}, "object_label": "oven", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "color, cleanliness, transparency", "answer": "The oven in the image is a black stove top oven, which is placed on a countertop. It is filled with a delicious stir-fry dish, containing a variety of vegetables such as carrots, mushrooms, and peppers. The dish is being cooked in a large pan, which is placed on the stove top. The oven is surrounded by a countertop, and there is a book nearby, possibly a cookbook or a recipe guide."}, {"question_id": 622, "height": 300, "width": 400, "image": "000000312552.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [165.86, 129.96, 41.55, 31.87], "segmentation": {"size": [300, 400], "counts": "m`b11ib02WFb0E5M0O2O001O0O101O000000000001N1O2N1O1O1O2N1O1O6J2M2O100N2O1O2N2NdSh1"}}, "object_label": "pizza", "attribute_label": ["color:orange", "color:red", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "size, color, state", "answer": "The image features a person holding a slice of pizza in their hand, with the pizza being partially eaten. The slice appears to be a cheese pizza, and it is being held up to the person's face, possibly to take a bite. The person is wearing a black shirt, and the pizza slice is placed in the center of the scene."}, {"question_id": 623, "height": 424, "width": 640, "image": "000000353027.jpg", "category": "description", "question": "Describe the pizza in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [56.22, 141.97, 583.78, 281.08], "segmentation": {"size": [424, 640], "counts": "Pei02U=2N3N2N1O1O1N2K6I5M4N1O100O010O1O10O10O101O1O1O0000000000000TKQO`Mn0_2VO^Mj0a2YO]Mg0a2\\O^Md0`2@^M`0`2B`M>^2DbM<]2FbM:]2HbM8^2IaM7^2KaM5^2MbM2]20bM0^20bM0]22bMN]23cMM\\24cMM]25aMK_26`MJ_28`MGa29^MI`28`MH`2:^MFb2=[MCd2?[MAe2b0WM_Oh2c0WM]Oi2c0WM]Oi2d0VM\\Oj2d0VM\\Oj2d0VM\\Oj2e0UM[Ok2e0UM[Ok2e0UM[Ok2e0UM[Ok2f0SM[Om2e0SM[Om2e0SM[Om2f0RMZOn2f0RMYOo2g0QMZOn2g0QMYOo2g0QMYOo2g0QMXOo2i0QMWOP3h0QMXOn2i0QMWOo2i0QMWOo2j0PMUOP3m0oLSOQ3m0oLTOQ3l0nLTOR3m0mLSOR3n0oLQOQ3o0oLQOR3o0mLQOS3o0lLROT3o0kLQOU3o0kLQOU3P1jLPOV3Q1iLoNX3P1hLPOT3U1kLkNU3U1kLkNT3V1lLjNS3X1kLiNT3X1lLhNT3Y1kLgNT3[1kLeNT3]1kLcNU3^1jLbNV3^1iLcNW3^1hLbNX3_1gLaNY3`1fL`NY3b1eL_N[3b1dL^N\\3c1cL]N]3d1bL\\N^3e1aL[N_3f1`LZN`3f1`LZN`3g1_LYNa3g1_LYNa3h1^LXNb3h1^LXNb3i1]LWNc3i1]LWNb3k1]LUNc3k1]LUNc3l1\\LTNd3l1\\LTNd3m1ZLTNf3l1ZLTNf3l1YLUNg3k1YLUNg3k1YLUNf3l1ZLTNf3m1XLTNg3m1YLSNg3m1YLSNg3m1YLSNg3m1XLTNg3n1XLRNh3n1WLSNh3n1XLRNg3P2XLPNg3Q2YLoMg3R2XLnMg3T2XLkMh3V2XLkMg3U2YLkMg3U2YLkMg3U2YLkMf3W2YLiMg3W2YLiMg3W2YLiMg3W2YLiMg3W2YLiMg3X2XLhMh3X2XLhMg3Y2YLgMg3Z2WLgMj3X2VLhMj3X2VLhMi3Y2VLhMj3X2VLhMj3Y2ULgMj3[2ULeMk3[2ULeMk3[2ULeMk3\\2TLdMl3\\2SLeMn3Z2RLfMn3Z2RLfMn3[2QLeMo3[2QLeMo3[2PLfMQ4[2lKfMT4kNSJP3i1UNU4dNWJX3c1UNV4aNXJ[3b1TNb4m1]KSNc4m1]KSNc4m1]KSNc4n1\\KRNd4n1\\KRNe4n1ZKRNg4m1YKSNi4l1VKTNl4j1SKWNn4i1QKWNP5h1PKXNQ5g1oJYNR5f1nJZNT5e1kJ[NU5h1hJXNZ5g1eJYN_5d1`J\\Na5c1_J]Nc5b1\\J^Ne5a1ZJ`Ni5]1WJcNk5\\1TJdNn5Z1RJfNS6U1mIkNX6P1gIQO[6n0dIROa6[NXH\\2V1YOk6b0SI_Oo6?QIAQ7=oHCT7:lHFX76gHK[73eHM[74dHL\\74dHL\\75bHL^76`HJ`77^HJa77_HIV7c0iH]OV7d0iH]OW7d0hH\\OT7VNSH_2h0\\OW7e0iHZOX7f0gH[OY7g0eHYO\\7h0aHYO_7g0`HZO`7f0`HZOa7e0_H\\O`7e0^H\\Oc7c0]H]Oc7c0]H]Oc7c0\\H^Oe7c0YH]Og7g0PHZMMP2T8P30000O11O0000001O1O1O3M1O00002N001O003M3M001O1O1O3L3N100O1O0000000000001O00HlKXG1OS4i8lKXGY4l8O0000002M2O00EmK]GX4`89N2L4N2M3I7M3L4N2N2IbJcH_5[78M3N2N2iMSJRMn5l2VJoLm5P3XJfKELh6]4fI]KM2^6a4]JZKf5f4^1O10O1000O2O000000000000000O01000000000000000000000000000000000000000O10000000000000000000000000000000000000000000000000O100000000000000O100000000001O1O000000000001O000000000O1001O0000000000000000000000000000000000000001O000O10000000000010O0002N0000001O004LLlGTKT8j4nGWKQ8j4nGVKR8k4mGUKS8k4mGVKR8j4oGTKR8h4mGWK21Q8h4SHVKn7j48001O01O0O01000000000001O10O01N2OO10000O100001O00000000000000000000001O0000001O00001O00000000000000000000000000001O0000001O000000000000001O00001O01OO2O000010OO10000001O01N1000001O0000000000001O00000000001O00000001OO2O00000010O0000O101O00000000001O001O00001O00000000001O1O00001O00001O000O10\\J"}}, "object_label": "pizza", "attribute_label": ["color:red", "color:white", "size:big/large/giant/huge", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture", "answer": "The image features a close-up view of a pizza with various toppings, including mushrooms and cheese. The pizza is being cut into slices by a person using a knife and fork. The person is in the process of taking a slice of the pizza, and the pizza is placed on a dining table. The scene captures the delicious and appetizing nature of the pizza."}, {"question_id": 624, "height": 291, "width": 640, "image": "000000438226.jpg", "category": "description", "question": "Describe the sandwich in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [333.51, 27.47, 133.4, 132.09], "segmentation": {"size": [291, 640], "counts": "Tfn27l822LUGLi89N0@KSHLF744X7;bHC64Q7j0mHXOo6k0PIXOk6j0VIVOg6l0[ITOb6n0YIbNO10;f6m1N2M4L4NO1N31O4L2M201N2N2N1O2N2N1O001O1O1O1O001O1O001O1O1O00001O0O101O010O1O5K2N1O1O1O1O001O1O01O001O001O10O00PMmJP2S5oMoJo1R5QNmJP2S5PNmJP2T5oMkJR2U5mMkJT2U5m01O0O101jLhJ^2Y5aMiJ^2W5`MjJ`2X5_MhJa2X5^MhJb2Z5]MeJc2]5\\MbJe2^5[M`Jf2a5=2N2N1gL^JQ3c5mL\\JT3i5O2O00O1O0010O1KSJSMo5m2201O2000001O0HmI`MS6^2nIbMT6[2nIdMS6Z2oIdMW6W2<N3L4K4M4L3M4L3N2M5I5L6K4K5K5F:M2OiRc1"}}, "object_label": "sandwich", "attribute_label": ["color:tan", "size:small/little/tiny", "state:piece/cut", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color, texture", "answer": "The image features a white plate with a delicious sandwich cut in half, revealing its contents. The sandwich is filled with meat and cheese, making it a hearty and appetizing meal. The sandwich is placed on a dining table, and there are also some vegetables on the plate, adding a touch of color and nutrition to the meal. The combination of the sandwich and vegetables creates a visually appealing and satisfying dining experience."}, {"question_id": 625, "height": 612, "width": 612, "image": "000000457262.jpg", "category": "description", "question": "Describe the banana in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [64.8, 151.2, 393.12, 234.72], "segmentation": {"size": [612, 612], "counts": "`T]1`0ab06M4J4M4M2M2N2O000O10000O100O101O0O1000000O10001O000O10000O1000000O100000000O1000000O10000O10000O101O0O100O10000O10000O2O0O100O100O2O0O1O2O0O101N2N2O0O101N100O2O0O2O1N2N2N10001N100O2O1N101N10000O100O101N101O000O10000001O0001O0000000000000000001O0000000000000000000O100000000000000000000000000000000001O000000O10000000000000000000000O100000O100000000000O1000O10000000000O10O1000O1000000000O010000O10000O10000O10O10O1000000O1000000O1000O10O100000O01000000O10O10O100O10O10O100O0100000O1000O10O10O10O10000O100O01000O01000O1000O10O100O10O010O10O10O10O0010O0100O010O100O001O010O1O10O01O1O001N10000O20O0001O000000010O10N11O010O10OO100O11OO2O010O001N1000001N100O1N2O1M20001O1O0101O000O1NO20010M2N4M2M4L4M3MO120JfNc^OX1_a0iNa^OU1f`0fNS@5WOS1g`0jN\\_O58W1]`0TO`_Ol0``0eNY_O79S1_`0eN\\_O19Y1Xa0mN^^Ob0fa0VOW^O15f0ka0YOW^Oc0ja0^OW^O`0ia0AX^O=Yb0O2L3N2OSNHPA4WY2LmWN201^ONh]O0L4kb0N2OZkn2"}}, "object_label": "banana", "attribute_label": ["color:brown", "color:yellow", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, state", "answer": "The image features a bunch of bananas on a wooden table. There are two bananas in the scene, one of which is partially peeled, revealing its yellow interior. The bananas are placed next to each other, with one banana being larger and the other smaller. The wooden table provides a natural and rustic setting for the bananas."}, {"question_id": 626, "height": 427, "width": 640, "image": "000000486438.jpg", "category": "description", "question": "Describe the donut in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [156.71, 228.78, 134.94, 80.8], "segmentation": {"size": [427, 640], "counts": "PgQ22W=3N2N1O1O1O1O1O1O101N1O100O101N1O1O100O2O000O1O2N100O1O100O101N1O2O0O101N10001N10001N101O001N101O1O10O2O3M1O2N2M2O1OO11OO11O01O1O0O2O001O001O1O2N0001OO01O10O0001O0010O01O00001O001O00001O010O001O000O2M2O1N2O2M2M3N2N2N2O1O1O1O2N1O101N1O2O1N2O0O\\Xf4"}}, "object_label": "donut", "attribute_label": ["color:brown", "size:small/little/tiny", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, size, texture", "answer": "The image features a close-up view of a donut with a glaze, which appears to be a chocolate-covered donut. The donut is placed on a table, and it is surrounded by other donuts, creating a visually appealing arrangement. The donuts are of various sizes and shapes, with some being larger and others smaller. The close-up view of the chocolate-covered donut highlights its delicious appearance, making it the focal point of the image."}, {"question_id": 627, "height": 483, "width": 640, "image": "000000493799.jpg", "category": "description", "question": "Describe the carrot in the following image in detail.", "dims": "color, size, state, texture", "region_anno": {"bbox": [470.3, 270.27, 79.67, 80.03], "segmentation": {"size": [483, 640], "counts": "n`V71n>301O1O001O1O0O2O1N20O01N1O2O000O2O001N10000O100N2O2N010O1O101N1O00101N100O001O101N100O100O1O1001N102N1O2M2O2N3L3M4Lfb[1"}}, "object_label": "carrot", "attribute_label": ["color:orange", "size:small/little/tiny", "state:full/whole", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, size", "answer": "The image features a close-up view of a carrot, which is placed on a plate. The carrot is cut into several pieces, with some of the pieces being larger and others smaller. The carrot appears to be cooked, possibly roasted, and is placed on a dining table. The close-up view of the carrot highlights its texture and details, making it the main focus of the image."}, {"question_id": 628, "height": 640, "width": 480, "image": "000000323151.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [0.0, 6.75, 480.0, 624.18], "segmentation": {"size": [640, 480], "counts": "=230O16Nf21]=0h_O0O11N10f11WO2T4Om5NRE`03AMW22i3S1QJi3^3`KQMAC1T21j3:nIH3M2M1m4]3iK^L[O2OO6OLX22i3:nIH3NNT5b3VLfNeNg3o0PJZ4`3RLiNeNf3_6dMiJeNgNh3`6QJ_I_3Y1hNhNg3h0UJm4\\3cKhNhNf3g6aMaJiNgNf3i6\\MVIiLZ1U2fNf3l6aMTIcLU1U2lNg3b0SJc5f3PJ[L0O7W2De3b0VJb5e3PJZL02OMOX2Nc3o6aMPIjL6KM30MOW20`3R7cMlHlL1JO0150NOT23_3T7gNiHjM3_3T7gNiHjM3^3V7gNgHkM3^3W7_NfHoK0T23]3Y7[MdH]M1IO03LMV23]3Y7kMdHgL0O2LOV22\\3[7UNbH]L2I2Y2O[3\\7_NcHmK2Y2N\\3^7_MbHgMNVO3Y2OY3`7\\M_HSM1OOi02`1NY3c7[M\\HXN1U10W3e7cN[HVN0V3g7Q1XHoNj7ZMVHlM2_O0Y2NR3k7RN\\H]LL]2NT3l7RNSHeL0V21S3l7l0THTOl7l0THSOo7k0PHUOR8j0nGUOS8k0mGTOU8k0kGUOU8k0kGTOW8k0iGTOX8Y62N1O2O001N2O0O2O1N2O0O2O0O2O0N3N1O101O1N1O10001O0O2O0O2N101O1O0O100O2N2N100O2O000O1O2O001O001N101O0O10000O2O0O2N101N100O101N101O0O101N10000nKiE\\J12Od3W:m1oE]JM0Ma3W:R2\\FjMe9T2_FhMb9X2`FfMa9W2bFgM_9R2eEkJo0Q3]9S2iFmMW9R2kFmMV9Q2nFlMR9T2oFkMQ9U2oFkMR9T2oFjMR9V2nFjMR9W2oFfMR9Z2oFeMR9R1`EZM^1d1R9Q1bEZM\\1d1S9R1aEYM]1e1R9jN^EaN0m15lNJWOc1e2P9jN_E`NO`00j06^OKWOc1f2o8jN^EaNO7OO11Oi07DI\\Oj1d2k8kN\\EcNO41L5OJ01n07Df1Q2g8kN\\ElN0F56Jh08Dg1o1h8lN[EmNNF2ONZ18ZOH\\Ok1b2l8lN[EROOl08\\Oa1j1m8lN[Eb07iN`1i1n8lNZEc08jN_1e1P9nN[Ea06mN^1d1Q9nN^E>4oN_1c1o8PO^EcNKf19fNFK0Hj1]2n8QO^EcNK;Ol0:TOGLOHk1[2n8SO]EcNL9On09TOGLOHn1X2l8UO\\EdNL5NK1W19SOH0n1k1j8WO\\EdNO2KN1V1:TOF1o1j1j8WO\\EdN01JZ1;oNF1P2i1i8XO\\EfNN2NR19SOG1P2j1i8WOZEjNMN1S18SOG1P2i1j8XOZEfN03KR1:SOG0Q2j1i8XOeE4JjNGOS2j1g8YOeE3KjNF1T2h1f8ZOgEgN^OS1;SOF0U2i1e8ZOiEeN\\OU1;SOF0U2i1e8ZO[EcN60EW1:SOF0U2i1e8ZOZEeN:U1LROF2V2f1f8[OXEgN9T1MROF2V2f1f8[OXEgN:S1LSOF2V2f1f8[OXEgN:S1LROG3U2e1g8\\OkEKBQOG3V2d1f8]OkEKBQOG3V2d1f8]OjELCoNH4U2d1f8]OjELCoNG5V2c1f8]OiELEoNF5V2c1f8]O]EdNNX13oNF5W2b1e8^OiELEoNF5W2a1f8_OhELEoNE6X2`1f8_OhELEnNF7W2`1g8^OYEfN1W12nNF7W2`1g8^OfENFmNF7W2`1g8^OfENFmNF7X2^1g8@eENFlNG8W2^1g8@eENFlNF9X2]1g8@eENFlNF9X2]1g8@fEMEmNF9X2]1g8@fENDlNF:Y2\\1g8@fENDlNF:Y2[1i8@dEODlNF9Z2\\1h8@dEODkNG:Z2[1g8AdEODkNF8^2]1d8AdEODkNF7_2^1c8AcEOFkNE7_2^1c8AcEOFkNE7_2^1c8AcEOFkNE7_2^1c8AdENElNE7_2^1c8AdEODjNF9_2\\1d8BcEODjNF8`2]1c8BcEODiNG9_2]1c8BUEkNMS16jNF9_2]1c8BcENEjNE9a2\\1c8CbENEjNE9a2\\1c8CaEOFiNE8b2]1b8CdELClNE7c2^1a8CeEKBlNF8b2^1a8CaEfN[OU1;lNF7c2_1`8C`E0GgNF2h2d1[8C`E1GeNE4i2c1[8C`E0LjNY2c1[8C`E0LiNZ2d1Z8C`E0LjNY2c1[8C`E0LjNY2c1[8C`EhNZOS1b0POY2b1[8C`EhN[OR1a0ROX2a1\\8C`EhN]O3Mf0b0\\OW2`1]8C`EhN]O2Ng0a0]OU2`1_8B`EgN_O2Li0`0\\OV2`1_8BlDgN?0D2M4N;a0GU2_1`8BlDhN>OD3Nf0`0_OT2^1a8CkDiN03:MGg0?_OT2^1a8CkDgN252JN4Mg0a0^OT2^1a8CkDgN5002L0Nh0`0_OU2]1a8CkDfN6004KNN`0OEa04T2\\1b8CUEgNL2KON?0F`04S2]1c8BUEgNM1KNNa0OF`05R2\\1d8BiEfNSO7M010`05R2\\1d8BiEgNRO6N010?6R2\\1e8AhEhNSO5OO1KN2`0:R2\\1e8AhEhNSO5N10O`06R2\\1e8AgEiNSOh0?BR2\\1e8AhEgNTO6M10O`06R2\\1e8AiEfNSO6O000>7Q2]1f8@bEfN\\O0N1N11OO11ON2`0:Q2]1f8@RFhNiNN020ON2`0:Q2]1f8@SFfNmN2K4>7Q2]1f8@SFfNnN0N3::Q2]1f8@dEgNAOL0O28<Q2]1f8@eEfNWOO11N07OO28<Q2]1f8@lDeNe02YOO353K118<Q2]1f8DbEfNYO30N1KO1==R2\\1f8BmEiNPOJM23ON0>>Q2\\1f8@hFeNaN?P2]1g8_OYGTO0]1g8_OYGTO0]1g8_OfEgNc0>o0\\1h8_OfEhN8MSOa0V2\\1i8^OfEiN`0<R1]1g8_OgEiNUOM90=?g1\\1g8_OgEoNUOE35b0<h1\\1g8_OgETOTOGf0;f1\\1i8^OgEjNUOJ;1;b0d1[1j8^OhEhN3LWOb0I_OY2n1l8]OhEgN4NUO`0K@X2n1l8]OhEgN4NUO`0K@X2n1l8]OhEgN=>gN@W2o1m8\\OhEfN5NUO`0L@U2P2m8\\OhEfNM1YON3<JD3OS2R2o8ZOhEfNM2XOM4<JD[2Q2j8ZOhEfNM2XOM4?T2c1k8YOhEfNM2XOM4?T2c1k8YOiEdNN2@?m1b1l8YOXGeNfMON8OIT2S2P9YObGoN]Oh1Q9YOcGjNYMJT2T2o8XOdGiN[MJR2U2o8XOiFdNlN5_1P2l8WOiFeNlN2`1R2j8XOjFdNlN1a1S2i8XOjFcNlN3\\OLn1W2P9WOcGgN`MKl1X2Q9VObGgNDT2i8VOcGcNC[2j8ROcGcNB\\2k8QOcGbNC]2j8QOdGaNB^2j8QOkFaNkN0_1_2k8POkFbNiN0a1^2k8POkFcNgN0b1^2l8oNkFcNfN0d1_2j8nNlFbNXNO41I1:O^1`2V9oN^GaNcM27Mg1a2Q9oNaGcNgMMf1b2R9nNaGcNEa2i8lN`GeNG_2h8mN`GdNI_2g8mNmIS1S6mNkII_KIf:>kIHaKIc:`0kIGcKIb:`0kIQO[KN:`0`:a0kIoN^KL:e0\\:`0lImNbKH<i0U:c0mIkNdKG<j0S:d0mIjNeKF>k0P:e0mIiNeLb0^9e0nIgNeLd0\\9f0oIaNkLi0U9f0jKZOV4f0\\F^NV4l0^5f0[FaNU4i0`5f0[FaNV4h0_5g0[FaNV4h0^5h0]F`NT4i0^5g0^F`NR2KjNn0e8h0_F_NS1McNOV1m0e8h0_F`NR1MaN1Y1i0e8i0_F`NC87GG1Z1g0f8i0_FaNA:5HG0^1c0f8j0_FaNA>F[OG10;<Oa1b0e8i0`FaNXOJJg15dNe1a0d8i0`FbNVOJKi12dNh1>d8j0aFdNQOI0_2j1ZNd8j0]FYNROf02n1k1ZNb8j0cFnNPOn1k1ZNb8j0dFmNoNo1k1ZNb8j0dFmNoNo1k1ZNb8j0eFlNmNQ2l1YNa8k0fFjNnNR2k1ZN`8j0gFjNnNR2k1ZN`8j0mEXN;b0]OR2k1ZN_8k0hFhNoNR2k1[N^8k0hFhNnNS2l1ZN^8k0iFgNmNT2l1ZN]8l0jFeNnNU2k1ZN]8l0kFcNnNW2j1[N\\8k0mFbNmNX2j1[N[8l0oF_NmNZ2i1\\NZ8k0PG\\NoN^2g1[NY8l0UGUNmNd2e1[NY8l0dGi03[NY8l0[GSNcNf2i1[NX8m0ZGUNdNc2j1[NX8m0XGXNeN`2l1[NV8m0TG]NjN[2l1[NU8n0TG]NkNZ2l1\\NT8m0UG]NjN[2m1[NS8n0VG\\NiN\\2n1ZNS8n0VG\\NiN\\2n1[NR8m0WG[NjN]2m1[NR8m0XGZNhN_2n1ZNR8m0XGZNhN_2n1[NP8m0ZGYNhN_2n1[NP8m0[GXNfNa2o1ZNo7n0\\GWNfNa2o1[Nn7m0^GVNeNa2P2\\Nl7n0`GSNeNc2o1\\Nl7n0bGPNdNf2n1\\Nk7o0eGlMcNi2m1]Nj7n0mGd0:^Nh7o0nGc0:_Ne6iNXHU2j0oMcNP2f1SOg7n0YIYOPOIf7o0fIlMbLk0R2;d7o0oIcN^N>c7o0XJZNUNg0c7o0gJiMhMX1`7P1PMQOo2o0QMQOo2o0QMROm2o0SMQOl2P1TMPOl2P1TMQOk2o0UMQOj2P1VMQOi2o0WMQOi2o0WMQOh2P1XMQOf2P1ZMPOf2P1ZMQOd2P1\\MPOd2P1\\MQOb2P1^MPOb2P1^MPOa2Q1_MPO_2Q1aMoN_2Q1aMPO^2P1bMPO]2Q1^G_Ma5a1P3P1dMPO[2Q1eMoN[2Q1eMPOY2Q1gMoNY2Q1gMPOW2Q1nL\\MlJd1V8P1lLaMkJ`1W8P1mLfMfJ[1]8o0dLWNfJl0d8n0eL7Z3JfL6Z3JfLAiJiMJ6e8a2gL_OSKnMV8c2fL_OWKmMP8f2hL]OZKlMn7g2hL]O[KlMk7h2^LVMYKT2a0mMh7i2]LXMYKQ2e0mMc7k2^LYMYKl1j0PN]7l2WLVM^K43g1o0RNX7n2XLVM]K34f1_9Q1oJXM]K15e1_9S1oJVM^K15d1U1UNn6P3[LUM_KO4e1V1WNk6Q3\\LTM`KN3e1W1YNi6P3\\LUMaKM3c1Y1\\Ne6P3^LTM_KK0O5c1\\1_Na6Q3^LTM`KN5Y1a1eNZ6Q3[LoLcK42O4o0l1mNo5S3ZLYMfKI5i0Q2SOh5S3]LVMgKI5`0Y2_O]5R3dLlLUL6V2Mo4R3i0mLVOT3k0lLTOT3l0mLROT3n0lLQOU3o0lLoNU3Q1lLnNT3R1mLkNU3U1lLiNU3W1kLiNU3W1lLgNU3Z1kLdNV3\\1jLdN8eHZ2g8_MbNV3^1kL`NV3`1kL^NV3b1kL\\NV3d1kLZNV3g1iLXNX3h1iLVNX3j1iLTNX3l1hLSNY3n1gLQNY3P2gLnMZ3R2gLlMZ3T2hLiMY3X2gLfMZ3Z2gLcM[3]2fLaM[3_2fL_M[3a2fL]M[3c2eL\\M\\3d2eLZM\\3f2eLXM\\3h2eLVM\\3j2fLSM[3m2fLQM[3n2gLPMZ3P3gLnLZ3R3gLjL\\3V3eLhL\\3W3fLgL[3Y3fLeL[3[3fLcL[3\\3hL`LZ3`3gL^LZ3a3iL[LY3d3jLXLX3g3jLXLV3h3kLULW3j3lLSLU3m3lLQLU3n3nLmKU3R4mLlKT3T4nLhKT3S3PKdIm1V3U3S3YK^Id1]3T3T3^KVIo0A`N67j3o4X3`KPIi08hN]3P5[3XM]IfMU3T5^3RMcIjMj2W5c3kLiImMc2X5d3gLQJnMX2]5g3bLUJTNn1\\5n3]LVJYNf1^5T4VLZJ_N\\1]5[4QL\\JdNU1\\5_4lKbJjNe0`5i4cKeJQO;_5P5_KgJTO3`5V5[KiJYOI_5^5UKmJ@\\O_5g5oJQKDPOa5o5jJRKIhN`5W6fJRKb7n4]HSKc7l4^HUKa7k4_HWK_7i4aHWK_7i4`HYK]7i4bHYKb1]M\\M2N2Mlh0"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:stone/granite/cobblestone/gravel/marble/pebbled/rocky/sandy", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "material, color, cleanliness, pattern, texture", "answer": "The dining table in the image is set with a delicious pizza on a white plate, accompanied by a glass of beer. The table is surrounded by chairs, and there is a cell phone placed on the table. The table appears to be in a restaurant setting, with a bowl and a spoon also present on the table. The overall atmosphere suggests a casual and enjoyable dining experience."}, {"question_id": 629, "height": 450, "width": 640, "image": "000000349480.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [160.28, 0.52, 229.42, 250.75], "segmentation": {"size": [450, 640], "counts": "SfW26k=3L3VEIaM1a98kHJ^M4e94kHJ]M4g94hH?W7BfH`0Z7@dHc0[7^ObHf0[7[OcHh0\\7YOaHj0]7WOaHl0^7UO^HQ1_7oN_HT1`7mN^HT1b7lN[HX1c7iN\\HY1c7hNZH[1e7eNYH]1g7cNXH]1h7dNVH^1j7bNUH^1l7cNRH^1n7bNPH_1Q8aNoG_1P8bNnG`1R8aNkGa1T8`NjGb1V8_NgGb1Y8`NeGa1Z8aNeG_1Z8cNcG_1\\8bNbGa1\\8`NcGa1\\8aNbGb1[8`NcGb1[8_NcGc1\\8_NbGc1\\8_NbGW1B^M0Kk8b1bGT1F`Mh8\\1aGT1HaMe8]1aGS1J\\MLNh8d1bGT1G[Mk8a1]G\\1KoLa8f1cGP1JaM3I^8h1cGo0M_M2L\\8f1bGQ12[MO2Z8b4QH`Kn7[4eG]K<:m7Z4XHgKg7Y4YHhKe7X4SH^KJ:R8W4THbKJ6P8U4TH_KJ91KM2R8Z4WH`KJ90IN6o7S4^HeKE97Ne7Q4hHSL@Of7l3iH[L^OJi7i3kHRL[OO14LGl7S4mHTLYON33KIj7R4QInKUO11451KKg7Q4iHnKJ1D68LLNc7T4hHlKD02<3C00]7Z4\\HeK53MO1>>Fm6Z4fHcK5>:Dj6\\4fHaK6a09Di6\\4fH_K8b07Ej6]4fHZK:g00En6[4VIPLJHn6Y4TIQLOGk6Y4TIRL1Ek6Y4SI_KI980l6Y4PI[K2<L6P7T4PI[K;Q1e6e3mH\\K`0n0b6Q4aImK]6d3RIkKO^O4U1k6_3XIaKHd1o6j2]I_KDg1n6i2`I\\M`6b2_IaMa6^2`IbM_6^2bIcM]6Y2XIfK7Q2a6X2XIhK6Q2a6W2ZIiK3P2d6V2YIYN_6n1bIRNZ6P2hIPNW6R2eIaKLW2_6Y2dI`K0g1M_N_6e4eIYMZ6k2dISM\\6o2cIPM^6^2aImK0`1b6b2`InKN[11TNb6W4_ImKO`2d6`1jI_NW6^1lIbNT6\\1nIdNR6Y1PJ[LZOS2f6b1nIiNS6Z1hIhNX6Z1eIdN^6[1`IgNa61VIZN9g1a60UIhM8ENf2f6`0_IhLFk2m63VIoL:2Bm2n61gI7Z6SORIUNe0h2Z6ROQIWNd0g2[6HUIQM6W3e6HTIRM7U3g6HRIRM7W3g6POPIZN2^O8X3f6HQIPM50HY3S7UORIlMLH4\\3n6nNWIlMFJ1`3S7TMRI11DMm3R7\\LRJGlNm3T7XLQJOjNg3Y7ULnI4kNAKQ4^7XLkI7PO`3W7ULkI<lN`3[7oKlIc0gN^3n8dLoF]3Q9j000000O100000100O10000O2N001O001O0000O1000001O0001N100O2L4O0N3N1O2N1]N_FdNc9Z1`FfN_9Y1bFgMFd0h9c1eFeMFg0e9d1fFcMFi0e9b1YGnMPOEi9[2\\GjMm8R2XGkMj8U2XGgMj8X2a1O1O1O1O1N2O1O1O2K5L3O2M2O2N1N3O1O001N1O101N1O2N101TORC`0P=\\OSCd0W=N2N2N2O0O1O2N2N2N2O2Nkce3"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plaid/tartan/checkered", "texture:soft/fluffy/furry/hairy"], "control_dims": "material, cleanliness", "answer": "The teddy bear in the image is a large, brown, and fluffy stuffed animal. It is sitting on a chair and appears to be wearing a shirt and suspenders. The teddy bear is positioned in front of a plate of food, which includes a cake and a cup."}, {"question_id": 630, "height": 450, "width": 640, "image": "000000349480.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, material, texture, transparency", "region_anno": {"bbox": [32.29, 125.11, 228.02, 249.22], "segmentation": {"size": [450, 640], "counts": "od?6h=6L4J9H8VLPOSJZ1dLRO_8MeJg1W5^NbJi1X5\\NbJj1Z5ZNaJk1Z5YNbJm1[5SNcJU2V5lMgJX2X5iMcJ^2Y5cMdJb2Y5`McJ3VNX1S7iNdJN\\NY1o6kN`JObNV1m6nN\\JMiNU1j6POXJNnNS1j6POTJOROS1h6POSJNUOS1g6PORJNWOS1f6POQJNZOR1d6ROoILDk0^6[OkIJIi0]6^OhIINf0[6DcIF3f0[6D`IG5d0\\6G\\IA_OfNk0Q2[6IYI@BfNj0P2]6JTIBFcNh0R2^6JQICf0b0X6MQIAg0b0Y6MnHCh0`0Z6OjHCk0bNYO`1S7Q2dI^L[O`1Q7R2eI\\L\\Oa1o6S2TJkMm5V2mIZLkN`1W7W2`IXLAh1o6Q2_IWL[O01h1V7R2hImMY6T2gIjMZ6X2fIVLPOX1[7b2VITL1W1k6e2QIXL3R1m6g2RISL3S1m6j2eIRLjNR1c7m2bIQMc6Q3\\ImLe6U3TInKTOl0i7[3mHhK]Ok0f7_3lHfK_Ob0m7h3mHQLSOEQ8[4ZHeK56BOi7V4`HeK55C1f7V4XIhKQO5e7T4YIgKRO7c7R4[IfKSO9a7R4oHbKD3INN;e7R4mHeKON_O=c7Q4eIbKhN?`7Q4kIPLT6o3\\IbKUO12c0]7i3ZIgLe6Y3YIkLd6U3]IkLc6U3]IlLb6T3_IkLa6U3_IlLa6S3YIbK@[1W7S3`ImL_6S3dIjL\\6V3UIbKMY1n6U3TIcKMY1o6T3UIbKK]1n6Q3dInL\\6R3dInL\\6R3dIoL[6P3gIoLY6Q3gIPMX6o2hIRMX6m2iITMV6k2lIUMR6l2VIeK`0\\1Z6n2VIjK?W1Z6n2XIjK?X1X6m2\\IiK=[1U6l2_IhK=\\1S6m2`IgKF2>\\1[6k2fIkKM\\1\\6h2gImKM\\1[6g2hImK^OK=a1\\6g2iIlK0]1U6h2lIiK1^1S6i2eJXMZ5i2eJWM[5\\1ZI]N8kNc0]1j5i2`IkKg0\\1h5m2\\IiKl0\\1f5V3ZJjLf5V3ZJjLf5V3PJVKDf1[6U3oIWKFc1[6^1^IWM8i09nNFd1[60_IFOnN;h06POGd1Y6LdI74ZO7nNIe1Y6JfI83YO4POJe1Y6HhI?GVN1n0g0e0j5DkIh0BROg0b0m5BkIP27^No5TOXJY1SOROe0a0o5SOZJY1TOZO;:X6QO[Jj2]OTNY6PO[Jl2]ORNZ6oN\\Jn2ZOSN[6nN\\Jn2ZOSN[6mN]Jo2XOUN\\6iN]JS3WOSN]6gN^J^1hN29Ff6fN[JY1dNfN0N5g15DZ8:aG06FY8;`GO7FY8V2iGiMW8W2jGhMV8X2kGgMU8Y2kGgMU8X2lGgMU8Y2lGfMU8V2PHgMQ8X2RHfMo7Y2SHdMn7Z2WHcMj7Z2YHcMk7Z2WHdMn7W2THXMiN13KP9l2SGRMk04oN32MP9j2SGSMn01mN51NR9e2`H[M`NMT9f2S2N1O1O3M1N1O100dM_DV2c;iM]DW2c;iM\\DY2c;gM]DZ2b;32TNhDj0X;P11K5N2OZDmM];S2cDmM^;Y1^DZOn;e0TDWOn;h0VDTOKEj;V1_DPOGKj;U1kDkNV;V1hDhN[;Y1f03N0O001O010OO101O10O01O1N2O1N1N3N2N100O2N2N2N2O2M2NfB^OW=`07M3O0011eCFk:4kCK]1Ni:7jCKe=:000O1O2N1LRP4LRPL4lNLSD8fj0LfmX5"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, texture, material", "answer": "The image features a teddy bear sitting on a table, wearing a sweater and holding a small teddy bear in its arms. The teddy bear is positioned in the center of the scene, surrounded by various items. There are two cups on the table, one near the teddy bear and the other further away. Additionally, there are two bowls, one located near the teddy bear and the other towards the right side of the table. A fork can also be seen on the table, placed near the right edge. The scene appears to be a cozy and playful setting, with the teddy bear as the main focus."}, {"question_id": 631, "height": 480, "width": 640, "image": "000000391140.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [120.49, 86.62, 46.95, 61.04], "segmentation": {"size": [480, 640], "counts": "dmg123Oe>7DLkA4U>NhA3W><0O1N3N1O1N20N1O20O1O1NDHSB8m==00O01001O000OL4FPBGP>9;01000O2O0O2N0O2O0O1O10O101O2M2O2N2N2NUbn6"}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, texture, cleanliness, transparency, color, material", "answer": "The image features a person holding a white remote control in their hand. The remote is designed to be used with a Nintendo Wii gaming system, as indicated by its shape and size. The person is holding the remote in a way that suggests they are either preparing to use it or have just finished using it. The remote control is the main focus of the image, with the person's hand and the remote being the main subjects."}, {"question_id": 632, "height": 333, "width": 500, "image": "000000447088.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [75.65, 61.9, 80.74, 78.16], "segmentation": {"size": [333, 500], "counts": "ZSi05W:2N2N2O1O1O1O100O02OO10000000000001OO11OO02OO11OO11O000O10001O0000000O10000000001O0O10000000000O1000001O0000O11O000O1000O101O0000O2O0O1O0ORe00P[O1N2N000O010cg_3"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, material, color, cleanliness, transparency, texture", "answer": "The baseball bat in the image is black and made of wood. It is held by a person, who is standing on a grassy field. The person is holding the bat in a way that suggests they are ready to swing it, possibly preparing for a game or practice. The bat is positioned in front of the person, with the handle pointing towards the ground."}, {"question_id": 633, "height": 333, "width": 500, "image": "000000447088.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [321.42, 19.52, 144.42, 310.55], "segmentation": {"size": [333, 500], "counts": "P[Y36W:001O001O1O001O000aKGjN9U1HjN:d50O100O100O100O100O100O1O100000001fG^Oc6f0]IZOV67_H>[1[Oh5e0mH1X1\\O^5m1bJSNV5U2jJiMh41RJ\\2U1dM\\4S3dKPMV4S3gKQMU4R3jKQMkNHm4[3UL\\MY3R3fLoLR3Y3lL^LPOEn3R4RMWLTOBM2d3V4]MVLYOGT3l3`LTLS1>ROFW3b3SMTLd0e0mNKW3Y3dNcMV1Z2QOgM\\OaN0f3h0jMWOjNDY3[1nMPOPO\\OQ3g1PNlNPOZOo2l1SNhNQOXOl2R2VN_NTO[Of2X2ZNVNSO^Od2_2\\NPNl2Q2VMmMe2X2^MdMS2l2oMkLR2[3]23O1I701O0O2InKmIW4Q630VNRJVOl5j0UJWO`5R1aJoN]5Q1dJQOX5Q1hJQO3YNa4h2\\KA`4`0aKB[4`0eKBX4>iKCT4>mKCP4XNiKT1:e0l3YNhKQ1=f0k39VLGl3;oKGS47lKIW43jKMY40gK0[4MfK2]4TN\\Kh08T1^4UNXKe0;V1_4EbK;_4YNVK7;a1a4WNSK9;a1c4@[K`0g4\\OZKf0h4UNPKK;Q2g4RNoJGL]O>l2j4nMjJK=X2k4lMfJM=Y2n4lMeJG<_2o4^NPKe1P5YNPKh1Q5VNnJl1T5^MkJB1Q3T5^MnJ\\ONa0Im1[5WNlJZO1a0Jo1X5YNiJWO4a0LQ2V5WNjJUO4d0LT2`0\\M\\OO?NS3j0jLIIe3JQL_3a0kLILR4\\3SLfLLNR4^3PLcLNOT4_3nK]LN6U4_3bLcL`3]3]LdLd3^3YLbLi3^3TLcLo3:^Kj1>nM\\4LeKm1JZNY6^1aIdNe6Z1oHTNLc0X7[21O2M4M3M4L1N2O2N4L5K:F7H7J5J6K5K3M2N3L3N2M3N3L4LcR;"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, maturity, gender", "answer": "The image features two baseball players walking on a field, both wearing baseball uniforms. One of the players is wearing a blue and white uniform, while the other player is wearing a white and blue uniform. Both players are carrying baseball bats, with one of the bats being held by the player in the blue and white uniform. The players appear to be walking together, possibly discussing their game strategy or preparing for their next play."}, {"question_id": 634, "height": 428, "width": 640, "image": "000000491464.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [197.02, 65.63, 150.73, 238.98], "segmentation": {"size": [428, 640], "counts": "RXc26U=3M3M2N4L2N3N2M2N3N2M2O2M3N2N1O2M3N2N1O2N2O1N2O01000O010O12M01O10000O02ON21N1O2OO1O010O10O1O10O01O1000O01O010O100O100O2EUDnNm;n0;N3M3M2A`0Hoda00W[^O2N3M201O1O00O02O1N2O0O4M1N100O010O11N100O10O100O1000O001M3N2N1O2N2N2O0O2O1N2MShi3"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The baseball bat in the image is black and white, with a black handle and a white barrel. It is being held by a young boy who is smiling and posing for the camera."}, {"question_id": 635, "height": 428, "width": 640, "image": "000000491464.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "length, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [515.3, 220.52, 19.72, 14.57], "segmentation": {"size": [428, 640], "counts": "dlg64W=2KKQC6l<LTC4l<MSC3m<MTC2l<NTC2l<MUC3k<MUC3k<MUC3k<MUC3k<MTC4l<MSC3m<LTC4l<LUC3l<LTC4U=Ln_\\1"}}, "object_label": "car", "attribute_label": ["length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, material, pattern, pose", "answer": "The image features a yellow car with its headlights on, driving down a street. The car is positioned in the middle of the scene, and its headlights are illuminating the road ahead. The car appears to be a small vehicle, possibly a compact car or a sports car, as it is not a large SUV or truck. The yellow color of the car stands out against the background, making it easily noticeable."}, {"question_id": 636, "height": 543, "width": 640, "image": "000000577932.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture, transparency", "region_anno": {"bbox": [284.83, 267.03, 61.33, 96.36], "segmentation": {"size": [543, 640], "counts": "d`h44i`05K5J6J4J5J7bN_OXBe0f=FkA`0T>V1O1O]NhAb0W>UOSBj0m=QOXBo0g=lN_BU1a=bNhB]1`>M100O00100O0001O001N2O001O1O1O0000000001O00000O101N11O000001O001O000O2O0O100O1N2M3J7L7H>_Oh`j4"}}, "object_label": "handbag", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "cleanliness, color, transparency, pattern", "answer": "The handbag in the image is a blue denim bag with a white design. It is being carried by a person, possibly a man, who is wearing a suit. The handbag is positioned on the person's back, and it appears to be a casual and comfortable choice for carrying belongings."}, {"question_id": 637, "height": 398, "width": 640, "image": "000000319935.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [381.1, 199.24, 52.47, 51.86], "segmentation": {"size": [398, 640], "counts": "mQe44Z<00O10000001N101O000000004L001O001mDGo9U1TElNl:\\11N0001O0O100O101O000000000O11O000O100eNTE0>?^:AUELP12l92TELR<4400O100000001Nfd`2"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:white", "length:short", "material:stone/granite/cobblestone/gravel/marble/pebbled/rocky/sandy", "transparency:opaque", "pattern:striped/lined/pinstriped", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "state, size, material, length, texture, cleanliness, pattern, transparency, color", "answer": "The dining table in the image is a small, round table with a white top. It is surrounded by four chairs, two on each side. The table is placed in a room with a balcony, and there is a vase with flowers on it, adding a touch of elegance to the setting."}, {"question_id": 638, "height": 333, "width": 500, "image": "000000006471.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [87.07, 71.44, 66.53, 69.07], "segmentation": {"size": [333, 500], "counts": "nfl06V:1M6M001WFC_9?^FE`9e0N1NHcFEP9KUGl0d8_OWGb0i8a0N201O2N4L3M1O000001O1BbGjNb81]Ge07UOi8g0[GXOf8i0YGWOf8j0YGVOg8j0XGXOg8g0XGVOH3P9d0_G[Oa8d0aGZO`8e0_G\\Ob8c0]G^Of8?\\G_Oe8`0[GAe8>[GAg8>XGDi8:VGGl87hFE21L3]96lFFF4`99cFL^9b00O1O1O1O1O1L5M2DTF3U:LjEO20o95oELR:3nEMR:81M102N2O0N2OiZb3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, pose, face expression", "answer": "The image features a man sitting on a bench in a dugout, likely at a baseball field. He is wearing a black shirt and sunglasses, and he appears to be relaxed and enjoying his time. There are several water bottles placed around the dugout, with some near the man and others further away. The scene suggests that the man is taking a break or waiting for his turn to play."}, {"question_id": 639, "height": 640, "width": 480, "image": "000000038678.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [74.46, 85.01, 90.77, 233.08], "segmentation": {"size": [640, 480], "counts": "Yg_1`0Vc0g0_O8G9I5K4K7H9l^ORNh?Y2m_OmMo?W2o_OkMn?Y2Q@fMo?[2Q@dMn?^2S@aMl?`2S@`Ml?b2T@]Mk?]3N1kMSLXDl3i;ZLQDg3o;aLgC`3Y<eLaC\\3_<iL\\CW3e<jLXCW3g<lLWCT3g<QMVCo2g<VMWCj2h<YMUCh2j<[MSCg2l<ZMSCf2m<\\MPCf2n<]MPCc2Q=^MmBb2T=^MhBe2X=\\MgBd2Z=]MbBd2`=m10O2O1N2O1O1O1O1O1O001O2N1O1O100O1O1O100O2N1O100O1O2M2O2N2N2N2kKiA^2Y>aMhA]2[>aMeA_2]>_MeA^2]>aMdA^2]>UMUAD`0U3\\>UMRBj2o=TMSBk2n=SMUBj2n=lLl@O\\1S3^?O2N2OjNPM\\An2d>SM]Ak2b>XM^Af2b>[M^Ad2b>\\M`Aa2b>^M`A`2`>^MfA^2W`0GZMiMoCk1n?SO?^OiPT6"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity", "answer": "The image features a man wearing glasses and a red shirt, standing in a room. He appears to be looking at something or someone, possibly engaging in a conversation or observing his surroundings. The man is standing near a dining table, which is located in the background of the scene. There are also a few other people in the room, but they are not the main focus of the image."}, {"question_id": 640, "height": 480, "width": 640, "image": "000000059598.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [531.92, 53.29, 63.28, 52.43], "segmentation": {"size": [480, 640], "counts": "mZk72n>1VAOc>8[AGa>=1OO0L4N2O1O1N200O1O10O10O01O02O0O1N2M201D<M3O1O1O00010000000000000001O0O3M3N3M>A2N4I>DWdj0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose", "answer": "The image features a man sitting at a table, wearing glasses and a black jacket. He appears to be looking down, possibly deep in thought or contemplating something. The man is seated on a chair, which is positioned in the center of the scene. The table he is sitting at is located towards the left side of the image."}, {"question_id": 641, "height": 320, "width": 640, "image": "000000129945.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [141.74, 51.61, 163.23, 183.27], "segmentation": {"size": [320, 640], "counts": "Qc\\14k93N0O2O1O00001O000000000O100O1N2N2O1O1O100O2O0N2M3L4O1M3O1N2N2N100OF;N11000O01O1O1N20O100000000O100N2O1O1O1000000010O0O2kM]OlJc0T5@iJ`0d4VOTJd0o07l4WOSJg0l02R5VOSJl0f0OV5VOSJo0c0KZ5\\OnIk0e0JY5BnIh0e0F[5X1WJmMGl0R6k2O010O10O10O101O2N2N3N1N1O1O2N2O001O001O0100nKcJ^3o510000O10O0001OcNUJeNk5>UJPO4`0g5<_JgN6h0[5>cK@\\4>iK_OW4>oK_OP4`0UL]Ok3`0YL_Og3=^LBb3=_LCa3>^LBa3?_LB_3`0aL_O_3c0_L]O`3e0_L[Oa3h0\\LXOc3j0\\LWOc3j0]LUOc34UJ3W2Id33WJ4T2Ie34UJ5V2Gd3n0\\LROd32YJ7R2Gd30_J7m1Jc3NbJ7l1Jb3NeJ5j1Ma3KjJ5f11_3IoJNh18Y3JfM7Y2HiM7X2IgM7Y2IgM8X2HiM7X2HiM6Q601O01O10O0100O1O1iFAk8?SGDl8>PGDQ9e00000001O0O101M2O2NdK]O]O?f0BZO;i0EXO9X5N3N2M]SY3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "face expression, gender, pose", "answer": "The image features a baseball player in a grey uniform, standing on a baseball field and holding a baseball bat. The player is in the process of swinging the bat, likely preparing to hit the ball. The player is focused and determined, showcasing their skill and dedication to the sport."}, {"question_id": 642, "height": 427, "width": 640, "image": "000000133969.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [209.63, 110.88, 57.18, 107.15], "segmentation": {"size": [427, 640], "counts": "XTh2<l<?C2N3oCVO\\;_1N3L1dD_Nn:a1PEaNo:l12O00@PNgEo1S:ZNjEf1U:]NjEb1U:dNfE\\1[:i00010O01O1O100O100BgEiMZ:R2b0N3N1O3N2eNfDa0^;WOgDh0[;UOgDi0n;00O2O000001O1O0000010O0001N101O1O3M2N2N2M4Hgik4"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, pose, gender, face expression", "answer": "The image features a man wearing a baseball uniform, standing on a field with his arms crossed. He is wearing a baseball cap and glasses, and he appears to be a baseball player. Another person is standing behind him, also wearing a baseball uniform. The scene suggests that they might be teammates or opponents waiting for the game to start."}, {"question_id": 643, "height": 427, "width": 640, "image": "000000133969.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [79.87, 249.13, 463.25, 9.92], "segmentation": {"size": [427, 640], "counts": "Uo\\21Y=2O1O00001N101O00000000000000O100001O0001O000000000000000000001Nkbe31U]ZL0000000O101O00000000000000000\\CJS<6lCKS<6mCKR<5nCKR<5nCKR<5nCKg;NTD74Lh;NSD65Lh;NSD65Lh;NSD62JF2U<NSD61KG1U<NSD65Lh;NSD6NKL2S<NRD56Lh;ORD56Lh;ORD54Nj;LSD6MLK3U<KSD6L4R<FRD6M3Q<GRD6MJK7U<ISD62Nl;LRD66Jh;0RD6_<K`C52JR<1lC52KQ<OnC62IQ<1mC7^<HdC7\\<Jb00diW1"}}, "object_label": "bench", "attribute_label": ["color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "transparency, material, size, color", "answer": "The image features a bench with several people sitting on it. There are at least five people visible in the scene, with some sitting closer to the front of the bench and others further back. The bench is located in a public area, possibly a park or a busy street, where people can sit and relax or engage in conversations. The presence of multiple people on the bench suggests that it is a popular spot for socializing or taking a break from walking."}, {"question_id": 644, "height": 480, "width": 640, "image": "000000156071.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [564.5, 80.48, 50.24, 186.86], "segmentation": {"size": [480, 640], "counts": "dQX86i>3L4L4M3M2N2O0O1000001XO[OSCf0k<[OUCo0BROX2Kn74XFo0BTOU2KP82YF=@M2No1G^70QG20<_ON32j1B]79SGJ4m0B^O0G\\1Lh7?PGD:l0B_OOIZ1Ik7a0mFC=k0B_OOLV1Gn7P1\\GMA@OOS1DQ8P1\\GMA@O0R1BR8R1\\GLA@O00_Ok04Y8R1[GKB@O00De00_8Q1[GKB@O00I`0Kd8Q1ZGLC_OO00N9Hk8n0[GMB_OO00O5Jo8k0[GMB_OO0001KT9i0ZGMB_OO01O0LU9h0YGNB_OO01O0LU9h0YGYO_O430O01O0LV9g0XGOB_OO01O0LV9g0XGOB_OO0001KW9f0WG0B_O0OO11LW9d0WG1B_O0OO11LX9c0VG2B_O0OO11LY9KiF6<e0A^O1O000MY9ImF69f0@_O1O000NY9FnF88f0@_O1O000NY9FPG66h0@_O1O000NY9FQG55i0@_O1O000NZ9FoF574^O2121O000N[9EoF565^O21210OO1N\\9DoF583[O5130O000M^9BoF774ZO4222ON10MR:HbFh0]O]O>LB:OMS:GbFL\\Od00_Oi0OWO>OMT:FjF`0SO_OU1=jNNU:EiFa0SO^OX1<hNNU:GbFLZOd0O^Oo14]8M[FM[O029MGi<0nC0R>00000XAOa>2]AOd>O]A1ne9"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, face expression, gender, maturity", "answer": "The image features a man wearing a cowboy hat and a suit, standing next to a metal fence. He appears to be a cowboy, possibly a rancher, and is looking over the fence at the cattle. The man is wearing a tie, which adds a formal touch to his attire. There are several other people in the background, but the main focus is on the man in the cowboy hat and suit."}, {"question_id": 645, "height": 480, "width": 640, "image": "000000156071.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [602.84, 95.98, 37.16, 126.01], "segmentation": {"size": [480, 640], "counts": "Y`n84W1N\\<3cCM]<3cCM]<3cCM^<2bCN^<2X10L5J7M7I3lB\\Oh;d0XD@d;`0\\DC`;>ZDJd;6WD1g;OTD7k;IUD9i;GWD9EQOg;e0cD<AVOi;>fD<AYOf;;iD<@\\Oe;8kD<@^Od;5lD=@_O1^O[;f0TE=@_O0EW;>YE>@_O0HU;9\\E`0_O_O0JV;4[Ec0_O_O0MT;0]Ed0_O_O0N2@i:?fEd0@^OOO1Cb7"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "pose, face expression, gender, maturity", "answer": "The image features a man wearing a cowboy hat and a white shirt, standing next to a metal fence. He appears to be a cowboy, possibly a rancher or a farmer, as he is wearing a cowboy hat and a white shirt. The man is looking over the fence, possibly observing the surroundings or the animals on the other side."}, {"question_id": 646, "height": 389, "width": 640, "image": "000000160864.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [542.85, 45.46, 68.19, 212.42], "segmentation": {"size": [389, 640], "counts": "kT_61n;8^Oa0M:F6K4`GnNf5Y1VHkNR14e6U1VHd0h7^OXHc0f7o1N2N3M2O2M3N2M3M00J_O`KjI_4FZKM3V6=QJS4IkKS65QJQ4KPLn5b5NcN\\J^L`5a3aJbL]5X3iJiLU5R3PKPMo4n2RKSMm4j2VKkLXOVOc5R4nJeKA^1a5Q3jJaKD_1b5V3^J]K0a1b5m40iN]JmKb5X4UKkJl4U5S1N1O2cKXIU3n6fLYIo2Q7nLRIn2R7mLUIl2Q7nLRIn2T8K7L3cNWGXOo8d0hFaNa:b101O1O1O2SFYNX9g1fFYN\\9f1[F`Nj9a1oEbNS:a1nEXNV:e1kEYN0010Q:<QFc05ROm97VF`0K[OR:2\\Fd0j9XO^F`0h:LY\\<"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, maturity, face expression", "answer": "The image features a baseball player standing on a field, holding a baseball bat and wearing a baseball glove. The player is wearing a baseball uniform, which includes a hat and a jersey. The player appears to be focused and ready to play, possibly waiting for the next pitch. The scene captures the essence of a baseball game, with the player in the center of the action."}, {"question_id": 647, "height": 389, "width": 640, "image": "000000160864.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [252.16, 269.51, 48.29, 12.25], "segmentation": {"size": [389, 640], "counts": "koo25o;2O1O00000000000001O00001O0000001O001O0000000000010O00000000000000001O\\Q3NfnL000aXQ4"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The baseball bat in the image is a wooden bat with a white handle. It is lying on the ground, surrounded by a few other items."}, {"question_id": 648, "height": 446, "width": 640, "image": "000000181421.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [339.04, 152.07, 87.23, 110.25], "segmentation": {"size": [446, 640], "counts": "TUb41j=5K3N2O1N2O1O1O2O0O100O100O100O1000000000000000000000O2O00O2O0000000O1YOAoC?P<CoC=P<HlC8T<i0O100N2O1F:J6O1N2WOkMhEV2T:PNiEQ2U:VNeEk1Y:ZNdEf1Z:]NeEc1Z:_NdEb1[:aNbE`1^:o00101O0O1000YOcE^M07]:X2iE^MJ:]:W2oEiMQ:V2oEkMQ:S2PFfMEM[:\\2QFcMI0W:\\2PFdMI0W:\\2[FeMe9[2\\FdMd9[2Q1O1O1O2N3kM\\Dj1T<VNhC^1\\<00O2K4L5N1L401M4K6GkBAX=?4O0O2J6N20000MjXk2"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:female/woman/girl", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "pose", "answer": "The image features a group of people sitting on a boat, enjoying their time together. There are two women sitting close to each other, with one of them holding an umbrella. The umbrella is open, providing shade for the two women. \n\nIn addition to the two women, there are three other people in the scene, one of whom is holding a baseball bat. The boat appears to be a small motorboat, and the people seem to be having a good time together, possibly on a sunny day."}, {"question_id": 649, "height": 612, "width": 612, "image": "000000245311.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [420.66, 172.51, 169.03, 235.98], "segmentation": {"size": [612, 612], "counts": "QYQ8376Zb0Kc]O8^b0Fb]O;db0E[]O6eb0I\\]O7ib0J^`03T_OLl]O9b2Gn;0hA2G8^a0Fg^O8I2Va0Fk^O5JL1842Ua0Fj^O5LK0915Ya0Ch^O:MO15Za0Aj^O4N9N3Ya0@k^O03<I4Ya0@k^O03<I4Ya0@i^O1LO7<K4Ya0@i^O1LO7<K4Ya0@W_O;A6Wa0_Om^OO2<K6Ua0_Om^O02<L6Ta0^Om^O31:L6Va0]Ol^O429L7Ua0\\Oo^O11<K7_a0[Og^O=J=j1VOY=1RA1N<M<i1YOX=OPAON03[1h1QOY=CPA\\1ca0POZ^O>ga0@Z^O`0ea0AZ^O`0fa0AX^O`0ha0@X^O`0ha0@X^O?ia0>SAhNm;Y1SDfNo;2VAR1Wb0E2\\Og]O4`b0L_]O5ab07`]OA[b0e0OO2O00OLd]OAmi7NbUK0ccM000V]O0`U11Y]O0Z]O0Xb0O_]O061[b0O_]O060\\b01=0\\]OO90Ta00b^O2:NTa00X^O053?Mba01^^O2Wb05]NIk^OOQ19S`0Ih^OOS1OmN:Xa0Lj_O8W`0Gi_O=T`0Am_Oc0P`0\\OP@d0R`0[O[_OOO6A7l`0CZ_O10Oc06WOMO5h`0Ib_O2h0d0d?]O`_O2k0a0e?^O^_O2m0`0a?D__OMo0`0b?C__OMo0`0f?^O^_O0l0c0f?\\O__OMKO?O04B4O3c`0Jb_O00Ke03VOc0c`0@b_ON0Md0k0i?ZOc_OMm0e0nNYOc`05b_OJP1c0lN^Of`06\\_OJR1a0g?FV_OLP1?i?NR@@SOe01[Od`0`0j_OBBl02SOb`0?h_Oe0FlNb`0?h_Oe0GjNa`0b0__O^O3U13kNU`0c0e_O]O3U12lNV`0b0m_Oc0MkNV`0b0l_Od0OiNU`0c0k_Oe00jNS`0`0n_Og0NkNJNP`0a0X@f0NgNH1213Oc?c0b@d08jNB0c?c0d@a09jN@4b?a0e@a0`0oNj>>h@c0>POi>=i@c0>TO_OGi>b0YAa0a0XOZOFl>a0YA`0c0YOWOGl>`0YAa0c0ZOWOFl>>UA^OMT1k0ZOWOGj>?VA\\ONR12nNc0>]OHi>9RAC;n0KTO:?ECh>9TAC:m0MUO6`0GBi>8SAC;n0LVO7=FDi>8SAC;n0LROH0?a0FCj>:QAB<n0b0DWOCi>?\\A:c0EYOAi>`0ZA:6QOLd0KAi>b0XA89SOGc00^Oj>d0UA91POM32c01]Oj>b0WA80WOI30a04^Ol>=XA4HZO71G01Q15TOl>:YA6G[O7Y1LmNm>8ZA7F[O80HR13UOl>OSAI9g0C\\O9NIONP18SOk>2cAi0EQOGS1_?QOVAl0DQOFR1`?QOm@NHn02ROIR18lNn>3m@;0b03ROJU11UO31W>:hA;Mc1[>RNgAT3X>nLfAFOo2U>]MlAU3P>nLPBR3e=QLZBU11k2`=\\M`Be2^=\\MbBe2[=]MeBc2X=`MhB`2R=m1C<M4G8I7M5H6M3O11]J\\DWO6P3o`>"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a woman sitting at a counter in a restaurant, looking at a plate of food. She is wearing glasses and appears to be enjoying her meal. The woman is seated at a dining table, which has a bowl of food in front of her. \n\nThe restaurant setting includes a sink in the background, and there are several cups placed around the dining area. A person can be seen in the background, possibly a waiter or another customer. The overall atmosphere of the scene suggests a casual dining experience."}, {"question_id": 650, "height": 612, "width": 612, "image": "000000245311.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, size, texture, transparency", "region_anno": {"bbox": [260.53, 387.82, 334.38, 131.44], "segmentation": {"size": [612, 612], "counts": "\\[R51Sc0000VV12hiN2M101O1O1N101O1O2M3f]OAka0d0k]OCSb0g000000O010O100O10O0100O100O100O010O1O1000O1000O10R@WOa=i0_BWOa=i0_BXO`=h0`BXO`=i0^BYO`=h0`BXO`=h0cBUO]=j0dBWO\\=g0eBYO[=g0eBYO[=f0gBYOY=g0gBYOY=g0gBZOY=d0gB^OX=b0bB]OhM1f?b0bB]OhM1g?a0aB^OiM0g?`0bB_OgM1h??]B_OoM4d?<]BAnM3e?<]BAoM2e?<\\BCoM0e?=\\BFkMOi?:]BGhM0k?:]BEhM1k?:\\BEjM1k?:ZBElM1j?9[BEkM2j?:[BCjM4l?8ZBDjM4l?8ZBDjMOO1m?=YBDjMN02m?<XBNh=3WBMi=4VBLj=5UBFmMLn?=UBBmMO12m?=UBBnMN12m?=TBCnMN12m?=TBCnMN12m?=TBCmM010o?<SBImMMo?:UBOl=OUB1k=OUB1k=MXB3g=K[BIfM8P`0M[BJiM6l?O\\BKhM6l?N]BLeM8o?G`B1`M9eb0F[]O:db0G\\]O8db0H[]O9eb030001O000000010O00000O10001O0001O001O0000000000O2O0001O0000001O1O01O00000000001O00000000000000001OO2O0001O000O100000000[MCcB=]=CdB<\\=DdB<\\=DdB<\\=EcB;]=H`B8`=GaB9_=GaB9_=GaB9_=H`B8`=I^B8b=H^B8b=I]B7c=I^B6b=K]B5c=L\\B4d=M[B3d=N\\B2d=N\\B2d=N\\B2d=N\\B2d=M]B3c=L^B4b=J`B6`=GbB9_=EcB;]=DdB<\\=CeB=Z=DfB<Z=DfB<Z=CgB=Y=ChB<W=EiB;W=EiB;W=EiB;W=EiB;W=EhB<W=EiB;W=FhB:X=GgB9X=HhB8X=HhB8X=IgB7Y=IgB7X=KgB5Y=LfB4Z=MeB2[=1cBO]=7]BIc=7]BIc=8\\BHc=8^BHb=8^BHa=9_BGa=8`BH_=9aBG_=9aBG^=:bBF^=:bBF^=9cBG]=9cBG^=9aBG_=9aBG_=9`BH`=8`BGa=9_BGb=8^BHb=9\\BHd=8\\BHd=9[BGf=9XBHh=9WBGi=:UBGk=:TBFm=;QBEo==oACQ>f0eA[O[>g0cAYO^>f0aA[O_>f0`AYOa>h0]AZOc>e0\\A\\Od>d0\\A\\Od>d0[A\\Og>d0XA\\Oh>d0WA]Oi>d0UA\\Ol>d0TA\\Om>d0RA\\On>e0PA\\OP?d0o@]OQ?d0m@]OT?b0l@^OT?b0l@^OT?c0j@^OV?b0i@^OY?c0d@^O\\?c0c@]O]?d0a@]O_?d0_@]Ob?d0W@Ai?m10O2O001O1O0O10000O101O00001NLZMm_Oe2R`0\\Mn_Od2S`0[Mm_Oe2o?\\MU@b2k?`MT@`2l?^Mo_OO3c2n?^Mn_O14`2n?eMQ@[2n?hMR@U2o?kMQ@U2n?mMR@R2n?nMR@Q2o?PNP@Q2o?PNQ@k1NkMn?:T@k1NlMm?9V@j1LmMo?9U@j1LnMn?:T@h1NQNj?d2V@]Mi?9W@Q2i?nMX@R2h?nMY@R2f?oMZ@R2d?oM\\@P2e?oM[@Q2f?nM[@_1N_Nh?1Y@S2h?oMX@n1i?QNX@n1h?RNX@n1i?QNW@o1j?QNU@o1k?e01O0000100`MQ@j1n?VNS@i1n?UNS@k1m?UNS@k1n?UNP@l1P`0WNR@d1n?\\NS@c1n?\\NS@c1Q`0lMP@N8i0k^>"}}, "object_label": "bowl", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, transparency, color, material", "answer": "The bowl in the image is filled with a variety of donuts, including both glazed and powdered ones. The donuts are arranged in a visually appealing manner, with some placed closer to the edge of the bowl and others positioned more towards the center. The bowl is placed on a table, and the donuts are displayed in a way that makes them easily accessible for people to enjoy."}, {"question_id": 651, "height": 612, "width": 612, "image": "000000266768.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [315.2, 251.71, 104.72, 150.55], "segmentation": {"size": [612, 612], "counts": "[UP6c0;@fa0e0U^O^Oia0f0R^O\\Oma0n0O101ZNjN[AW1d>lNo_O1P1S1P?YOn@h0Q?[Om@e0Q?_Om@a0R?Ck@=T?Gi@:T?Ii@9V?If@:Z?Fb@>]?Da@=_?D[@b0c?@Y@c0f?_1OO00LgL_@o2j?60O3N1O1O02Q@mL?0h>\\3k@mLS?Q3PAmLQ?R3PAmLJJT?Y3QARMo>o2k@VMU?\\3n@ULk>b3RAbL4Lk>`3SAcL2Ml>_3QAdL4Ml>^3PAeL3Om>[3PAdL51l>Z3o@dL71k>Z3n@eL71o>V3j@iL63P?T3i@mL20V?R3h@nL21W?o2g@PM31\\?Q3b@PM`?L_@l21VMi?i2V@XMj?h2W@VMj?h2Z@TM20\\?m2`@UM3NY?0b@n20SMOO50[?Q3a@PMOO50\\?P3`@TM4L\\?Q3_@TM4K^?X3a@iL`?V3^@kLd?Y31N2SOX@]Nk?_1X@UNMHP`0JR@R23UNMJO5o?LP@Q23`No?f1P@XNS`0h1k_OXNV`0@k_OR21\\NW`0Ah_OR22[NZ`0f1f_OXN[`0k1c_OTN_`0Q2a_OfMc`0_1b_O`NM<g`0EW_O12Q18YO``0S1Z_OnNk`0Q1R_OmNTa0R1k^OlNXa0S1i^OkNZa0b0d^OG1F^a0[13XO^^OKda0@_^O9O5na0JR^OI0K04Pb0j04M2N8H4L2N2N2O0O1N201O0NWjd3"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, pose", "answer": "The image features a man and a woman sitting at a picnic table, enjoying a meal together. The man is wearing a brown shirt and a white hat, while the woman is wearing a white shirt. They are both seated on a bench, with the man on the left side and the woman on the right side of the table.\n\nThere are several other people in the background, some of whom are sitting on a bench and others standing. A bowl is placed on the table in front of the man, and a cup is located near the edge of the table. The scene appears to be a casual gathering or a picnic, with people enjoying each other's company."}, {"question_id": 652, "height": 612, "width": 612, "image": "000000266768.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, material, pattern, pose, texture", "region_anno": {"bbox": [189.76, 412.51, 37.87, 9.66], "segmentation": {"size": [612, 612], "counts": "f[a33ob03N2O00000O1000000000O10000000000000000000000000O100000000000O10000000000O1OTSU7"}}, "object_label": "cell phone", "attribute_label": ["color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a cell phone with a green and white color scheme. The phone is placed on a table, and it appears to be a flip phone. The phone is open, revealing its screen and keyboard. The screen is located on the left side of the phone, while the keyboard is on the right side. The phone is positioned in the center of the image, with the screen and keyboard occupying a significant portion of the frame."}, {"question_id": 653, "height": 428, "width": 640, "image": "000000267169.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [234.87, 1.94, 124.22, 167.9], "segmentation": {"size": [428, 640], "counts": "cUS3l08VOd;f1VOb0O100O1O100O010O100OWO`EhN`:T1gEiNX:V1mEfNS:X1RFfNn9X1S101O001O001O1O1O00100O010O100O00100O010O10O0100O10O10000O1_NSOcFm0\\9WOaFi0]9[OaFe0^9^O`Fb0`9_O_Fa0`9A^F`0a9B^F>b9B]F?b9D\\F<d9D\\F<c9F\\F:d9G[F9d9KXF7g9OSF1l92QFOo93nENQ:6kEKT:h1N1O1O2N1O2N100O010O01000O0100O100O001O2N100O00100O1O100O2N10000O101N101N101O1nNeEPO]:k0hETOY:k0hESOZ:k0hETOY:k0hETOY:j0iEUOY:h0jEUOX:j0iEUOX:i0kEUOW:h0jEWOX:g0jEXOY:e0hEYO\\:c0fE\\O]:`0eE_O]:?dE_O^:>eEA\\:=fEA^::\\Yf3"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender, face expression, maturity, pose", "answer": "The person in the image is a man wearing a green jacket, standing next to a large elephant. He appears to be observing the elephant, possibly a trainer or a wildlife enthusiast. The man is positioned on the left side of the elephant, which is located towards the right side of the image. The elephant's trunk is visible, extending from the middle of the image towards the right side."}, {"question_id": 654, "height": 427, "width": 640, "image": "000000281409.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [79.16, 228.15, 194.1, 177.03], "segmentation": {"size": [427, 640], "counts": "^RR16S=5L5K2M3O4K101\\DVOd:m0XEXOd:i0ZEZOc:i0ZEZOd:g0ZE[Oe:f0YE\\Oa0CQ9Q1^F]O`0CR9o0]F@`0CQ9m0]FC:]O\\O5m9j0^FD8^O[O7m9g0aFD6MV9`0]FnNMf0`0MU98[FVOOON13d0?C^O2h9?bF]OG`0`0AB3c9`0eF[OF`0a0C@2c9a0gFYOEa0`0DA1c9a0hFXODa0a0DA2a9c0jFSODc0b0AB6]9d0QGC0_O]O06;Y9e0TG@NGE3Y9g0UG[ONNC0Y9h0YGUOK5CNX9j0YGoNZO0?4AJ58X9m0WGmN]O183LJKO18]9l0WGZOAKOII025^9m0WG[O\\OO5IJL_9R1WGXO]OO60U9n0`GfN\\O258m8k0cFoNR25\\7l0bFoNQ26]7j0cFPOo16]7k0eFoNn16\\7l0gFnNLMg0O>8Y8n0gFQO5JKOL2R16\\8n0bFTO9HN0k05\\8P1aFTO:GHN22n04_8Q1_FSO;HF0T1OlN2b9U1^FoNa0M`03b8P1_FnNa0N0MG7Z9P1^FmNb00<Og8S1]FlN7NL5i0Kh8W1YHjNj7W1THmNj7S1UHnNj7S1VHmNj7S1gGgNkN0F3j9W1dGfNjN6c9U1kGfNYN4m9Z1eGcN^N2l9]1gG_N^N2l9`1jG_NU8d1cG]Na8d1\\G_Nd8a1XGcNg8^1[G^Ng8b1ZG\\Ng8d1YG\\NkNMc9h1cGXNkN1a9h1lGYNS8h1mGXNQ8i1nGYNR8h1lGTN`N2W9W2oGjMlNON0T9Z2QHhMlNOOOQ9]2THfMjNO1NP9^2UHlMjNFP9`2UHjMkNFo8b2SHiMoNEm8d2RHhMQODl8e2RHlMo7U2PHkMP8V2oGiMQ8X2oG_MSOJR9h2SGUM?8d8e2XGWMC6OGP9m2]GWMC50GP9Q3XGbMH^ONOm8T3VGdMO\\Ok8Q3SGeM2ZOk8n3UGRLk8]3SGmL3Ej8^3SGmL2El8^3RGhL7Ih8g3[GZLe8f3RGVL54j8Y3TGjLMI26n8X3QGjLOI06P9Y3oFhL13P9_3PGaLQ9^3oFbLQ9l2nFXM3JQ9m2lFYM3JR90kF41C`0b1AgNNM32?Jo76aGJm0^1TOhNOI46=Mm75aGIOOl0^1XOjNLJ54>Mn7=SHA_O\\12ROMHb0Jn7?QHB@Z13_OT9AfFD3O0074HR1;Eb0UO\\7<fGD22M02N34MP1<VOB6n0A]7:gGF000O0140On09_OCKOJ]97fFK3NOM1m0:@CFd95mFHB00j0=ZO]O33Oa91YGJUOj0c0UO_O7N22Gd06e70`Hi0FTOA3O31G82J6W8N`Hi0EVO_O5O6:EF9]8GXHKAo0;N@YO5b0W8]O`Hk0DL_O[O2e0\\8XO`Hl0B6@G^8WO`Hm0B_OA2O9a8XO]Ho0ASOC20KNX1b8hN[HS1AmNG33T1a8jNiGV1KkNF2N110NL1c0O[Oc85gGJJ\\14_O5VOId0]8@nGY1E]O7VOJc0U9j0iF\\O9WOHd0V9k0gFYO;YOFe0Y9h0fFYO;8P9?dF]O3ILH^9Q1dF]OOK1G^9o0aF@0H4H]9n0_FB0BNE79a9i0ZFG;WOCO8:b9g0YFH;ZOL6a9g0YFoN13K7`0GL0F3j9k0YFQOO4L6`0GL0G2j9j0YFUOK206`0FI3IOl9j0WF_OJO>GN:d9?VF06XO09e9>TFIKD2I6348f9>TFIKEm02V9>SFAJN11m00W9?QF_ONM?Oa:f0QE\\Oe02[:a0PE]Od03\\:`0QE\\Ob04_:?PE]O?4c:>nD_O=1h:`0jDA<Ol:`0gDA8LC4_;`0eD@81W;?`D@:OW;c0gD_Oc;a0ZDEc;:]DCg;=d0000O0100O100O0100O0100O10010N1O2M3N2M3N3M1O00001O2Ngan4"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, face expression, maturity, pose", "answer": "The image features a baseball player wearing a catcher's mitt and crouching down on the field. The player is wearing a baseball glove and is positioned in a ready stance, likely preparing to catch a ball. The player is also wearing a baseball helmet, which is essential for protection during the game. The scene captures the player's focus and readiness to respond to the ball's trajectory."}, {"question_id": 655, "height": 640, "width": 433, "image": "000000291634.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [314.94, 194.28, 25.54, 93.47], "segmentation": {"size": [640, 433], "counts": "gfU684:a0LUa0i0e^OROaa0R1Z^OPOfa0S1U^OnNla0c1DUNb^Ol1\\a0=O100O2O3i^O_Mi`0c2S_O_Mm`0k20O1O1mNV_OnNUa0d0Q_OlNGNZa0P1W_OlNB3Xa0l0g_OSOZ`0;c^OD\\10S`09X@En?4R2MUaj1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, gender, pose", "answer": "The image features a woman walking down a sidewalk, wearing a white shirt and black pants. She is carrying a handbag and appears to be looking down at her phone. The woman is walking past a pole, and there are other people in the background, suggesting that she is in a public area."}, {"question_id": 656, "height": 640, "width": 433, "image": "000000291634.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [15.27, 218.0, 167.09, 132.73], "segmentation": {"size": [640, 433], "counts": "YZ:<ac04M4L4L3YO_Ok]Od0Qb0_Oo]O`0Pb0Bo]O>Pb0CQ^O<oa0DR^O8Pb0IQ^OMFIXb0;S^OJVb08i]OHXb08h]OGWb09j]OFVb0;g]OHZb08f]OFVa0Gc_O2nN=9JWa0Fc^O21231LNM<:IXa0g0b^OC6Fn`0Ko^Ol0MA5JPa0Go^On0LA5I\\a0f0_^O@6Jk`0HX_On0FA6Hn`0Im^O02n0M@6Jn`0Gm^O4Om0N_O8Ho`0HU_Od1KeNPa0GT_Ob1OgN\\a0S1Z^OfN:7\\a0Q1\\^OjN64`a07X^O74]O45`a07Y^O63^O44m`0I\\_O?A44^O31F0ka0<[^OCK1O6f0H\\O1ja08k1N00^]OI\\a06b^OMWONYa00h^O>a0EWOM01]a02j^O<`0OVOB\\a0Of^O48<?3c`0]Of^O48;`05a`0]Oe^O4:KH7l0=\\`0Fo^OFI72Ie0;YOF[a09n^ONILc04m`02g^OKK2?0Pa03f^OJFM17c0OPa03g^OIEOO7f0JZONea09h^OHC=bb0Kk]O:Tb0Fl]O<Rb0Dn]O=Rb0Bn]OICb0^b0Eo]O?Qb0Ao]O?Qb0Bn]O=Tb0Ck]O=Ub0Dj]O<Wb0Ci]O<Wb0Ej]O:Vb0Fj]O:Wb0Ei]OLE7]b0Cf]O:7HG0O;cb0Lh]OHF00;db0Lf]OIJ:S1FX`01l^O0H8U1GU`04m^OOG6X1FR`07o^ONF5hb0Jd]O1D5ib0Ge]O`0\\b0@d]O`0\\b0@d]O0A<lb0Dc]OOC2N5mb0Jf]O0_O4gb0LX]O1g02Rb03Y]OK>0Zb05X]OL7NH1jb0=]]OCIOkb02U]O58IH0Rc07b0000O10000OH^\\O4bc0N]\\O1dc0N\\\\O2ec0M[\\O4hc05K1K4O2N2N2O8H1Y^OTOX`0g0_^O[OS13\\`0a0e^O\\Om05\\`0>j^OB:GE:2Fi`0g0V_OCOGO2KM1:6Hh`0h0W_O^O1HO3M94Di`0k0U_O\\O;MB9Xa0?i^O\\O5HMf0Ta0e0m^OhNMd04YOh`0[1V_OjNLc06XO01]`0Y1b_OkNKc0`0YOR`0Y1e_OiNJe0>YOT`0Y1d_OjNId0`0XOR`0V1\\_OmN4MOQ1>oNR`0V1g_OkNGQ1Ua04X_OLh`04Y_OUOA8Xa0c0l^OjN3P1Sa05j^OQOLj0\\a05h^OPOLk0]a04h^O1Za0Ng^O1Ya0Nh^O2Ya0Mg^O3Ya0Le^OPOLU1^a0Kf^OQOKT1`a0Je^O9[a0Gd^O;[a0Fb^O=^a0S1N]Nd^Oc0]a0QOb^OH2W1]a0POb^OH1X1]a0POc^OHNY1`a0mNd^O\\1\\a0dNd^OHNY1`a0nNb^OINW1ba0PO_^Ok01QOba04Z^Og0[b0TOg]Ol0\\b0SOf]Oj0Vb0[Ok]Oe0Xb0YOf]Og0\\b0XOd]Of0^b0[Oa]Od0_b0]Oa]Oc0_b0^O`]Oa0bb0=3K4N2O1N10O1000O1O1O00100N2O2N101N2N3MO1O2N22M101O1N2O2M3M1O0L5O2O002MY`d4"}}, "object_label": "motorcycle", "attribute_label": ["color:gray", "color:red", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:off", "texture:smooth/sleek"], "control_dims": "transparency, material", "answer": "The image features a row of motorcycles parked on the side of a street. There are several motorcycles in the scene, with some of them being parked close to each other. The motorcycles vary in size and design, showcasing a diverse collection of bikes.\n\nIn addition to the motorcycles, there are several people in the scene, some of them standing near the parked motorcycles, while others are walking by. A few individuals can be seen closer to the foreground, while others are further in the background. The presence of people and motorcycles creates a lively atmosphere on the street."}, {"question_id": 657, "height": 427, "width": 640, "image": "000000329456.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [391.17, 2.58, 114.59, 261.4], "segmentation": {"size": [427, 640], "counts": "^bS55Q=6I7K5M2N2O2N1N2L4M3M3M4L3K5M3N3L4jDQNk:^2aHcMd3`2XLeMd3^2YLeMd3b2lKjMR4X2iKlMU4V2hKnMV4S2hKoMV4R2gKRNX4m1hKUNW4_1`I_M[2T1T4^1PLgNP4Y1iKnNV4S1`KXO^4i0[K^Od4c0TKDl4>lJIT59fJKY59`JK_5:hI;X6\\3O1N2NWOnI]JP6_5XJ_J\\5_O`Jn5:aJo4B^J64f5b0aJg44dJY5i0bJa4S6bKmI]4R6fKmIY4Q6jKnIV4Q6mKnIR4P6QLPJo3n5SLQJm3m5WLRJi3k5[LTJe3i5^LWJb3g5`LYJ_3f5dLXJ]3d5gL\\JY3a5kL]JV3a5Z2021N2NgK`Hj2]7lLPIU3m6jLXIR3h6lL]IR3b6mLdIVOROi0e0o0d6QOUJFAV1Y6QOSLTOeLe1X7TO\\Li0c3SOaLn0^3lNiLT1U3fNSMZ1l2aNZM_1e2_N]Mb1W7O011]NYD]1T<G101O0O2OjCoNQ<V1OO3M2O3L2M2O1O001O2M2O2M2M2O1O001O010O01O1O0100N2FRC6o<JRC4o<23NU`h1"}}, "object_label": "person", "attribute_label": ["face expression:happy/smiling/laughing/grinning/joyful", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity", "answer": "The image features a man walking down a street, wearing a blue jacket and a hat. He is carrying a book in his hand, possibly a notebook, as he walks. The man appears to be smiling, suggesting that he is enjoying his walk or the content of the book he is carrying."}, {"question_id": 658, "height": 640, "width": 425, "image": "000000338304.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [200.75, 255.6, 28.55, 104.96], "segmentation": {"size": [640, 425], "counts": "]mm34^c0a0J6L4K4L5L3]OmNT^OX1fa0g0J4M4K4M3L2O2N2N]Om^OZNSa0d1n^O^N:\\OY`0V2]_O^NQa0S25QNi^Oo02YNXa0e0i^Om0`a0QOb^Og0KjNda0>d^Od0ea0VOb^Od0`0QOQ`06d_Og0;TOS`01f_Oh05UOTO2Pb0OU^O?g0@TO2Yb04f]O1R1I[a02_Z1N`he3"}}, "object_label": "person", "attribute_label": ["face expression:sleepy/sleeping", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "gender", "answer": "The image features a man standing in a crowd, holding a beer in his hand. He is wearing a hat and appears to be enjoying the event. The man is surrounded by other people, some of whom are also holding beers. The scene suggests a social gathering or a celebration where people are having a good time."}, {"question_id": 659, "height": 640, "width": 425, "image": "000000338304.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [0.0, 483.16, 146.88, 155.88], "segmentation": {"size": [640, 425], "counts": "[W12190KTc0e0O1O1O1O1O1O1N2O1O1O1O1O1O10000O1O1O1O1O1O1O1N2L`Ng]Oa1Xb04O1O1O1O1O100O1O1O10000O100O1O1N2O1O1O100O1O100O1O1O1O1O100O1N2O1O10000O1O10O00001O000000001N01K5001O1OK5I7K5O0OFb_OVM^`0k293N1M4OO110O010O10001N2N1N2O2N1O1O2N1O2N101N1O2N1N2O2K6A?K5LAcN`^OY1ba0iN^^OU1ca0kN^^OQ1ea0oNk]ON=R1ha0QOl]OL=Q1ha0RO\\^Oj0ha0UOZ^Oh0ja0VOV^Oi0Pb0WOk]Og0hb0_Ol\\O5Uc0IQ]O1Rc0MR]ONo]20`UN3OO1Ok\\e5"}}, "object_label": "sheep", "attribute_label": ["color:gray", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a group of sheep standing together in a pen. There are at least five sheep visible in the scene, with some of them appearing to be shaggy and woolly. The sheep are gathered in a line, with some standing closer to the foreground and others further back. The scene also includes a person standing near the sheep, possibly observing or taking care of them. The overall atmosphere of the image suggests a rural or pastoral setting."}, {"question_id": 660, "height": 427, "width": 640, "image": "000000371552.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [134.58, 149.81, 42.07, 76.44], "segmentation": {"size": [427, 640], "counts": "`_h1:o<2N3_OKiC6S<f0J9I3MI8L3O2O00GlN]DT1a;SOYDm0g;<O0100000001O001O2fNVDo0U<N01O10O0111O2N6M2OcNSDP1T<10O002Nd0\\O8H1O1OVkP6"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "face expression, gender, pose, maturity", "answer": "The image features a man sitting on a bench, likely at a sports event. He is wearing a baseball cap and appears to be enjoying the game. The man is holding a drink in his hand, possibly a beer, as he watches the event. The bench he is sitting on is located near the center of the scene."}, {"question_id": 661, "height": 640, "width": 426, "image": "000000413552.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [0.0, 0.0, 426.0, 640.0], "segmentation": {"size": [640, 426], "counts": "W[11c00c?2l_Og3<WLE[6U2VJiMa2;nLH2M[21eM1g3:XLE\\6T2jIkM11I011OO60LOO1n18RNH`21^M3i3>YL_O5N11OO10b48VK]41cKON2?a2]O]M52K50OO10O101O1OO2N100O10Mc0KE00000O2O00O110N11O0c01]ON10M4N12Mc0:o47YJO0h01hN5Y1JmN004KN>N;?VOF11OO1O100O12NM4OO100LN0241JM41211N1001OOO22N:d50\\JA0005000h01RO5m1OhNK74RO32K40001O0O100000:0F0:1EO10]2e4[MmK0@b0N@11O5000h01RO5k2JRN=ROE5000001O00000O10000000O2JN304000d00c0c4aNeK001Ia0OA0f12XN4l2JUNm0oNZO001O000O1MNO11OO1501O0O1000:1@6NK1010NO35OL1a0O_Ol3NZL1I11O:e2F[M5Q4c1nKhN0^23QMO1N`00Kj0i2VORM1N10:2^2JWMO10S40kK27MJ352MMON0240LN025N1050F1N011N1042KOO11OO60`0OA0O<i0d2POXM1O0O<JD4OMg20\\MOO1W40SL0K10N10:0n00cN0O1[21cM6X1`2hN`M1O0O?1W2J[M6V4JkKO42O01N100000X10cN0O1[2;lNe2hNVM0O<JD7f2J[M6`2ISOd0]N_ONM3231OO101N10:0A0O2O41Kh1OXN10`05_Oj0Z3oNnL0K1OO015f2J[M6_2NcMKN7P1;POANN250O11OM4M11;OA0O2O41K1Oa17]N:5@L1OO2O50J25b3JcLO0g2J\\M0M2b2MfM0J101R15mNK6N10000000X10cN0Q20SN2I:8DK0c01A0O[3KfLO015o2LLMWM0O1T14mNKd50[J;1E0000d00@14l2EVM0O3NO016OK`20aMON4j2L\\M1Q13iNM601O00:0S10i00dM<OE1000001O0041005\\2DkM001I2OO1050K`21_M0O2k2L\\M3Q14hN60F1N020N020OO52KOO11OO10000001N;0F1N2OO100;O00E10001Ob1O_N0000<Y2DlM001I1000O5g28;GTNR2iNVN0S10cN001OO11N2OO;0GN\\25AKYN1OO11I1000O5g2LXM102S3MnLOY11fN0213OLO1140KO11OO11OO2OO150K00001N1000Oe1NcN0J10`0N;0F0@8NIj1O^N1OO11I60J5g2LYM002R3MoL0Y10lNO011O:0F0n00lN11OZ2`0eMGN11N1LN1051I;h1E^N00O12H96]2LYM011V30QN2iNN3N3O000000n00mN000Z2a0cMG000O2KN;1D<g1C`N1N11OJ60J5g2LXM120W32oM7kNF4OO1001O0O;0F0J101ONY2R2fMQN=d1CaN1J0O16OJ2ON204g2LXM121W37hM2POF5O02NO1O2N;1EO02W2T2SN]O_OeN0K64JK20N014g2KZM013W36lMLoNJ=0F0R4`0fKC1N0<0E0O1;OEa0b1^O`N1OO11N16OJ2OO104f2LaM1S36eLHT14Z48bJE101OO2O00O101OO2N61Ig0\\1YOeN00000O11N11N2O45MK^21aMO12W3;jMHCK@0X10hN0U2a0dMA0O16NL1O0O11N61Ig0\\1YOeN00000O16OJ2OO015e2MYMO31R2OlN<3OlNK0J07OM4M20000OMOO2O0O11N2O00X10mN0J10c1NnN6_O2OL]1MeNO020OO150LOO10O5OKe21\\M020h15UN026:1j0MjNf0000K0\\O0K1N114OMO41LOO2N10Y23fM4NK^10hN1KN0150LN011O7d2H]MO40S10nN104K0282BO?U1FkNKM353LMNM310OO1506OE2OO11OO7Ob10XNa0NG092AN;0J2J6OK0N[10kN2KM1241KN002O5f2I\\M030R1?kNF0M3=MA1:MHZ1OQONL20NY10hN0U27cM02KOO150LOO2OO2N52KOO10`0X1_OmN1LN0245KK0O6U1I91cN031Q1=mNF0M35JN5KO:LH]11jNN010OX1OiN0U27cM02KOO150LOO2OO;0GOO10a0W1^OjNO020OO155KJ105f2KZM013S1NPO001ON200079T1KaNN3N110M21c0O]O0U2a0cMG000K1N100:0GOO101O;X1CjN0O11OO114OL1N017d2I\\M004h1MB764dND110N01e0N]O0U2Z1cMhN2O0:0G0N011O:Y1DiN1N011OO24OL502c2I^MO41T37WNN`NL?Nh32gK61I11O0000O101O42I52J1O00?Y1_OiN0O1000006OJ2OO17c2IgM075m1L`M2c10`3NnJ0O11N101OO100001O50I72Ii01TOU11lN000O10001O51N8^2HhM01;T2E_M3e1O^NM5000Q4a0hKA00O1001N1050J61KOO10`0X1_OiNO020OO11OO2OO247^2HdMOI26:`2JQO1XN24MOLNO142K40O2J0O11N101Ob10]N10c1NhN1LOK1N105Y1ImN2O000K0147^2I^MN0709g2BROm0UNC1@0O11O0O`00K1E0O1000`0OE2J0OR20]N2A0NO[1OlN2O000LN166^2HeMg0c4[OUKN1142NNMO115N:2@0000O2OP2a0mM;1VO00O6000K7M02IT10RO1N100LN166^2HfMb0g4_OVKN020N10n00W17cM025NG1O0O1000O70J0O11?N@8Od00\\O1N101KM266b0HQ11XNO3c0n4]OoJ011401N10n00W1`0dMMOF1O0O1000O<1C015000K5OP10lN0O150LN166c0GP12XNk0P5_OSKF3N02i0NSO0V21gMa0000A1N1001N;6DM:MH121P10mNOO1140J255_2I\\M;;He48SKE4N02X3]1bLbN1001N;6DL`0OD1P10mNO00050K147^2G_M006:Nf43_O8aKBN52J00>=EDL5O10O1e0O[O2KO0000O100157\\2HeM54JF1R54^OM_K0001N02O00O2O00>=_OD2:06O:0\\O0J11OO10000163ILa20eM65Oh4N^O3^K02KO50J10>`0BJ0LN02d0O\\O0K0O11O00O1164HJc21_M0063KM;m40WKE00e0NWO2O0R2NoM10^1ObN2ONa01KNL0N31M;0F1JO025OK0O1018`2I^MO1`0NNo40QK42^O15NLO`01@0O11OO2Oi00VO2N1000a12QO0]ON;1EO431M;0F1N11OKO02007a2I_MN0a0NKS5KmJJ71O0e0NWO11OP21oM0Oa0O01@O03N0?4CI:2EO521M;0F1N11OKO10113OJb21dM6JI12O004V5KWKNY30aL7I020NL1N11OO9<MEJ0O11N10O610N;0F1O000KO10:1DU1O42gNO160IO3O005V5JVKNb38RLO20NL0O20OO8=NCK1N11N10O70OO;0F1JO1140K00O3011Ka21^M1055;P5GnJH4NZ30`L30m00RO0O7?3GKJK7On00mN1N07OK1501b2I]M:68o4EnJI4NZ36`Lj0OSO1N7a01DNLIc11\\N060L0421`2J_MON58LH60NV50oNLmK90GO0O02O00<4B2<KEO61I61m0OnN1O050J11N133MJc21cM5NJN101N023U5NQONkKOO24OL06OK0;5BNa0N@02OO2O51ON<0F1J0000O11N11N044LJc22bM4OJN10500T5NcNO^L0K80GO00O1000<4B2=IF000O2O500O;0F1JO1140K000O35a2M^M40OO1O0U56nJG1M3O:0X10WN82Y1O_N2d0c0\\OZO80c0O]O1O00O11I36`2L^M500N001j2MYO9mMK0K4M20K0O2c1L_NS2OnM2i0a0^O\\Od00\\O0000001J25a2M\\M53NN0O3U5LlJL510M<0F0a1U1WNSO0O2K:c0E\\O<OE1O7On00RO0:1@25a0IZ1=RND21N11OO10002X5MUKNd27oLL19OK2KOO11OO10;d0D\\O7OK0O2N^10hN0:1@25a0IZ1=RND21N11OO10003W5MkJN50i26PML19OK2LNN210N01;5C62E6OK0O10h1NiN0A34a26aMJL0O8S5LPKG4N`27YML0d00@2KON2285E44E82EO11Nc10SO2@a25bMJLb0Q5CPKFn20UM0Le0O_O3L301NK6O4b0K@LNd1OSO2@_26eMDJ11OO11`04_Ob46^KHl21[M6DL042K5N1047D17H10K1M13NNe1O^N050031\\26gMCKO11O0000O28MOf4MdNLRM5FK01OO10n06PO12H1041LOO11ON`1OcN1OO100000036Z29hM@K020O0000O2g0_4\\OgNNSM5DL042K5NL00097D11I;0GOO14Z1JmN000K000035Z2;cMI1K001d0P2UO94fM35J2OP2d1hMdN0K1N1005O76CK101OO5Z1JmN00000L24Y2k0eMUO1O0J1g0e1XO[N7Y28fMH2LNN;1n0NiN\\2MfM24O94AM1028W1FnN00062IY2m0eMSO2KN11O000504n1E>6eMM3O2Nm1^1lMiN20OK0O66I70C3OO101OO6Y1IH2UOX2`0fM[O0100042KOO11OO7OK0O:i1Fc04fMM3OW26cM01;NF2K0N02OO10:e0E[O2O00O2OO6]2KjMV2i0hMRO131LN1140K00O`0Y4DhKM5MX25dM1O<OE2K40KO10:e0E[O7OJ1005^2JiMU2P1kMnN11O0Om0R4XOSLD=0W11ZNOO7Nd02WO40LN029d0F[O7OJ1001OOk2Q2_NnMlN11OX1P4mNgLFl01cNS1JlN5O114b0H]O50N0L00j2m1UMSNZ1OlN1001NS1o3oNaNJiMOHO1`0NF2J`0OJe0F\\O6O00J10R2NWN1On17RN:1\\O000LN10Z1m3jNcNLkMMH0O2N:2FOO2Om07PO11I10501OJ10Y1N]O0B20m17RN:1\\O000c1i3]NeNNiMNH0O`00E2K5NL0O1:j0JVO2OJ10Y1N]O0B2Om1V1SNhN01Ng1g3XNRMKYO3Z13eNb1O`N:g0FSO<MFZ1NXO0L3Il1W1SNhN0S2R1hMlN1[23hMN02O1001JO16O>`2]OaMOU19jNHY1MYO1EOM32i1JUN`10bN0O11N10Q2d3PNkLLI0J2OOY1c1fNdN078g0IkN10000Y1NXO1K2Ih1Y1UNdN1O0O11N10V2_3kMdML63gN50d00[O2O0LO0009o0FRO1N11OO11Nh11cN2Jg1X1VNdN1O0O11N_2\\3dMhLKg01><gN?0[O2O0LO00096F?0\\O2M02O00l1OUN062Oc1a1\\NYN0O1j2U3[MjLMON206OK0O5S1V1kNlN2O0LOO1186Fd05b1KXNd1K\\Nd02mNOO1l2n2SMSM?OB6OO6o0S1jNnN2O0K1OO16OI72c02d1LWNb1K_Ne00mNOO1S3l2WMmMEc03bN000001=1CNM31:O01C5>JD7NL1OO60l10UN20^1;bN`00nNOO11No2l2ZMAFeM0000001O0O11N115N6001C5b0K@1OO11N100000i0050WO30]12dNFN10S10nNOO11NR3i2WMDFeM0000001O0006N10K05051C63IO151J41LN10000050:0:0WO054OX17gNDM11Q11RO0T3:hLE50K1N01Y1OfN;Q1E81hN001OO11O000`0NA114OMOO29OMO0OO3LM10000032P1NRO1JO10053V1;eNc01TO1N0U3OfL61J5O57Ej0OPO;7F?O@1i00WO1O0LN10?0@2O4011P12kNL;0H4P1LSO1OOL52S1KjNh10_NOK0O1e3=\\LX1:CFgNOU1ORO000c05XOMNN2k0MA2FO000082k0NRO000K43S1g1jN[NOK0O1e3>ZLX1=AJXOJ:O]O0c02[O00:JL1I1:0GO00O191k0NRO000K43S1h1iNZN0J100g32XLl1?eNf0]OkN07OK1N016Om02QOO1e0J[O0<0EO11O082k0MSO153IQ1R2mNiM000Q42nK311Oi0h0ROZON0OR21mM11i0N\\O2OO2d0Hi030OdNN73No09nNY13WN00OS41PL1O2Oj0j0POh10eM0K`0OA47J3b0El02MOfN11N81NP16SOZ1OXN4[4Y18bNaKa08]O]12AOhN00062Om0:ROW10YN5d3JnL_1Q4aN`Kb08^OFOj00\\O042i0NnN001O054Ok03UOHMg10ZN4c3KQMO]OV1n4jNPK<;EFOj00K14O]O001J00O153g07TOJ0c10YN0O2c3OYM3RO32I0205T5KjJ5;OZ1JWO0\\O001JO10052d0KYOk20j0N\\M1VOO11K4Y5MdJ0;3[1KVO0F1D1L33c0MXO\\21iM0J1n3NRM1PO`0n5AQKNG050F1@O11O43c0]2ZOcM0L0n3OXL0?c0Z5^OaJNB051>0i00cNO11O43c0]2YOdM1K0X4NcL7TOK1OP6OfJ0@2KNR21nMO10052b0^2ZOdM0J1j<0WCNR20oM152N<JEf2LaM0L0`<1_C0N21Om1NUN00152N;8DV2O]M1R<NYD3D50J2N10b10^N1O054O99CS26l1IeK1OO11N1m6NUI1N7O51D1O10]10cN1O054O9:BS21^M0c4OiK0k6=hHE101N1000b11]NO100538U3CT9:hCF60X10cN0K538g?EU@1d0Mo00cN0L429n?EX@OKO^10cN0L419m2CP:1UCOK2l1NZN0L416c`0FgA4gM0JNZc01m\\O0mb0MU]O3ON:Ooa00g]O5d0Ki?0UA0^N5d0Kea00g]O5d0Kja00^]O4`c0Ld\\O0\\c00X]O0Rc00O11O00mN0X]O0i01_a0Oh]O0000000i01Sb0Om]O0hb50d\\J0\\W60`C0daJ0\\J0di50Rd70ToB1eg41YXK1T\\OOgc00Z\\O0kc001Nbk60^TI2O0`d5N[SN0WXL0SX70Y[N0Zd50ZhD0`f00eeN6`c0K_\\O5ac0J`\\O6ec0KY\\O1bc0Nd\\O2\\c0Nb\\O4]c0Mc\\O2_c0M:1O0U\\O000`c01`\\O4a9JdI0]32^I4`9L;NVF6_9L`0OPF0ac0Od\\O2\\c0Nb\\O4]c0Mc\\O3[b0N_^ONYO1]=OSG4VLLZO1Wb03_^OLUO1O0P:OmM2XH3g0LTO5P:LoENi73[HOK0n0OTO5Q:JnE2k7NYH6i0JVO5R:MgM0UH5U1Jc`00`^O1NOn01b?OW@0\\OOn00lN4b`0NX@OXOOU11iN3b`0Na@0TONb00ZO1`9OeF0m30iM1UO1SO0b0N[O1o9OXL1aJ1RO29Mc0OYO2P:NPM3nH?0^Oi01TO5U:JoL4nH`0P1]OnN5U:KoL2nHa0O]Ok0OVO5S:LPF00Oe50iJ2_Oi0S1WOZ9NdK1bJO]Ol0i0TOZO2``00W@j0NTOYO4b`0OV@c0TO^O1Ld02^O2c`0OV@o0IoNA0g91WFNY63VJMCS1InNb00E0``02m_O0_OQ1MmNb00E0``02[_OM<o0EZOc0H\\O5e`02__OIMo0OWOg0IZO6d`02__OKJn00WO0Jo00h?5`_OX1JdNn0Nh?3c_O1FS14iNj00i?2c_ONF20U14iN`0OB3a`00c_ONG00W13iN`0OC2R>NSD3nMMLX1NjN?NE1Q>OUD0mM0JX1OkN0M90K1n`0Oo^OX10iN00a00]`03n^OT17iNOO96``0m0Q_OTO0I:0K294a`0NR_Og0N]O0J:NL2:NA2m`04T_Oe0N\\O1K8OM2=N]`03R_OQ1NmN:NL4;N``01P_OS10mN`000O``0a1a_O^NO1a`0_1]_OdN3L``0_1W_OaNK5=Kb`01m^OZ1a0hNONj`0Q1j^OoN<1N1l`0e0f^O^O5K<ON3i`0g0h^O\\O2N?LO2n<MZFj0YL\\O2O>L01g`0i0h^O\\O1O9LJN=2h`0Z1o^OiN>Mc`0T1g^OmN83>Lb`0V1h^OjN85JI`01]=OXE1jLj01ZO:2FI1190l`0Oj^OS11nN55OL30Pa0h0g^O\\O2M:M83e`0f0g^O]O3MP10T`0Ni^Oe01@0O;KJ231n`0Ni^Oe00A0O<JJ231n`0R1h^ORO2I6000aa0]1i00NcN`]O`16bN10Q9NTO0fG_13dN22aa0T1n^OhNX;0mIo0WJUOe<KVI;SJM1N10eb04Y]ON0O10gb02X]ON1000j?IoBn0VMYOk?InBX1gMiNh>OaCY1eMjNi>NaCR1ZMPO;Oj>0aC>XM13@;1JNe>2kC>XMMj0C]>2bCb0ZM@Q`0MgB8UMN4MQ`0LgB8TMO2OQc01n\\O01O0Jlb0b0T]ODob0h0N1WLQOfA0m1n0mMROi=0]B0m1`0WMLd0Fk=NXE`0YLC0O10Pc07T]OJ`0O]ONc`00TA7[NMa0N]ONb>0[C0J7YNO0K0OV?0bD7XLO0KO1Rc05n\\O01JO0Qc0h03OXNXOY@h0[>XOZA0RO0j05jN3ONo`0J]_O1[13ZN31Kj`05[_ONc16XNFi`08\\_OJf12UNK10j`03U_OM60g12QN02OPa01[A0dMN21_c02^\\OO2O_c08310J]\\OOONT;0WM2kGN^c0O?0fW61ThIO10U\\O0fc0030V\\O1gc0O_\\O0Sa00c20R\\10ncN0fX1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:female/woman/girl", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, maturity", "answer": "The image features a woman sitting on a chair, holding a baby in her arms. The baby is wearing a pink outfit and appears to be sleeping. The woman is also wearing a pink outfit, which complements the baby's attire. The scene is warm and comforting, showcasing the bond between the mother and her child."}, {"question_id": 662, "height": 640, "width": 480, "image": "000000550349.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, gender, maturity, pose", "region_anno": {"bbox": [354.93, 291.58, 72.1, 83.63], "segmentation": {"size": [640, 480], "counts": "QSP71kc05X\\OK60Wb03R^O9_OE60[a0R1d^OIOUO^a0T2b^OmM]a04_^Og14VN\\a00c^Oj11UNda0l1a^OUN[a0i1d^OZNea0^1X^ObNla0\\1P^OeNSb0T1m]OeN`b02_]OS1eb0mN]]OQ1cb0oN^]OP1bb0PO^]OQ1ab0PO_]Oo0ab0QO`]On0ab0RO`]O5K=fb0]O[]OQ1eb0[O[]O96[OUb0Od]OT14PO[b0?a]OJ2L\\b00c]OJ12OOO7Zb01g]O016Xb0Hi]OOMG3a0Wb0Hj]O4N4Wb0Hl]O4L5Vb0]Oj]O85l0Ub0nNf]OO4U1Vb0kNg]O02V1Xb0iNf]O11W1]b0iNb]O`0N5Wb0ZOP^O2J?O5_b0Lb]O_O1d0\\b0\\Oc]O>56Xb0Mi]O3Wb0Lj]O4Vb0Jm]O5Sb0Km]O5Sb0Km]OAFa0^b0No]O1Rb0B`]O8`04Pb0Cb]O:=2Qb0E`]O60K?9Rb0O`]OH>8Rb00_]OJ?4Sb09n]OFRb0:o]ODQb0>P^O_OQb0a0P^O^OPb0c0Q^O[Ooa0f0P^OZOla01b]Oe0Sc040Dl\\OLTc04m\\OKSc06n\\OGSc09n\\OFRc0<n\\OBRc0?n\\OAQc0?P]O@Pc0`0810001N01K4O2K4O4N1N2N_em0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "gender:male/man/guy/boy", "maturity:adult/old/aged", "pose:sitting/sit"], "control_dims": "gender, face expression, maturity, pose", "answer": "The image features a man sitting in the driver's seat of a bus, driving it down the road. He is wearing a white shirt and appears to be focused on the road ahead. The bus is large and occupies a significant portion of the image. The man is holding a steering wheel, which is located in the center of the scene, and he is also holding a cell phone in his hand."}, {"question_id": 663, "height": 640, "width": 480, "image": "000000550349.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [100.67, 134.11, 379.33, 414.2], "segmentation": {"size": [640, 480], "counts": "^dP2d0Zc0X1hNl1UN=B4L4M2_@eKY?c4M4j@XKo>Q5J4L=D:E8H5L3M2N0O1eB_IX=b613M101N2N2O1O3K4N2L5L4M2M4M3L4M2M4M2M4L3M3L5M3L5L7I:D5O0N2J^FkEf9m9_FSFf9h9ZFWFh9g9XFXFm9b9UF_Fm9]9QFbFM1S:Z9RFeFK1U:W9UFiFl9T9b0N2M3M2O1L4N1N3NaE^Gd9a8o0M5L2N1N5L4L4L2N2N100O1OdD^H\\:b7cE_H]:a7cE_H]:`7dE`H\\:_7eE_H]:a7cE_H]:`7R10`D_Hb:`7]EaHb:`7\\EaHe:_7[EaHe:_7[EaHe:^7[EbHf:^7ZEbHf:^7YEbHh:^7WEbHj:^7VEbHj:^7VEbHj:^7VEaHk:_7k0O1000[DaHi:_7WEaHi:_7WEaHi:_7WEaHi:_7WEaHi:_7WEaHi:_7VEbHi:_7VEbHj:^7UEcHk:]7UEcHk:]7UEcHk:]7UEbHl:^7TEbHl:^7TEbHl:^7TEbHl:^7TEbHl:^7SEcHm:]7SEcHm:]7SEcHm:]7SEcHm:]7SEcHm:]7SEcHm:]7SEcHm:]7SEcHl:^7TEbHl:^7TEbHl:^7TEaHm:_7SEaHm:_7SEaHm:_7SEaHm:_7SEaHm:_7SEaHm:_7SEaHl:`7QE_H]O1b;`7SEaHm:_7SEaHm:_7REbHn:^7QEcHo:]7QEcHo:]7QEcHo:]7QEcHo:]7QEcHo:]7QEcHo:]7gD^HO5Z;]7QEcHn:^7REbHn:^7REbHn:^7REaHo:_7gD]HO4Z;_7gD]H03Y;`7gD]H11Y;b7RE^Hn:b7QE_Ho:a7PE`HP;`7QE_Ho:a7QE_Ho:a7QE_Ho:a7QE_Ho:a7aD]H:2U;a7QE_Ho:a7QE_Hn:b7RE^Hn:b7RE^Hn:b7gD\\HO2[;b7PE_Ho:a7RE^Hi6OeLc7bL]Hn:d7QE]Ho:c7bD[H92U;c7QE]Ho:c7QE]Ho:c7QE]Ho:c7RE\\Hn:d7lD[HF1^;d7QE]Ho:c7QE]Ho:c7oD_HQ;a7bD[H32I2b;a7bD\\HM1O101a;b7cDZHN1O8`;]7hDZHI8_;^7lDbHT;^7lDbHT;^7lDbHT;^7lDbHT;^7mDaHS;_7lDbHT;^7lDbHS;_7iDYHH9_;^7mDaHS;_7mDaHS;_7mDaHS;_7mD`HT;`7lD`HT;`7lD`HT;`7lD`HT;`7lD`HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HS;a7mD_HR;b7nD^HR;b7nD^HR;b7nD^HR;b7nD^HR;b7jDWHI7];b7nD^HR;b7nD^HR;b7nD^HR;b7jDWHI6^;c7hDYHI4_;c7hDXHJ5^;c7iDWHI6^;c7mD]HS;c7mD]HS;c7mD]HS;c7mD]HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HR;d7nD\\HS;c7mD]HS;c7mD]HS;c7mD]HS;c7mD^HQ;c7oD]HQ;c7oD]HQ;c7oD\\HQ;e7oD[HP;f7PEZHP;f7PEZHP;f7PEZHP;f7PEZHP;f7PEZHP;f7PEZHo:g7QEYHo:g7REXHn:h7REXHn:h7REXHn:i7PEXHP;h7PEXHP;i7oDWHQ;i7PEVHP;i7QEWHn:j7QEWHo:i7QEXHn:h7REXHn:h7REXHn:i7QEWHo:i7REUHo:k7QEUHo:k7QEUHo:l7PEUHo:k7QEUHn:l7RETHn:l7RETHn:m7QESHo:n7PERHP;n7PERHP;o7oDQHQ;P8QEmGo:S8QEmGo:S8QEmGo:U8oDkGQ;V8nDjGR;V8oDiGQ;X8nDhGR;Y8lDhGT;\\8hDdGX;b801O000O11O000001O00000000000000000000000O100O1O2N10000000000O1000001O0000000000000O100000000000001O0O100000000000001O0O1000000000001O000O100000001O1O1O002N1O2N3M6J4L2M100O10001O1O1N2RKoEKR:5mEKU:3lEKb>\\KnAl0AVO0M4NK1g6"}}, "object_label": "bus", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:orange", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "cleanliness, material, transparency, pose, color", "answer": "The image features a large orange and white bus parked on the side of a street. The bus is likely a public transit bus, as it is parked at a bus stop. There are several people around the bus, with one person standing close to the bus, another person further away, and a third person closer to the edge of the image.\n\nIn addition to the bus, there are a few cars parked or driving nearby, and a handbag can be seen on the ground near the person standing close to the bus. The scene captures a typical day at a bus stop, with people waiting for the bus or just passing by."}, {"question_id": 664, "height": 480, "width": 640, "image": "000000036844.jpg", "category": "description", "question": "Describe the refrigerator in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [514.41, 344.28, 125.59, 93.85], "segmentation": {"size": [480, 640], "counts": "[Xb7:Z>=@?E;N20001O001N101N2O001O0O2O000O2O001O0O2O000O2O001N101O000O2O001N10001000O0100O00100O1O1O1O1O1O05L0gM]CT2c<kM^CT2b<6O1N2O001N2O2N1K[MmCe2S<[MnCd2R<\\MnCc2X<0000O1000000M3N2O1O10001N010O100O100O100O100O100O0100O0010O10000O100O100O2O0O2O1O0O100O3N1N010O2O001N101N101N101N1O10eD"}}, "object_label": "refrigerator", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, texture, cleanliness, material, transparency", "answer": "The refrigerator in the image is white and appears to be old. It is placed in a room with a couch and a chair nearby. The refrigerator is situated between the couch and the chair, and it is surrounded by various items."}, {"question_id": 665, "height": 640, "width": 478, "image": "000000111207.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [99.47, 156.44, 255.23, 73.36], "segmentation": {"size": [640, 478], "counts": "ohQ2=bc0101N100000000000000000000001O000O10RPS1GVPmN8H100000000000000000000000000000000000000001O1O1O3M001O10O01OO100O1M3N2O1O10000000000000000000000000000000001O0T]OCUb0=[]OA0055JN]b0<d]OA014?Tb0Om]OA0`0Sb0OX^O0ha0OZ^OOga01Z^OMga03S100000000000000000000000000000000001OO100000000000000001OO100001c\\OAWc0?g\\OD5NMOhb0>X]OD3OMOhb0>Y]OB31LOhb0>Y]OB90^b0>Y]OBVc0?i\\OAWc0?i\\OAWc0?i\\OAWc0?5O100000]]OBda0>[^OEca0<[^OEea0<b]OA=1D4\\b09b]ODZc0;g\\OEYc0;600O10000000S]OCWb0=i]OCWb0=f000000000000T]ODTb0<l]ODTb0=l]OBTb0>g00000000U]OBTb0>k]ODTb0<m]OBTb0>l]OBTb0>l]OBTb0>l]OBTb0>l]OBTb0>g00000000U]OBTb0>l]OBTb0>k]OCUb0=j]OEUb0<i]OFVb0:j]OGUb09k]OGUb09k]OFVb0:j]OFVb0:k]OEBN[b0=U^OC@1Zb0<e]OA<2D2[b0;e]OA320NN3[b0<P1000000O100000000000000O2O0OR[]2"}}, "object_label": "bench", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:gray", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty", "texture:smooth/sleek"], "control_dims": "texture, pose, state, color, pattern, material, transparency", "answer": "The image features a bench made of wood and metal, with a person standing next to it. The bench is located in a building, possibly a warehouse or a factory, and appears to be in a state of disrepair. The person standing next to the bench is wearing a black shirt and jeans, and their hand is visible as they walk past the bench."}, {"question_id": 666, "height": 427, "width": 640, "image": "000000013348.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [0.0, 228.61, 54.69, 18.23], "segmentation": {"size": [427, 640], "counts": "S7=n<00001OO10000001O00000000O1000000O10000000000O2O00001O1O0003M1O001O0000O100O1000O100000010O0001N2N1O2N2N`ad7"}}, "object_label": "airplane", "attribute_label": ["color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "color, size", "answer": "The image features a large white airplane parked on the runway at an airport. The airplane is positioned in the middle of the scene, with its wings visible. There are several people around the airplane, likely working on maintenance or preparing the aircraft for its next flight. Some of these individuals are standing closer to the airplane, while others are scattered around the area. The scene captures the busy atmosphere of an airport, with people and airplanes working together to ensure smooth operations."}, {"question_id": 667, "height": 361, "width": 640, "image": "000000036678.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [496.82, 241.6, 82.48, 26.3], "segmentation": {"size": [361, 640], "counts": "TWa58l:9K2N10000000000000000000000O1M30000001O0000000O10O1000000O100000000000000000000O0101O0000000000O11O0000000000000O100000000000001O00000O4M2N0O2O0O3M5K`ce0"}}, "object_label": "boat", "attribute_label": ["color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material, texture", "answer": "The image features a large boat floating on a body of water, possibly a river or a lake. The boat is quite long and has a white color. It is docked at a pier, and there are several smaller boats nearby, some of which are also docked at the pier. The scene appears to be a busy harbor with multiple boats of various sizes."}, {"question_id": 668, "height": 427, "width": 640, "image": "000000136915.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [627.46, 219.86, 12.54, 67.59], "segmentation": {"size": [427, 640], "counts": "bfU88T<h1VO1O10O000J7O0100000000SI"}}, "object_label": "chair", "attribute_label": ["color:black", "color:white", "length:short", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, material, texture, pattern, length, color, pose", "answer": "The chair in the image is a wooden chair with a brown color. It is placed in a room, and there is a person sitting on it. The chair is positioned in front of a table, which is also visible in the scene."}, {"question_id": 669, "height": 427, "width": 640, "image": "000000136915.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [11.1, 213.41, 46.91, 14.55], "segmentation": {"size": [427, 640], "counts": "jV54V=2O0010O00000001O00001O0000001O0000001O0000001O0000001O0001O01O00010O00000001O00001O001Nclb7"}}, "object_label": "book", "attribute_label": ["color:white", "length:short", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "color, state, material, length, transparency", "answer": "The image features a bookshelf with a row of books neatly arranged on it. The books are of various sizes and are placed in a way that they are easily accessible. The bookshelf is filled with a total of nine books, with some books placed closer to the front and others towards the back. The books are well-organized, creating an aesthetically pleasing display."}, {"question_id": 670, "height": 427, "width": 640, "image": "000000136915.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [156.51, 1.57, 31.05, 71.93], "segmentation": {"size": [427, 640], "counts": "iQQ22W=S2nM1000000001O00000000001O001O00001O001O0000001O00001O0OUgm5"}}, "object_label": "book", "attribute_label": ["color:white", "length:long", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "texture, pose, size, transparency, color, pattern, state", "answer": "The image features a book with a green cover, placed on a surface. The book is positioned in the center of the scene, and it appears to be a small, thin book. The cover features a picture of a mountain, which adds to the visual appeal of the book. The book is likely a travel guide or a book about the mountainous region, as it is placed in a location that suggests it might be a travel destination or a place of interest."}, {"question_id": 671, "height": 480, "width": 640, "image": "000000385997.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [456.0, 147.15, 143.74, 153.1], "segmentation": {"size": [480, 640], "counts": "Xih63W>1[B0d=0]BNd=2Q\\3M]aL3aGM[88PGHRN1k:9iFFQN49Mo:5oELWOOA48MS;1nEOUO1A29Nm:5oEIgN3m00BMj:9nE3<Db99QF4<Ea98SF3HBk:<ZE5J@k:;[E6d;EcD;[;FaD9e;HYD8h;ITD7oN@2Og<7[D9lNEi<0^D;iNEi<0\\D=kNCi<0ZD5nNMONh<2iCKJ:FF43c<OlCOF90H^<1mCMG0H2R=NYC0F1MN0O1024Q=NZD2f;MQD0PO3o<MQD0PO4n<MfC2XO032m<M]CMH6JLNO57m<J\\CNM5GN55k<JZC1O2FN66j<IkC3A0CLR=1kC2@0h<0nBLe02B5m<I[D1Tj1OYUN5j=0000LWA2k>1eMNfE2[:LgE3c<0LN52O00O2N100002N000Yk1NiTN0X]10_oN0XVO2n:2nD0R;1mDOS;3jDMW;4gDMY;3eCI=6n;3aCH7?X<J_CH8?Y<I_CH7`0[<H]CH4d0_<E[CH3f0b<EVCHNI4l0i<DRCH7c0i<NXC1j<o03N201O000004L5H300O1O01N2O1N31N9H0NO2N11M4O1NO1000100O2J7nMTCd1Y=K4cNfBQ1]=mNeBo0i=I6K6D=HSn00RRO1le4OUZK0000000Rm="}}, "object_label": "potted plant", "attribute_label": ["color:black", "color:gray", "length:long", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, transparency, texture, length", "answer": "The potted plant in the image is a small, green, leafy plant that is placed on a table. It has a long stem and is positioned near a fan, which is also on the table. The plant appears to be a decorative element in the room, adding a touch of greenery and life to the space."}, {"question_id": 672, "height": 480, "width": 640, "image": "000000385997.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "cleanliness, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [548.35, 233.65, 44.25, 80.35], "segmentation": {"size": [480, 640], "counts": "PcQ83i>5M3N1O2N100O2N1M3O2O0O101N1M301N1N2M301O0WClNf;U1SDSOk;n0VDlNo;T1eCPOb<Q1g01N100O2OO1M3VO\\B2i=J[B5X>O3M4L2M3MkSh0"}}, "object_label": "vase", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:empty", "texture:smooth/sleek"], "control_dims": "length, size, pose", "answer": "The image features a vase sitting on a table, which is positioned in the middle of the scene. The vase is large and has a unique design, making it stand out in the room. The table appears to be a dining table, and the vase is placed on top of it, adding a decorative touch to the space."}, {"question_id": 673, "height": 480, "width": 640, "image": "000000496597.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [364.37, 294.57, 70.42, 18.58], "segmentation": {"size": [480, 640], "counts": "VZ\\53m>2O000O2N1O1O1O0O2O1O01O12M01O000000000000001O01OO10001O0000000000001O000000001O0000000000O11O001OO1GIiA7`>001O000000000001O000N3MbeQ3"}}, "object_label": "boat", "attribute_label": ["color:black", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a small boat with three people on board, floating on a body of water. The boat is positioned in the middle of the scene, and the people are sitting close to each other, enjoying their time together. The boat appears to be a canoe, and the passengers seem to be having a good time as they navigate the water."}, {"question_id": 674, "height": 335, "width": 500, "image": "000000013291.jpg", "category": "description", "question": "Describe the frisbee in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [182.73, 195.78, 33.06, 36.54], "segmentation": {"size": [335, 500], "counts": "j\\l11[:?C2M3N2N2N2N2O0O2O0O101O0000000000O1000000O2O0O2O0O2N3M2M4K5Hjfl2"}}, "object_label": "frisbee", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The image features a white frisbee with a blue logo on it. The frisbee is being held by a person, who is standing in a grassy area. The frisbee is positioned in the center of the scene, with the person's hand holding it securely. The person appears to be enjoying their time outdoors, possibly engaging in a game of frisbee or simply admiring the frisbee's design."}, {"question_id": 675, "height": 428, "width": 640, "image": "000000023359.jpg", "category": "description", "question": "Describe the snowboard in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [265.46, 172.9, 34.61, 119.13], "segmentation": {"size": [428, 640], "counts": "[Y]38S=2O1[CGU<9iCI_;;_DL2JQ15f8j0XFROk0<j8j0SFmN>n0]9X2000OOcLVFj0O63<g9dNWFj0053<f9eNXFh0250UOMT1i9jNXFg0270=f9eNXF5080d02GMIh9_OYF286Hi049c9fNlF2Dj0N<b9jNXGi0WO<`9kNZGf0ZO]OEj0f9SO[G?BA_Om0d9RO]G8HHWOn0d9ROeHOgMP1c9QOlHn0T7ROhHOcMP1V<300O10000000000000000000mNUDd0l;\\O]D9bd^4"}}, "object_label": "snowboard", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, cleanliness, transparency, color, material, texture", "answer": "The snowboard in the image is white and has a blue stripe. It is being used by a person who is standing on it, likely preparing to ride down a snow-covered slope."}, {"question_id": 676, "height": 427, "width": 640, "image": "000000221754.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [554.82, 177.15, 11.54, 54.2], "segmentation": {"size": [427, 640], "counts": "nUW72232d0Q<o0^O000000@gDnNY;Q1iDnNW;Q1kDnNT;S1lDmNT;S1kDnNW;P1kDlN_^o0"}}, "object_label": "traffic light", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "cleanliness, texture, material", "answer": "The traffic light in the image is a black and white one, located on the side of a road. It is positioned at the corner of a street, and its pole is made of metal. The traffic light is currently displaying a red light, which is visible to drivers and pedestrians. The traffic light is an essential part of the road infrastructure, ensuring the safe and orderly flow of traffic at intersections and crossings."}, {"question_id": 677, "height": 427, "width": 640, "image": "000000221754.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [152.7, 260.67, 34.91, 18.22], "segmentation": {"size": [427, 640], "counts": "\\Wo125Om<8N110O1O1O1O010O2N1000000O2O00000000O10000O101O00O100001O01O0001O0O2N4KSWl5"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, texture", "answer": "The image features a silver SUV parked on the side of a street. The car is positioned near a pole and appears to be parked in a parking lot."}, {"question_id": 678, "height": 427, "width": 640, "image": "000000360951.jpg", "category": "description", "question": "Describe the mouse in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [541.09, 297.21, 38.39, 26.24], "segmentation": {"size": [427, 640], "counts": "PZR77R=3N2N2M2O2N1O2O0O1O2O0O10001O00O2O000O10001N1O1O1O2N1O2N1O1O2N1O2N1O1O2O^Ti0"}}, "object_label": "mouse", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "texture, cleanliness, transparency, pose", "answer": "The image features a white computer mouse sitting on a flat surface, which appears to be a piece of white plastic or a white mouse pad. The mouse is positioned in the center of the image, with its body facing the viewer. The mouse pad or plastic surface it is sitting on is slightly curved, providing a comfortable and ergonomic surface for the mouse to rest on."}, {"question_id": 679, "height": 473, "width": 640, "image": "000000430286.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [302.06, 33.71, 81.49, 125.36], "segmentation": {"size": [473, 640], "counts": "i^]48^>>^M_OTFe0i9^OTFe0i9]OTFf0j9\\OPFE^NR1a;[OiEo0U:TO^EY1`:iNSEb1l:eNeDe1Z;n0N2O001N2O001O0O2O001O0O101O000000001O000000000000000000000000000001O0000001O0O1000001O0O101N101N1O2O0O2O0O2N1O2N1O2N2N2M4hMiDh0Z;UORE?R;^OWE8l:EYE5k:JZEMm:MPgf3"}}, "object_label": "remote", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a close-up of a remote control, which is gray in color. The remote has a few buttons on it, including a power button and a volume control. The remote is placed on a surface, possibly a couch or a bed, and is positioned in a way that it is easily accessible for use."}, {"question_id": 680, "height": 375, "width": 500, "image": "000000474452.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "cleanliness, color, material, pose, texture, transparency", "region_anno": {"bbox": [249.12, 37.92, 77.61, 335.29], "segmentation": {"size": [375, 500], "counts": "agl2f1j8X1M2O1O101O00000000000`KRM7n2ISM6m2MPM3P3MoL4Q3InLnK1Y4Q3GTM9l2FUM:k2EUM<k2iNnLmLo0[4R2_NYNb1g1SMPMeN1?N]Ob1\\4_1VN`Nk1`1VN^NiN5O]10cMnNX1FP1\\16fNVMNN0\\6[1`LeNT4[1lKeNS4\\1T3000001O00O2O0000000I7ZNf1nMR2hLdJZNW7e1^1001O0000000000000000000000000000O100O100N2N3gNYG`Nh9T1`lQ2"}}, "object_label": "stop sign", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture", "answer": "The stop sign in the image is red and white, and it is located on a pole. It is positioned on the side of the road, possibly near a parking lot. The sign is clearly visible and serves as a traffic control measure to ensure the safety of drivers and pedestrians."}, {"question_id": 681, "height": 640, "width": 480, "image": "000000012748.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [2.41, 50.36, 240.35, 505.41], "segmentation": {"size": [640, 480], "counts": "gj0541001O1OM34K2O83EO02Lh0O\\O000b0\\;j7M2O1O000O2O001O00001O0000000O2O001O00000O2O00001O00000O101O000O10001O0N2N3M2N2N3L3N3L4J5N3L4N2K4M4M3L4L5K4M3L4M3N2M3L4N1N3N2N2N2N2N2N2N2N2N2O0O2N3N1O00100003kCaHHNd;g7YDkHY1@k8^8lFgGS9]8gFeGZ9`8ZFgGg9X910O01O100O10000O011O0O010O100O1O010O1000O100O11O000O02OO1ZOeEgGZ:W8gEkGW:T8jEmGV:R8jEoGU:Q8kEPHU:n7kESHV:j7iE\\GOj0X:j7iEYHNUOV:`8mE[HMXOT:[8PF`GMT1Q:Y7XFhHg9U7[FlHe9S7SFiG0U1l9Q7TFlGOT1m9o6]FSIc9j6_FVIb9f6eFPH\\OR1P:k6hFXIW9f6jF[IW9c6`FgIa9fN[Fk6OfJ]:T5VEWI8j1c:m4UEaKj:^4VEcKk:k6O2N1N1O1O4L>B7I0O3N1O1N102M101O001O002N1OO01O100O4L001O3L4M3M6I4M3L3M4L5J4L5L5L3M4L4L3M3M2N4L5K2O2M3M4L3M3M3M2N3M3M2N2N2N3L3N1N3N1N3M3N1N3M3N2L4M3N2M3M4K5L4L3L4M3L5M2L4K5L;C`0A7K3K3M4M3M4L4K5L5Fb0ZOh]g4"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "state, texture, color", "answer": "The image features a brown horse standing in a stable, with its head close to a brick wall. The horse appears to be looking at the camera, possibly being photographed or interacting with a person nearby."}, {"question_id": 682, "height": 427, "width": 640, "image": "000000038825.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [335.43, 0.72, 304.57, 392.3], "segmentation": {"size": [427, 640], "counts": "fXc43X=033J1O100O3M210N2N1N3L3N1O2N3M2N1O1M2O101O10O02N010O100O001000O00001O101N1O01O001O01O01O010O010cEWOW8h0cGJR86fG3X8MdG8\\8H_G=`8D]G?b8B[Ga0e8^OXGf0g8[OWGf0j8YOSGk0l8WOoFm0Q9QOkFW1S9hNdFc1Z9X1O3M5K5K3M6J4L3M1O4L2N3MAlGjKQ8i4O3N0OmJUHh4k7UKVHn4h7:12FaJ_Hc5Z7=JDlH\\J0:n6P6MATIgJe6Q6`KgIi1`6oMhIj1c6oMaIk1d6RN_Ii1h6QN[Im1i6oMYIm1n6lMUIQ2V7aMPI\\2X7QMbGO_1m2g821M4N2N2O1O1L5L3N3M4K3L3O2N3M2O1L3O1O3N3L2ON30O1O20N101N11N20O00000O001O100iIaNnKOcN0n00X2a1`8O3NO0RLeNaHND10Nl2^1i2bN\\L6UN>`2k0V5dN[H=d2m0S5dNZH2GO11n2X1\\5iNeGN11n2X1[3fNfJOPO4OMa04DONLh2[1c2eNjJ0J25NK2n0OPO7`0MENNONO7OT2[1a3eN`J0i06ZONEO0N7Oo1\\1S4dNiJ2ZO2DNl2[1d4gNkH1ELl2]1i3dNWI00O2OO<70n2S1^3bN]I1N52:NC38T3S1c3kNYIHMb04CU3Y1Z3aNaI80IL73N2LV3]1V3cNcI51JK72O3K;MP11D`1d4`NmJ5^OLNO5e0L\\OO3=Mj0=CU1Y4]NnJ00000051JN415OJ8c0KB:Ki0a0]OS1f4YNiJ0O2N74>30N@;Kd0m0lNT1Z5mMkJ`0M94ZOK41O6M9Na0V3X4\\NmJUOM^O^1U3^3fLVKc10AY1Y2a3dLUKS1KWO3n0Y1V2P3`LVL2CQ1MZOO<OF]1Q3i2bLjK1c0MBR1N@MG1O14\\1U3f2bLnKO?1BP11ZOLD2c0NI1CY1b3h2bLQLNNO11OO140=NF0O;LKS1Q1_2j2_LSLNM0O`00F0N3MMN25d0j0ZOTOd0N]O03i3m3ZLRLMM10g03YO2001c0j0[OUOg00XONOf3n3gMULeN1O12b0i0]OUOf01ZO_11;k3aNSL;OZO2002b0`0^O[O`00F6G^14;k3RNTL4OMNNO8O01K42M80C61H2132Jg00ZOe0Mn06<j3QNVL4MNM:O52FN`01@1I60a03YOa00n04?W4PNfKT1O40iNo01ROa0Mn0:>R4YOjKHJQO23m0OROa00e0a0e0`3TNTLm2ORM?W20E\\3XNRLV3b0kN2GV3RNVL7NW3a0fL_Om1i0LS3n1eLVLAo1i0MQ3lNVLYOOT20QN0O`0JBn1j0OP3XNSL42J2M55Hb11^N2O20MONl1l0Nk2TN[L0Z1X1dNmN1L=<Ag1n0HW1SN[O2cNN]1V1bNPO0L5NOc2i0[Oh2TN\\LO_1]1^NfN40N;Oc1P1Ke2TN_L0e1]1VNWO5\\1o0Ja2VN_Nk1ZN3h0K^2WNbNOPNb19^NC41]1U18Z2ZNnNMcMZ1c0hN]O]1X19W2[NWOo0QNc0b04T2[NZOO]MNK44Kg0d1a03R2]N[ONcM2HM=l1k0JR2\\N\\ON[MOK:0K;k1R1Gn1[NCNWMk00V1Z1Fl1[NM<gLB:U2W1Bh1^N12fLK1N6V2\\1Af1[Nc0\\2iMZOd5?cJB\\59jJHo4<RKEl49XKG_4a0bK_Oj0VN[NO`0[2>@g0XNYNNQOOn0\\2T1^Oe0YNXNNQOOi0^2\\1\\Ob0YNWNM^O03Z2i1A?XNROMdNV2Q2Ed2UNRKW2a2EX2TN[KQ2d2KX2TNhJP2V3LQ2UNeJn1_3Mh1TNfJ20j1g31l0VN\\KO9k0GTO1f0T4U1?WNQL:h4_1U5YNPFh1n9[NPFd1n9aNPF^1o9gNnEY1Q:iNmEX1R:Q1O1O1O100O100O1O1O1O100O1N2O1M3M3L4SOm0H8G9J6F;C<I7K4O2L4J6M3N2M3M3E;K5O1M3K5H8K5L4LfIUK\\N1]13U2e4TNWKZN2\\12W2]4j4L3L3N3N2K5K[LULTNf3k5L4M3M3BXIRMo3m2X3O1O1OlKjMUMU2c2]MnI`03\\OT3f2n2RNPJVOT3g2o2mMhI]Oa3d2n2jMaIC5NT3c2k2_MWJ?IBR3`2o2_M[J;CFS3_2h3gMTIKT3]2m3eMnHMV3]2S4bMQL\\2Q4dMoKZ2b7O10000"}}, "object_label": "zebra", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, pose, texture, pattern, color, maturity", "answer": "The image features a zebra standing in a grassy field, with its head down and its mouth on the ground. The zebra appears to be grazing on the grass, which is a common behavior for these animals. The zebra's head is positioned towards the left side of the image, and its body is visible in the background. The zebra's stripes are distinct and visible, adding to the overall beauty of the scene."}, {"question_id": 683, "height": 480, "width": 640, "image": "000000047010.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [75.51, 211.42, 143.46, 108.94], "segmentation": {"size": [480, 640], "counts": "TeV12l>2O1N2O001O1N2N2O1O001O1000O100O2O0O101O1O00001O01O00010O001O0010O01O010O00100O001O00010O000010O01O0010O0001O010O001O10OlBCe;=YDGe;9YDLd;5ZDNd;3YD4b;NZD6d;LbCA;5D2]<d0mCXOM2T<i0jCUO72l;k0hCUO?0g;Y1^DfN`;Y1cDgN[;Y1gDgNW;X1kDhNT;W1nDhNS;W1oDcNU;]1W13N3L3N2M2N:\\CkMj;g2O]NVDNk;1XDLh;4fD^O[;a0kDYOV;g0nDTOS;k0nDTOR;l0mDUOT;j0kDVOW;i0hDVO[;i0cDWO_;i0`DWOb;h0\\DYOe;g0ZDXOi;g0UDXOn;h0PDWOT<h0kCXOV<h0hCYOY<f0eC[O]<f0]C^Oe<]11N2O1N2O2N1O2G8I70010O010001O00000000010001O5J6K7I5MM201]AG[>>3L4K4K^`U6"}}, "object_label": "giraffe", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, pattern, color, pose, maturity, state", "answer": "The image features a giraffe walking across a dirt field, likely in a zoo enclosure. The giraffe is the main focus of the scene, and it appears to be walking towards the camera. The giraffe's long neck and legs are clearly visible, giving it a majestic appearance. The dirt field provides a natural environment for the giraffe, and the enclosure seems to be designed to accommodate its size and movement."}, {"question_id": 684, "height": 480, "width": 640, "image": "000000098839.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [112.27, 113.92, 287.39, 360.52], "segmentation": {"size": [480, 640], "counts": "n_d11m>2O1O1O1O1O1O100N2O1O100O1O1O100N200O100O1O1O1N2O1O1O1bMKPF6S9P1cFQOY9W1]EPNm0k0`9n1RFTNj9Z2hEjMT:c3K5M3M3M3N2N2N2M3M3N2N2N2L4N2N2N2O1M3M3M3M3N2N2N20O01N2N3N1O1O1O1O1O1O1O100O1O100O1O10000O1O100O1O1O1O1O100O1O100N200O1O100O100O100O1O10000O10000O100000000O1000000O10000O10000O10000O10000O10O01O00000O2N2O1N1O01000OO2001N2O2NK[IRHc6V8O1O1O1O1O100O1O1O1O1O10OO2O1N2N2N2N2M201O1N2O1N2O0O2O1O1N2O1O1O1O1O100O1O1O1O001O100O010O10O000010O00O2O01O00100O00TNkJYH3[1S5Q5RKRJk0`0T4\\5]KfIm0d0f3d5[MYJe2d5`MZJ[M\\OP5W6jM]JUM\\OQ5T6nM_JPM^OR5n5UNbJiL@Q5l5ZNcJeLAP5j5_NdJaLBP5e5dNlJ[1S5hNlJX1R5kNmJT1R5oNlJQ1T5QOkJn0T5UOkJj0U5WOkJi0R5\\OkJd0T5_OkJ`0Q5GkJ:R5k4M4ZN\\FmMf9P2`FkMc9R2bFiM`9W2cFeM^9[2fF_M]9`2gFXM]9i2]10O10O10O10O10O01O001O1O0dMYD`1h;]N_D]1c;`NbD^1^;`NeD^1\\;`NgD^1[;`NhD]1Z;_NjD_1]<N2N2M3N2N2N3M3K4I6O1O1N2J6O100O100O100O100O10000O1O2O0O2M3O1MgTc3"}}, "object_label": "cat", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:sitting/sit", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, maturity", "answer": "The image features a black and white cat sitting on a desk in front of a television. The cat appears to be watching the TV screen, possibly intrigued by the content displayed. The television is located on the left side of the scene, while the cat is positioned on the right side. The desk appears to be a flat surface, providing a comfortable spot for the cat to sit and observe the TV."}, {"question_id": 685, "height": 480, "width": 640, "image": "000000129756.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [353.47, 371.66, 53.0, 87.03], "segmentation": {"size": [480, 640], "counts": "oZV5<T>c0]BVOf<f1K4M2N2O\\OfCdNY<Y1h0O2M2102N2M101bBVOd<e1N1O00]OgC_NY<\\1oCaNQ<]1j000000010O00000O101OgBiNi<Y1SCiNn<X1PCiNP=Q1b0K^BjNe=S16N2O001O0QOSBk0U>M06J2N0VBPOd=b0e0K]BEk<O]C1ia_3"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, state, texture", "answer": "The image features a sheep standing on a dirt road, with its head turned to the side. The sheep appears to be looking at something, possibly a person or another animal. The sheep is standing in the middle of the road, and its body is facing the viewer. The scene is set in a grassy area, giving the impression of a rural or countryside setting."}, {"question_id": 686, "height": 480, "width": 640, "image": "000000129756.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [61.79, 324.8, 61.29, 33.14], "segmentation": {"size": [480, 640], "counts": "Z\\m05j>2O0O2O001O00001O2O001N001N1O100O100O10001O1O001O0001O01O100O01O1LgA_OY>a0gA@X>`0hA@X>e0O1O0O20O02N01O00001KkA]OU>c05O00100O00010O1O2GbALc>N^A3c>K^A4h>N2NPPb7"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, maturity, state, cleanliness, pose, color", "answer": "The image features a black and white dog lying on the grass, possibly in a field or a park. The dog appears to be relaxed and enjoying the outdoor environment."}, {"question_id": 687, "height": 480, "width": 640, "image": "000000129756.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [510.29, 392.51, 41.57, 75.39], "segmentation": {"size": [480, 640], "counts": "\\\\`73l>4M2M3N2N4L9G5YBTOP=U1dBoN[=[1000O11O013L00001iBZNR=l1O3LN2DRCeNo<[1TCaNm<_1;O0O1000010>A01N1B?M2O200O1O1M4J>YO]\\X1"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern", "answer": "The image features a group of sheep standing in a grassy field. One of the sheep is particularly noticeable, as it has a large, hairy, and round backside. The other sheep are standing around the large sheep, creating a sense of a herd. The sheep are positioned in various directions, with some standing closer to the foreground and others further in the background. The scene captures the essence of a typical day on a farm, with the sheep grazing and interacting with each other."}, {"question_id": 688, "height": 480, "width": 640, "image": "000000172547.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [397.67, 321.63, 20.26, 11.03], "segmentation": {"size": [480, 640], "counts": "Slj54k>1000004L1O000000M4N1004L000001O1O2NiVX3"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "maturity, state", "answer": "The image features a brown horse walking across a grassy field. The horse is the main focus of the scene, and it appears to be running or galloping through the grass. The horse's body is positioned in the center of the image, with its legs spread out as it moves across the field. The grassy field provides a natural and open environment for the horse to roam and exercise."}, {"question_id": 689, "height": 480, "width": 640, "image": "000000205282.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [11.81, 181.58, 255.57, 295.11], "segmentation": {"size": [480, 640], "counts": "VS93l>4L4M2M20O01O10O01000010N100N4K6H=D7K2SE`NX8a1c211O0O1O^GiN[3W1X5O00M3N6K3N2O1014K00N3M2N3L4LWN\\CZ1a<gNaCY1\\<gNeC[1Y<dNjC]1R<dNoC`1l;_NWDc1e;\\N]Df1`;YNbDi1[;UNhDm1U;QNoDQ2o:kMUEW2j;1N2N3N1O1N2O1O1O0O101N2O1O00O11WE^MP9d2gFeMW9[2bFlM^9U2]FnMc9U2XFmMi9T2QFQNn9R2iEUNW:Z31O12M1O2O1O1O2N3L5M4K10N01OgM[FWOe9g0^FQNJ75mN\\9h2hFYMJ?4h0Z9[1TGlMCh0[9Y1SGoMCEG:00g8BSH_2LoMFBH931`8FTH_2IQNNHH1]8FUH_2GSNOFJ1Z8IWH\\2FSNOFL1X8KXHZ2DTN2AO3R80YHY2CTNj0AZ74YHV2ESNi0@W7<^GEi0Z2KTNY96kFf1MQNY9;iFc10nMY9f0aF[17mMY9i0_FZ1b:QNRE5<i1b:iN^EV1c:jN]EV1b:kN^ET1b:mN]ET1b:nN]ER1a:RO\\En0c:XOYEg0f:]OXEb0h:@VE`0k:BSE=P;@oDa0S;\\1oDcLT;Y3nDeLT;Z3:O1hL^Do2d;nL`DP3h;O2O1LPGWMP6g2W3M2OXO^MTE_2m:aMUE]2h;N2O001N3N2N1M4L3NZCWNY<f1gC\\NZ<b1fC]N]<a1bC`N_<_1`CbNb<\\1\\CeNf<Z1YCgNi<e14M2M3MkE]NS7`1lHcNT7[1mHcNW7[1jHbNY7]1V3O2O1O0011hDeNf8Z1YGgNh8Y1VGhNl8V1PGnNQ9P1mFSOT9j0lFXOU9>QGFo88QGIQ95mFNR91nF1R9NkF6PNZOj:?VG8oMZOk:=VG:nMZOl:;UG=lMZOP;8SGi0m8WOQGl0o8TOoFm0Q9SOoFm0R9SOnFl0S9SOmFl0U9UOjFj0W9UOiFj0Y9UOgFg0^9YOaF=k9AVF=l9BTF>o9YOWFg0Q<0107H2O00O02M3M3M3M2Nja<2T^C2N2O101N3NO02O002M10O1O1O100O1N2O1O1N1O2O1O002N00`_^5"}}, "object_label": "giraffe", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "pose, texture, cleanliness, state", "answer": "The image features two giraffes standing in a grassy field with trees in the background. One giraffe is positioned towards the left side of the image, while the other is on the right side. Both giraffes are standing close to each other, with their necks and heads overlapping. They appear to be looking in the same direction, possibly observing something in the distance. The scene captures the beauty and grace of these majestic animals in their natural habitat."}, {"question_id": 690, "height": 375, "width": 500, "image": "000000232244.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [3.22, 33.31, 480.49, 341.69], "segmentation": {"size": [375, 500], "counts": "`d1c0m::K8G9G8I6J4M5I6L7H3M2N_NgGPO\\OLi00l7S1QIWOg6g0YI^Oc6b0dIZOZ6e0kI]On5e0UJYOh5g0[JXOd5e0cJTOaMMj7P1j20O1O2M:bEbNS:g1I6I7IgNcF`0X9R1lJgMQL8o3T2I`N4d1CdN:`1]OfNa0_1hLlMm0k0Z2`1[LZNi0;k2Q6N1O1O1N2O1O100N2O1O1O1N110O101N1O1OjGgLP8Y37O100O100NaLPM[NP3e1lLQK2Y3R3KmLiNO[1S3lLlLW8S3jGnLX5OfJ1b2S3_MnL^5NRMU3`MmLT8S38OYMlLmLP3_3QMXLm2h3VMWLh2]6OWMUMhLc2^3_MbL_2`3aM`L]2^6N\\OeMoGZ2T8eMlGZ2V8eMjGY2k8N101O001N2N1O1OJ8QNhM_JW2b5iM^JV2b7O1O10O0100O1000oNQNYHo1c7]NVHb1g7dNWH\\1g7iNTHY1i7mNSHT1i7^101O0N3M300O0O2000O101O000000O1O010O1N2O1O1O0O200O1N1102N001O1O1O001O1O2N1O0000N2O1N2O1O1N101O1O1N1100000001O1O1O1N3N1O00001O1N10000000O1O1O1N2O1N2O1O10O10001O001O1O1O001O1O001N101O00O1O1O1O1O1O1O1N2N2O10000001O002N1O1O001O1O1O001O00O100O1N2O1O1M30[NdHoN\\7m0hHSOY7l0hHSOY7f0mH[OS7a0oH@R7:SIFn66VIIk64YIJh6KbI6^6BiI>W6cNiJ\\1W5cNjJ^1n4fNVKY1j4fNXKY1g4eN\\K\\1a4cNcK]1[4aNiK^1U4dNkK\\1U4cNmK]1Q4cNPL^1n3cNRL]1m3dNSL\\1l3dNUL]1i3cNXL_1a3cNbL]1W3^NUMc1P1^NhL2a2a1U2]NkMe1n1\\NWNe1m52YK[NXOf1\\51O1O1kIZNV2h1SMRNf3R2iKnMiM0K=[6f1PLPNfMM01f6S2aKPNiMKm6V2a20kGkMg6U2^10QOVNQHj1o7YNmGh1m7jMnG:4l1Y8UNfGk1[8UNdGl1Z8WNdGi1\\8XNbGi1_8XN_Gh1a8YN[Gk1c8e0InLdGX3[82O101O02N10O0000001O0O2mHfLoNN_6]3aJgLoNL^6_3bJgLROLT6a3hJaLWONY2NP1f3^MZL_O2R20l0h3VNVLbN0S2Q1UNPOFo05[3b1gK;_7EaH9`7dN_H92o0a7iN[H:4h0g7gNUHg068o78QHGW82hGfNMl0c8;^GLf84YGnN07m8l0TGlNO5o8Q1QGkNOE46l8\\1RG^NO2b9b1<000O3UFXNb9k1\\FYN32KJS9l1ZG\\NDIm8k1_GdND@f8m1]GROV8WOgGh12ROV8VOhGi12POU8XOiGh13QOR8XOjGh14mNMSOR8:mGh13oMO3O<0@R8:mGh17SNK:S8S2oGbMO;Q8V2oG_MO7U8\\2kG]M06V8]2hG^M27U8b2jG_MU8S3O1O_OlG_MS8b2mG_MR8S301O1N2O1N2OQOVHRNi7n1VHSNj7m2O10hNXHbNg7h2N_NZHSOf7m0ZHSOf7`2O00jM[H:e7m1O1O001O1OZMaHT1_7lN`HV1`7iN_HX1a7`1O100O2O0O100O1O100O3N1OO1O0N4J5K6F:D:N3L5M2^M[GP2f8>2O22N1O1OO1O010O10ZGSMa8l2_GUMa8k2]GZM`8o201N2O4L00000gGcLV8l2kGfMS8P31O0002M11N12NO12OO0]OnG\\MV8c2jG\\MZ8P322ONO1002YOfGiM]8T2cGiMOD`8b2`GjMf8b2ZGRM21^8o2_GRMd8o22[O\\GSNe8m1\\GQNh8k1XGUNj8j1UGWNm8f1SG[Nn8e1PGXN0FQ9^2oFbMT9[2lFdMV9[26M4M3B^FaNb9]1^FfNb9W1_FiNj9o0TFTOk9k0UFUOk9j0UFXOk9]10WOUFAk9<VFEk98UFKl9ESFj0o9ROQFQ1n9?N00\\NTFZ1o9`NSFc1P:_NnEO001V1n9oNRFI1Z1k9POTFS1k9kNVFY1g9fNYF\\1g9_N\\Ff1j9O40M2N020O0O2N2ON21ON102M1O2M3L5M3L3M2M7J3L5K7Ela5"}}, "object_label": "elephant", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:gray", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "maturity, pattern, pose, texture, state, color, cleanliness", "answer": "The image features a large elephant with a red blanket or sheet covering its back. The elephant is standing on a dirt ground, possibly in a forest or a similar environment. The elephant's trunk is visible, and it appears to be walking or standing in the dirt. The red blanket or sheet covering the elephant adds a unique and colorful touch to the scene."}, {"question_id": 691, "height": 427, "width": 640, "image": "000000235252.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [240.85, 154.73, 95.95, 140.09], "segmentation": {"size": [427, 640], "counts": "b_U34W=010O2K4N6K1O1O10O11O0O2O^O]C=a<AbC?e<1O1O2N1O2O0O2N100O00101hCWOi;i0RD^Om;a0PDCo;n0O1O2SOeNeE^1W:bN\\EO2b1k:_NUEd1h:\\NWEi1e:UN]En1Y:RNnEY2f9hMYFd2^9ZMaFf2_9\\M_Fe2T:bNaENo9iN[FX12Cd9VOZFV1d0ROc9n0^1OFjN_DV1`;lN`DS1`;mNcDP1m;OCoN`DQ1o;M2O1OFVOSDk0k;XORDi0o;VORDj0n;UORDk0MROn;3UDj0NTO0Oj02n91ZEk0a0XOCLb:0ZEl0?ZOFIb:0ZEn0;[OIFb:1ZEo08]Oh:DPEP17[OFGP;MQEQ1j0WOo9IUEQ1l0VOo9o0V14M2N2N2O0O4eD`Nb:T20N6XOc00010\\O_D^Ob;`0aD@];G]D`08@C8e;HaD?<I_;2eDNX;0lD0Y<O1O1O1N2MZ;0fD01O]=0cB1aYm3"}}, "object_label": "giraffe", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, pose, maturity", "answer": "The image features two giraffes standing in a grassy field, with one giraffe being taller than the other. They are both looking up, possibly observing something in the sky or their surroundings. The giraffes are standing close to each other, with one giraffe being on the left side of the image and the other on the right side. The field appears to be a natural habitat for the giraffes, providing them with ample space to roam and graze."}, {"question_id": 692, "height": 480, "width": 640, "image": "000000320632.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [144.11, 92.91, 136.52, 85.6], "segmentation": {"size": [480, 640], "counts": "TVR26i>9H4L2N103MKiA_OW>`0kA@U>>8O001N2O1O1O1O2N1O001O001O001O1O010N10100O0000ZY30ffL0000000fg3?kWL2N1N3H6J9L20O10M2J7O1O001M3N2O10]NhB\\1_=0O011I7NZNiBd1[=O1OO^NeBa1Y=30XOgBIY=4kBLX=IPC7o<EUC<g=0O2O1O1N2O1N2N2N3M2O1M4M2N1O3M2M3N1N2N1000O011O0O1AQCmNQ=P1TClNm<T1?O00100O1O1O101N1N11O001OO10100O1O2M3M5L5DYn[5"}}, "object_label": "zebra", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, texture, state, pattern, maturity, pose, color", "answer": "The image features a close-up of a zebra's head and neck, with its mane blowing in the wind. The zebra's head is turned to the side, and its eyes are looking to the left. The zebra's mane is black and white, and its stripes are visible on its body. The zebra appears to be standing in a grassy area, possibly in a field or a savannah."}, {"question_id": 693, "height": 427, "width": 640, "image": "000000367818.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [143.25, 49.59, 404.96, 341.6], "segmentation": {"size": [427, 640], "counts": "nhk1=k<4L5M2M2M3O2O4L0O2O0HPOUDP1h;SOXDm0g;TOXDIOQ1g;YO\\Dg0c;ZO]Df0a;\\O`Dc0_;_OaD?^;CcD8LVO_;e0dD6^;LaD4];ObD1];0dD0Z;2gDLX;5iDIV;9jDFU;<lDAU;`0kD]OW;d0mDWOS;i0lDWOU;i0fD]OY;Z101O1O1N200SORN\\Fn1d9WNVFj1l9XNPFi1Q:XNlEi1U:WNiEi1Z:XNbEh1_:ZN^Eg1c:?2O1O1N101O0O2N3M[OWNkEg1V:[NhEe1Y:\\NdEd1^:d01N2O2N3M4L1N3N2O1O1N2N1KjDSNV;Q21O0LiDSNX;l14000001O0010O001O10O01O1O010O1O1O1O100O1O2O0O002N100O2N1O10001N1O101N1O101N101N2N100O101N101N5L8G4M3L2O4L5J3N1N1O100O101O0O100O100O100O010O011O000O7J2M6K5K5J:Gh0XO4hIRJi4V6hJRJX5P71O001O1O001O1O1N2O0O2nN]JVJh5f5Q1O11N4M2M5L6bIjIY5T7100N2N1O2O001O1O001[L]KlLPOd0d5^2eKaLVOg0U5h2PMnLR3Q3TMeLP3[3b3N001O1O1O001O010O001O001O000010O01O00001O0000001O01O0000000001O00000000000000000000000O100000O100000000000O100000O1000O100000O10O1000000O0100000O0010000O10O01O100O010O1000O010000O010O1O1O001O100O1O00100O1O1O001O100001O1N2O1O2N3M1O00003N0O1O1O1O2N1O101N1O1O2O0O1O2N2N2N100O2N1O2O0O1O2O0O100O100O100O2O0O2O1O1O1O0O20O0001O010O102M4L7J2M5K\\L_Hg1X7oMVIm1i6dMhI[2W6SM\\Jm2b5SM`Jl2_5XM_Jg2a5YM`Jf2`5YMaJf2`5YMbJe2`5ZMaJd2_5\\McJb2^5`M`J^2b5aM_J^2c5aM]J]2d5dM]JZ2d5gM\\JU2f5lMZJR2g5oMYJQ2f5oM\\Jo1d5QN]Jo1b5RN_Jl1a5TNQKZ1o4fNaKk0^4VOQL:n3GWL4h3Ni42OO1001O001O000001N2O1N6K2M101MfeX1"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:black", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a woman standing next to a large brown horse in a grassy field. The horse is positioned to the left of the woman, and they are both facing each other. The woman is wearing a cowboy hat, which adds a touch of style to the scene. The horse appears to be calm and well-behaved, as it stands close to the woman without any signs of agitation. The woman is holding a rope, which could be used for leading or controlling the horse. The overall atmosphere of the image suggests a peaceful and pleasant interaction between the woman and the horse."}, {"question_id": 694, "height": 480, "width": 640, "image": "000000394611.jpg", "category": "description", "question": "Describe the giraffe in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [85.94, 202.83, 103.76, 102.97], "segmentation": {"size": [480, 640], "counts": "e_Y1=b>7D9L3SBFm<Z1M2NO1E<L31O100O101N101OO001N2L4K5L3N3M2O10O2O1N2O1O1O100000O01000001O2N:F:F2N1O0000N2F9lNmB31]OS=?PCC;Ne<>jCCU<=lC_OW<`0U100O^BAe<?ZCCe<<P10O10O1000000O010O10O10O100O10O0100O10O01O1O010000000000O100O2O1N10000001O1O2N9GWRe6"}}, "object_label": "giraffe", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "color:tan", "maturity:adult/old/aged", "pattern:dotted/speckled/spotted", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture", "answer": "The image features a giraffe standing in a grassy field with its head bent down, possibly grazing or eating. The giraffe is surrounded by tall grass and trees, creating a natural and serene environment. The giraffe appears to be the main focus of the scene, with its long neck and legs visible as it stands in the field."}, {"question_id": 695, "height": 426, "width": 640, "image": "000000504635.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [334.51, 187.84, 186.79, 229.67], "segmentation": {"size": [426, 640], "counts": "fi\\43V=4M3M3O1N1O01O000O0100ZC?Y1ZOb8^1QGnNl8^1fFfNZ9]1^FiN_9Z1WFPOh9[2N4L2M2M5K2L6I7L9E7K6K3M50N6KM2N21OO3BkJ^HZ5[7gJkHW5P7jJRIU5l6lJVIR5j6lJZIP3J_Nl6`N\\Io2N\\Ne6eN_In29PNW6SOaI7\\OT2`1oMa5FdI5^OU2b1lMZ5IkI0]OZ2c1lMP5JSJNZO\\2f1lMj4GhJ\\2`0mM[6T2gIkMW6V2kIlMQ6T2oInMn5W2ZHiMg03l6U3RIhLn6d3hHZLX7n3dHnK]7R4dHlK\\7U4dHhK^7Y4j0O000OlGfKZ7i3VIYLi6Q3THSM`9d2h0EfEaM^:_2BdM\\F\\2d9eM[FZ2f9gMXF[2h9dMlEN7^2n9hMQFX2P:iMoEW2S:hMkEY2U:jMgEW2Y:=1O0000O0OO22O1N2O1N3N3M7I5K3M1000O0110O011N200N3L5L:Ea0_O1O1O1O001OO2O0O2cMoG^OR8`0iIeMZ6_2V2X1_ESLV9T4L5K`0AO001O1O1O1VOi0M4M3\\Od0I8B=L3O200O2O0000001O2N1dNjDa0V;VOhDG8P1`;lNhDo0R<H8H2OkNB\\E>b:C^E>`:BaE>_:BbE>\\:CdE=[:DeE=Y:ChE>V:BlE=S:CnE=Q:CQF>l9BVF?g9A\\F>b8AjF1g0=\\8EkFOn09R8NlFIW16k73kFH\\17f72lFGb16_75mFEf17[74nFEi16X78lFBn14W7j0kHUOU7k0mHQOV7n0d2N2M3N3L5M4J6CRC1bie1"}}, "object_label": "zebra", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "maturity, state, pattern, color, texture, cleanliness, pose", "answer": "The image features a group of zebras standing in a grassy field. There are three zebras in total, with one zebra standing in the foreground and the other two zebras positioned behind it. The zebras are facing different directions, with one zebra looking to the left, another looking to the right, and the third one looking straight ahead. The zebras appear to be grazing or simply enjoying their time in the field."}, {"question_id": 696, "height": 425, "width": 640, "image": "000000560266.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [78.31, 48.55, 242.59, 265.5], "segmentation": {"size": [425, 640], "counts": "_VP1h0[<7H8M2M3_Oa0D=I6N2O100M4N1N2N2O1O2YMXMhJk2U5[MeJh2Z5[MSJW3j5mLdIc3[6`L[Ih3d6ZLWIj3i6VLUIl3j6VLSIl3l6VLoHn3Q7TLkHn3T7U1O0O10001O000000001O0000000001O0000000001N1O1N2O1O1O1O100O1N2O1O1O001O1O1O2O000O1O1O101N10000O2O0O100O2N100O2O00000O2O001N1000000O101O0000000000001O000O1000000000000O10000000000O1000000000000O2O00000001O000001O00O1000000000001O00000O100O1000000001O01O0000010O000O2N1O2N2nNPJQJNa0R6]5SJoIMd0o5\\5VJoIMc0n5\\5VJQJN`0m5^5VJSJM>n5^5_J_Je5`5VJTJD:X6b5hIVJ3102W6e5gIXJ2020W6h5eIXJ20f6g5YIXJ03g6d5YIZJN:b6\\5`IZJM<c6Z5`IYJM>c6Y5_IYJN>e6]1YIl19dLb6_1VIUN1e34hLe6^1VIUNa0V3CWMg6]1TIXNd0Q3AZMg6b1hIS1A[Mh6b1hIS1^OZMk6f1hIl0]OTMONR7R2dIk0ZOUMV7P2`I\\NZOn1OgM0MS7R2dI[N^Ol1LlMS7m1kHPNd0:Fj1GkMX7V2[ITNLe1m68WISNOb1i6;XIRN1c1f6MhI_NCd1d6GPJdN]Of1a6ESJeN]Og1^6CXJdN[Oi1\\6BZJeNZOi1\\6A[JfNYOi1\\6@WJbNfN6g0g1]6^OWJgNdN4i0d1^6AUJhNcN3k0b1^6BVJhNaN4m0_1]6EVJPO^OY1]6FVJQO^OW1]6HVJQO]OV1]6HXJQO[OW1]6G[JPOYOW1]6G]JPOXOX1[6H`JmNUO[1[6H`JmNWOY1X6JZJlN^N1Q1V1Y6M]JoN\\OQ1X61[JmN@Q1U62\\JjNCQ1R65mKJR47oKGR49oKFQ49QLEP4;RLCn3;VLCj3=WLBi3=ZL@g3F^H>l3Kf3`0[L@e3`0\\L_Od3a0]L^Od3`0aL[Oa3c0bL[O`3b0bL\\O`3KWHb0[4B_3JYHa0Z4De39^LDe38j4KQlX4"}}, "object_label": "bear", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:wet", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, cleanliness, color", "answer": "The image features a large brown bear in a body of water, possibly a lake or a river. The bear is in the process of catching a fish, with its mouth wide open, displaying its teeth. The bear's mouth is open, and it appears to be in the middle of the action, trying to catch the fish. The bear's size and presence in the water create a powerful and dynamic scene."}, {"question_id": 697, "height": 426, "width": 640, "image": "000000044699.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pose, state, texture", "region_anno": {"bbox": [437.57, 256.36, 39.48, 61.81], "segmentation": {"size": [426, 640], "counts": "j_f5a0e<7K8G4N2N2N2O0O01M201O100004K2O1I6J6O101OO10O01O1K410000000O1L5L3L5YOQDNR<1TDGP<NkCOh<O^oS2"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture, color, cleanliness, pose, maturity", "answer": "The image features a large white sheep standing on a grassy hillside, overlooking a body of water. The sheep appears to be looking at the camera, possibly posing for a picture. The scene is set against a backdrop of a beautiful blue lake, creating a serene and picturesque environment."}, {"question_id": 698, "height": 480, "width": 640, "image": "000000046804.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pose, state, texture", "region_anno": {"bbox": [223.04, 62.84, 236.4, 301.16], "segmentation": {"size": [480, 640], "counts": "igW3`0X>>G8H9H:G8kBWNc<_2^CZMR<S3G7H9H3M4L2N4L2N3M2N3M2N2N2O1N4L3N`0_O6K:EU1kN4M4K7J2M2N1O1O100O100O100O1000dMeIhJVOT1U7o3YJhKh5V4_JeK`5[4jJ[KW5d4oJUKS5j4a210O0N3FUF]Km9a4:000000001O1O1O1O1N2O1O1O2N1O001O3M5K3M2O1N2N1O1O3M2N4L2N2N3M3M4L2N2N2N6J4M3L4L6J2N10O01O2N2N3N1NfMhHnLV7Q3PIlLn6S3TImLk6R3WImLi6S3XIlLh6S3ZIlLg6S3_IgLa6X3fIbLZ6^3jI^LV6b3oIYLQ6g3RJVLo5j3\\JjKd5W4`JcKa5]4bJ`K^5a4dJ\\K\\5e4eJXK]5h4dJUK]5l4gJmJ[5T5X2001O1O1O2N001O2M2M4L2N3N2N4gN\\JPIg5m6\\JoHf5l0VJW4;fJb5g0_J`4OiJd5?dJg4IhJb7V5dHbJ`7\\5T1N1O1O10O001O000O2N2O001O0O2O2M2lL^JmINk04e0a5a4eJgJIj0e5\\4cJbL`5]3`J\\Li5c3SJaLn5_3PJcLo5_3kIeLV6S6O10O1O0O10000O10O100O[NnJ]IS5Y6]K`I_4MkIa6[8M2N2L400O100O1O1000HiIgGV6Z8jIfGV6Z8jIfGU6c800O100O100010O00O2O0000O101N2O0OG\\GYJc8g5^GYJ`8h5aGWJ_8h5bGZJ[8g5fGXJY8h5iGWJV8h5mGWJR8h5QHXJl7i5UHXJi7g5ZHYJd7g5^HYJa7f5`HZJ_7d0lGT4h0XK\\7c0mGT4h0WK\\7f0mGQ4S9oKmFP4S9PLoFl3T9TLmFh3U9XLmFf3T9ZLoFb3R9]LPG`3R9`LoF^3R9aLPG[3S9dLPGW3S9gLQGR3T9nLoF49l0j8oNQG1:k0f8QOYGL=g0]8XO]GMg06R8IlI2X6J]md2"}}, "object_label": "sheep", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state", "answer": "The image features a large, fluffy white sheep standing in a grassy field. The sheep appears to be looking at the camera, possibly posing for a picture. The sheep is standing on a grassy area with a rock wall in the background, adding to the natural setting of the scene."}, {"question_id": 699, "height": 393, "width": 640, "image": "000000291490.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "cleanliness, color, maturity, pose, state, texture", "region_anno": {"bbox": [117.0, 76.7, 246.16, 242.85], "segmentation": {"size": [393, 640], "counts": "ZQ]13R<6M3N2N2N2N3M2M3N2N100O2M3N100O2N1O1O2N2N101N2N10O02N01000O1O100O2N2O4K5L1N2N2O1N3N2M3M1O1O2N101N3M2N1O2N2N0O2O000NXMjFb2T9ZMlF00g2S9YMnFN0k2o8XMUGi2j8WMVGk2j8SMWGn2j8PMUGP3c8RMbGP3\\8SMbGP3Z8PMeGT3Y8jLiG2Go2^8nLkG3Jo2X8nLoG3IP3W8mLPH3IR3U8jLTH4FS3T8jLVH_3j7aLXH^3g7bLYH_3f7aLZH_3e7bL\\H]3d7bL]H_3a7bL`H]3`7cL`H]3`7cL`H]3`7cL_H^3a7aL[Hd3e7\\LZHe3T81AXLSH05h3h7XL]Hh3c7[LWHh3i7XLVH0Jd3o7]LXHf3i7YLXHg3g7[LXHe3g7]LYHa3g7cLUH^3k7bLUH^3j7dLUH[3l7dLTH]3k7aLYH^3f7bL[H]3e7dL[H\\3c7eL_HZ3a7hL\\HX3c7nLYHR3e7PMZHQ3d7RM[Hn2c7TM]Hk2a7P1M3M2N3N2M2O2N2N2N1O2N2N101O1O1O10O010000O01000001O1N2O1O1O4L4K3N3M2N3L4M3M7I5K3M3M=B3N1O001N2O1O1O1O1O2NgGPM[7n2bHXM\\7g2]HbMc7\\2ZHhMg7V2WHoMGUOk7k2ZH]Nc7b1YHfNc7R3O01O102M001N0010O01O0000010O01O0000O1000000O100O10000O10000O1O101N2N2N100O1OIoKXHP4i7PLWHo3j7QLVHn3k7RLVHk3V8nNcGTN_8i1gGQN]8l1fGlM`8S2eGfM_8Y2h001M4M1N1O2L6K5L3ZNeE[1^:dNcEZ1_:cN_E02Z1b:36QOXE9j:\\OcE>a:AcE8\\;JVX`3"}}, "object_label": "cat", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose", "answer": "The image features a white and brown cat lying on a bed, possibly on a pillow. The cat appears to be looking at the camera, possibly posing for a picture. The cat is positioned in the center of the image, occupying a significant portion of the frame."}, {"question_id": 700, "height": 612, "width": 612, "image": "000000459396.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "cleanliness, color, maturity, pose, state, texture", "region_anno": {"bbox": [203.96, 144.41, 110.25, 28.17], "segmentation": {"size": [612, 612], "counts": "PYh31Qc03M3N100O1O2O0O10000O1000000000001N1000000000001O00001O00000010O000001O00010O00001O00000000001O00001O00001O00001O000000001O0000000000001O0000001O000000001O00001N10001N1000001O000100O101N1O0A?L4O10000000000O10000O100O2Nlgc5"}}, "object_label": "cow", "attribute_label": ["cleanliness:clean/neat", "color:brown", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a cow standing in a grassy field, with its head turned to the side. The cow appears to be looking at something, possibly a person or another animal. The field is spacious, providing ample room for the cow to move around. The cow's position in the field suggests that it is grazing or simply enjoying the open space."}, {"question_id": 701, "height": 428, "width": 640, "image": "000000005992.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, pose, state, texture", "region_anno": {"bbox": [548.06, 213.63, 91.94, 207.13], "segmentation": {"size": [428, 640], "counts": "ljZ75`01o;5gC6S<f0K7I7I3M3K5G8L4M2N3M3M3L3M3H8J6_OkLfFZ3X9>N2B>K5L4K5N2M3O1N2O1N2N2N2O1N2N2N200N2O1O1O1O1O1O1O1O100O100O100O1O100O1O1O100O2N10O01O1O100O100O100O10000O100O10000O1SI"}}, "object_label": "sheep", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "color:tan", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, state", "answer": "The image features a herd of sheep standing together in a grassy field. There are at least nine sheep visible in the scene, with some of them standing closer to the foreground and others further in the background. The sheep are of various sizes, indicating a mix of ages and stages of growth. They are all facing the same direction, possibly grazing or looking for food. The scene captures the essence of a peaceful, rural setting where the sheep are free to roam and graze."}, {"question_id": 702, "height": 480, "width": 640, "image": "000000417779.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "cleanliness, color, length, material, pose, transparency", "region_anno": {"bbox": [264.27, 198.47, 140.22, 281.53], "segmentation": {"size": [480, 640], "counts": "iQl33k>4M7TOCiB`0n<KlB8l<2oBOo<6mBMP=S1N1O2O1N2O0O2N2O00VOWC]Oi<c0WC]Oh<d0XC\\Oh<d0YC[Og<_12N10I6H9M5eF[MQMOn8o2iI[MQ6U4_HoK]7P5eGTKGAY8R7^O4K2O1N2O1O1O100O1O1O1O1N2O1M3O100O10000O1O1J6M3H8M3O100000000000000000000001O2N7I2N5K3M2N00001O001O1O1O1O2N1O3M1O1O00001O1O1O2N1mKbHb0`7\\O`Hd0a7\\O]He0d7QOZHYM1g3g7X32N2N3M3jLSHSOQ8eNkG>k06^7YOjG=Y1ET7LjG8^1mN\\7k0WG7^1lN\\7l0WG4CbNl1<[7n0VG1g1kNX7R1RG2\\;NeD1[;NfD2Z;NfD2[;MfD2Z;MgD3Z;KgD6X;JhD7GfNT;Q1VE;\\OeN30\\;n0WEf0j:YOXEe0k:XOVEg0m:VOUEi0m:QOWEn0o:iNUEV1P;cNTEZ1[<N2N2O1N4K5L3D<N1O1N2N2M3MVW_3"}}, "object_label": "fire hydrant", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "length, cleanliness, color, material, pose, transparency", "answer": "The image features a fire hydrant located on the side of a street. The fire hydrant is painted silver and has a chain attached to it. It is situated on the sidewalk, close to the curb. The hydrant is positioned near a pole, which is also visible in the scene."}, {"question_id": 703, "height": 427, "width": 640, "image": "000000473869.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pattern, size, texture, transparency", "region_anno": {"bbox": [287.79, 296.02, 73.96, 52.41], "segmentation": {"size": [427, 640], "counts": "\\jh39P=4L3N2M3N2N2O0N3N1O101O1N101O00100O0010O10O01O01OEiCBX<=iCCV<OiC41MU<0kC>U<BkC>i;^OZD5M=i;@XD?OEi;f0XDYOg;i0WDXOi;U10DWDVOj;i0WDWOi;h0WDXOi;h0WDWOj;;UDG2Nl;e0SD\\OR<?nCAT<<lCDZ<7fCI_<2aCNa<0_COd<O\\C1e<NZC3h<KXC4l;HoD>Q;BPE<Q;DPE;P;FPE8Q;InD6S;KlD5T;LkD3V;NhD2Y;OfD0[;1cDO^;2`DNb;2\\DNe;3XDMk;3PDFH6Z<6lCKW<5gCKZ<b03M1O2M4M2L5LZQd3"}}, "object_label": "bowl", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:floral", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "pattern, texture", "answer": "The bowl in the image is white and blue, with a floral pattern. It is filled with a red substance, possibly a sauce or a mixture. The bowl is being held by a person, who is using a spoon to scoop the contents out of the bowl."}, {"question_id": 704, "height": 426, "width": 640, "image": "000000007108.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, pattern, pose, state, texture", "region_anno": {"bbox": [567.63, 49.79, 69.71, 323.1], "segmentation": {"size": [426, 640], "counts": "Yd]73U=2O2M2O1O1O101N100O2N100O1O2N100O2O0O2O0O2O001N101`KVO]Ll0]3YOcLg0U3AjLa0k2IUM8c2O\\M2`23_MN]25cMLW29hMIT2:lMGR29nMIP28PNIo17QNIP26oMLP23QNNo1fNlIT1V47o1bNmIU1U4:m1aNoIT1S4=]1_NjJ0FT1S4>k0fNQK?N=U4`0b0P1^OQO>R1APO:T1EnN6V1JlNNY12iNH\\17hNB\\1>fN\\O^1c0eNZO\\1e0gNVO[1j0hNPO\\1o0iNjNZ1V1iNaN]1^1jNYNX1g1mNPNX1P2QOiLRMGo3_3WObLPMFl3i3VO]LQMGj3l3XOXLc1i3^NULb1l3i3401M3E;L`N"}}, "object_label": "elephant", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:rough"], "control_dims": "cleanliness, color, pose, state, pattern", "answer": "The image features a large elephant with a red substance, possibly mud or dirt, covering its back. The elephant is standing in a dirt field, and the red substance appears to be flying off the elephant as it moves. The scene captures the elephant's powerful presence and the dynamic nature of its movement."}, {"question_id": 705, "height": 427, "width": 640, "image": "000000216739.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "cleanliness, color, maturity, pose, texture", "region_anno": {"bbox": [0.0, 305.13, 17.79, 31.99], "segmentation": {"size": [427, 640], "counts": "o9e0e<000O00OO201001N2N2N2O1F:N101O2Nd_S8"}}, "object_label": "bird", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:yellow", "maturity:adult/old/aged", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a bird with a yellow beak, perched on a branch. The bird is looking upwards, possibly observing its surroundings or searching for food. The bird's beak is prominently visible, adding a striking detail to the scene. The bird is positioned in the middle of the image, with the branch it is perched on extending from the left to the right side of the frame."}, {"question_id": 706, "height": 427, "width": 640, "image": "000000216739.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "cleanliness, color, pose, texture", "region_anno": {"bbox": [29.99, 254.73, 15.86, 26.59], "segmentation": {"size": [427, 640], "counts": "RV=6S=7K1N00O00O2O1O0101O0O2O1GUC0n<N_^g7"}}, "object_label": "bird", "attribute_label": ["cleanliness:clean/neat", "color:brown", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, color", "answer": "The image features a bird perched on a branch, possibly a crow or a similar species. The bird is facing the camera, and its head is turned to the side. The bird is positioned in the middle of the scene, with its wings spread out, giving a sense of its size and shape. The branch it is perched on is located towards the top of the image."}, {"question_id": 707, "height": 400, "width": 600, "image": "000000007386.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [51.12, 12.56, 548.88, 387.44], "segmentation": {"size": [400, 600], "counts": "jmf027002N01Nd90WF`00O2AO1O0101NO342MM4OX9e0bFA1N7K81GOn91mEO?0jT12jjN0ig0NYXO10Oc;2\\DO00c;3ZD00Of;2YD1NOi;M]D0m;NTD1V<0EOPD2132L2Ob;1ch4OcmM0U\\M0ZN0iC0hf00SYO0X<0hC0Y<4K4HKSD80EQ11TOOV:4dE<P1CTO0V:f0cF[OUO1V:e0dF\\OUO10K5Nd9i0SGZOVO21KP:2mE0O52JOOW11T90eE1041KOOX10S9`0fEDS11W91dE02Mk0MZO2JOcg2OWdM0dD2U:OUF=XOI0MS;2oDJ42_;7?1OO01mCGo;=1N10O101O001O001OO1O01M4N101O1O0000O4N0O0O1000kN@ZF`0d9DYF=f9EWF>g9FUF<j9DUF?i9BPFe0n9AjEb0V:l00010O3K3L34hMhEQ2]:1N0O01PNdEk1n:XNTEP1n:lNUEU1i:kNXEm0JXOj:N[ET1d:nNYES1f:93hNUEg0o:YOREd0P;\\OPEc0Q;]OPE=V;AlD0LLa;N`DN52d;3VDJ73c;5]DLb;5^DHd;9VDFQ<<00003M3MO1lCIn;8RDJm;5SDJU<O60^<1aC02OdC0^10Q90_E12OU10oN0Y:6cEKn;6QDK[<NaU10ZjN1jC1S<2lCNn;NTD5NMm;9SDGT<2lCNV<0jC0W<OiC0X<OiC1U<1kC0S<7HJTD9OF1Nd;i0O1000L5KYD_Of;b0mL_O[JORMc0b8_OmIT1`MmN]8OQJ\\1o5cNiI1lMa0N6\\8ZOiIOnM`0M8\\8XOhI0PN`0L8R;XOnD70a0\\;ZOeDd0k5[O@0hJb0g5@L?2DL<3FK>IXOiJ;i1EWN2R3h0T2VOjJ;h1HSN2V3f0\\2@SLF_N<P3?V2UOjJ:i1ITN0T3h0U2UOjJ:k1E`1l0j1WOiJ9_5c0ETOlJ9]4D^LR1X4QOmJ6\\4M\\Ln0Z4oNnJ4[44\\Li0=QO_2N^L0\\4<YLe09UOc2J]L1_4>ULb0<UOc2J]L2]4>WLa0<UOc2J]L3Z4`0YL>=UOd2I[L4\\4b0WL;>VOe2HZL5[4d0WL:>UOf2G[L6Z4f0dK[O8m0i0UOe2H\\L6Y4Q1iKMm0TOe2I[L5Y4]2gLeMe2IZL1_4a2bLeMe2Nh0^2dLbMe20g0^2dLbMd22g0o1cKSNQ1Mf2JYL1]4c2dLbMf2JZL0\\4e2dL`Mf2KZLO]4f2cL_Mf2NYLN\\4f2eL^Mf21f0b2cL]Mg21f0b2cL]Mg21f0R2fKSNl0Jh20f0U2gKoMk0Lg21g0T2gKPNi0Li20g0U2fKoMj0Li20h0S2gKPNi0Lg22i0R2gKQNh0Ji23h0R2gKQNh0Ji23[LKW4Y2lKnMi0Jh2<c0m1kKnMi0Ii2=a0b1PLPNM9h0If2?e0^1QLRNK9h0Hg2?e0^1QLRNK9h0Hg2?e0^1QLRNK:f0Hi2=f0b1mKoMO9e0GXOL`3d0g0b1lKmM1:e0Ej2b0d0j1nKnMd0Fj2b0e0h1nKQNa0Gk2?g0i1nKPN`0Hj2=Q1f1eKTN`0Kg2;V1e1cKWN>Ii2;U1g1dKTN>Jh2<f0BmKQ20YN4Na0Jg2=a0R2SLfM32a0If2?=U2]L^MN7a0Gg2?8Z2bLlM?YOi2a03]2eLiM?YOh2b00`2iLeM?YOg2b0Nd2lLjLO??Be2`0Of2SMgLKa0?Bc2`0Lj2WMbLLb0=Cd2?Kk2PMaL312`0<Dd2?Jl2QM`L313?;Ed2?GS3WM[L3?9Cg2`0ET3XMZL3`08Ai2a0DU3VM[L4>9Ai2a0CR3UMdL67:Bh2a0@U3XMaL689Aj22iL0h2e3WM`L58:AV3MTOk3WM_L58:BT3MUOk3XM^L598AW3LUOl3WM_LOD3d0;AW3LTOm3XM]L598@Y3LQOo3ZMRLOO94H:<EV3N\\L1f2n3lMTL@;;DW32QOl3_MQL52J;:DX31POn3]MRL60K<:A\\3OlN\\4_MlKN9:AS6b4bI_K0?<@P6d4dI\\K0`0;AQ6c4dI^KO=;CR6b4cIRL;\\O]3LkNa4_M_KOi0:ZO\\3NkNX4`MlK2e07YO\\3NkNa4aMYL8WO^3NiNc4`MXL8WOT6a5jIbJS6_5kIdJT6]5kIcJU6]5kIcJU6^5iIcJV6^5jIbJV6_5iIbJV6_5iIaJW6_5iIaJW6`5hI_JX6P5hIWK0IX6n4lIWKMJW6o4lIWKMJW6c3hI_M3UONIW6P5iIXK0GX6Q5hIiJ29MNY6T5kImJLNZ6V5hImJOLY6X5gIlJ0Km3L\\Ni4hMSLN[Ol3J]N_4hM_K94J=LHk3K\\N]4VNbKHi0f3WO]N_4TNcKGg0h3XO\\N^4UNbKH4L:k3C[N[4YN`KH7K:i3DhLNk0]4ZOgK[O9h3EhLOj0\\4[OgK[O8i3FfL0k0[4[OgK[O8g3IcL3n0U4UOeKA139e32ZL7m0[3POSLe08@0d3Q1VM_2ROSLn0<VO1c3S1UM^2TOSL21c0:_O1c3T1TM]2TOVL0Of09_O1b3W1SMZ2WORLo0:WO2^3\\1PMY2?WLVO3[3_1mLX2b0VLVO3Z3c1hLQNDT4k0lK\\O933Z3f1bLY2c0eK^O:5NY3h6iLPII;5MX3i6]LTI<8NKY3R7`LgH2<4K[3R7\\LjH494L]3k7cLUH^3j7cLUH]3k7cLTH_3j7aLWH`3h7`LWHa3j7^LWHb3S5YLTM5iMb3o4]LYM0hMc3o4]LYM0hMo23PMl41ZMOgMl29RMf43ZM0eMh2`0SMb4NjJ2U1M18jNIOn2i0TM`40kK123kNKNl2l0VM[40TKL=6ZOMl03UOj2l0QMY44nK0kNOn02SOi2V1TMY30hK15N:OYO342=1_Og2U1YMV3JeK37O708NZO503a0M_OLOf2X1^MX3OjKM4196[O0`0M_Oe2Y1ZMV3OlKM22;3[O2>M@f2Y1YMS32mKLT1NhN8<M]Of2]1YMf2;XLC^14gNJDQ3Z1RMd2=XLC]2n2gNQMe2?ULD^2k2iNRMf2=SLFQ2KSN:FW2]1`Mj2:RLGn1ORN0JO1_2j5hM[JIe12UN15O4\\2R1bMo25nKLY10_N1014050ES2]1jMo25nKMX1OaN001219MCU2]1kMo24kK0>M72UO13N`0R2i0lMS30dK8K2O4f0H\\OO5K?T2i0lM]3Y1hKoN]ONP1n1>lM\\3k0TKAe0L]ONP1n1>lM]38SK71Ld0M\\OOQ1m1>mM_33RK2O0270C4?KGS1m1<oMQ42aJ`00M0CS1o1;oMR41aJV10jN0Nk0R2b0PNW20mM0_Na0MEON5KQ1Q2;PNX20kM0`Nb0MC0N4L2Nf0T2c0SNV2I\\L1`11aNo0NUO2N05d0l1j0kM_N5i32eMa1eNaN5J2S2Y1oMU23hMk0`N]O3J4K1Q2[1PNT22[LH[1R1cN^O3J4MNQ2]1oM[2JULO_1a0bNGM00N344OKP2`1PNS45_JJMN4LN83^2Z1eM_2DRL2Y1:kNKMM;MC33f2^1bM]2J]M5kNKLN4KO9Nb2U1VMnN`0e3F`MIeN97MKO4KN:0b2Q1WMoNe0d3[OhM5dN0MN4KO9Oc2P1ZNb2jN\\L5Y1g0hNXO150f2l0\\MTO<e3@bMd0fNZO340h2i0[MXO=b3]OiM`0aN_O340i2h0ZM[O<c3ZOjM?^ND240j2>_MG<W5@cJF15OQ3OgL0e03ZOMQ1\\2oNc01QM3>5BP43fKN2Nm0W2ROkM000O1l22aM5DQ46gKJm0U2WOlM2j2LZMMN9MQ47fKJn0]2YO>KWM1O6NQ47fKNj0W2_O`0IWM1N7OP47fKOi0U2Aj0JjL9Om3e0]Lh1Cj0JiLf4e0mKb0ZOL0nN1[30eLh4d0nKa5Q4_JQL]OAd5]4nJcLl1PO9\\4kMeLk1PO;X4kMkLg1QO<R4nMPMa1POb0^OXM]4f0VM^1ROd0h3nMWM4]N;e0f1c3jM_M2YN?d0f1c3iMaM\\1kNo0a3bMkMb1bNh0a3eMRNc1\\Ni0^3dMVNc1]Nk0Z3fMVNZOnMR2b0o0Y3eM[N]1aNi0Q3jMbN[1[Nm0R3gMdN[1[NQ1m2dMkN[1YNn0l2gMjN\\1]Nl0h2eMPO^1[NZOWOO]3XOSO`1\\NRO[O68UOe13?`1YNoN\\O;OXOn1]OgM>g2e1XNlN]O\\1P2RN<g1XNjNZO]1S2lMd0k1RNkNSOSOMV2Z2mMi0R2kMjN[OS1P2QNk0U2hMiNYOQ1T2RNPNL^2V2VNjNXO?JPO[2Dl0T2hMjNROR1[2oMk0X2jMj0[1nLl0OkLU2k0k0_1RMj0MnLV2i0j0`1SMQ1U2_Mf0a1SMQ1Y2aM?S5DkJ;T5HkJ7d4YMcJd1J^OQ1b1a1\\M;2RMi11VNOP1P1b1b4h0YKZOe4[NgJNM6a0b1k4nMaJD=`0G<>c1g4YMjJd0MD>`0H::f1i4XMjJn0=KD<9c1R5QNWK6\\O29h1T5PN[K2\\O52i1X5PNZK2UOUO5P11k1[5oM\\K1XOW3\\5hL]K1VOW3]5gLcK2SOo2Y5QMfKMROQ3X5SMfKMPOP3Z5mLaJ\\OZ1e0kNP3Z5lLVLP4j3cKcJOg1g0YNe2\\5gLcJNh1f0YNd2\\5hLcJNi1e0[Nb2[5iLaJ0m1e0RNc2k5fLWLU4k3hKVJ2i1T4Q4lKSJ1o1P4Z3lKXK9a1i3W3oKWK2AOT2m3T3SLVKOP2l3i2WLlMf3T2[LlMd3T2\\LmMc3S2\\LTK1Y2`3d2]LTK4CKb2a3h2aLRK8W2U3f2eLRK5Y2V3e2eLUKNZ2]3a2eLSN[3m1dLSN]3m1dLQN]3o1dLoM]3Q2aLQN_3o1`LfK0V1a3U3^LbK6W1\\3V3_LbK9U1X3Y3_LbK9T1Y3Z3]LdK6U1]3\\4^LeKc3d60hMZLeKh3U3XLhK1S1g3X4[LgKe3j3cLSJKQ2c3W3WLWK=ALm1a3Z3WLWK<CLl1a3P4^LXJJl1h3_3WL_Mi3`2YL_Mg3^2WLcJ3n2f3_2WLcJ3m2g3d2XLmJMo1k3c3[L[Le3\\3ULYJ315Y2c3X3ULcJ?T2\\3Y3ULdJ>R2^3c3XLWJ6Q2a3j3WLVJ;m1^3l3ZLUJ8o1]3m3WLSJ20:P2]3m3WLSJ20:P2]3m3YLVJ<j1]3P4VLVJ>i1\\3P4XLVJ;k1]3o3YLUJ:l1]3o3XLVJ;k1^3o3ULWJ<k1_3R4SLQJ>m1_3Q4ULQJ<n1_3m3TLVJ1O;o1`3l3dLXL\\3g3aLVJDd0Oi0k3]4fL]JBM1X1g3V4VLbJ?M9W1R3Z4ULcJ]1T1]2`4dM`K\\2`4dM`K\\2]4VL[J\\1Y1^2\\4VL[J[1Z1_2[4VLZJ70i0^1i2l3VLmJ2J43N54^1a3_3]LoJM0ON282]1c3]3^LoJM0MN69O]1c3]3^LoJL6321[1b3_3\\LQL2b0a3b3XLlK7b0`3l4`LTK`3l4aLTK^3l4bLTK^3o4^LSK`3o4^LZI3NLZ1b3_5^LZI4NKY1d3g5aL]J_3d5^L_Jb3W700000000HXGhLh8W3ZGhLf8Z3WGgLi8a30O0O1000011N1O001O0000fMaLcK_3]4aLdK^3g601O1N2O00001N101N2O1O1N1O101O1O1N2O1N1O10dF"}}, "object_label": "motorcycle", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness, transparency", "answer": "The image features a motorcycle parked in a driveway, with a dog standing next to it. The motorcycle is an old-fashioned, vintage model, and it appears to be a three-wheeled motorcycle. The dog is positioned close to the motorcycle, possibly curious about the vehicle or simply enjoying the company of its owner.\n\nIn the background, there are two cars parked, one on the left side and the other on the right side of the driveway. Additionally, there are two bicycles, one located near the center of the scene and the other towards the right side. A bottle can also be seen on the left side of the scene, possibly belonging to the motorcycle owner or someone else in the vicinity."}, {"question_id": 708, "height": 400, "width": 600, "image": "000000007386.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, pattern, pose, size, state, texture", "region_anno": {"bbox": [180.91, 281.14, 38.4, 45.48], "segmentation": {"size": [400, 600], "counts": "XcV273Kk;b0K4N100000ZOZDb0e;1\\D[Oe;b05101O4L4aDUOQ;V1O0000000O100000KjDoNW;l0oDROQ;o0800O1O11O6I2O1O10O003L2H8FjZe4"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:tan", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, texture, color, size, cleanliness, pattern, pose", "answer": "The image features a small white dog standing on a snowy ground, possibly in a park. The dog appears to be looking at something, possibly a toy or a treat, as it is holding it in its mouth. The dog is positioned in the foreground, and the snowy ground extends behind it. The scene captures the dog's playful and curious nature as it interacts with its surroundings."}, {"question_id": 709, "height": 640, "width": 480, "image": "000000138241.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 2.01, 480.0, 637.25], "segmentation": {"size": [640, 480], "counts": "31nc02W\\O1]c0<V_Ol3\\7eKSH`0?m3^MiKMKU54nJO1<0B110O02O01ML013b0f0_O631a2Z3\\MgKM10Nj5OdL1XNk0\\O9NKi2Y3Q7[L_F1GA5g0d2[3T7[L^F_OF01N65Mg0f2Z3R7_L]F^OF00O2N073d0f2Z3S7bLVFZOM2O50J164a0h2[3Q7cLYF6NKj2[3XMmK_9f0aF8MIm2Y3XMPL]9f0aF9LGo2Z3VMRL[9h0bF7LDR3Z3PMSLO0a9i0`Fo0Q3S2WMTLX9k0`Fl0S3T2UMTL\\9j0_Fj0P3X2UMTL^9`0XFE5:J010X3[3RMWL]9`0YFH16N01OY3\\3QMWL]9`0YFI040EO00c0[3R3P7fLeEK53KL0O14[3]3P7oLlEMHC31[3^3P7PMjENHC4O[3_3o6TMhE4NYO[3^3P7WMeE3MSOO2b3`3n6XMcE3NXOb3\\3o6XM`E4NYOc3Z3dL_LT:j0fE:f3\\2`L`LT:j0fE90nNc3^3dLbLQ:o1iEQNc3\\3dLcLS:n0dE11ROe3Z3dLeLU:i0eE4NSOd3Z3W7^MZE2c3`2S7_MWE3f3^2PMfLV9k0RF2i3[2S7cNmH]1U7eMPEOi3[2Z7cMoD3e3Y2\\7fMnD1g3X2Z7hMnD1h3V2_7eMjD4h3V2`7cMiD7g3U2b7cMhD7f3V2a7eN`HY1`7hN`HX1]LPMk:g1hHY1]LPMl:k0mDNk3U2]LRMl:i0nDOi3V2\\LSMm:i0mDNk3T2\\LUMl:i0mDNk3S2]LVMl:h0mDNj3S2i7lM`DNg3V2j7kM`DNg3V2h7mMaDMg3U2h7PN_DLi3T2i7PN]DLk3R2i7SN\\DJk3S2j7SNZDJl3R2k7TNYDJl3Q2l7VNWDIn3P2l7VNWDIm3P2P8TNTDKl3Q2Q8TNSDJm3P2Q8XNoCIP4o1P8YNPDHP4o1Q8kNoGU1WL`Ma;i0YDFo3Q2WL`Ma;i0ZDEn3Q2XLaM`;i0ZDEo3P2WLbMa;i0XDEP4o1XLcMa;g0XDGo3n1V8ZNlCGn3n1X8ZNkCGm3o1X8[NjCFn3n1X8_NhCCQ4m1X8nNhGS1X8lNhGT1X8`NgC_OR4o1X8bNfC_OR4o1X8aNgC@Q4n1Z8aNeCAQ4n1]8^NbCDQ4n1]8^NcCCP4n1^8_NaCDQ4m1^8`N_CDT4j1^8nNbGR1_8mNaGR1`8gN\\C[OT4n1`8gN\\C[OT4n1`8nN`GR1a8eN]C\\OR4n1c8ZNYCL4KP4o1d8YNXCM4KQ4n1b8[NYCL4KQ4m1c8\\NXCM3JR4m1d8[NWCN3JR4m1f8YNVCO2KR4m1f8XNWC11IR4n1f8XNWC12HR4n1e8YNWC12HR4m1f8[NTC1]4c1`8\\NSC2\\4a1b8jN^GV1b8jN^GV1b8jN^GV1b8kN]GU1c8]NRC3[4`1f8ZNoB7Z4^1g8lNXGS1i8mNWGS1j8lNVGT1k8kNUGT1l8lNTGT1l8lNUGR1l8nNTGR1l8nNTGR1m8nNRGQ1o8oNQGQ1o8POPGP1P9QOoFo0R9POnFP1oKZNl<e0UGQ1oKZNl<e0VGo0S9QOmFo0S9QOmFo0T9POlFP1U9oNkFQ1V9nNjFR1V9nNjFR1V9nNjFQ1W9oNiFQ1W9oNiFQ1X9nNhFQ1Y9oNgFP1Z9POfFP1Z9POgFo0Z9POfFP1\\9nNdFQ1\\9POdFP1\\9POdFP1^9nNbFR1_9mNaFS1a9kN_FU1`9lN`FS1`9nN`FR1a9mN_FS1c9kN]FU1c9kN]FU1c9kN]FT1c9mN]FS1c9mN]FS1d9lN\\FT1d9jN^FU1c9iN_FW1`9jN`FV1a9iN_FV1c9mNYFS1g9mNYFS1g9iN]FV1c9kN]FU1d9iN]FW1d9hN\\FX1e9gN[FY1d9hN\\FX1c9jN\\FV1d9jN\\FV1d9jN\\FV1d9lNZFT1f9iN]FV1d9jN\\FV1d9jN\\FV1e9iN[FW1f9hNZFX1e9iN[FW1d9jN\\FV1d9jN[FW1e9gN]FY1U>00OaKgNYFY1g9gNYFY1g9hNXFX1g9iNYFW1g9iNYFW1e9kN[FU1f9jNZFV1h9iNWFW1j9iNUFV1k9iNWFW1h9jNWFW1h9jNXFV1g9kNYFU1f9mNYFS1g9mNYFR1h9nNXFR1i9mNnAKU4Y1m9kNlANV4X1n9nNRFQ1n9PORFP1n9nNTFR1l9mNUFS1j9mNWFS1i9mNoAJT4X1n9nNVFR1j9nNVFR1j9nNmAKU4W1n9RORFn0o9QOQFo0o9lNmAMT4W1Q:jNSFW1l9jNTFV1l9kNSFU1l9nNRFR1m9QOQFo0o9QOQFo0o9QOPFP1Q:oNoEQ1R:nNnER1R:nNnER1R:lNPFT1o9mNQFS1n9nNRFR1n9oNQFQ1o9lNSFU1m9kNSFU1m9kNlALS4Y1R:nNnER1R:nNnER1Q:oNoEQ1Q:oNnER1R:nNnER1Q:oNoEQ1Q:oNnER1R:nNnER1R:nNnER1R:nNnER1Q:oNoEQ1Q:oNoEQ1R:nNnER1R:nNnER1R:nNmES1S:mNmES1S:mNmES1R:nNnER1R:nNnER1R:nNmES1R:nNnER1R:nNnER1R:nNnER1S:mNmES1S:mNlET1S:mNmES1S:kNoEV1P:jNoEW1Q:iNoEW1Q:kNmEU1S:kNlEV1T:jNlEV1T:jNlEU1U:gNoEY1P:hNPFX1P:jNmEW1S:kNkEU1U:kNkEU1U:kNkEV1T:jNkEW1T:jNlEV1T:jNlEV1T:jNlEV1T:jNkEW1T:jNlEV1T:jNlEV1S:kNlEV1T:jNlEV1T:jNlEW1S:iNlEX1V:fNjEZ1V:fNjEZ1V:fNjEZ1S:hNnEX1R:iNlEW1W:gNhEZ1X:fNhE[1V:fNjEZ1V:eNkE[1U:dNkE]1W:aNiE_1Q:UN]B;a3a1R:SN^B;a3b1W:_NiEb1P:RN^B<a3c1P:SN]B<b3a1P:fNPFZ1P:eNPF]1o9bNRF^1m9cNRF^1n9RN_B9c3e1n9RN`B8b3f1n9SN^B7d3g1n9`NRF`1n9`NRF`1m9SN_B6c3h1dLlMo<8jB3d3j1bLkMP=e0]Fa1cLjMP=d0^Fb1j9^NUFc1j9^NVFb1j9RNcB0d3n1i9]NWFc1i9\\NWFe1i9[NWFf1h9[NVFf1cLfMP=d0]Fg1bLeMP=d0_Fg1f9ZNYFg1g9XNYFi1f9XNZFi1c9fMkB=5BR3\\2n9XNQC[OQ3]2n9XNQC[OQ3^2m9VNSC\\Oo2_2n9mMlBG9Ll2a2o9lMlBF5MU3b2i9PNRC_ONNR3c2n9PNQC@NNR3c2n9PNRC_ONNQ3d2o9oMYC]Oh2d2n9oM[C]Of2e2o9nM[C]Of2e2P:lM[C_Oe2f2n9lM]C^Od2g2n9kMbFW2[9jMfFV2Z9jM^C\\Ok2l2f9hM\\C@l2i2h9gM[C\\OK2R3k2h9gMXC^OU3m2a9fMYC^OV3l2a9eMZC_OT3m2a9dM]C^ONNo2P3f9dM]C^ONNn2Q3VMoLX<e0eC]OQ3Q3QMmLX<f0fC]Oo2Q3SMlLX<e0gC^OMNl2S3XMlLW<f0hCCKIh2S3^MkLV<g0hCCLHh2S3^MkLV<f0hCEg2l2g9_MbCALLj2U3[MhLV<f0iCFMEe2W3_MhLV<e0iCGNEc2Y3_MfLW<e0jCBKK2Ob2[3^MfLW<c0QD]OMO\\2]3^MdLU<e0VDYOL1Z2^3_McLU<e0QDYOK200N0a2_3_MaLV<d0PD^OJN15_2[3`M`LV<d0PDBLL_2_3_M^LW<e0RD_O_2b3^9PMTD]O^2c3^9oLSD@IJa2V1WNa0[;nNTDBHK`2R1aN>S;SOUD\\OG11O^2o0mN<h:YOZD[OV2n0oN:_:_O\\DYOU2m0SO:[:@RDZO0OO1O0[2j0A8S:DTD\\OLO0000[2i0E:l9BXD]OKO0O20W2g0O9kMnNd;h0]D\\ONNN04ON1o1g0;6gMQOc;h0]D^O2L0OM2m1f0`04dMSOc;g0^D@MKO02012j1c0f06^MTOe;e0`D@JM0O1033g1b0k04[MWOd;d0bD^OKMO11O26d1?S12VMZOd;c0eD]OMNL029_1=[10RM\\Oa;e0jDYOL029Y1=^1OPM]Oa;d0jD[OK1KN3;Z1<e1LmL_Oa;d0eDAKKN02N3=W1:j1KkL@a;d0dDBLIO2ON5=T19R2MS85jD^ONOO9Q19W2EcLG2LW;j0iDXO055NN=m07\\2CbLH1MX;h0jDD4HN?h07d2_O_LK0MX;f0lDEME124d0>6P3B\\LBX;e0mD\\OL41JO27j043[3^OYLDW;f0nDZONON1512P1H2j3[O[7:QEWO11O12V2d3WNX78SE[OJ0OO2N036U2f3RNRLI1Mo:h0WEFKDN17U2i3VNPLCP;f0WEHKG7P2j3YNl69WE_OJ02O7o1m3YNd6=\\E\\OLO1N7Q2n3WNb6?[E^OKN2L:Q2o3VN_6IVEb06NJ@;R2R4TN]6JVEa07EIN1K9S2V4TNX6a0eEXOEOO11O71Ho1`4WNW6a0gEWOD0O20O71Hn1b4WNT6b0dEXOF100001O71Hn1b4WN]KJb:i0cEWOM=ND1O8T2]4PNZKLb:h0dEYOK7O29i1`4oMWKOb:e0dE\\OL4028KFj1j4XNh50^E94GNO138LEi1m4WNe5a0eEAI1118m1e4oMc5a0hEJGD0O:R2g4nMa5b0hE@FN10000O:S2\\?_Ne@_OFOO16N3T2X?nM`@`0<_ODO10500V2n4kMR5f0SFYOG2O000?T2g4lMlJNn9h0YFZOG50K1O8U2o4kMl4h0UFDFE2O7U2X?dNc@VO07M01I8V2V?QN`@;3@05N01I8V2V?dNd@NNXO7V2W?dNf@N5_1e5iM^3h0kFJGA;T2e5iM]3h0mFZOHOO10001;R2e5kMZ3i0PGYOGN020OO2<Q2d5lMY3j0mFWOJ10001O00O<S2f5kMiJ1a7h0kGYOJ1OO1:7DIV2Q6jMjJ0^7j0nG^OHK089m1S?cNl@\\OI00N;P2Q?eNl@]OH00M7MIU2]6jM_2i0\\G@G48n1g5eM^J1_8g0^GOOc1V6gM^2e0`GACK158S2V6gM^2c0fG^O_OOO2OO84Hl1_6PN^2a0hG^O]OO02O065Ik1U6oMRJ1e8a0iG_O]OOO56U2n5hMRJNc8d0cG_OENO0045e0Jd0V6cNQJOc8c0cGAFLO0O36f0Ke0U6aNQJ0K1d8`0gG_O06Hf0Lb0`6bNaI2c8?fGA22Ih0Lb0_6bNbI2a8>iGBDN630j0K`0`6cNcI3U8MiG?8AF20OO1017j0L`0_6cNdI2T8NhG`0>AAO02O08l0J>]6dNaI160U80fG=a0BD2KO6o0J<^6iNgIKU8<dGGe0MC1J05Q1J:_6iNgIKT8a0[H_O]O001N15P1L9_6jNfILS8`0WH_OB1O0044m0M9_6iNeILT8`0WH@A1O0O46l0M:_6hNV26PHGZO84h0O;^6gNhINP88SHHI0L72e0KTO7Z1^6fNP20]G6=KG1K45e06?Q?gNc@6?KBOO1019i03=Q?iNd@2a0M_OO02O19i03=Q?iN]AN\\O2KO8g0F[O8NJW1Z?mNhAMnNO8g0F[O8NJW1P7hNP11oG6`0IG0K001N16m079Z6hN]I3m78ZHFE11N11O0055i0OROOV1k6lNR18ZHGD02N1001N56j077c6jNU16XHNIK051f02UOMW1T?mNVA0FLO53f0:<`6iNR14\\HL_O32NO11OO19j06=d6hNo03^HM@11OO11O0O7n06<e6fNd00bH29O^O11OO11O:n03;_>gNVB1nNN020O:j0DYO<V1b>hNWBNSO1J0:;D10H9W1k6eN?0^H11Ne00\\O1N11N11N1:j0FWO8Z1j6fNoHNV7OjH<c0F\\O001OO2OO1:j0FUO9]1i6eN?7TIH[O1OO1001ON8o06>e6dNb04SIK[O5OKO2:n059d6hNRINW75\\ILZO5O19j059d6iNSIMT74_INXOOO110N0;m05QOAY1T7kNPINU72\\IM[O11OO2O0<o03;R7dNBOTI1d01WOOO11O;Q11<S7bNYO0]I3m0MoN1N11O>n0N?o=bNjA3c0M^O0K1N11O:OG7M?:j0T7dN[ONYIOO1j0N]O0K1N11N:2El0:c0Q7fN\\OKYI1n0MYO0J2O10M86Ga00]O;^1Q7eN_IIP53UJOk0NXO050K1N3:2Ee0=g0o6eN_IIP56lJJ\\O1OO60K88NEc0?i0m6eNkHIW65ZJL[O0N07OK780Eb0?i0m6fNjHHX64WJL]O20OO16OJ2;MER1<oNCa1\\7gNiHGX64YJM[O11OO11N079n02b0P7`NdHI20\\61XJ0ZO11OO11OO6:n01c0T7[NgHMn52mINe00\\O1N11OO11OO5;LE6O>=Q1[7YNYH1k5O[J3JMa01_O100001OO11OO5;LE001Oc09[OHe1a7[NaH4i5KWJ1N1e0O[O2OO101OO101O0?0A00?0C:f1X7WN`H3j5LUJ2h0OYO4OL000:<DD8O93A6k1Z7TN_H4o5KZK0hN001N1d00]OOO2O9b0_1\\`0WNX_OOc06WO02n0n`0kNS@2SO1OR1Qb0lNP^O11Q1hV1"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pattern, pose", "answer": "The dining table in the image is set with two plates of food, each containing a delicious-looking taco. The tacos are topped with meat, cheese, and various vegetables, making them visually appealing and appetizing. The table is also adorned with a white tablecloth, adding a touch of elegance to the presentation. The overall scene suggests a pleasant dining experience with a focus on enjoying the flavors and textures of the tacos."}, {"question_id": 710, "height": 480, "width": 640, "image": "000000236721.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [162.6, 125.29, 64.98, 62.35], "segmentation": {"size": [480, 640], "counts": "bP]2=a>4L4L5L4K4MAWBKf=4^BKa=4aBL]=4fBLW=5jBKT=6lBKR=6PCIo<6RCKl<6UCIj<8WCHh<8XCHh<7ZCIe<7[CId<7^CIa<7_CIa<6aCJ]<6dCJ\\<5eCK[<5eCK[<4fCMY<2hCNX<2iCMW<2jCNV<1kCOU<OmC1S<LPD4P<LoC5Q<KoC5Q<KoC5Q<KoC5Q<KoC5Q<KoC5R<JmC6T<JlC6T<KkC5V<JiC6X<JgC7Z<IeC6\\<JaCJUO<[=J_C8b<J]C4e<KZC6f<KXC5j<KTC6m<JQC6Q=KlB5U=MgB4[=M_B5d=KWB8k==3L3M6H9AdkR6"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pattern, texture", "answer": "The cup in the image is filled with a red substance, which appears to be a sauce or a soup. The cup is placed on a dining table, and it is positioned next to a bowl of white sauce. The table also has a few other bowls, one of which is filled with a red substance, and the other is filled with white sauce. The arrangement of the bowls and cups suggests that they are part of a meal or a dining setup."}, {"question_id": 711, "height": 640, "width": 541, "image": "000000366225.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [50.85, 249.75, 44.91, 72.94], "segmentation": {"size": [640, 541], "counts": "mSP1`0_c0<h\\ODUb0e1_O1O0000001O00000000000000000000000001O0000000000001O3Ma0_O=C>B7I2N2N1O1O1O001N101O0OU^f8"}}, "object_label": "cell phone", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:off", "texture:smooth/sleek"], "control_dims": "cleanliness, size, transparency, pose, state, color, texture, material, pattern", "answer": "The image features a cell phone sitting on top of a white surface, possibly a table or a charging dock. The cell phone is turned on and appears to be charging, as it is connected to a power source. The screen of the phone is visible, displaying information or content. The overall scene suggests that the cell phone is being used or charged in a comfortable and organized setting."}, {"question_id": 712, "height": 427, "width": 640, "image": "000000388846.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [234.89, 272.89, 49.88, 59.91], "segmentation": {"size": [427, 640], "counts": "USS31Z=000dj04WUO101O1O1O00001O1N20O000001N100ODUC8m<HTC8k<GVC;h<EYC;f<EZC;k<00100O1UCCf<b001N01N2O1O0O101O001O001N2N102Kibd4"}}, "object_label": "umbrella", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:tiled", "pose:horizontal/lying", "size:big/large/giant/huge", "state:open", "texture:smooth/sleek"], "control_dims": "pose, state, material, texture, pattern", "answer": "The umbrella in the image is a large, white, and red striped beach umbrella. It is set up on the sandy beach, providing shade and protection from the sun for the people sitting underneath it."}, {"question_id": 713, "height": 479, "width": 640, "image": "000000515077.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [99.94, 297.3, 73.42, 110.38], "segmentation": {"size": [479, 640], "counts": "[R_13j>:eBFRO>];4VEB[Od0V;L[EB_Oc0T;L\\EBAa0S;M[E_OM<i:7XE\\OW<V1VCiNl<e10001O=nBkM_<j0dCl0o;lNcDj0];VOgDf0Y;_OdD_O\\<a0dC^O]<c0bC\\O_<d0aC\\O_<e0`C[O`<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZOa<f0_CZO`<g0`CYO`<g0`CYO`<g0`CYO`<g0`CYO`<g0`CXOa<h0^CYOb<g0^CYOb<g0^CYOb<g0^CYOb<g0_CXOa<h0_CXOa<h0^CYOb<g0^CYOb<f0_CZOa<f0^C[Ob<e0^C[Ob<e0^C[Ob<e0^C[Ob<e0^C[Ob<e0]C\\Oc<c0^C]Ob<b0_C^Oa<5mBHNLe00[O5T=d0`C_O`<b0UCUOK<Q=\\1000001O1OoNVCNj<0ZCOd<1`C<o;CVDc0b;ZO`Df0m;jNUD0WOQ1a=?C<FTNWC24Z1^=J<Dd0[OSRj6"}}, "object_label": "chair", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "cleanliness, color, pose, state, texture, transparency, size, material", "answer": "The image features a wooden chair with a red seat and back, placed in a room. The chair is positioned near a table, and there is a person standing next to it. The chair has a sticker on the back, adding a unique touch to its appearance."}, {"question_id": 714, "height": 605, "width": 640, "image": "000000050811.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [524.71, 316.61, 70.65, 276.21], "segmentation": {"size": [605, 640], "counts": "Ujg9g0oa0S2kMd0B`0\\O=G5L4L3M3L3N2N3K5fNY1^Ob0A`0VO`HaET8^:6O101O000O1000000000000000000000000O1001O0000000000001O009fG\\Ei7W;E7I5K=Cc0]Od0\\O:F4L3M2N2N2N1O2M3N1O2N3L4M7Ho0QOg0WMU@Q1^a0[Ohkh0"}}, "object_label": "bottle", "attribute_label": ["color:white", "length:short", "material:glass", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "size:small/little/tiny", "state:open", "texture:smooth/sleek"], "control_dims": "color, pattern", "answer": "The image features a bottle of beer, specifically Corona, sitting on a wooden table. The bottle is almost empty, with only a small amount of beer left in it. The bottle is positioned in the center of the table, and it appears to be the main focus of the scene."}, {"question_id": 715, "height": 605, "width": 640, "image": "000000050811.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [448.06, 332.8, 19.8, 110.97], "segmentation": {"size": [605, 640], "counts": "mRY8=\\b09I3X^OXOWa0j0i^OVOTa0n0:3L2D<M3CdNX_O_1e`0=CoMh_OZ2Q`0;2O1M2N3[Oe0SOm0FglU3"}}, "object_label": "bottle", "attribute_label": ["color:brown", "color:yellow", "length:short", "material:glass", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "size:small/little/tiny", "state:open", "texture:smooth/sleek"], "control_dims": "size, transparency, texture, pose, material", "answer": "The image features a bottle with a long neck, which is prominently displayed in the foreground. The bottle appears to be made of glass, and it is positioned in a way that it is almost filling the entire frame. The bottle's neck is curved, giving it a distinctive shape."}, {"question_id": 716, "height": 375, "width": 500, "image": "000000139077.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [280.09, 0.0, 155.87, 155.83], "segmentation": {"size": [375, 500], "counts": "X[W3>:J\\9[1_FgN`8Y2`GhMo7h2RHXMl7i2THWMl7i2THXMk7h2UHXMk7h2UHXMk7h2UHXMk7h2UHXMk7h2UHYMj7g2WHXMi7h2WHXMi7h2WHYMh7h2WHXMi7i2VHWMj7i2VHWMj7j2THXMk7h2VHWMj7i2VHWMj7n1TH^N1Dk78SHk11oMk7FTH81W10UO1Ej7FTH92F1X1O^O1Di76THC1V11]O0Fi7l1UH_N1Fj7g2VHYMj7;UH31WO0l00@i7Z1WHZN08O51Oi74VH@10O1000O2OO9Oi0j7>VH`N3N0o01]Of7U1XH_N3ONP12]Od7[1[HZNLQ14ZOe7Z1[HBOUOf7T1`HHKROe7>WHC4C65Fm05YOd7`0XHYOO03M46Jk04ZOc78XH@100O1O1NM81IOm05^Oc77YHA0O1O10O:Of04ZOc76ZHDOJ:3F90f03\\Oc7k0\\H[OM>4\\Oc7m0YHRO0n02dNN>g76ZH@2N0Q22[Na7M\\HI1N9P2I\\Na7N[HH2N8R2I[Na7M\\HH2M9S2H[Na7F[H01Nb0j0]OXO10Oa02Kc7D[H6c0a0^OXO11N50028b71_HB4P1J>c7PO_HB5o0H`0d7gN]HIi0b0VO_O10O10n0d7WO_HGh0b0VO@11O0OP1c7VO`HFj0c0SO@21N10o0c7oN^H02Lk0S1ROSO0o0c7oN_HOj0MYOS1KRO1M1n0`7TO`HO;MH1MOO04Z1LhN2m0_7VO^H10L5O0O9[1BgN3m0_7VO^H10L50ON:Z1ChN2n0^7[OcHF10008g0H@OIOo0^7[ObHG:O0`0F_O66KKOo0^7UO_HN4N1O109a0OEFKNQ1^7QOcH00O1N209a0OEFKO5Nb0_7[OdHO0O2OO18`00FGJ03NO0>^7BcH1ON20008`0I^O17NJ03NO1>\\7AeH:MI0O9?I@24OJ04MN2>\\7BcH3NN21OO91L1LM53MK04Md0^7[OaH14M00MNO39126LLMK05L207_7EbH02N11N17061JOLMO>M0^7DdHO1O11N1715LB193KMO9LI1<^7DdHN2O11O0629NE5JK1>M0^7D\\INA180D4KL0>MO_7DeHM1011O0629OD4KL0P1[7QOeHN2000K011929OE4JK1?MN^7DeHN:00OE68NI1MK280K0;12Z7CeI2nN41O2;OAO:31Y7DeI2oN?1O0AO:31Y7DfHN:OO6E>2NNC0931Y7FcH02M1102M11V1OjN0841Y7NcHI0;1@0[1OjN0824Z7f0eHiN0S2O`N\\7d0eHiN0?4c1W7PNjH9J31B0a02A02MN0M150P1Z7mNmH5N:K31\\O40O101Na0MM[7BnH4M8JB2d00\\O40O101NS1X7mNnH0GO7<JC15N90C500001NS1T8nNiG36OJ1000N2NNN2130O1Lo0W8ROiG36NL0O90EOO11ON2130Lo0V8[OlGEM60d00WO11OO0140Mo0U8[OkGEO50d00WO050L41Mn0T8\\OkGC238b0F@2L22Ol0h7QO^H>ID:b0DA2L22Ol0T8^OkGE9c0EA0L41Om0T8]OiGH1O11O8OI0L400n0`7SOjHi0DXOO10O10OO2O19N6b7BjHn0BPO140MON25NO2M39N7a7EfHo0GXOOF0N050K5P1^7VO_HKOU10SOOF16OO1L4P1T7oNoHo0IUO46LK0M32MO:<F0W7CjHN1n0>XO@N1N22MO:;G1b7>PI]O^OH22MO3M1>N0a7?QI]O\\OKO01O2L2;14R7AlH01a00A1NO12h0I\\O2K4916W7BeHa02@01MO5g0I\\O2L3915X7BbHd05^ON2MN7n0IQO5815^73aHAM94d0KRO4905f7KYHGOb0M30\\O4N1:14i7HUHJ0c0L^O2?NC2N3914k7GPHK6e0MJLE1M4915k7DTHMOe0O2NZO4OK768k7CTH0N:1c0NQO3OL849l7BTH0N92d0LRO4:M7o7@SH1O:0b0NRO3;M7P8JQHS12`N1;L9n7Z1QHSN5N4:GF3`0l72QHi00hN4N1OL:OG2?n70RHa0N\\O2E3NL=14n7OQHX12XNN>03o7j1SHeMN?01o70QHX12XNNR1o7^OQH1Oe01lN0P1m7@SH\\10SOm7BSHZ11`NO3m71VH[1NbNN3m70WH[1McNO2m7OWHO55KEN305j7DTH35853LCM6N6k7BWH2MK0a092NALl0i7SOVHj00SO3b02BLm0g7SOVHk02RO2P1O\\ON2i7DWHl01RO3o0N]OO1g7FYHi01TO2o0N]O01e7E[Hk0OSO2P1O\\O01d7F[HS1OJ4\\OL2e7CZHN1\\25eN_7QO[HN2[24TNJ0d7D\\H^26lMK2a7NbHi11WNL2`7NeHOLY12hNN1_7OeHOL\\1OeN11^70eH0K\\10dN1M`7O`HIOn2b7nLhH;JU23bMb72aH:Km1P8hMUHd2U8\\MbG20]2d8aM\\G11o1R9oMPGO3g1T9ZNiF03U1e9kNWF04n0l9ROPF13d0W:YOgE3MM1`0a:Oc002IS^g0"}}, "object_label": "tv", "attribute_label": ["color:black", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "color, transparency, state, texture, length, size, pose, material, pattern", "answer": "The television in the image is a flat screen TV, likely a modern model, placed on a wooden stand. It is turned on and displaying a video game, specifically featuring a character named Mario. The TV is positioned in a corner of the room, and the game appears to be engaging and entertaining."}, {"question_id": 717, "height": 426, "width": 640, "image": "000000142620.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [158.31, 104.1, 187.1, 165.03], "segmentation": {"size": [426, 640], "counts": "_mQ24U=2N0O200N200O2O0100OLGVC;h<7Mg0YO6J1N10O1O1000O2O0000iNkD8U;HW1O1O10O10O10000O10O1000O10[DHW:9]10O1[DFZ:9fEJjNOU;9QFHjN:0Ce:4XE0Z1OiNc0a:^O^ENX14gN?c:DhFKgNa0_:DlFIfNc0^:DlFIfNc0^:DkFIhNc0]:ClFJfNd0\\:DnFHfNd0\\:DPGFcNg0\\:CVG>i8CTG`0h7d0WH]OT7j1YHWNc7X2RHiMl7X2THhMl7X2SHiMm7V2THjMl7V2THjMl7V2UHiMl7U2VHjMj7U2WHlMi7R2WHoMi7Q2WHoMi7Q2WHSM[Oe0^8X2XHQM\\Of0\\8Y2XHPM]Og0[8Z2^HfMb7Z2^HfMb7Z2^HfMb7[2]HeMc7[2]HeMc7[2]HeMc7Z2^HfMb7Z2WHQM\\Oe0]8d1eGfMK;g0F]Od0\\8[2WHQM]Od0\\8\\2VHPM^Od0\\8\\2VHPM^Od0\\8\\2]HeMd7Z2ZHhMf7X2ZHhMf7X2WHPMYOg0`8Y2UHRM[Oe0_8Y2WHQM[Of0^8OdG]ONMOP10oN2?c0D]Od0]80dG^OMK1Q15]O?E]Od0]81cGANj05ZOb0EZOe0^8Z2^HfMb7Z2]HgMc7Y2]HgMc7Y2]HgMc7Y2XHQMYOf0_8Y2WHRMZOe0_8Y2WHPM\\Og0]8Y2WHPM[Oh0^8=gGSOI1?28D\\Oi0]8FeILfN?e70`G\\O0L7c09F<>d7X2\\HUMUO:_8a2\\HPMTO21>^8a2ZHQMXOOO`0_8`2YHRMYOb0^8\\2YHRMYOb0^8\\2YHRMYOb0^8\\2XHSMYOb0_8[2XHlMh7T2YHkMg7U2YHkMg7U2]HTMTO<^8`2^HTMTO<^8`2^HhMb7X2_HgMa7Y2[HnL\\Of0Y8\\2ZHoL]Oe0Y8\\2XHPM@d0X8\\2XHQMB`0V8_2XHQMB`0V8_2fH`MZ7d0iGIM_OP14Z7LmGBg09ZO3h07Y7KcGC71>h0ACm06[7OdGEON6_1k0PO\\7^2eHaM[7_2eHbMZ7^2gHaMY7_2gHaMY7_2gHaMY7_2gH`MZ7`2fH_M[7b2dH]M]7b0SHnN:=63]7OcGCk1;TO4^7OaGDl19UO2`7m1^GhM1:R1O`7f2_H[Ma7e2_HZMb7f2^HZMb7f2^HZMb7f2^HYMc7g2^HVMd7j2\\HVMd7W2^GkMo0Md7g1oG[N=Nd7:ZG@4N76c054Le7:SH@UO0n0<5Je7;YGA0P1>]Od0Ge7k2[HTMf7l2YHUMg7m2UHUMk7U40000000gMXG0h8lNWGYO0Hd0R2U8ZNZGKLHX1R2c7[N`GBR1S2^7[NXG1MHl0l1P81VG0j8R1cG_M]8^2THRMn7l2Y1ElE`MT:^2mEdMR:\\2nEdMl0HT8c2QGeMQ:n0bF]O]OEQ:i0lEoNg0b0^OEo9;kEJ1Df0c0@Cn93jEN150Ef0c0BAm9Z1mEgNO>3Fo9[2nEfMQ:j2N2O11O00eFkL_O5d8P3jG\\MW8b2iG^MY8]2PHQMP9OVak3"}}, "object_label": "chair", "attribute_label": ["color:brown", "length:short", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "state, material, size, transparency, color, length, pattern", "answer": "The chair in the image is a wooden bench with a metal frame. It is placed in a grassy area, possibly a park or a backyard."}, {"question_id": 718, "height": 612, "width": 612, "image": "000000143998.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 0.01, 612.0, 603.01], "segmentation": {"size": [612, 612], "counts": "0b?T3c@nLM3`?m2>QOd@XN\\?i1k@PNT?R2m@mMo>W2RAhMj>\\2UAgMb>a2k@RNZ>l2^AYM[>l3F9N2I6L5J5M3N2MIPCaJm<a5VC]Jg<g5YCYJe<j5ZCVJc<d5\\C]J0O`<g5aC[JNN`<X6\\ChIa<\\6^CdI_<_6`CbI^<c6N3K4O0O2N3MlNZDWJ08b;]5^DXJ:<T;n4TEfJE?V;h4jEZKQ:h4QFPK`NK];V5SFPKaNI[;V5SFSKbNHZ;R5WFVK`NHX;R5YFTKaNJU;R5QFjJjN83Lo:X5_EXKYOG:Ik:`5[E_KJROj:T7XElHh:R7ZEnHd:j5mDXJ1f0>YOb:]6QEPJ=Ca:]6SE^IN>>Fa:W6QEeI7OH?a0EONk9l5`FbJI@J6l9b5gFhJ1IW9]5bF[JVOc0n0IY9V5fFTKOKX9P5kFTKMd0VOhN4Oe8`5SHXKN[2f6\\2[I[KNm2VO[Lf6\\5WJ]KMS4UOTK4NU5]5cKaKOk4YOVJb4]5VLaKOW6VOkH^3\\5[MdK2]7TOdG1OQ2^5cNfK7_9TOPK`0eK:o>VOk_O;X1a0m>BTA?m>@RAa0P?YOVAb0P?WO]A`0f`0AYN0lB=YLF3L30f=2kEh2]LVMj?f3\\OX1h@SKi=Z6jNn0]CgH_;U8mJkGkMe8hK\\Gb54gNl8l0nFnJ1K1b4N`K2Nb8V5^GQKNg51SJ6Ol6V5PIU21eHQ6V5nI]3ObG1L40S4T5kK\\4KeFk3f4hLR6]OTE^2f4[NP7l0PITOTO]O]4JkG7L:h49UOEn4DnKd0WOJf98YFId9:ZFIe94]FLd92]FO`9ZO`Bc0R45TLd0LeNe;e0ZH3ULU1MUNn:c0PI4ULg1N`M\\:8`EN^48iK_2JUMU:3ZKi3g3QLjF7_5e4g2aKjGFY5V5gJjJb7<]HC[5m6h0^I^On67gHXJ3d5\\7]JhHQ53c0f7WO[Hi0e7XOYHi0e7\\5O1ORJTHf0k7ZOWHe0h7\\5M3O1OUNgHlFBd0e7`8nIjFQ6V9RJhFl5X9VJhFi5X9XJhFf5X9]JgF`5[9aJeF\\5\\9fJdFY5Z9iJfFW5Y9kJgFS5Z9nJfFP5Z9RKfFm4Y9UKhFh4X9ZKhFe4V9^KjFa4S9cKlF\\4U9eKkFZ4R9jKoFT4n8oKSGP4l8RLTGn3k8SLUGl3j8VLUGj3j8XLUGh3k8YLTGh3j8ZLUGf3k8[LUGa3n8`LRG_3l8dLTG[3l8fLTGY3k8hLVGW3i8kLWGR3k8oLUGo2k8SMVGk2j8VMUGi2h8\\MXGc2h8]MXGb2i8_MWG`2h8bMXG\\2h8fMYGV2i8kMWGS2j8nMWGP2h8RNXGm1g8UNYGj1e8YNZGf1g8[NXGd1g8_NYG_1g8cNYG\\1g8eNXG[1g8fN[GW1f8jN[GS1f8nN[GQ1c8QO]Gn0b8TO]Gk0b8XO\\Gi0`8\\O`Gc0\\8BdG;[8IeG6Y8MgG2W81hGOW82kGKT88lGdJKP5Y8=lGcJKP5W8?nGCR8>mGAS8a0mG]OS8e0nGYOR8h0nGXOQ8i0nGVOS8k0mGTOS8l0oGROQ8o0PHoNP8R1oGmNP8V1oGjNP8X1oGgNR8Z1oGcNQ8_1PH_NP8b1oG^NQ8c1nG]NR8d1oGXNS8i1nGUNR8l1oGRNQ8o1nGPNR8R2lGnMU8R2kGmMU8U2lGhMU8Y2mGiIHc3[8e2lGjII`3[8g2lGiII^3\\8j2lG]MT8d2mGZMS8g2mGWMT8j2kGUMU8m2iGTMW8m2jGPMV8R3gGYIN6NU3]8\\3lG_IGU3\\8]3lG_IHS3\\8_3lG^IHQ3]8b3lG\\IGQ3]8d3lG[IGP3]8f3lGZIGn2]8j3hG\\IKi2\\8m3hG[ILf2]8P4gGQIL50h2]8T4fGPIM40f2]8X4gGVILa2]8Y4iGUIJ`2^8\\4jGRIHa2^8^4lGoHFb2]8a4mGmHF`2^8d4gGhHK50^2^8f4fGQILW2^8j4eGPIMT2^8n4eGnHMS2^8o4fGnHLR2^8Q5fGmHLQ2]8T5gGkHLo1_8V5fG`HLb2]8P5hG]HLa2\\8R5hG^HL_2[8U5hGQKX8P5hGoJX8R5gGnJY8S5gGlJY8T5hGeHKf1]8f5iGhJX8X5hGfJZ8Z5gGXHKV2^8c5hGUHKW2]8e5fGXHJR2a8g5eG^J[8c5dG]J\\8d5dG_IM[O^8W7eG]IOZO\\8Z7eG[I2XOY8]7gGZI1VOY8a7fGZI1TOX8c7hGoGJS16ZOX8e7gGPHIS18WOW8g7gGZI2mNW8j7gGYI3jNV8o7fGYI4gNT8R8hGXI4dNS8V8iGVI4dNR8W8jGVI4aNR8Z8jGUI5`No7\\8nGeGJX19eNo7_8QHaGH[17eNn7a8oGdGJW1a8W7eGQIZ8P7fGQIW8Q7iGPIU8Q7jGPIU8Q7kGoHU8Q7kGPIS8Q7mGoHQ8S7PHZGKY1T8^7QHYGJZ1T8^7QHkHo7U7QHlHm7U7SHkHl7V7THkHj7V7UHkHj7U7WHkHi7U7WHjHi7W7XHhHg7Y7ZHSGIZ1l7e7ZHcHf7^7YHaHi7_7WH`Hh7b7XH]Hh7d7XH[Hh7f7XHWGK?m7Z8YHWGJ>n7[8XHWGJ=o7\\8XHVGI>n7]8ZHTGH>n7_8XHUGJ;m7b8XHTGK8n7e8WHnGi7R8YHmGf7T8YHRGJ5o7i8WHRGJ4o7k8WHiGh7X8YHfFIf0o7d8ZHcFIh0k7g8[HbGd7`8ZHbGe7_8ZHaGe7a8ZH_Gf7b8ZH]Gf7d8ZH\\Ge7e8\\HYGe7g8\\HWGe7i8]HTGb7n8ZHRFO6M`0j7Y9ZHRFMn0g7R9\\HQGd7P9\\HPGc7Q9\\HPGa7R9`HmFa7S9`HlF_7U9aHkF^7V9bHjELl0`7\\9dHgEN6M>`7f9eHgELl0^7^9eHfF\\7Z9dHfFZ7\\9eHeFZ7\\9fHdFY7]9gHcFX7^9hHaFY7_9hH`FV7b9jH`EM40;Z7Q:iH`EN3O<Y7R:iH`ENg0X7j9jH\\FU7e9jH\\FU7d9lH[FT7f9lHYFT7h9lHXFT7h9lHXFS7h9oHVFR7j9nH\\EL4O7V7Z:oH\\EKc0U7R:oHUFP7l9PISFP7m9QISFn6n9RIQFn6P:RIPFm6Q:SIoEl6R:TInEk6S:UIlEl6T:UITELNO>o6a:UITEL`0n6]:UIjEk6W:UIiEj6X:UIhEk6Y:UIgEj6Y:WIgEi6Y:WIgEh6Z:XIeEh6\\:XIPEM1O0l6P;XIoDN9j6h:XIbEg6_:YIaEg6_:YIaEe6a:[I_Ee6a:ZI`Ee6a:[I_Ee6a:[I_Ee6a:\\I^Ed6a:]IlDL:g6j:]IlDL:h6i:\\I`Ee6_:ZIbEf6_:YIaEh6^:XIbEh6]:YIcEh6\\:XIdEi6[:WIeEi6[:XIQEL:m6c:XISEK:m6d:VIfEk6Y:TIhEl6X:TIhEm6W:SIiEn6V:RIjEn6V:RIjEo6U:QIkEo6T:RIZEL7S7^:RIYEM8R7^:QIZEL9T7\\:oHoER7P:nHPFR7P:nHPFS7n9nHRFR7n9nHRFS7m9mHSFS7m9mHSFT7l9mH`EK9X7W:nH^EL:W7V:mHbEJ9Y7U:lHVFT7j9kHWFV7h9iHfEM6[7S:hHgEM6\\7R:hHZFX7f9hHZFY7e9gHhEL7^7P:eH`EN609]7Q:eHaEL619^7P:dH^F\\7b9dH^F]7`9dH`F]7_9cHoEL4a7m9cHaF^7^9bHbF_7]9bHbFg3TOHZ:aLfEK619i3DJV:aLfEM6O:h3FJT:aLhELh0i3\\OJT:aLdFc3[OLP:`LfFc3\\OMm9`LgFb3]OOD\\LU:3jFb3^O0h9^LjFa3_O1g9_L^FLFd360e9aL_FKFc372c9aLmEL51:_332a9aLnEM509_344_9_LZFM4_354]9_LnF\\3G5Z9_LoF\\3H5X9_L]FO2\\3:6W9_L]FNHO4^3`06W9_LdFOD[3c07R9aL^FMJ03[3c08Q9aL_FMHO5Z3e09o8aLUFL41MO7Y3e0:n8_LXFL31MO6Z3f0;k8_LUGU32;h8aLVGS34<e8aLeFK2W3e0=d8`LeFN1T3g0>b8aLfFLGO4V3m0?a8`LfFLH04T3o0`0^8aLfFLH04R3Q1b0\\8`L_FK12L26o2S1b0Z8`L_FL30K27o2T1b0X8`LjFLE07Q3T1b0V8`L^Gm2=d0T8_L_Gk2`0f0P8_LmFNEN5n2Z1g0o7^LnFOCO6l2[1i0m7^LmFOEO5k2]1h0\\N[L]94oF0EO6i2^1l0h7\\LhFMN3L18g2_1l0f7\\LhF8KI8f2a1l0d7]LhF8KH9f2a1m0c7]LiFL63Mf2c1m0a7^LYGMCf2e1P1^7\\LkFM10M04f2g1P1\\7]LkFM03LM6e2h1Q1Z7^LTG0CM7c2j1R1W7^LTG1DL7b2k1T1U7]LnFML6ML8`2m1S1T7_LlF>3o1n1T1S7_LhFK1b07o1o1T1Q7`LlF=4n1Q2U1n6_LZGM@07^2R2X1k6]LQGL03KN7]2T2X1i6^LQGNM3ML6]2X2Y1f6\\LSGOK4NK6\\2Z2Y1d6]LZG3BL5[2[2Z1b6]L[G3BL5Z2]2Z1a6^LSG?Og1_2\\1^6cLoF:4f1`2^1\\6aLQG:4f1a2^1Z6]LWGMI6OM7U2a2^1X6]L_GME23T2c2`1V6]LXGNK4ML7T2d2b1T6\\LXGOM2ML1O1U2j2b1Q6]LZGOK3MM1M2T2k2c1P6]LZGOJ94h1i2c1n5]L[G0H96e1k2f1k5]LZG?0]1m2g1g5dLVG86]1n2f1g5^L\\G>O]1o2g1f5]LcG8Ic1P3i1a5]LaGKL:2d1R3i1_5^LaGMJ84c1S3k1\\5^LbGMK3MM1M1m1Z3j1[5^LaGMK:ND1m1Z3j1[5^LbGKK=0_1Y3l1X5^LcGMH<4\\1[3m1U5aLaG:0W1[3o1S5\\L]GL66J35_1]3o1R5[LoG6C_1]3Q2P5ZLRHM]O34d1_3Q2m4\\LRHO]OO5e1`3P2l4\\LSH0]ON4e1a3R2j4\\LRH0^OO4b1c3S2i4\\LQH1_ON3b1f3S2f4\\LRH8AY1h3S2d4\\LbGM61L91Y1i3S2b4]LbGM55K34Z1i3U2`4\\LcGM?7EZ1j3W2^4ZL]H0[O^1l3W2\\4[L^HOZO_1m3V2Z4]L[HM[O03_1n3X2X4\\LZH0\\OM4^1P4X2V4]LXHM^O0022\\1S4Y2T4\\LYHMB2N\\1S4Z2S4\\LRHKJ1N41X1T4[2Q4]LhGL55L32S1U4]2o3\\LiGM44M23S1V4]2m3[LbH1[OW1V4]2m3[LdHOYOX1X4^2j3ZLgHOWOX1Z4_2g3ZLiHNVOX1[4a2e3YLiHOVOW1^4`2c3ZLaHN\\O0O23V1^4a2b3YLaH9^Ol0a4b2^3[LbH6Al0`4b2]3\\LbH6Ak0a4d2[3[LcH6Ak0a4d2[3ZLdHO_O01R1c4e2X3ZLeHNA0NS1e4e2W3ZLnHNVOR1g4f2S3[LPIMTOT1i4d2R3\\LPINTOQ1l4e2o2\\LPIOVOo0l4f2m2\\LPI0WOm0m4g2l2\\LbHMI7Mg0m4j2j2[L_HKI3NN272g0n4j2h2\\LRINXOl0o4i2g2]LSIMWOl0P5k2e2[LUINUOm0;QOW4i3S3[LoH1ZOL1o0;ROD0_4g3V3[LQI2YOM1l0b0SOn3f3U3\\LPIZ1GcNC6_4b3V3[LhHNH[14SOU4Y3W3[LhHc0C59FU4W3V3[LbHNJg0227GU4X3U3ZLgHNGa0277HU4W3T3[LQI0@O0g05IV4V3T3[LRINA0Nh05JV4U3S3[LoHN@1OO002j06IW4U3R3YLnH2B7Oa01TO3d0[4V3Q3XLnH3CY13WO[4T3Q3YLnHf1DoN\\4R3R3YLmHe2P4R1R3ZLhHi2V4n0eKULX74lHh0LR1\\4m1n2YLoH2F82`1\\4m1l2XLRIOH2M11j1[4k1n2YLSING1K42j1[4i1o2YLmHOH5O1OK2P2[4f1Q3ZLlHOH5O1OK2P2\\4e1o2\\LQIc0B]1_4c1n2]LQIc0B]1_4b1o2^LkHh0GY1_4`1o2_LcHO2j0NW1^4`1P3`LdHM0k0OX1^4^1P3aLnH1F:Ng1]4[1S3cLmHOG2K31n1]4Y1U3eLlHOB0O6OK2R2^4W1U3gLeH0H4O10J1S2_4U1U3iLjH5@00L0S2`4Q1W3mL_HMOe0K`1`4P1X3nL^HMN5L90g1a4n0W3QMZHK2l0L[1`4l0Y3RMXHN1h0O\\1`4i0Z3TMbHOH:Mi1`4h0Z3VMbHMI2J31Q2`4d0\\3YMkHNXO41S2_4?^3]MbHKA1O6OK2X2^4=`3^M[HLG0O1050J0Z2_4;a3_M_HMAO0;OP2`47c3bM\\HNB=Ol1`46d3cMZHb0Be1a44d3dMnGOOi0N`1a43e3eMnGNNi0Ob1`4Og3gMnGN02O4KM1Z2_4Mj3gMUH1G0N0N[2^4Kj3jMYHM_O011N1O01^2^4Gl3mMRHMF0M12OO10O0`2^4Dm3PNQHKE6O1OL0_2^4Bo3RNiGLO10n2X4SOo3SNiGMM3Nn2]4lNQ4UNeGc3Z4WNR4VNbGf3\\4RNT4VNdGn0Kd1]4VOU4XNdGNN3O9NZ2Z4TOW4XNlG1G7L\\2[4ROW4ZNfGLI2OO1009O_2Z2XMBh1g6[NeGMG12O0005OK0h2Y2YMDf1e6^NdGLJ0O11N0;O^2V2[MHb1f6_NcGLJ50V3T2hLJa1e6aN_Gj3o1ULM`1e6i2[IhK1^1d6j2[IhK1]1e6cN]GN010[3l1gL2\\1e6bN_GM02O0NS3l1QM4Z1d6cNbGKL4O\\3j1iL5Y1d6`N\\GN6OK2O0O1041l2j1YM6V1d6aN\\GN60J1O1091g2i1ZM7U1a6dN^GL60L4N\\3j1kL7U1a6hNcGJM1N]3j1lL7T1`6iN_Gd00U2j1ZM7T1`6HaGj1h1ZM7T1`6FcGl1f1[MVNCm1_1d6hNbGK111M0R3f1_M2n0d6eNRHKEOMS3f1`M4m0b6fNaGJ0060J15OO3Jj2k1fM4m0b6fN`GK1O1000O10O11OO01Ol2j1fM5l0`6hNaGJ50MOO141LNO3Oi2l1gM5k0_6mNeGH0O10M3Mg2l1gM5k0_6mNeGH0O01N2M2"}}, "object_label": "dining table", "attribute_label": ["color:brown", "length:short", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "size, material, length, pattern, transparency", "answer": "The dining table in the image is a wooden table with a cutting board on it. The cutting board has a knife and a bunch of carrots placed on it. The carrots are arranged in a way that they are tied together, possibly for easier handling or storage. The table setting suggests that someone is preparing to cut or chop the carrots for a meal."}, {"question_id": 719, "height": 480, "width": 640, "image": "000000147415.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [200.62, 334.69, 240.71, 134.31], "segmentation": {"size": [480, 640], "counts": "[PP3a0Y>6J7J5I7N3J5I8K4H8L4N3N1O101lCbMd;_2[DbMd;_2\\DaMc;_2]DbMb;^2_DaMa;`2^D_Md;`2\\D`Md;`2]D_Md;`2\\D`Md;a2VDdMk;[2TDfMl;Z2TDfMm;Y2SDgMm;Y2TDeMn;Z2RDgMm;Z2SDeMm;Z2TDfMl;Z2TDfMm;Y2mCcM53m;Z2nCcM53m;\\2TDdMl;]2TDbMm;Z2lCeM80l;Z2mCgM6Om;[2lCeM80l;[2lCeM_<[230jCfMf;Y2[DgMf;Y2ZDfMf;[2?O2NmCgMa;Y2UDgM10j;Y2UDgMU<Z29O00kCiMa;X2^DiMa;W2_DiMa;X2_DgMb;X2^DhMb;X2^DhMb;X2SDfM52i;W2QDhM62h;W2QDhM61i;X2PDfM82i;X2nCfM92j;W2YDjMf;V2ZDjMf;V2ZDjMg;U2YDkMg;V2XDjMi;U2XDjMh;W2WDiMi;W2WDiMj;V2VDkMi;V2UDkMk;U2UDkMk;U2VDjMk;V2TDjMl;W2QDkMo;U2PDmMo;S2PDnMP<S2nCoMQ<R2nCnMR<R2nCnMR<R2oCmMQ<S2PDlMP<U2oCkMP<W2oCiMQ<c201O00001N100000001N10001O00001N1000000O1000001O000010O000000010O0000000001O0001O0010O0001O0010O0001O10O01O010O00001O00100O000010O0001O0001O01O00001O010O1O1O00010O00001O00010O1O00011N001O01OG9M3N3N2N2jMaC20Y1Z=N2O1N1O2N2POXBd0T>N10000O1000001O1O010O001O1N101N101O001O001O1O1O1N101O001N1O101N3NZ_R3"}}, "object_label": "book", "attribute_label": ["color:white", "length:short", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "state, material, length, pose, size, transparency, texture", "answer": "The image features a person sitting at a desk with a laptop and a book in front of them. The book is open and appears to be a notebook, possibly containing notes or ideas. The person is using a pen to write or take notes on the book, while the laptop is also open, likely for reference or additional information. The scene suggests that the person is engaged in a task that requires both digital and traditional resources."}, {"question_id": 720, "height": 375, "width": 500, "image": "000000148620.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [222.47, 61.52, 206.46, 136.51], "segmentation": {"size": [375, 500], "counts": "i[`2260\\:2`EM0m0Y:UOfEV1^:hNPF0Eb0^;BL5GGmD?Q;4I7jNYOlF0CN6c0o8BiFf0NYO9LJ>l8m0jGROd7V1dG\\N10k04TO3l7a3N3O00000O0100O100001O00000000000000000000000000000000000000O1001O00001O0000000000O1001O00O100000000001O00O1001O00000000WOXHoL1>g7a2[HdMe7\\2[HdMe7\\2\\HcMd7\\2^HcMb7\\2bHaM^7_2dHYMCLi7k2dHYMCLi7U3YHPMOKg7i2XHiM4\\Od7k2XHiM4\\Od7k2XH_M0L4Jd7k2XH^M2L2Lc7j2YHXM2M051Md7i2YHXM2L25ONd7P3\\HlL11N022c7S3YHlL332Nb7W3[HkL4Mb7S3ZHlLO64Lb7R3_HSMNKc7i2^HUMOOM83Kc7f2YHXM<OD94Jc7i2gH]MFJc7h2iH]MCLd7g2_HUM28JMe7e2_HXM25JNe7e2`HVM28HMf7e2jH_M@Lf7d2lH^M@Md7e2lH^MALc7f2lH^MALc7g2kH]MCKb7h2`HVM27KLb7i2_HVM35LMa7g2bHVM25KNa7f2oH]M_OMb7f2oH]M_OMb7f2oH]M_OMb7f2QI[M]OOa7g2QI[M^ONa7g2oH]M_OMb7f2oH]M_OMb7f2nH^MAKa7f2oH_M@Kb7e2iHfMDEc7f2hHeMEEc7`1\\H_O=[OEEa7[1\\HfN2o0;\\OEEb7g2gHgMFBc7g2gHfMGCb7g2iHdMEEb7g2iHdMFDb7f2iHeMFEa7f2iHeMFE`7`2^H`M=NA94I`7g2kHcMEF`7h2iHdMEEb7g2jHbMEGa7g2jH^MBI41`7h2jHVMB94Ia7g2iHWMC93Ha7h2mH`MAIa7h2nHZM^ON30a7h2jHVMB:3Ha7i2iHbMEFb7h2iHbMEFb7e2\\HXM=0C50M21b7i2lHXM@M32a7i2PISM]O222a7i2PISM]O311b7i2PISM]O311b7i2nH\\M^OLd7i2lHcMT7\\2mHWM_O001d7h2lHXM@O02c7h2kHfMU7Z2kHfMU7Z2kHfMU7Z2kHfMU7Z2kHfMU7Z2kHfMU7Z2kHfMU7Z2kHgMT7Z2kHfMU7Z2lHeMT7[2lHeMT7[2lHeMT7[2kHfMU7Z2kHfMU7Z2lHeMT7[2lHeMT7]2`HTMOa0a7d2_H\\Ma7d2`H[M`7b2^HcMb7\\2_HdMa7\\2_HdMa7\\2_HdMa7W2^HoMb7Q2_HgMO]Ob7l2^HhM0\\Ob7l2^HoMb7Q2_HnMa7Q2`HoM`7Q2bHmM^7S2cHYMK9a7_2aHnM_7U300000mN_HPNa7S300000000000000000000000001O0000O1O1CcHZLc7b3;YOg0G9UOm0^NPgj0"}}, "object_label": "tv", "attribute_label": ["color:white", "length:short", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:on", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a computer monitor with a space shuttle on the screen. The monitor is placed on a desk, and it appears to be turned on. The space shuttle is prominently displayed in the center of the screen, capturing the viewer's attention. The scene is set in a room with a few other items, such as a keyboard and a mouse, which are placed near the monitor. Additionally, there are two bottles in the room, one located closer to the monitor and the other further away."}, {"question_id": 721, "height": 516, "width": 640, "image": "000000152465.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [413.05, 30.65, 130.91, 409.24], "segmentation": {"size": [516, 640], "counts": "`ob632Ol6<VIK\\7b1\\NUO\\1R1bNoN^LPOb2X2l0iN`LVOk1g2c1TN`LWOa1R3m1gMaLXOW1_3U2YMdLYO;7eM]3Z5UMdLXOVOKkNO<g4o4WLdLYOnNg5]4RK`LHYNc5U5hJ_L]6a3mIkJ^N8`8l4Z2O0N2O2M2O2N101O0O00013L2N2O0O101O0O2O00000O2O0O2O000O2O1O0O2O0O101N1O100O101O00000000001O000010O2N00010O0010O01O00001O001L3FfKfD_4\\:bKdEZ5e9n0F;]NRJbHZ6k5UIaJd8X5dGbJa8Z5iGXJ^8d5T1_Oa0D;J7J6M2F;L4L4N1AhCPM[<n2gCoL\\<n2?O1SNSC`0o<\\OWC?k<@YC4HlNQ=n0[DoNQ<Q1a1O1O2O0O1O2M3Bj@H[?5P\\h1"}}, "object_label": "fire hydrant", "attribute_label": ["color:brown", "color:red", "length:long", "material:asphalt/cement/clay/concrete/stucco", "transparency:opaque", "pattern:plaid/tartan/checkered", "pose:vertical/upright/standing", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "material, texture, length", "answer": "The fire hydrant in the image is red and white, with a rusty appearance. It is located on a dirt road, surrounded by a chain-link fence. The hydrant is positioned next to a tire, which is placed on the ground near the fence. The scene appears to be in a rural area, with the fire hydrant being the main focal point."}, {"question_id": 722, "height": 400, "width": 500, "image": "000000183246.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [220.27, 162.98, 7.73, 31.92], "segmentation": {"size": [400, 500], "counts": "kSf25d;3_D:`;;01OO1H_D@b;?`D@`;OjD0F0R<O701OmlX3"}}, "object_label": "traffic light", "attribute_label": ["color:black", "color:yellow", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "material, texture, color", "answer": "The traffic light in the image is red, indicating that vehicles must stop at the intersection."}, {"question_id": 723, "height": 368, "width": 500, "image": "000000306893.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [5.79, 159.6, 494.21, 97.59], "segmentation": {"size": [368, 500], "counts": "ga02Z;f0VNZObF;0D2m1e8j0O001OO2O00000O1O1O1O101N10000O1O10000O1001O00O1001O1O10O00000O100001OO3NO13L3ROf1fNbj1f0UTN]1_O8N100EeM`G]2_8cMaG]2_8cMaG]2_8dM`G\\2`8:000ZM[Ga2e8^MaG]2_8cMaG]2_8cMaG]2_8cMbG\\2^8dMbG\\2^8dMbG\\2^8dMbG\\2^8dMbG\\2^8dMaG]2_8cMaG]2_8cMaG]2_8cMaG]2_8cMbG\\2^8dMbG\\2^8dMbG\\2^8dMbG\\2_8cMaG]2`8bM_G_2i80HaMZG10_2f870O100D<N2O100O1L4O1O11O10001N2LPNiFl1X9QNiFP28QN`8OXGQ25RNc8a2O10O000[MYGa2g8_MYGa2g8_MYGa2g8_MYGa2g85O0000[MYGa2g84000000000000000M4VOn0YOS^:WOTXEL1e1l8f000ZG_M\\8c2711O00O1O100000000001O000001O0001O0010O00000000O100001N100000000001OO10000000001O00OO200001O1O000000001O00001O0000000000001O00000000001N101O1O1O000000010OO01000001WNRGn0o8POTGn0l8SOSGn0m8QOTGm0R9jNSGT1V9cNSGi0[O^Oe9IPGP1R9POfF1Gm0f9VO^Fm0f9UOXF;JLP:JRFIO90G11O;o9KVF00JM7P:JWF3J10JU:1RF2K3h:KYE5Q;01Oci1M`VN02NhT21l_M`0b9OaFd02ROm8f1PG\\No8f1nF\\NR9Q200O2O0O2N1O100O10000000000000000000000O1000000O101O000O1001O0000000000001O0001N10000O0100O2O000000000001O00O010000000000000000000000N2002N1OO100O1N200000\\MZG^2f8bMZG^2f8bMZG^2f8bMZG]2i8aMXG;O371NBLNQ\\:4ocEL21R:W2lEgMQ9^2M2HaM[Ga2e8`MZG`2f8`MZG`2f8500001OO1O10O101O0O2O10M2O01DaGfM`8X2>N2M3N1OO11O110O03M1O1O1N2O=C001O0002NM3O1O10_M[GW2e8hM]GW2c8fM`G[2_8eMbGZ2^8eMcG[2]8fMbGZ2_8eM`G\\2`8dM`G\\2a8cM`G\\2`8dM`G\\2`8dM`G\\2`8dM`G\\2`8dM`G\\2`8dM_G]2`8dM]GMN`2e8cM\\GN0^2e8cM_G]2k8O00000000001O0O[b2oMk]M=lF_O0i0Q9Z100NfMnFZ2S910000O100000000000000O2O1O00000000000000000000001O0101N01O01nMQG`1d9SNaF003Lb0N\\OaV1"}}, "object_label": "train", "attribute_label": ["color:red", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "pose, material, state", "answer": "The image features a red train parked at a station, with two other trains visible in the background. The red train is positioned in the middle of the scene, and the other two trains are located on the left and right sides of the image. The train appears to be a passenger train, and it is parked next to a platform."}, {"question_id": 724, "height": 480, "width": 640, "image": "000000308466.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [44.14, 396.2, 183.46, 83.05], "segmentation": {"size": [480, 640], "counts": "eRe06i>3M2N2O0O2O0O1O10O10O1O2OO0100O1O100O100O1O100O100O100O1O100O100O1O100O1O100O100O1O100O100O1O100O100O1O10SOdB6[=FnB6R=JnB6Q=JQC5n<LRC4n<LRC4m<MSC3m<NRC2m<0QC1n<1QCOo<2oBOP=4nBLQ=5nBLR=2PCNo<1SCOm<0RC2m<MTC4l<LSC5l<KTC6k<KUC5k<KTC6k<LSC5m<KTC4k<3oBMQ=4oBKP=MlBF1=R=MoBFO<R=DZCOE<P=F\\CMD=P=F]CLC>o<G^CKB?o<H^CJA?Q=G^Cb0a<_O^Cb0a<_O_Ca0a<A]C?b<C]C=c<C\\C>c<D[C=e<DYC=f<o0O100O100O100O1O100O100O1O100O100O1O100O100O1O100O10000002N3M3M3M2N1O1O1O1O1O1O1O2N001O1O2N1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O1O100N2O1O1O1O1O2N001O1N200O1O001O1O001O2N1O2N1O1OT\\m5"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:gray", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "state, size, cleanliness, pattern, color", "answer": "The image features a white sink with a silver faucet, placed on a white countertop. The sink is positioned in the middle of the counter, and the faucet is located on the left side of the sink. The sink appears to be a modern, minimalist design, and it is situated in a clean and uncluttered environment."}, {"question_id": 725, "height": 640, "width": 428, "image": "000000381587.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [3.01, 433.69, 209.32, 201.79], "segmentation": {"size": [640, 428], "counts": "ji43=6\\1?i>Dd_O8c0^OYO[1m1gNZNOg=;UB5e0n0U1dNTNL13k=;VB3f0n0T1eNZNNf==UB1i0n0R1eN[N0d=<VB0k0n0P1fN[N0d==UBMo0n0n0hNZN1c=<VBKR1n0l0jNYN1c=<WBHU1n0j0kNYN2a=>VBFX14fN<S2YOYN3`=>VBEZ1m0g0nNXN1b=?UBD[1m0g0POUN1d=>UBD\\1l0e0ROVN0d=>kC?;SOWNOc=?lC=;UOVNOc=?lC=;UOVNOc=?mC<:VOUN0d=>nC::WOVN1a=>oC9:YOVN0a=>PD89ZOVN0a=>PD7:[OUNOb=?oC7:[OUNOb=?PD59^OUNNb=?QD48_OUNNb=>RD56AUNLc=>SD36CTNLc=>SD36CSNMd=<UD33DVNLb=8TBGR2`03EUNLb=8[D5OGTNLb=8[D5NHUNKb=9YD50GUNJc=:XD40IUNIc=;XD2OLUNHc=:YD2OLUNHc=:XD20MTNHd=9XD20MTNHd=9YD1ONUNGc=:YD1NOVNGb=9ZD1NNWNHa=9ZD1M0WNEc=:YD0N1VNDd=;XD0M2WNCd=;VD3NOXNCd=;UD4NOYNBd=;UD4M0ZNBc=:VD4M0YNCd=9VD4M0ZNBc=:VDFmM:o14\\NBb=:VDFmM:n15]NBa=9WDFmM:m17]N_Oc=;UDEnM:m17]N^Od=<SDFoM9m17]N^Od=<RD6K1_N]Od==PD7KObN^Ob=<QD7KObN^Ob=<QDERN>g15bN]Od=<oCDWN<d16dN^Oa=<oCEXN<a17gN\\Oa==mCD[N=^17iN[Oa==mCD[N=^17iNZOb=?jCD]N=\\17kNXOc=`0iCE\\N=\\16lNXOc=`0hCF]N=Y17oNWOb=`0gCF_N<X18POVOb=`0fCG`N;W19QOUOb=a0dCGbN:V1:jNSO13h=`0cCGdN9U1;SOTOb=`0aCIeN8Q1?WOPOb=`0_CKgN7o0?YOoNb=c0[CIkN7k0ZOSOT1:nNc=g0VCGoN7d0[OYOX19iNd=h0UCFPO7<YOCa19aNc=j0RCESO6<m0N]Na=m0nBEWOON@038]14_Na=n0mBCZOOLK=o0OfNa=Q1mB]O[OGKK11O;=CCV15jNO3h=d0WB^Og0:ZO=g04BRO`=3TBL_1`0cN9o02ZOVOa=3UBJ^1c0cN7R11WOXOa=4SBK52N1?MBa0O4V14ROWOc=P1VBQONON23?03X15nNXOe=k0PCCUO3\\14kN[Od=g0XCBnN6a12fN^Oc=h0^C\\OhN;c11eN@b=<RBJ]1OgN:c11eN@b=;SBI\\14fN6g10ZNA03i=9TBG`14bN6j11^NEb=8UBFb15`N4l13\\NEa=9TBEf15]N5l13\\NEa=<lCGZN4o14YNEb=<mCGXN4P24XNEd=<mCFWN3T24TNGc==oCDUN4W22TNHa=>PDBUN5X22RNIa==QDDSN4Y22QNJb=;SDDQN4[22iMHO4h=:UDCPN4\\23nMLa=OUB4U2M:2lMM`=0UBNO2W20:3kMM`=9[DG:3jMNa=8ZDG=3gMMc=8ZDH<2hMNb=8ZDG>2fMOb=8[DF=3fMOb=8\\DE<4fM0a=OVB1o4NUKNN4h=OVB0P50YK1a=OVBOQ51XK1a=OVBNR52XK0`=0UBOT50VK2a=5XGIVK3b=4YGHUK3c=5XGIUK1c=5YGKSK0d=5ZGJlJN14h=4\\GIkJO05i=3gGMY8NTBOe52W8OTBOe52W83hGNX82hGNX82hGMY83]GIoJ3d=4hGLX84aGJeJ4i=2bGJdJ5j=1cGIdJ5i=2iGMW83[GIUK4`=3[GITK5a=2[GITK5a=2[GITK5`=3ZGJWK1`=5YGJPKOO3g=4ZGJPK0N2i=3YGKoJ1M3k=MTBO]2N92_M0M3j=MUB0[2O92gM1`=NVBOZ2181hM1`=NUB1T2MoM2`22fM1b=NTB0U2MoM2`23dM1d=MTB0U2MoM3^23gMOb=5XDGQN3\\23jMMa=6WDHRN3Z23fMH04g=2UBLQ21SN3Y22fMJ02h=1WBMn11TN3X23gMIN4k=MXBOk10VN4W23gMIO3j=NYBNi12WN4U23PNJb=OYBOg12YN4T22QNJb=OXB0g12ZN4R22RNJb=0WB0h10[N4Q23SNIb=1UB1h10\\N3P23UNHb=;kCH]N4o12RNB04f=>jCG_N4m13RNB12g=>iCH`N4k13TNA03i=1VB2b12`N5i13VN@N5k=OXBMc1NZN559e13YN@N4j=OYBMh1O\\N`0_12cNAa=0ZBM12g1`0F1hN@`=0ZBM12Q1NSO0Ld0Z11iN_Ob=OYBN13o0OSO1N`0X13lN]Oc=MZBO02n0`0QO2W14nN[O\\?a0^@2T16ROVOY?f0`@2o06VORO]?f0[@6k06]OnNa?f1m@^OCkN`?i1f@Ng=[OoAoNM5N55E0m2o=]O]BfMG]2l=5PB]M=[2c=`0]BZMAk1Q>P1ZBUMD30]1R>\\2oAcMP>e2QBiK1>L0S>Z5000`NXBhLg=R3eBiL[=U3iBiLW=V3mBgLS=W3PChLP=W3SCgLm<W3WCgLi<X3YCgLg<X3\\CfLd<X3_CgLa<X3aCgL_<X3cCgL]<U1\\B1X1iN\\<S1aB1U1kNZ<P1gB2Q1mNX<n0lB2m0POW<j0RC3i0ROU<i0UC3h0SOS<g0YC4f0TOQ<g0[C3f0UOo;f0^C3e0VOm;f0`C2d0XOl;e0bC1d0YOj;f0cC0c0ZOj;e0dC0c0[Oi;d0fCOc0\\Og;c0kCLQ?_OY_ONXUW4"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, cleanliness, color, transparency, texture, material, pattern", "answer": "The dining table in the image is filled with a variety of food items, including several bowls and plates. There are at least five bowls placed on the table, each containing different types of food. Some of the bowls are placed closer to the front of the table, while others are positioned towards the back. \n\nIn addition to the bowls, there are three plates on the table, with one located near the center, another towards the right side, and the third one towards the left side. The table appears to be set for a meal, with a diverse assortment of dishes to enjoy."}, {"question_id": 726, "height": 491, "width": 640, "image": "000000425361.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, material, pattern, pose, texture, transparency", "region_anno": {"bbox": [293.03, 186.18, 57.03, 145.89], "segmentation": {"size": [491, 640], "counts": "UW\\43P?9I5K6L3N20010O0100O2OO0100OjDXOk7g0TH@g7`0YHCd7<]HEb7;^HFa79`HG`78`HI_78_HJa75_HM`73_HNa71]H2c7NdG^OTNi0X:IcGl0]8TObGm0^8SOaGn0_8QOaGP1_8PO`GP1a8PO^GQ1b8nN_GR1b8mN`G@[Ni0U:F`H3`7MbH1^7OcH0]70dHO\\71dHO\\71eHN[72eHM\\73dHM\\73dHM\\73dHM\\73dHM\\73dHM\\73bEBb29m75aECa28n75aECa27o76`EDa25o78_ECc24o78]EEe21Q89ZEFd21V86UEIf2N[86nDMZ>NfA3h>20OljZ4"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "cleanliness, transparency, pattern, pose, material", "answer": "The wine glass in the image is filled with wine, and it is being held by a person's hand. The glass is positioned in the middle of the scene, and the person's hand is visible on the left side of the glass. The wine glass appears to be a clear glass, allowing the wine to be seen inside."}, {"question_id": 727, "height": 360, "width": 640, "image": "000000277020.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [369.52, 259.21, 18.34, 21.83], "segmentation": {"size": [360, 640], "counts": "UdQ41U;;G2N1O2N1O1O1O1O1O1O00000000000008Hmeh2"}}, "object_label": "bowl", "attribute_label": ["color:black", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "state:on", "texture:smooth/sleek"], "control_dims": "color, pose, size", "answer": "The image features a large wooden bowl, which is placed on a wooden table. The bowl is positioned in the center of the scene, and it appears to be empty. The wooden table is the main focus of the image, and the bowl is the only object in the scene."}, {"question_id": 728, "height": 640, "width": 640, "image": "000000286908.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [14.79, 300.0, 143.85, 122.6], "segmentation": {"size": [640, 640], "counts": "\\o:h0Qc0<H7I6K4K5L5K3M5K3N3L3N2N2M3N2M3O1M2O1O2N100O1O1O1O100O1O1O1OYO]_O_M0`0c`0V2\\_OjMc`0j2OF__OWMa`0h2a_OWM^`0j2b_OVM]`0k2c_OTM]`0o2a_OQM_`0X3O2O0O10O0100O2O0O10iLf_Oh2Z`0WMh_Oh2X`0WMi_Oi2V`0XMi_Oi2W`0XMg_Oi2X`0`0000ROj_ORNV`0n1j_ORNV`0l2O1000fLi_O70m00PO0KW`01i_Ok2W`0?00000cLj_OP3U`0QMk_Oo2U`0>00000cLn_Ol2R`0UMl_Ol2T`0`000000SOj_OPNV`0m20iLl_Ob2T`0]Mm_Oc2S`0^Ml_Ob2U`0^Mm_OFLL0:0S10QOW`01l_O^2T`0bMk_O_2U`0aMl_O^2T`0bMm_O]2S`0cMm_O]2S`0cMm_O]2T`0gMh_OX2X`0aMh_OF1h2W`0aMi_OG4d2S`0eMh_OH8LI_2W`0TNQ@Q2P`0oMg_O^O0f2Y`0kMh_O_OOf2Y`0kMi_O]OOh2Y`0iMn_OV2R`0kMm_OU2S`0kMl_OV2U`0jMj_OV2V`0jMk_OU2U`0kMm_O_OI_2[`0RNj_OT2W`0lMg_OU2Y`0lMf_OT2[`0kMh_O^1K`N]`02m_OX1HeN\\`04j_OX1HeN^`06g_OBJl1``0bNe_OAL0Oc1a`0kNd_OAMn1_`0aNd_OZOM125LL0g1b`0nNe_O[OMQ2``0dNa_O^OMn1c`0cN`_O_OMn1c`0eN`_O[ONo1c`0fNg_OX1[`0iNb_OV1a`0mNY_OT1i`0lNU_OU1l`0n02ZNP_OTO1d0Ra07n^O7Ta0Hl^O6Wa0X12N2M3N3M3L4L3M3N4K4M3L4L5I8I8FQa]9"}}, "object_label": "bowl", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, color, state", "answer": "The bowl in the image is filled with white rice, which appears to be a delicious and healthy meal. The rice is placed in a white bowl, and it is accompanied by a small black bowl, possibly containing a sauce or a side dish. The bowl is placed on a dining table, ready to be enjoyed by someone."}, {"question_id": 729, "height": 426, "width": 640, "image": "000000289938.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [1.91, 117.75, 210.61, 70.84], "segmentation": {"size": [426, 640], "counts": "iV22V=5L6K2M2N2O0O2N1O1N3N1O2N1O2N100O2O0O2O0O2O001O00001O001O001O00001O00001O001O01O01O001O00001O001O00001O01O01O001O001O001O00010O001O0000001O0000001O00001O0001O01O0000001O0000001O01O000001O0001O01O00000001O0001O000000001O000001O0000000000000000000YObD\\O0D_;g1O01O0010O01O001O001O00001O000000001O0001O01O000000001O000000001O000O101O001O001O001O00001N101L301O010O001N101O001O00001O1O001O001O001N1N2N2N3N100O1O2N1O1M4J[bc5"}}, "object_label": "umbrella", "attribute_label": ["color:red", "color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:open", "texture:smooth/sleek"], "control_dims": "state, texture", "answer": "The image features a large, colorful umbrella with a red and yellow design, hanging from a building. The umbrella is positioned in the middle of the scene, covering a significant portion of the image. The vibrant colors and unique design make it stand out against the backdrop of the city."}, {"question_id": 730, "height": 359, "width": 640, "image": "000000302030.jpg", "category": "description", "question": "Describe the mouse in the following image in detail.", "dims": "color, pose, size, texture, transparency", "region_anno": {"bbox": [562.81, 109.6, 21.85, 17.01], "segmentation": {"size": [359, 640], "counts": "f_U63S;3M3M3N100O1O0O20O0001O00000001O001O0O4Ih`c0"}}, "object_label": "mouse", "attribute_label": ["color:white", "transparency:opaque", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size, pose, texture, color", "answer": "The image features a white mouse sitting on a white surface, possibly a table. The mouse is positioned in the center of the scene, and it appears to be a computer mouse."}, {"question_id": 731, "height": 359, "width": 640, "image": "000000302030.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [163.19, 12.81, 15.1, 56.19], "segmentation": {"size": [359, 640], "counts": "RUi12T;8I9G;E9G9G6J1O000001\\NdF[1\\9dNQGP1m9F9G:FmaQ5"}}, "object_label": "book", "attribute_label": ["color:blue", "color:white", "length:long", "material:paper/cardboard", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "state, size", "answer": "The image features a bookshelf with a variety of books. The book in focus is a blue book, which is placed on the shelf between two other books. The blue book is positioned in the middle of the shelf, with one book on the left side and another on the right side. The shelf appears to be well-organized, showcasing the books in an orderly manner."}, {"question_id": 732, "height": 359, "width": 640, "image": "000000302030.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "color, length, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [418.39, 91.47, 136.83, 36.65], "segmentation": {"size": [359, 640], "counts": "Yfc43S;2O4K2O1O2N1O1O2N1O2N1O1N200N3N001O000000000000000O10000000O10000000000000000000O10O10000000000000O0100000000000000000000O010000000000000000000O100000000000O1000O100000000000O10000000000000O10000000O1000O10000000000000O02O1O001O1O2N1O1O1O001O1O2M2O1O2N1O001O0O2O1O1ORfm0"}}, "object_label": "keyboard", "attribute_label": ["color:white", "length:long", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "length, pattern, size, texture, pose, transparency, color", "answer": "The image features a white computer keyboard sitting on a desk. The keyboard is positioned in the center of the desk, with its keys clearly visible. The desk appears to be cluttered, with various items surrounding the keyboard. There are two computer mice in the scene, one located near the left side of the keyboard and the other towards the right side. Additionally, there are two cell phones, one placed near the left side of the keyboard and the other closer to the right side. A cup can also be seen on the desk, positioned near the right side of the keyboard."}, {"question_id": 733, "height": 427, "width": 640, "image": "000000017959.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [23.11, 203.96, 75.69, 204.96], "segmentation": {"size": [427, 640], "counts": "dd;7o<6M2O1M2M2M4K5M3N2K5O1N2O1H8L5L3N2K4O2N2L5M2N2O2M2M4N1N3J5N3M2N3N1N2O1N2N2O0O1O[O[FcMj9Z2d0O10O1O101N2O1O1O001O00O1I7L4L4N2N2O1O1N2N2O2L5K5M4J7I=ATWR7"}}, "object_label": "kite", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:red", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material, pattern, color, cleanliness, pose, length, transparency, texture", "answer": "The kite in the image is a large, red and black striped kite, which is being flown in a grassy field."}, {"question_id": 734, "height": 427, "width": 640, "image": "000000017959.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, transparency", "region_anno": {"bbox": [240.52, 400.89, 23.63, 20.18], "segmentation": {"size": [427, 640], "counts": "hlT34U=3N1N2M3N3N10001O000000000010O1O2N2N1O2N3L3K[\\l4"}}, "object_label": "backpack", "attribute_label": ["color:gray", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque"], "control_dims": "color, material, transparency", "answer": "The backpack in the image is red and black, and it is lying on the ground. It appears to be a large, possibly a duffle bag, and it is positioned in the grass."}, {"question_id": 735, "height": 427, "width": 640, "image": "000000038829.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [399.9, 151.48, 86.3, 84.92], "segmentation": {"size": [427, 640], "counts": "TYZ53W`23nlM0O1YDNU:2\\EK[O:V;K\\EOYO=X;D^E0WOa0X;@`Ej0^:VO_En0a:RO^En0b:RO^Eo0a:QO_E?CAn:1]E>H_Ok:4\\E<M^Of:7]E:O\\Od:;ZE;Y;FcD=^;E_D:a;\\O_D1M:NEg;2]DONb0d;A]DMOa0d;D\\DK0`0e;0[D0e;0[D0e;0ZDOh;0YD0f;2YDNg;2YD@M5k;<WD_ON5l;;VDLl;3TDLn;4QDJR<4PDJR<6mCIU<MiCN24W<JkC2M2[<KhC3N01J\\<7dC0OIi<4UCN0Ok<;MCZC=f<DYC<g<5N100100]O^C:R=G2Odj00ZUO4ILRC6P=1O1VCHb<6;O2Lee11\\ZN0O100001N[fQ2"}}, "object_label": "motorcycle", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:tan", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "transparency, material, texture, length, color, pattern", "answer": "The motorcycle in the image is a silver scooter with a woman sitting on it. The woman is wearing a blue shirt and appears to be riding the scooter down a flight of stairs."}, {"question_id": 736, "height": 640, "width": 427, "image": "000000105455.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [190.2, 155.6, 29.1, 58.5], "segmentation": {"size": [640, 427], "counts": "nXf3i0Vc06I5L5L3M2N2N2N2N2N1O101N1001O1O001N101N2O1N3L3N3K6K5J9ES^R4"}}, "object_label": "clock", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "color, transparency, pattern, cleanliness, length, size, material", "answer": "The image features a large clock with a red and blue face, prominently displayed in the scene. The clock is positioned in the middle of the image, and its face is visible from various angles. The clock's hands are visible, indicating the time. The clock is mounted on a wall, and its design gives it a unique and eye-catching appearance."}, {"question_id": 737, "height": 480, "width": 640, "image": "000000112298.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [167.42, 396.6, 73.68, 74.83], "segmentation": {"size": [480, 640], "counts": "Vc`27f>4L5M2N2M3N1O2N101N1O2N2N101N100ATOiBl0U=YOiBf0U=b002O0O200N010000VOkBJV=o00M2BhBWOY=h0iBRONJZ=U1hBQO[=P1dBPO[=[100O10JfBfNY=a100O01000000000O0101N10000O2O000O2N2O0O2N2N2N2M3N3M2M4M3K5L4C[Sk5"}}, "object_label": "tennis racket", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "length:short", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "transparency, cleanliness, size, pattern, texture, pose, material, color", "answer": "The tennis racket in the image is black and white, with a black handle. It is being held by a person, who is wearing a red shirt. The racket is positioned in front of the person, with the handle facing the camera."}, {"question_id": 738, "height": 480, "width": 640, "image": "000000112298.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, pose, state, texture", "region_anno": {"bbox": [329.05, 131.57, 42.97, 77.64], "segmentation": {"size": [480, 640], "counts": "bhk41m>4N1O1O2kAI06]OKP=>WCI28g<^1N1N2O1O1O100O1000000O10000000000000000O02O0nMYCl1g<RN\\Cl1n<N3M4L1O001O8H9G1O1N3Laol3"}}, "object_label": "bottle", "attribute_label": ["color:black", "length:long", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The image features a bottle sitting on a table, which appears to be a coffee maker. The bottle is placed next to a coffee maker, and it is likely that the bottle is used for holding coffee grounds or other ingredients for the coffee maker. The bottle is positioned in the middle of the scene, and it is surrounded by other items on the table."}, {"question_id": 739, "height": 480, "width": 640, "image": "000000126226.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [362.83, 175.59, 61.37, 19.93], "segmentation": {"size": [480, 640], "counts": "o`W51j>1WA3e>500O1O10000O100O1O1O100O010O10000O1001O2N1O1O00001O0010O000100O01O00001O0000001O000000001O00000000000O10O1O1O10000O11N10O10003L3M2O0O2OSeS3"}}, "object_label": "baseball glove", "attribute_label": ["cleanliness:clean/neat", "color:brown", "length:short", "material:leather", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size, pose, cleanliness, transparency", "answer": "The baseball glove in the image is red and white, with a red leather exterior and a white interior. It is placed on top of a pile of red and yellow leaves, creating a visually appealing contrast between the glove and the leaves. The glove appears to be a catcher's mitt, which is designed to catch fast pitches and provide extra padding for the catcher's hand."}, {"question_id": 740, "height": 480, "width": 640, "image": "000000527528.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [300.54, 224.14, 209.86, 68.06], "segmentation": {"size": [480, 640], "counts": "VZ]44k>3M3N2N1O1N2N2O1O1O1O1O001O00001O01O1O101N00001O0O100000000000000000000000000000001O000000010O000O10000000000000010O000000001O000001O01O2N1N101O00001O001O00001O00001O00001O0001O010O000010O00O2O001O010O00010O01OO2O01O0000010O01O001O01O0010O1O01O0010O010O01O10O1O01O1O01O010O010O010O00000010O0000100O00010O01O010O00010O01O01O010O01O010O001O01O01O00001O01O01O00010O01O01O001O0000010O001O01O00010O00011N10N1O2O010OQRn1"}}, "object_label": "kite", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:yellow", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "color, texture, transparency, size, material, pose, cleanliness", "answer": "The image features a group of colorful kites flying in the sky. There are at least five kites visible, each with different shapes and sizes. The kites are spread out across the sky, with some flying higher and others closer to the ground. The kites are positioned in various directions, creating a lively and vibrant scene. The sky appears to be clear and blue, providing an ideal backdrop for the kites to soar and enjoy their time in the air."}, {"question_id": 741, "height": 480, "width": 640, "image": "000000527528.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [177.28, 324.98, 35.8, 32.48], "segmentation": {"size": [480, 640], "counts": "[hc27g>3N3N1N3N2M2O00DiAOW>OjA2V>NjA2V>OhA2X><O0100O10100O3M3M1O1N4L1O1O001O010N10001O1OmXX6"}}, "object_label": "kite", "attribute_label": ["color:orange", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "material, pattern, color, texture", "answer": "The kite in the image is large and orange, with a unique design that resembles a large orange banana. It is flying in the sky, possibly in a field or an open area."}, {"question_id": 742, "height": 480, "width": 640, "image": "000000255165.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [420.61, 373.58, 39.97, 41.81], "segmentation": {"size": [480, 640], "counts": "dgU63l>2N3M2O001O1VO0bB0]=3aBN]=4bBL^=5aBK^=7`BJ`=9\\BHd=j00001O000O1001O000000000000001O00001N101O1O1oNhB7R>O0O2O1N2N[Qc2"}}, "object_label": "cup", "attribute_label": ["color:white", "length:long", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material, transparency, length, size", "answer": "The image features a white coffee cup sitting on a wooden table. The cup is placed on a coaster, which is designed to protect the table from heat and potential damage. The cup is positioned in the center of the table, and it appears to be empty. The wooden table provides a natural and warm setting for the coffee cup and coaster."}, {"question_id": 743, "height": 480, "width": 640, "image": "000000255165.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "cleanliness, color, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 286.74, 162.88, 140.23], "segmentation": {"size": [480, 640], "counts": "b9f1Z=009G5J7J5K5K4L2N0O10O1000O2O0000001O0O2O0UDSMc;m2]DSMc;m2]DUM`;l2`DTM`;l2aDSM_;k2cDUM];k2cDUM\\;l2dDTM\\;k2eDUM[;k2fDUMY;k2cDTMNN_;n2dDSMMO^;n2fDSML0];m2fDTML0^;c2bDaM2NMO];c2dD`M15[;[2dD_M36X;\\2cD_M56W;[2dD_M55X;\\2cD_M61Z;`2`D\\M0N74Z;g2_DUM84W;h2aDTM85V;g2bDUM2N07[;g2cDZM0K0O];l2cD_M0G[;j2eD_M0H1LU;m2jD_M0H0MV;[3kDgLONU;[3nDfLONR;\\3oDfL0NP;]3nDhL0KR;f3nD[LQ;m2nDmMQ;n1[EkMd:R2aEnM^:R2kEfMT:Y2nEgMQ:Y2oEgMP:Z2PFfMP:[2oEaMVOHk:h2`EYMN7GHk:h2_EZMN7HGk:h2_EYMN:GEl:g2^E[MO;d:U2SEaM90KMN=k:Z2]E\\MO:d:X2_E\\MO<a:Y2`E\\MN;b:Z2_E\\MM;d:X2`E^MJ:g:X2`E\\MI=g:V2aE[MI?f:V2aE\\MH?g:U2]EaMK:h:T2]EcMJ:i:S2]EdMH9l:S2[E[Nd:f1^EWNc:i1^E`MF;m:U2]E_MH;k:V2]E_MG<l:U2]E_MG;m:V2[E`MG;m:U2XE[MJ7O9P;U2VEYNk:g1VETNn:c1kDjM8a0n:e1jDjM9>o:h1hDjM;LFNO3^;Y2bDkM:JHOO1^;e2jD]MG1a;b2gDdM\\;]2`DbMh;Y2VDgMV<n1jCRNZ<j1fCUN_<g1bCWNe<d1XC]NQ=[1oBcNW=KjBP10]O`=NcBNM3e=FeB5F5V>DkA`0]>N1N010O6K4L0O010O100O0010O02OY_?Ofnc6"}}, "object_label": "laptop", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:open", "texture:smooth/sleek"], "control_dims": "transparency, texture, state, pose, color, cleanliness", "answer": "The laptop in the image is a small, white Dell computer. It is placed on a wooden desk, surrounded by various items."}, {"question_id": 744, "height": 480, "width": 640, "image": "000000255165.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "length, material, texture, transparency", "region_anno": {"bbox": [122.0, 270.0, 517.0, 209.0], "segmentation": {"size": [480, 640], "counts": "nci11o>1`e<OVRG0XXL3OOXm00gRO30N1O1000UA29Nn=NiAh0V>]OiA9Y>FhA010Y>OgA10OZ>0gA20KZ>1gA0M0fm00UA3ELaA>ODV>OiA?0C0NS>0mA?0B2NQ>1nA107[>GgA016`>J_A2MOd>O_A1N0ak12`TNNO1^>4aAM0O7NR>2hA01Ng>0mY31]UMOcT<0aVE2fUNOSl:0dPEOcG0]81YP3OPSM20NV[20Sfa00hn[O0000001OO10R?0URO2`>O^A5NK^>OdA:b>00OKGcA111[>O>000JO\\A3c>N[A3d>N\\A36MR20d9OTD46NR>MiA52KN4U>LkA52KN4\\>OeAM12[>0dAN20S>0oA1\\>1cAO]>1`A22OR>;kAHNLf=NbBn0l1UOY9MkDb0IGS2He9a0YDCNLS>>oAGT>8lAH0JP>>PBHOLP>;SBGNNo=;SBGNNn=<TBEOOm==SBD1Nl=2PB91G3Nm=1oA92I1Mk01Q<OSC90M3Ie03Y<7oBN1Jf01Z<8oB4e0D]<2oBLO2O>>AD4g<0]CLK?=AC3j<2ZCKL400>KB4k<2YCKO0N5<KB3l<2YCJ7OE79a0GXOY<8kCH;a0@<Y<[OkCJ;?A;Z<\\OjCMOK3a0L6MZO;OJ0b;8^DM8:CB3e0:[OHOb;9]DL=5@H3<ME=OENd;9^DK=5_OI40M50J=2CMe;8_DL;6AG95GL=O_;6XDM8LC;<MEI107Oe;5YDN8?D^OO8NJ1O71f;2ZDM89@L2J09MI2N66JLf;1UE6UOM1J0>3MKId;0YE?UO]O0`0O4c;_OgDM54@82D0`0N10Ac;1hDM=;ZOE160MM>j;@\\E:SOJ00FM14i;JaD0e06ZOO1NGN04h;KbD1a06]OK4OM1n;OdD6NJ]OOJ1Y<ObD7VOI63ONO0K0Y=5gBK72N2JNOO2N10c;1eE5gNK72M3KMOO2O00a;2hE4fNJ21O15=IB2Na;3iDN`0;WOF0050I;g;GcDLc0:VOHOOc<2eD3oNJc<2^D4n;KTD0dN0X=OZD1U=O[A2R=N[D0cN3Q=MYC0c02RO2`=N\\COUO4_1MY:1RENVO6]1K\\:0QEOo00R:OPE1n0OS;1n10001Oam00_RO000]A1c=ObB0J2LNo<2VC06OG1IO01T=0UC08NF1L0U=0QC090DON1T=0PC1:OZ=OUB2N0d00X=OTB6f0OJN`<LRC6f0MH2`<KRC6g0KG5e=K]B3Z>MTO0QC4i=O000001QN1kDOU;NUCNa19Y;IjD8n<1O100000O100E^A8k<GjD1[N92F[>=eAC[>=eACf<0kD=^NDf<3iDM`N:0Ff<5iDJcN=c<JjDIbN<f<KhDJaN;g<KhD8X;HhD8X;I\\CHV1a0\\;G^CHV1a0\\;H]CGW1a0\\;H\\CHW1a0^;KaD5O^OY:=gE5I@TON_;9eE9HASOM`;9eEIjN;n0Id:3_DHP1a0MFb:J`D7e0GDc0H]Og0:g:HaD8b0HCNLc00]Og0;f:4TECGa0H]Og0:g:5REBJb0E_Og08i:3REDIc0D^Og08k:3QEE]O11i0b0Co:NmDCC2No0a0AQ;_O^D9`0JAm0`0]O@Bb;0aD7<LCm0=^OW;C\\D6d0j0I]OW;C[D6f0m0E_OU;^O`D6f0m0E@S;JbDCa0Q1L]OQ;AbDc0b0>K]OR;B`D?k0?VORO31N;`;5\\E_OSOa0ND1N0=g;0hD@B475KHNe0O\\Oi;>fD@C4551:i;M^D@D424KI5:JG?1CN\\;7dDJ`0NB424KI5?JA94IL^;3ZELYO620NL1c00Dc;GUE0WO71N1MNd0ODc<F^C70M3OMb03]OK1c<M^C5203NKb0;DT<ITD0_Ob09El<IlBb06HU;DSF5cN?L\\O3=a<CfC6H`0NZO3=`<DgC1Do06\\OS=b0nB]OT=a0mBUOI5Z=f0mBUOJ1[=k0kBTOH3[=k0hBQOO8X=h0iBQON7a<GUDk0YOWO60K2c<NSDg0DYOGOd<0lC1_Oh0:WOH1b<OaCO3R1OoNM1`<NlCR1OQOj<l0VCTOc<NQCn06QOJ3o<NQCn06QOJ3n<OSC[1MeNY=l0gBTOO41K[=a0cB@a01S=<^BA`03X<NmC2YO72Fa03U<O_CO62C72Fb03S<O`CN82A91Eb04P=;QCD\\ON30Z=>nBAL3IN30Z=>lBCM5MJi<O\\C1M=3GK3OJ]=;jBCO8IJc=8nB2S=MRCM^<JYC;8K_<JUC`0:D]OLT=1TC;`0F`<0PC97EB20O\\<O[D3_O88KBK[<0mCO25J7<Mk;HmC104J7?Ki;JnCN26H6b0Kd;KWDOE2N6MIg06_;I[D0D1N8NGg06T<IZC2L70Gg07\\<KmB70Gh05]<KmB8c>N2N01O0aA0n=0QBLT>2lANU=0]COWO180T=1hBN;1BO72k<NPC6NJ=2CO10N2R=MQC2e0NZO010N2Z=OoC0R<OTC071]<0oBO=11O@17O_<3[CMN1:17O^O36No:OYF2eNM>1BO=2INk:4WF1\\OK]O1<0f:0PE3U11ROKJ0M1<OR;3iE2hNK320NN1Q<2VE1iNL22`<1dD3iNJ40Q<4QDNQ15hNI_<5hCNIOo0;_;IiC5g03_;IhC6h01OD^:5kD4k02MC_:6hDOT10hNM^<4fCOT10iNK^<6dCOV1OhNN\\<6`C2\\1JhNN?NY;c0_EBiNM]<8REKbNN[<7REKcN0Z<5QEMfNMh0N_:8SFNeNMg0NFNV:9dFFfN74Nf0N_OMJ1c:8eFGeN74MY<5VEJaN1Y<4WEK`N1Y<3XEL_N1W1LkN0^:7QGKaN1^1NQ90YE2g1OcNOZ14Q9K^E1c12dNMV10cN6a:J^E3b12eNLU11cN4d:J]E4]16iNIS18[9E\\E4^1492Q9KhFN7N^N0c:6iFK41]90lDOa126O]90`F31N]NLn:2fF21N^90mDNa13QOM>1VO0I1d:0]ENb11fN0M2i0OVO5_:LRGObNON2h00UO6a:K^EL^14fNNO1g02VO5c:HQG1aNON0h03UO5l<GWC1i02TO6h:FWG2TNOi03SO3NJl:OVG2TNOi03SO6h:JWGMUNOj03RO7i:IWGNSN1j0OVO8g:IUG1SNOS12lNMh:1UG2TNOR1OPONc:3nFNaN2L1Q11i9MiF1ZNN2211o05POHc:1RG0YNO2211o05POIc:0RGN`N3L1o00XOLZ:2]G0TN0n01ROOK0b:0VGN_N2N1l01RO5_:HVG0_N1N1l01QOOM1d:MUG0_N1N1l0OnN=c:BVG0`N0OOP1>[9DTG1\\NONO7Oo0?\\9CaEN]13`N57Ho0?\\9C_E1^10`N77Go0=^9FQGO[N77GP1=]9EQG<bNAQ1c0jNAV:N^G<K>f8VO_G0[NO13_1g0g8WO^GO\\N002`1h0f8WO^GO]NO02_13^N?W:_OkGNA3]N`0W:_OfGOJ1ZNa0V:@_GL\\N4d10[N`0W:@\\GN]N2e10[N`0W:_O]GO\\N2e1f0c8XO^GN^N0b1j0c8WOiGOUN0P1i0S9XO\\GOaN011o0h0S9XO\\GOaN0O3Q1f0S9XO\\GO`N102Q1g0U;XOjCOR1i0R;ZOYEe0i:XOWEi0i8VO]G0XN1T1OVOj0Q<YOVEf0j:[OUEL_Ne0l;\\OaD4W1?W:^ObD3V1`0W:^OcD2S1K`Ne0j;^OcD2W10[N8a;CfD4M1N1d1NZN9`;FdD2O;NAb11^N;_;EeD3N`0^1No9_OeD3Mb0\\1\\OcN<_;DeD1Nc0[1[OcN=a;C`DON242M9b11o9D_DN1033M9a11o9F_DL2026L8a10o9GeDKN8M5a1E_N7`;LeDKN8M64BU12gN64"}}, "object_label": "book", "attribute_label": ["length:long", "material:paper/cardboard", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "transparency, material", "answer": "The image features a wooden desk with a laptop, two computer monitors, and a keyboard. There are also two mice on the desk, one near the laptop and the other near the keyboard. Apart from the computer equipment, there are several books scattered around the desk. One book is located near the left side of the desk, while another book is placed closer to the right side. The third book is situated in the middle of the desk, and the fourth book is located near the top right corner. The desk appears to be a workspace for someone who uses multiple screens and has a variety of books at their disposal."}, {"question_id": 745, "height": 426, "width": 640, "image": "000000290179.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [176.16, 345.03, 45.57, 19.41], "segmentation": {"size": [426, 640], "counts": "\\oY22V=3N10001N1O2N1O1O2N1000001O0001O010O00001O01N1000010O0O1001O1O1O0O2O00001N101O000O101Oln]5"}}, "object_label": "boat", "attribute_label": ["color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, pose, material, transparency, texture, color, length", "answer": "The image features a large white boat floating on a body of water, possibly a river or a lake. The boat is quite long and has a distinctive red stripe running along its side. It appears to be a passenger boat, possibly used for sightseeing or transportation purposes. The boat is currently empty, with no passengers or crew visible in the image."}, {"question_id": 746, "height": 500, "width": 333, "image": "000000301376.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [65.39, 0.36, 45.79, 131.53], "segmentation": {"size": [500, 333], "counts": "\\gP17`011O10LKQ<>iC1O03NJLR<U3PDeLc;\\3[DeLe;]3YDcLe;_3[DaLa;c3_D]La;j3100J]DZLd;\\3\\DhL2Kb;l33TL[Dc3k;PMTDX2l;gMUD10O0h0k;XOVDO010g0k;XOUD0010OO@N<n;4UD0010OO@N<n;4UD10O07MEn;5TD01O05OGl;5UDO0005OGl;5UDO0005OBNIo;`0TD00014NCNIo;`0TD00103OCNIo;`0TD00103OHm;4UD0O004OHm;4UD0O004OHn;4SD00004MJP<1TD00014KLo;NWD01O07ILb>KdACK9a>K`A08LG6`>LdA15MG6`>LdA245X>JdA037Y>IdA037Y>IeA017Z>IfAO17Z>IdA108\\>I_A255[>3eANZ>2fAN[>0fAO\\>OhANng\\3"}}, "object_label": "traffic light", "attribute_label": ["color:black", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, transparency, color", "answer": "The traffic light in the image is a large, multi-faceted sign that displays several traffic lights at once. It is mounted on a pole and is located near a building. The traffic lights are arranged in a way that allows for easy visibility and understanding of the traffic rules. The sign is designed to provide clear instructions to drivers and pedestrians, ensuring smooth traffic flow and safety."}, {"question_id": 747, "height": 640, "width": 480, "image": "000000342006.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [171.24, 503.98, 101.31, 47.0], "segmentation": {"size": [640, 480], "counts": "`d\\35hc04HHc\\O<Zc06000001O0O2O000000000001O01O00000O11O01O00000002O0O01L3000001O0005K2N1O0010O1N1000000000001O000010O1O1O001O01O00001O01O01O0000000001O0001O01O0000001O00000000001OO1000010O00O2O00010O001N101OWSR4"}}, "object_label": "boat", "attribute_label": ["color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "size, color, texture, material, transparency, pose", "answer": "The image features a large boat floating on a body of water, possibly a river or a lake. The boat is quite long and has a distinctive red roof, making it stand out in the scene. It appears to be a cargo or transportation vessel, as it is carrying a large load on its back. The boat is situated in the middle of the water, and its size and presence make it a prominent feature in the image."}, {"question_id": 748, "height": 427, "width": 640, "image": "000000429109.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [306.1, 182.31, 305.13, 102.68], "segmentation": {"size": [427, 640], "counts": "^\\o3:1=W<?M001N1000000000000000O1000000001O00O10000001O0O1000001O0000000000001O0O2N1M3N2O102M1N2N2O2N100O101O1O001O0O2O1O0000001N2O2N4M1N;E3M001O0000000000O010O1O100O100000000O1O1000000000000000000O100000000000000000O10O100000001OO1000000000000000O10000000000O100000000000000000000O10O1000000000000O1000000O0100000000000000000000O10000000000000000O1000O1000FbEeM`:Y2:@PE`NU;]1PE^NS;b1;O100000000001O002N1O2N000O101O3M1O2N4L2N1TEhMc:Y2ZEiMf:^20001O00000000000001O00000O100000001O00000000000O2O00001O1N201O00O100O001O00000004L00O1001N2OO010O02N100O2M3L300O2K4L5Aa0I7I9\\OV^50RUJ054K14KP<6lCe0k;UOXDU1f;nNXDS1g;90O01O0N3N2O1O1O1000000O010O1000O2O1N2Ie0A?@_f<"}}, "object_label": "bus", "attribute_label": ["color:red", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "length", "answer": "The image features a red and white bus driving down a street, with a bicyclist riding alongside it. The bus is quite large and occupies a significant portion of the scene. The bicyclist is positioned close to the bus, maintaining a safe distance while sharing the road.\n\nThere are also several other people in the scene, some of them standing or walking along the street. A car can be seen parked on the side of the road, and a handbag is visible near one of the pedestrians. The overall atmosphere of the image suggests a busy urban environment with various modes of transportation coexisting."}, {"question_id": 749, "height": 612, "width": 612, "image": "000000173091.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, pattern, texture, transparency", "region_anno": {"bbox": [9.05, 10.0, 590.85, 593.75], "segmentation": {"size": [612, 612], "counts": "32i01\\a02m]O12X1MhN4Lb`0U>[_OQB0O3L20N2O10O3NM3O11M4M01i0bb0_O01M2O1O1O02K4OO2UJAjCO0055\\O10O1KN213010O1KO105O01K54K1O;?_O02FOL0N62K40JO21N0;0FO;O50F10O0100O1O00100O1L31O100O3NO:MJO0104KLV7OQJn5gNWJ211NO2=KC00O100000O014k8LTG24NM0O100:^7EQI1F0LN6?IH3Q3Lb00kL1]O5OL050J<W:R2nEbM1000O010L400O1O01O2ON1014Kd0O1;`9l1bGiMZN10OW10d0:W8P2jKPNT4S2jKnM_JES9`2]LkMT4V2lKcMRJNS:_2lKaMZ4b2dK_MSJOo9g2lKaMcJFl8l2`L^MQ4d2nK\\MQ4f2nKZMfJFh8S3aLWMgJFg8V3_LTMkJFc8Z3WGgLGOQ54nJOb9\\3dFlLj4Hg4^3ZFQMl4AiKMV8\\4nKgKUK1a0LX8c4oKgKhKFW8f4PLdKiKFV8g4QLcKiKFU8i4QLaKjKFT8k4PL`KlKER8o4PL[KoKFP8P5QLTK_KO`0MP8P5RLSKTLMi7R5RLQK_K0`0Mm7U5SLUKoKFl7X5TLRKPLFk7Z5TLPKQLFk7Z5TLPKQLFj7[5ULoJQLFg7_5VLlJSLEf7`5WLdJcK0h8]5fKbJdKOe8`5gK`JfKOa8c5iK_JcK0`0M`7e5]LeJT4]5kKcJS4_5mKaJR4`5nK`JP4b5PL^JSLFX7o5dLUJdK0[8k5RLTJeKOX8o5RLRJgKNV8Q6SLQJfKO?NS7T6hLoIdK1a0LQ7V6jLTJTLFQ7W6kLSJf3n5ZLRJTLFn6Z6nLPJTLFj6^6RMeIdK1a0Li6^6RMeIeK0`0Mh6_6SMdIfKOg7`6cL`IhKN>0c6c6WM`IeK0`0Mc6e6WMdIiKG70f6i6YMaIiKF80e6j6ZM`IiKF80c6m6[M]IjKF80a6P7\\MYIYLGX6U7]MnHjK1a0LW6V7^MmHkK0Z7T7jLlHY3X7fLhHoKMT7^7lLeHmK14L70W6`7`MjHQLFl6a7RMiHRLFk6b7SMhHRLFi6e7TMeHSLF80R6h7bMaHbLGk5j7bMYHRL1m6i7PMVHULOj6m7PMTHU3n7jLRHVL0`0Me5T8dMVHfLFd5W8eMSHZLF]6Y8XMQH[LF\\6[8XMoG\\LF80e5^8fMlGjLF^5b8fMaG\\L2`0K]5c8gM`G\\L1_6a8TM^G_LO[6f8UM[G`LOY6i8VMXG_L1a0LT5o8kM[GPMFU5P9jMZGg2g8YMYGe2j8ZMVGRMFP5W9mMlFcL1a0Lm4Z9nMiFdL1o5Y9\\MfFfL0n5Z9\\MfFi2\\9VMdFgL0`0Mf4e9QNdFYMGd4g9SNcFkLF^5h9gMbFkLF]5j9gM`FlLF[5l9iM^FlLF80c4P:XNZFZMF]4Q:YNRFjL1`5m9fMRFkL0\\5R:hMnElL0[5S:iMSF\\MGV4X:^NRF[MFV4Z:^NPFoLFo4[:RNoEoLFn4\\:SNnEn1V:RNjEm1X:RNhEm1Y:SNgEl1Z:TNeEk1]:UNcEf1b:ZN_Ed1b:\\N^Ed1b:\\N^Ec1b:^N^E_1e:aN[E^1f:bNZE\\MF\\3T;XOVEZ1j:fNUEZ1k:gNUEX1k:iNVEZMFW3V;_OUEZMEV3W;@UEYMDV3W;CTEm0m:SOSEWMES3Z;EREXMDR3W;JTEUMEP3X;KSEf0n:ZOREd0o:]OQETMEj2X;7SEoLEi2Q;`0ZEgLEh2R;b0YEXLE90l2R;d0YEWLE90j2S;g0XEcLEd2S;j0XEcLE`2T;o0WEaLE_2T;Q1VEBh:`0XE_Oh:b0YE]LE[2R;[1YEZLEY2R;_1YEXLEY2Q;`1[EiKD90]2R;a1ZEVLDV2S;f1YETLDS2U;j1VETLEQ2U;l1VEeNj:\\1VEaNk:a1UE^Ni:e1XElKDl1R;[2ZEiKDk1R;]2[EZKC:0n1R;_2[EYKC:0l1S;b2ZEjMi:W2VEiMi:Y2WEfMi:[2WEdMi:]2WEaKDY1\\;W3PE`KDT1`;]3mD^KCR1b;a3kDPKC:0T1b;c3lDnJB;0Q1d;g3jDmJB;0l0l;i3aD^KCg0Q<h3[DfLi;Y3WDfLj;Z3VDcLn;\\3RDdKD=]<n3oCeKD=_<l3nCfKC=a<l3lCgKC;c<n3jCZKC:0=e<n3hChKC8h<o3dCaL`<\\3`CbLb<^3]CcLd<\\3\\CoKE2Q=n3[CoKD2T=m3XCQLD0W=n3UCeKD903X=o3UCdKC:03X=o3UCdKC:02Z=o3RCSLDN\\=m3PCULDM_=l3lBXLEL_=l3lBXLEKa=l3jBYLEJc=l3hBZLEIf=k3fB[LDJg=j3eBoKD90Mh=k3dBoKD90Mi=j3cB]LDEn=m3]B_LFBP>m3ZBaLk=_3UBaLk=_3UBaLk=_3UBaLl=^3TBbLm=]3SBcLF@T>m3VBcLFAS>l3XBbLEAT>m3VBcLm=]3SBcLn=\\3RBdLH@Q>l3WBdLFBS>j3WBdLFCS>h3WBeLFCT>g3VBfLFDS>f3WBfLEFS>d3XBYLE80LR>c3YBfLEGR>c3YBfLEGS>b3XBgLEHR>a3YBgLEHS>`3WBiLFHR>_3YBhLEIR>_3YBhLEIR>_3YBhLEJQ>^3ZB[LE80OQ>^3ZB[LE800Q>\\3ZBiLEKQ>\\3ZBWMf=h2ZBYMe=g2[BYMe=g2[BZMd=f2\\B[Mc=e2]B\\Mb=d2^B]LE805m=V3^B]LE806l=U3_B]LEk0m=g2^B^LEl0l=f2_B_Ma=a2_B_Ma=a2_B`M`=`2`B`M`=`2`BaM_=_2aBbM^=^2cB]LDQ1h=b2dB]LDQ1h=b2dB]LDQ1h=b2dBcM[=]2dBdM[=]2eBdMZ=\\2fBeMY=[2gBfMW=[2iBeMW=[2iBfMU=[2kBeMU=[2lBeMR=\\2mBeMS=[2mBeMS=[2lBgMS=Y2mBhMR=X2nBiMP=X2QChMn<X2RChMn<X2RCiMm<W2SCiMm<W2SCiMm<W2SCjMk<W2TCkMk<U2UCkMj<V2VCkMi<U2WClMh<T2YCkMf<V2ZCkMe<U2[CkMe<U2[CkMe<U2[CcLEg0n<g2\\CcLFf0n<g2\\CmMc<S2]CnMb<R2]CPNa<Q2`CbLFi0j<e2aCaLEk0h<e2cC`LEk0h<e2cC`LEl0f<e2eC_LEm0e<d2eC`LFl0d<e2fC_LFm0c<d2gCoMg6QN\\NQ4lJPNb6UNaNk3nJ^LFn0^6VOnN^3nJ^LFo0V6\\OUOX3PK\\LEP1R6@YOT3PK\\LEP1Q6AZOS3PK\\LEQ1l5D^OP3QK[LER1a5MHg2RKZLES1\\50Mc2QKPNQ5^OMc2RKoMn4A0`2RKPNl4B0_2UKXLEU1P596Z2UKXLEV1m4:8Y2VKWLEV1k4<9X2WKVLEW1j4;8Z2YKTLEX1i4:9Z2YKTLEX1h4;8[2[KlM[4K8[2\\KlMZ4J8\\2^KjMY4K8\\2_KnKFX1_4c07[2eKiKEZ1\\4d02a2mKaKE[1X4g03_2PL_KE\\1V4g01b2TLnJE80b1T4g01c2VLYKE]1R4j0Oc2ZLVKE^1P4j0Lg2^LRKF]1P4k0Hi2bLPMd38Ii2cLPM`3;Gj2iLiJF`1e3R1Bn2TM_JEa1c3V1YOS3_MVJEb1b3U1UOX3dMdIE80g1a3W1PO[3jM_IE80g1a3W1oN\\3kMkIEc1^3X1SOY3jMlIEc1\\3\\1UOS3jMSLP3l0VOP3iMVLo2f0hLdLc2^6gMXLk2Md0d3aLXJEf1Q3=V1]3TL`JEg1o28^1`3nKaJEg1m22i1e3eKUJE80m1k2MR2g3^KdJEi1i2_Of2P4lJhJEj1g2]Om2n3gJkJEj1g2ZOQ3P4cJYM[2fNT3P4aJZMY2dN[3Q4\\JnJEl1`2VOc3n3XJPKEm1]2UOj3l3TJaMP2dNm3k3TJaMn1cNo3l3SJdJD90T2X2QOW4k3lIhJE80V2U2nN_4i3gIkJE80W2S2mNd4g3dImJE80X2Q2lNh4f3bInJE80X2P2kNl4f3^I]KFS2l1iNU5f3ZI]KEU2h1kN[5a3XI_KEU2f1lN^5`3WIRKE80Z2e1mN`5^3VISKE80[2d1kNb5_3UISKE80[2c1hNi5`3oHbKEV2b1fNo5`3jHdKEV2a1fNQ6`3iHdKEW2_1eNU6_3fHfKFW2]1cNY6`3dHfKFX2Z1`Na6a3`HfKEZ2V1`Nh6_3]HcNj0nMj6_3\\HdNh0kMo6a3YHdNg0iMT7b3UHfNd0gM[7b3QHhNb0fM^7b3oGiNc0bMa7e3lGiNa0bMf7d3iGiNe0XMj7o3bGfNh0TMl7U4\\GdNl0UMj7V4ZGdNS1lLg7`4VG_KEo2`1PMf7b4UG_Nd:`1\\E[Nj:d1VE[Nk:e1UEYNm:g1RETNT;l1mDQNV;n1jDoMY;Q2gDnMZ;R2fDbKEV2g;W2eDbKDU2i;Y2cDbKD90^1j;g2aDPLEX1l;g2_DQLEW1m;h2^DiMc;W2]DgMe;Y2[DeMh;Z2XDeMi;[2XDdKDk1U<a2WDdKDk1U<a2WDdKD90T1V<o2VDQLDo0X<o2SDSLEn0X<o2SDSLEm0Y<P3RDSLEm0Y<P3RDSLEk0[<R3PDSLEj0\\<S3PDRLDk0\\<S3PDeKD90o0\\<S3PDeKD90n0]<T3oCeKD90m0^<U3mCfKE80l0`<U3kCgKE80k0a<V3jCgKE80k0`<W3kCfKE80k0a<V3jCTLEf0a<V3jCTLFd0a<X3jCfKD90j0b<W3jCfKD90j0a<X3kCeKD90j0b<W3jCfKD91h0b<Y3iCfKD91h0b<Y3hCgKE80i0c<X3hCgKE80h0d<Y3gCgKE80h0c<Z3iCeKD91f0c<\\3hCeKD91e0d<]3gCeKD90f0e<\\3gCeKE8Og0e<\\3gCeKD90f0e<\\3gCeKD91d0e<^3fCeKD90e0f<]3fCRLDa0f<]3fCRLDa0f<]3fCRLDa0e<^3gCQLDa0d<_3hCcKD90e0d<_3hCcKD90e0d<_3hCcKD90d0e<`3gCcKD90b0f<c3fCbKD90b0f<c3fCoKD>f<c3fCoKD>f<c3fCoKD>e<d3gCnKD>e<d3gCaKD90b0d<e3hC`KD90b0d<e3hC`KD90b0d<e3hC`KD90b0d<e3hC`KD90a0d<g3hC_KD90a0d<g3hC_KD90a0c<h3iC^KD90a0c<h3iC^KD90a0b<i3jC]KD90a0a<j3kC\\KD90b0`<i3lC\\KE8Oc0`<i3mC[KD9Oc0`<i3lC\\KD90a0`<k3lC[KD90a0_<l3mCZKD90a0^<m3nCYKD90a0^<m3nCYKD90a0]<n3oCXKD90a0\\<o3PDWKD90a0\\<o3PDWKD90b0[<n3RDVKC:0b0[<n3RDVKC:0b0Z<o3SDUKC:0a0Y<R4SDTKD90a0Y<R4SDTKD90a0X<S4TDSKD90a0X<S4TDSKD90b0V<S4VDRKD90b0T<U4YDoJC:0b0S<V4ZDnJD9Oc0S<V4ZDnJD9Od0Q<V4\\DmJD9Od0Q<V4\\DmJC:1b0o;X4]DlJC:0c0o;X4^DkJC:0c0n;Y4_DjJC:0d0k;Z4bDhJC:0e0i;Z4dDgJD9Of0g;\\4gDdJC:Of0f;]4kDmJ_Of0e;^4lDlJ_Of0d;_4jDaJC:0e0`;c4lD_JD90e0_;d4mD^JD9Of0`;c4mD^JC:0e0^;e4oD\\JC:0f0Z;g4SEYJC:1e0V;k4VEVJD9Og0U;l4YESJC:Og0R;o4\\EPJC:Og0Q;P5]EoIC:0g0j:U5bEkID90g0g:X5eEhID90h0d:Y5hEfID9Oi0b:[5kEcIC:0h0`:]5mEaIC:1h0Z:a5RF]IC:1h0V:e5WFXIC:Oj0U:f5\\F`I_Ok0Q:h5`F]I_Ok0o9j5aF\\IAi0j9o5bFnHC:2h0h9Q6cFmHC:1j0d9S6hFiHC:0k0b9U6kFfHC:1j0_9X6nFcHB;1j0Y9^6VGhHAj0V9a6YGeH@l0U9`6\\GcH_Om0R9c6^GaHAk0P9e6_G`HBk0j8h6eG]H@l0h8k6gGYH@m0f8m6jGVH@n0b8o6nGSH@o0_8P7QHQHAo0Y8T7VHmG@P1Y8T7XHkG_OR1W8T7ZHjG_OS1U8T7\\HiG@S1m7gNRH]8`0jGBR1g7]7hHaG_OT1g7^7iH^G@T1c7b7kHoFB;0U1^7e7RIVG@V1n33bMj7POmF@W1g3b0WMb7BeF@X1b3[;nL]C@X1^3_;RMYC@X1]3`;SMXCBW1X3b;WMWC@X1W3c;YMUC_O[1U3b;[MSC@[1T3c;\\MRC@]1P3c;`MPC@^1m2d;cMnB@^1l2e;dMiDZ2X;fMlB@`1h2e;hMkBAa1d2e;kMjBBa1`2f;lM_BB:0d1`2e;mMjBCb1^2e;oM\\BC:0g1Z2e;TNYBB;0h1U2g;\\NaB@i1o1j;`N]B@m1j1i;fNZB@o1f1i;jNXBAo1c1j;lNWBBQ2\\1k;oNWBDT2=eMNV>0RBDfa0<Z^ODfa0<Z^ODfa0=l]OC:1ia0?W^OAia0?W^OAia0?W^OAia0?W^OAia0<Z^OEea0:\\^OEea0;[^ODfa0<Z^ODfa0=Y^OCga0>X^OBha0`0V^O@ja0`0V^O@ja0`0V^OAia0=Y^ODfa0:\\^OFda0:\\^ODfa0<Z^ODfa0<Z^ODfa0=Y^OCga0>X^OBha0`0V^O@ja0`0V^O@ja0`0V^OAia0<m]OC:2ha0:o]OD91ia0;[^ODfa0<Z^ODfa0=`03M0001Oh]OAja0`0V^O@ja0=l]OC:1ha0=n]OBS91SGO71n1:eMW10eN0J015O100O010Oi1>QNBV41lK8NP50iJh0O^O0O1LON70U40jK2N010O1KO150I?0@;3G^b07800?X]O^O00100O1KN22NM2600Oi?m1Q@VO1RO1O1LM13NN21OO0510O10LON160LON25OMON21OO140MOO15O01LOO06Oi9[1PFlN100O010O100KO0d?P1\\@UO1O1L31KN25OM9Nd?n1Q@mN0F0A2NY?W4e@kK7NW>`4bAeK3N2O01LM133N200O010OO3OO2Ne:]4VEhK100O010O1O010O1O01O10O1O1N]:T4]ESL2N10O0100O10O010O010O1O02N1O1OR:S4hESL1O1000O0100O010O10O001O02O0O1O1Oi9R4RFSL10O010O10O1O010O10O1O01O100O100Oe0N]O1b8Q4YGSL10O010O10O1O0100O010O0100O100O003L20N3OO1MY8"}}, "object_label": "dining table", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "transparency:opaque", "pattern:striped/lined/pinstriped", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The dining table in the image is white and features a sandwich, a cup of coffee, and a pastry. The sandwich is placed on the left side of the table, while the cup of coffee is positioned towards the center. The pastry is located on the right side of the table. The table appears to be clean and ready for someone to enjoy their meal."}, {"question_id": 750, "height": 640, "width": 480, "image": "000000097585.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "cleanliness, color, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [2.78, 488.85, 58.13, 145.87], "segmentation": {"size": [640, 480], "counts": "Y[48cc06H8I6H8E;F:B>_Oa0E;F;M2N2J6O01000000001O00000O100N2N2N2O1N2M4L3O1001O1N20O01O2O2M1N4M1N2O000001AWLe@h3\\?XLd@f3^?[Lb@^3d?aL]@U2m`0kMS_Ob1`a0_N`^Om0Sb0TOb]ONgc01Y\\OO[\\U8"}}, "object_label": "vase", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:violet", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "size, color, cleanliness", "answer": "The image features a purple vase with a black handle, which is hanging on a wall. The vase is made of glass and has a unique design, making it an interesting piece of decor."}, {"question_id": 751, "height": 426, "width": 640, "image": "000000228144.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, state, transparency", "region_anno": {"bbox": [1.99, 74.98, 213.55, 335.78], "segmentation": {"size": [426, 640], "counts": "Y8:27Z<=O1O1N2M3N2N2O1O1O101N001000O001O010000M3M4SN^NmGe1Q8_NjGd1T8_NiGc1V8_NgGc1Y8^NcGe1]8\\N`Gg1^8[N_Gg1a8[NZGi1d8aNnFd1R9Z10000O1000000O1O100O[NeF]O[9`0iF_OW9;oFDR96TGJk8POmF6<k0f8oN]HQ1b7oN_HQ1`7PO`HP1`7oNaHQ1^7oNbHR1]7oNcHQ1]7nNdHR1\\7nNdHR1[7oNeHQ1[7nNfHR1Y7oNgHS1W7mNiHU1U7kNkHV1T7jNlHV1T7jNlHW1S7hNnHX1Q7iNoHW1Q7iNoHW1Q7iNoHW1Q7iNoHW1Q7iNoHW1P7jNPIV1P7jNPIV1P7jNPIV1P7jNoHX1P7hNPIX1o6iNQIW1o6iNQIW1o6hNRIX1n6hNRIX1n6hNRIX1n6hNRIY1VNfNP81iIX2P6gMQJe2b5\\M^Jk2[5UMeJT3^O^LR4>`L^3PO_LY42hLP4XN\\Lh4DPMW5o2hJQMY5o2gJQMY5o2gJQMY5o2gJQMY5o2gJQMY5o2gJQMY5o2fJRMZ5n2fJRMZ5n2fJRMZ5n2eJSMZ5n2fJRMR2fN_M\\On14SNm4>mLa1g6^NZI`1h6`NXI_1i6aNWI_1i6`NXI`1h6`NXI`1h6_NYIa1f6`NZI`1f6`NZI`1f6_N[I<lM:i8[O[I_1d6aN]I_1c6aN]I_1b6aN_I_1`6aNaI_1^6bNbI^1^6aN^ICoMm1b8aNTHF92oNg1c8aNUHI15WOa1`8dNWHIM5]O]1^8hNUHHK7BY1]8KlGROGX1T8U3K9F;F6I8I6I8I7H7J6I[NUJSLg5m3eJmKU5T4RKkKg4W3fJVLk0>Z4Y3UKTLh0=P4b3WKQLo07i3k3UKoKX11a3R5dLjJ\\3V5kLbJU3]3`KeM_1jNQ3Z3fKmMa1`Nj2S3SKVM`08]O@2e0W7^2jHUM?O^OL3J2g0S7`2kHUM><CNT7c2jHSM?>ALT7U3[IoL@MT7U3\\IoL_OKQ7[3aIiL^OLP7\\3bIgL_OMn6]3cIaL@\\O0f0m6]3cIcLB0k6]3cIVL^O24;j6^3dITL_OKO33a0k6]3dIbLA0l6^3cIbLA0k6`3dI_L@2l6_3dI_L@1m6a3bI]LB2k6c3bIZLC4k6b3cIYLB4k6d3cIXLA5l6d3bIPLCGOd0m6e3aIoKDHMe0m6e3bIPLBFOd0n6f3aIRL@D1d0n6f3bIQL@DOe0P7g3`IhKBO1c0l6g3bIfKAO2c0k6i3bIdKKc0`6l3eIaKKb0a6n3dI_KJd0a6n3SJSLl5n3hI\\KCh0f6l3dIaL[6_3cIhLW6Z3dIoLV6]5F:F4L8H4M5K5J5K5K3O2O2L3L4L2O1N`NQLjIj3h3jNULT1U3CmL:j20VMOe2:XMDf2b0VM_Od2l0VMTOe2V1VMjNh2]1SMdNi2b1TM^Nj2f1TM[Nh2m1RM\\Nd2X6K4L4M2L4M3L5J5L4J7J:Dcf`5"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty"], "control_dims": "cleanliness, pose, state, color, transparency", "answer": "The image features a wooden chair with a cushion on it, placed in a room. The chair is positioned near a wall, and there is a potted plant located in the corner of the room. The chair appears to be old and possibly antique, adding a sense of history and charm to the space."}, {"question_id": 752, "height": 427, "width": 640, "image": "000000463730.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "material, pattern, pose, texture, transparency", "region_anno": {"bbox": [318.24, 188.49, 22.4, 14.93], "segmentation": {"size": [427, 640], "counts": "aVU42Y=2N2N2N000000OoBLm<90O13M2N0000O1N2O100O1O2GSC1UZm3"}}, "object_label": "car", "attribute_label": ["material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The car in the image is a red sports car, likely a convertible, parked in a parking lot. It is positioned in the middle of the scene, with a person standing nearby."}, {"question_id": 753, "height": 427, "width": 640, "image": "000000463730.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "color, material, pose, size, texture, transparency", "region_anno": {"bbox": [82.03, 229.93, 16.7, 25.54], "segmentation": {"size": [427, 640], "counts": "XXS11X=:F:H1O1O000000O2K4O1HVCOk<MYC0k<OUCOn<Oh[Q7"}}, "object_label": "motorcycle", "attribute_label": ["color:black", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size", "answer": "The motorcycle in the image is a black and blue one, with a black seat. It is parked on the side of the road, and a dog is standing next to it. The dog appears to be looking at the motorcycle, possibly curious about it or waiting for its owner. The scene captures a moment of interaction between the dog and the parked motorcycle."}, {"question_id": 754, "height": 480, "width": 640, "image": "000000131138.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [125.25, 111.26, 123.15, 113.5], "segmentation": {"size": [480, 640], "counts": "^Vk13n>1VAOa>2\\A1c>7fADo=<oAGo=:oAHP>;mAES><lADU><jADV>d00O010O00QBYOe=h0YBYOh=f0TBZOO1m=n00000ZBoNk<0_CP1FROh<1bCk0FVOg<ObCc0A^O80d<0bCb0C]O72d<OaCb0D]O75b<LbCc0E[O85b<NVCL6d0J]O98]<L_Cd0JYO;:Y<H`Cm07Eo;^OSD9BDc0=^OAV<3nC1a14j:LeCOe1Oh:2cCOf1Mh:4bCO[>3bAM_>:N1GGkA<T>81O1O1O0O2O1O1OJAkA?U>6001O1O1O000O2O3L2O001O00O100O100000OO2M3N21O2N1O2M2O00O1O1O1O0101O1O0000O1O100O10O01O1O1O1O02O2N1N01O1OHfALZ>OkA1V>KmA5_>01OO1O1O10O10001O2NO1O1O1O0011O001NVQi5"}}, "object_label": "potted plant", "attribute_label": ["color:green", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:rough"], "control_dims": "texture", "answer": "The potted plant in the image is a small, green, leafy plant that is placed on a desk next to a computer monitor. The plant is situated on the left side of the monitor, and it appears to be a decorative element in the workspace."}, {"question_id": 755, "height": 480, "width": 640, "image": "000000135561.jpg", "category": "description", "question": "Describe the refrigerator in the following image in detail.", "dims": "color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [246.98, 278.22, 158.93, 194.37], "segmentation": {"size": [480, 640], "counts": "Pcc3l0P>5L4\\BmNJ0\\=P1[EWOX8b0eGEZ86iGLS87mGJQ87kGMP8[O\\Ej0d2Ko78mGMS83fE@LMMGO84K0h0]:1`E\\2_:fM_E[2a:R10001O000000001O000001XNbElN^:QObEV1NXN54KT1_:U301O001O001TG_KW7R3XGfN7ZNNO14KLg8[5YGZKe8a50VLZGiM4T3b8]O\\Gd0d8^OZGc0e8]O[Gc0e8[O]Gd0d8[O]Ge0c8ZO`G`MJm2e8]OjGbMB1Ok2d8L^G]MNL0k2d8<]GhL3N31NS2_8W1VHhLYOh1a8b1SHjLYOd1d8c1_GbL51NR2_8[1^GdL31NP2a8X1aGhLN1OP2b8W1aGhLN2No1c8V1bGiLM2No1b8V1eGgLL4Mo1b8Y1`GhLL[2d8i3100O1K56J1O001O000000000000000000O1bL\\G?e8_O^G]ONiNd8j1cG<\\8CeG=[8CeG=[8CeG=[8BeG?[8BdG>\\8BcG?]8C^G`0b8o20001O000000000000000000000001O00O1000000000O100000000000000D\\G\\Jd8d5\\G\\Jd8d5\\G\\Jd8d5\\G\\Jd8P60000000000000000000000000000000000O100000001O000001O0O010000000010O00O1PJ\\GS51QKc8k52I\\GPJh8g5<M:F7Kc0\\Oj0^KmD61J0O?3_O5`0IE3KQ1cW]3"}}, "object_label": "refrigerator", "attribute_label": ["color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "material, pattern, length", "answer": "The refrigerator in the image is a white, two-door refrigerator with a freezer on the bottom. It is covered in various magnets, which add a personal touch to the appliance. The refrigerator is situated in a kitchen, and it is surrounded by other items such as a microwave, a bowl, and a spoon. The microwave is placed above the refrigerator, while the bowl and spoon are located on the countertop nearby."}, {"question_id": 756, "height": 281, "width": 500, "image": "000000140840.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [135.11, 172.27, 70.36, 67.63], "segmentation": {"size": [281, 500], "counts": "]RV16_88K1M4M3L3M4M2N2O1N3M2N2L4L5N10010O000010O00010O0000010O0001O00010O1O00010O001O01O0001O01O01O00000001N1N2K5M4J5K5M4J5O2M2L5M4N1N1O2Mah`2"}}, "object_label": "kite", "attribute_label": ["color:white", "length:short", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:open", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, state, material, transparency, texture, length, pattern", "answer": "The image features a colorful kite with a cartoon character on it, sitting on the ground. The kite is made of paper and has a unique design, making it visually appealing. The character on the kite appears to be a monkey, adding a playful and fun element to the scene. The kite is positioned in the middle of the image, occupying a significant portion of the frame."}, {"question_id": 757, "height": 427, "width": 640, "image": "000000520077.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [87.32, 1.76, 344.48, 49.9], "segmentation": {"size": [427, 640], "counts": "cSU1`0k<?A>B3M00000000000000000000000000000000000000000000000000000000000000000000000000000000000000O11O00000000O10000000000000000000000000000000000000000000000000000000000000000000000000000000000O100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O100000000O1O1N2O1O10000000000000000000000000000001O000000000000000000001O000000000000000000O100000000000000000000000000000000000000000000000000000000000000O100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000N20001N2O3M3M5J4M6J3L5Lo[h2"}}, "object_label": "tv", "attribute_label": ["color:black", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "pattern, color, material, texture, pose, state", "answer": "The image features a flat screen TV mounted on a wall, with a green background behind it. The TV is turned off, and there is a remote control placed on the left side of the screen. The TV is positioned in the middle of the scene, and the green background extends from the left edge to the right edge of the image."}, {"question_id": 758, "height": 427, "width": 640, "image": "000000520077.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [119.94, 153.59, 343.52, 55.66], "segmentation": {"size": [427, 640], "counts": "SWb1;o<3M1M3O2N1N2O1N200O1O1O1O1O1N200O1O1O001O1O1O1O1N2O1O1O1O100O1000000001O00O100000000001O00000000007I4L1O003M1O2N003M8H2N1O0000000000000000000000000001O00000000O10000001O0000000000000000000000000000O100000001O002N00000000NFSC:m<2001O1O1O0000O1N2O1000000003M0000O1N20000000000001O1OO100O1001O00O1010N100000O1001O00O1001O000001N11O000000001O00001O000000001O000000O100001O000000000000N2O2O0000000000000000000001O000000000000000O100000100O001O0O10O2O00000001O000000O1000000001O00000000O1O1O1001O000000001O0001O001O0001O01O00000O100000000000O01001O000000000010O01O00O10O10000000000000O1000000O100001O000000O01000000000000000000000001O001O0001OO10O1O2N1000000000BVC;k<21O1O0000000O0110O000001OBElC;T<ElC;b<J7L3OUiX2"}}, "object_label": "book", "attribute_label": ["color:black", "color:yellow", "length:long", "material:paper/cardboard", "transparency:opaque", "pattern:lettered", "size:small/little/tiny", "state:closed", "texture:smooth/sleek"], "control_dims": "length, size", "answer": "The image features a collection of books on a shelf, with one of the books titled \"Bringing Down the House: Are You a Transhuman?\" The other books on the shelf include \"The Marvel Comics Guide to the Marvel Universe,\" \"The Marvel Comics Guide to the Avengers,\" and \"The Marvel Comics Guide to the X-Men.\" These books are arranged in a neat row, showcasing a variety of topics and interests."}, {"question_id": 759, "height": 333, "width": 500, "image": "000000156924.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, pattern, pose, texture, transparency", "region_anno": {"bbox": [179.47, 309.85, 29.95, 17.27], "segmentation": {"size": [333, 500], "counts": "SVj13Y:4jEMk9<O000O2O0O10000O10000000010O0000^OXF>l9KVFGk97VFIj93:O20O01O]no2"}}, "object_label": "remote", "attribute_label": ["color:white", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "color, pose, pattern, transparency", "answer": "The image features a close-up view of a remote control, which is located near the center of the frame. The remote is white in color and appears to be a standard TV remote control. The focus of the image is on the remote, with the rest of the scene blurred out, creating a sense of depth and emphasizing the remote as the main subject."}, {"question_id": 760, "height": 538, "width": 640, "image": "000000210099.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, pattern, pose, texture, transparency", "region_anno": {"bbox": [45.36, 57.86, 578.49, 479.64], "segmentation": {"size": [538, 640], "counts": "k^`0>2E001O000O10Y?b1D?G15EVA[Ni>e1WAiNZ>m1]OdM[Bo2]=QMaBV3^=XMcBW2o<\\MUC:IF3m2>QMd;R4YDoKd;\\4QDgKn;Z4SDfKm;X4VDeKf;0VDZ44gKe;OUD\\45fKh;]4VDdKf;`4ZD`Kf;5WDo32mKe;6YDn31lKd;d4\\D\\Ka;f4`DZK_;g4`DZK`;f4_D[Ka;e4_D[K`;g4_DYK`;h4`DYK];h4dDWKZ;l4fDTKX;n4iDQKV;P5jDPKU;2iDd42[KU;P5jDPKU;Q5kDoJP;`500O1O100XEWJ^:7]E9NU41aK4K_:7\\EQ51mJ0K00b:l5^EYJ5KQ:n5iEXJ4MQ:l5kERJ1014Q:k5nEQJ00060H44_9n5\\FUJ171I_9k5_FUJ2f0Y9V5eFUJ0g0Z9JfFU40YK2R1V9AhFT40YK2JOY1Q9a4nF\\J2X1o8\\4oF\\J20NR1m8c4TGZJ02OR1l8b4UGTJ20O2O1OX1j8b4`GUJGc1c8Y4bGSJK60\\1_8\\4eGSJL50_1[8]4fGoI04Oc1X8[4iGlI52Jk1S8X4nGkI61IQ2m7T4SHlI6NLR2j7T4THlI;S2]7R4XHkI1O0O1V2d7n3_HlIM001OV2c7n3fHkIH1N[2`7k3hHiII11_2Y7gMdHh54SJN12]2W7gMeHi52RJ022]2V7h3gHiI141_2R7e3lHhI150c2n6`3QIiI0N012k2j6]3TIiI0N1O2o2e6\\3YIhION012o2b6Y3aIgIL0O21P3a6W3cIfIM1M41P3_6Y3cIbI43KS3]6Y3cIbI41MZ3V6S3iIcI30N\\3T6m2jIeI1<1W3o5h2SJQJNX3m5h2QJeIO<4Y3i5f2TJnI0H4g3`2XL<[6QMTJ2[3_2VL=\\6RMSJ2\\3^2TL>^6RMRJ2\\1M5\\2PNc0]6QMiI003i3Y2RLb0f6RM^I4j3X2RLb0\\6RMhI2O2n3MoKR20nMNi2Y6[MlIN01U4n1hKoMNh2Z6]MgI5OI:Ke3R2TLoMMi2Z6]MgI<Z4HgKo0NlN4g2V6YMhI<Z4HiKm0LnN4h2T6YMjI1M2S4GTL:Nn0KoN1g2V6\\MkIHN11OO1S4OnK0O:3W4S6dKkIJ1001N011W2MoM3NNP1;kNK2]4U6aKlIKN21:Q4OoKI33NP4V6jKmI3L8Q4OoKH4O6Q4k5PLoI1K9R4NoKH5NLO5R4n5SLoIOL82FS11kN2X27iMH4LN051Ij3Q6ULnI55NJ;20a05A_O120NW1;fNM1J?a3e5^LoI`0NAR1NlN2U2:kMG7M=_3b5aLoIa0`1_OM0kN<DFW1W3m4hLPJ`0N^OY126OiN1C00245OJh0V3[5kLQJMI<5FOOe0NYO0O4P21PNK1319MI3M9]3i5fLnIJO2O:42c01]OA30O1003046CJ122c0M@2KNb3T6bLoIKN2O96HS14f0ORNLN158LL2L7_3l5aLoIML308f1JFLTO5A044MKa0N]OW3U6jLoIMK2093LOLP11o01QNLN03:0LOK90GV3S6nLnIU1MkN3L3N020N13MOf0N[O7MH0109196^OMW3o5SOnIhM3N11N4MO1M0O85FM0O6NJ94;O\\ON15V3n5hMkIH0@2Nh0K]O4MO5201HM0O:7I:?d2a5mLnId0OM1\\OX1OkN33M0616IE:7H1MMd0P3_5nLnId0OM1\\OW11kN14M14458L]O5k0m2U5TMnIS10hN5Le0;\\OE4O756<GEBL0T3S6TMmI\\14[N<OB00;4G0M70J6`0KYO>=8CU2T6ZMmI[1Z1mNkNB2122L3`0g0\\OJ0T2T6YMlIS1NPOY19VOBA0611MJ2e0l0[OCOA7f2m5^MnI[1O_Ni0k0[OYOO31L1OJ0g0^1ZObN4h2n5]MnIJ1h1NZN1T13POL342LGf0[1_ObNOk2MUM11i5:WJLN\\20iM192Lc0m0]OfNNg25VMd5;YJ^2OZM2MM<OJ2;d0T1[OU15VMd59\\J0Ln1>iM@;2J0<e0S1[OU14VMe59\\J[2?^M\\O4N12;e0Q4[O]Kg21:6UMj1S1oMkN;M7e0P4ZO^K\\20jM3j21YMl1g0PN_O9B:e0o3U2_K62ZMl1\\1WNYN7NHg0]4W2^K53QMM4m1b1ZNWN6OHg0]4o1_K_MOl25SMK5j1c1^NTN41Ig0[4k1aK]M9n2MTMI;3H0N0M50<P2OTNBc0[4\\O`KZ2>gMCZ20cM0070J<0?2ZONR2?mMDa0[4]O`KZ2>=MXMF<Oc00b1`0dMC?]4]O`K[2==LXMH;Oc00b1a0dMA`0]4\\OaK[2>fMBZ2?eMBT4`0mKCb0\\4m1VLDNlM\\Om30VLa0LEd0Z4m1WLBNnM[O?2b0NYO2b0NB6@;0G`0HA`4a2WLBFmMF2M`00f23iL=OHd0W4m1WLCDPNHd0Na21jL=NKc0U4l1ZLACTNHLMn32SL<0Jb0V4h1cKbMh0o1FWNFJMo32UL<NBN2g0Y4f1aLYORO\\Na06I]3GaL3N0O3OKN2h0X4f1`L]OAaNMb3JVL002OJN3h0Y4e1`L]O^OcN1a3GVL2O31Ke0Y4d1bLZO@fNMb3HTL302MOi0U4d1bLTOGkN@FMo2OVM0O5LN120;f0k38eKVO1OO>n0l0LgNZOh1LWN1e0O\\O0N7LL220;c0@ZO[4\\1fKAl0b0H`N]O2N35T2LVO3fNN02O<f0k3d0eK@m0b0@cNFNN1O35R2KkM1]11cNN1024O=d0k35[L@a0j0]OmN]O:5l1ITO3iNMN4O=e0j3OfKXO_2i0`MXOk09UO5:W3J_LNO30<f0i3MZN]O_M14Kd0P1AQOE_33dLO03N<h0_OWOU4g0jKYO`24`M3n0m0@]2FdLMN4O>k0b3M[NFVNj0HY2DcLNM5N?l0a3M[N[OaMOg0W1EX2FbLNO3Ma0k0`3K_NZO]N\\1UOdNLn21VMN03NO1k0g0W3L_OC^Li03oNMl22WMNO3NN2k0g0W3LkKYOY1OnN2a1?XNb05POMm22TMO110N11Lc0k0^3NTMWOiNO13^19`NK0l03QONl22SM03O0N02Kd0k0^3NTM[OjNN\\1;bNI0l04oNNm3OUL4Kd0l0Z30mLTOUO50LY1?bNo04cNOk3Z1mLe22nLTOVO31MT1U1gNQON>4]O27JX3^1ZMc23lLUOYO1OOQ1Y1kNB2TO3i3X1oLd24oKSOh03]O2LO3LN0O2;l0CD0;3TO3i3W1PMe22PLTOg03]O1MO3M036_1E[O2TO2j3X1nLf23oKTOc00]O340N0<OGc1KaNO>9AFY20gN2kNW1h0k20RLXO=3_O030O04M00N>LHN21O0O20N>8R2GeN0fNT1f0Q39]LTO_OO42MO4O8=Ce00RO0<7d3l0cLn26`LTO_OO34ML53LLO0O`0000F00000;8d3l0cLn23nKTOb03@N25NK43NKN2N?20NG1N02O<8`3o0eLk2NjL[OWO0044JO251F935MC5NN3Nc06^2H`MY14h2MkL[OXO0N0N07NO260G2OM51K53K2NO3Me05=HnN0f12lNW15h2NkLYOXO1M5>LLOH817LD5M04Lc06<InN0_2Y1XNh21hLVOZO2N61I52L6O20KN10O2L34Kb07YOIo00f1Y1SNh21nLXORO52I43NM52F242LO3N2M14L3N77BKg3X1RMg2NPLXOm04TO2;O;N]O1N13L;1C3N;3BMc3N\\LY1f0iNYOo3h0PLXOm04TO273a0H\\O20N2O:0C40OM70H1e3V1lLgN_O2No3l0lLXOUO353b0H\\O2OOf0N\\O4M2M65Z3T1QMgNYOQ4k0kLYOWO215d0FYON26OLOO2O?1D5L1N56\\3Q1TMj2OmLYOUO404f0D^O6K01J?0E6K`04R3Q1TMi2LRM[OQOe0Z1\\OTOLN5Cb06T3j0RMm2JUM[OoN>0C[10iNM1164Dc0:R3b0SMQ3KTM[OmN`01B7Ng03TOL3174Da0;U3?PMT3NQMNPO]O319IK2JO150M32NM26K`0<Z39lLZ3MQMMQOJe0^OA4NN100N07Kb0<^31nKBb0o31TMNPOJo0B_OON3E1M;3A3^4NeKL>O@P4e0SMLTOMm0@^O0N3D1O2M22K8Y4JhKN<OB1Nj3h0ULXOn0c0XONj0AANM4E2M<OB:X4GkKO?P45oLIWONL^O6000O20N1000O6K1N;0D8`4HQLo33RMXORO937k0_O34oN2N0O10O9U5g3ZK]MBfNHO:NK[2MkM3NNO103:MCj40SKQ4d0^M^OgNOK1:M_10fN2G1ON865J^Og41XKP4e0[MIdNE2N01f1OfN2F3NM:65d4CTKh3g0]MFiNEMO232K32KN02OO2O51O270G3MO1MNO0;>c4BUKk3b0`MHiNC13OL3000X12eN3OL3O02I5`0NBh4i3iKjM_ObNKO2X2NiM1n00ZO2Fl4b3gKoM^OiNNo1NjM0l03PON41NQ5\\3cKTN^OhNOY2NSNO]O5LN<R5R3bKTN^OhNNIM20:000O1G0b01WOO0600;n4MlJG35O`2c0RO\\OiNNn10hN0QO2I024<n4I`K\\2_O]M=g6DSJNWOO2`41XLMXOZ22fM9\\4DXN1YN0SO2O]10i00SN1`0OUO[22fM9OEW2OW22cKO11k0X1TOn2Y2kKgM=T2AVOOlN2O0:01NA1n01QO0O1n0V1UOm2W2mKgM=l3@[L0:0W12XNO11k0OTOU10a1OhN[2cNfM>P8ASH2O4MT32SNY2dNfM:OFQ8NUH2N3Nf0Nb13iMMo0[2mNfM:OF[7OkH1;OD5KQ30jL4\\1W2eNfM:OF_5NgK0RO0K0O2OO14<KH^3KcL3]1V2cNiM:NE[70kH3b02XOP31kL3]1U2dNkM8LGV22T4NlI3Ic01]11mM3\\1V2eNjM8LGQ27c4I^I1M22M02O015Nb12WN3\\1V2eNjM8KIQ26c3HdJ0d0>TOD1m1OSN2N2]1W2dNiM9LHi1N\\N9?GI000Y30aL1LOO2i0a2VO_M1O1\\1X2dNiM9LHQ2Oj3O\\J2d01WO:O_10VN01O\\1b2kN^MH`92bFM?]1@dN01O52k0_2XO_MFe10W5OPJ3K2ZOP10mN01OO014<L2a2MROGW5L\\I2O10Ob0d1ZO`N3k0]2[OROE]N0:NT10V30cK2JO15O03L<NC0N[1OnN2O1j0]2[OZOCP50]I5LOn0U1SOnNN02k0\\2ZOk6FhGa0nN_O0;>EB03o0]2[OS8K]EK1N11O:>GBN7i0IWO_2=i6CmF4d0MVO11N52K9<HEM92E`00^O`2=YOD9Ok20YK2O5JMU1NmN9<HEMd0=l1OR7EaF1W14cNK?3BNg3:cLDk90fF3E3@Lg39cLGi91RFM=2N0_O010g39bLH`9O\\F2NO>MO3_O4h34_LLb9KXFO060NR17f2ObLF`91VFO16NM82<6U3Kn6O[EL6:53[3GQ7JjE<H6\\3DeLJe90VF1<;G:Z3@gLLU2NgM11O0000m52QJ0<:H>W3[OkLK_20Y40TI0;<_OD4l00VOQ30i0N]3=cHD4b1j2]NR10]3a0eHEOL0\\1e2bNbM1a:O`Ea0IFN]1e2\\NcM1`3O[L0f62_I?J\\1_=SNfB21`0KBN`1_=^N`B68:N^OM1N^1V=aNPC<163^OH^1T=cNoB;281\\ONZ1Q5jNPKMJ6OKl60YI:290[O1X1i4iNoJT1i6lN\\I<1c0JRO2V1j49S2lNWIS1JdN1b0i4n0V2iNUIR16UOZ2]OZOi1l4dNZIR1JcN9;GCf21WOk1e4SNeI>08I97XOKIi21kNV2j4iMgI?Oi1JjM2Nd21kN_2k4`MjIa0NP2b2_MlNc2^N]MW61nIa0No1c2_MkNh2c4\\MPJ=OQ2b2^MhN2cNo2k5UMWJ:2R2l3S1_1aLbJ<2P2f3d1VOnKUM0c10YNa02m1c3j1\\LdK^1`0gNCNf0M\\O]1NcNb01m1a3T2`M]LmN2]1FeNg1^3W2YMkM\\O\\MQ11kNf01k1Q3eMnL`73]Hc1MZNg00j1n2P5E_H]Mg00j1l2R5KTIYMj1k2Z5FUH^Mc01n1k2[5HgH]Mn1k2]5TMRHW2k0jMf1l2c5VO]Ki0d4UO]Kk0d4TO\\Km0i4lNXKU1k4fNUK[1R5^NYHdNc1o2T6aM\\G5n0[Ob1P3T6XN[HhNa1P3U6UNYGjNR10`1R3X6nMPKS2R5oLXG9P4i2o4UMTKj2m4UMRKl2n4TMRKm2P5PMPKQ3P5nLPKS3P5lLPKT3P5lLPKU3o4kLQKV3n4iLSKW3m4hLUKX3j4gL_G0T3Z3o5gLQJZ3j5eLbF1j0Ol1[3h6eLaG1f1]3i7cLWH^3h7bLXH^3h7aLYH_3g7aLYH_3i6aL[G0l1`3g6aLVJb3d5]LiF2b3b3d5\\LjF2b3b3d5]LhF2d3a3d5]LhF2k0Ml1e3V6[L[G0J2i0Nl1f3U6[L[GOK2i0Nl1f3U6[LZG0L1i0Nl1f3U6ZL[G1K1i0Nk1i3T6WL]G1K1i0Nl1i3R6WL^G1K1b3h3T5VL_G1J2d3g3R5WL_G1J1e3g3R5XL^G5`3e3P5WL`GNK2e3i3P5WL]Ki3c4WL]Kk3a4UL_Kl3`4TLcGMN0c3P4k4SLhGN]3P4[LoK\\83lGN\\3V4g4kKmGO\\3V4h4kKgGNN1R2O[OX4m6kKfG3R2KZOW4n6jKgG4b3Q4h4jKhG0d3W4c4hKjG1c3X4j4hK^G0d3Y4m4gK_G0d3Z4l4eKaG2b3Z4l4dKbG3a3Z4l4cKbG4b3Z4f4bKjG1M3c3[4e4aKjG8a3X4h4hKYKX4f4hKZKY4e4gK[K[4c4eK]K[4c4eK]K^4`4bK`K_4_4aKaK`4^4`KaKc4]4]KcKd4\\4\\KdKh4X4XKgKk4W4TK]KIRM0IT5g7PK`KMPMOIT5h7QKkKo4U4QKkKR5R4nJbHKR3Y5Z4hJ\\H350R3V5oMgJW54gI0o2KnL[5c7kJ_H0o2LnLZ5c7iJaH1n2LnL[5d7eJbH2Q3b5U4[JkHOT3f5P4ZJZLf5f3ZJ[Le5]7001O3M001O4K2\\ERJZ:Y6N00003QGbI\\7_6bHcIeNNe8a6dHfIZ7\\6eH^IgN2d8`6hHaIW7a6dHcI[7a6`HbI^7b6ZHeIc7\\6_HdI_7\\6aHdI^7a6]HaIa7a6oGnHNMMi0Q8]6SHmHOMMk0o7]6RHmH5g0h7f6XH[If7g6YH]Ic7c6]HaI_7_6]H\\HOW1a7^6`H[HOX1`7]6aH\\HM[1_7Z6bHlI\\7m7L2M4M2M3O2N2N2MgMZI_Je6`5\\IcJb6[5]IkJ_6U5aImJ]6S5dImJ[6S5fImJY6S5eISKV6n4iIXKR6h4nIYKl5TMSJd71[Ki5i4XJXKf5h4ZJ\\Kb5lL\\Jd72cKc5]4]JhK_5W4aJkK\\5V4eJjKZ5V4eJoKW5Q4iJULn4ULQKe71XL1TLf4OXKe72]Li4c3YK\\Lg4c3WK`Lh4`3XKbLf4^3YKdLg4[3ZKfLd4Z3\\KfLd4Z3\\KgLc4Y3\\KhLd4X3\\KiLb4X3_KgLa4Y3_KgLa4Y3_KgLa4X3`KhL`4X3`KiL_4W3aKiL_4W3bKhL^4X3aKiL_4W3aK^HLX4b4[3bK]HLX4_4gKbKc77fLW4gKbKc78eLV4hKbKc78fLY4Z3bK]HMZ40hK\\4a7fK_HM^4\\4R3iK^HLZ42gKZ4`7lKhLZ4X3eKiL[4W3aKmL_4U3^KlLb4P3cKoL]4Q3fKlLZ4T3fKlLY4U3hKjLX4V3hKjLHfK\\4`7lKjLX4U3iKkLW4U3hKlLX4T3cKQMX4aKdK_73QMY4aKcK]75RMY4_KcK]77SMZ4l2iKRMV4n2bKfH2[4\\4n2bKhH2[4\\4l2cKgH3[4[4m2cKhH2[4[4m2cKiH0\\4\\4l2bK_M]4a2bK`M^4_2cKaM]4^2dKhHMf4`4b2fK_MY4a2gK_MY4a2gK_MY4_2cKkH1e4\\4_2dKlH0e4\\4_2dKlH0e4\\4_2dKmHNf4]4]2fKhMZ4X2hKfMX4Z2kKcMU4\\2iKgMW4Y2hKiMW4V2jKjMV4V2kKiMU4V2mKiMS4W2mKiMS4X2jKkMT4b2dKZM\\4W2hKRIOMMk4\\4V2RLjMn3V2SLjMl3V2TLkMk3U2ULkMk3T2VLlMj3T2ULmMj3T2VLlMj3T2nKRILj4Q4Y2SLnHJj4S4W2TLoHIj4S4W2ULoMl3P2TLPNm3lJjKQ79oHHQ5Y4n1oKQIHQ5Y4n1RLRNo3l1RLTNn3l1SLSNm3m1SLTNk3m1ULSNk3m1TLTNl3k1TLUNm3k1TLUNk3k1ULUNk3k1ULUNk3k1VLTNj3l1VLTNj3l1VLTNj3l1WLSNi3m1XLRNg3o1ZLPNf3P2ZLPNf3Q2ZLnMg3Q2YLoMh3P2XLPNh3P2YLoMg3Q2ZLoMe3Q2\\LnMd3R2^LlMb3T2`LjM`3V2cLgM]3Y2cLgM]3Y2dLfM[3[2fLdMZ3]2fLbMZ3^2hL`MX3`2iL_MW3b2kL[MU3e2oLWM7jKY1o6dNSMEmKRO`0`2a6lNoLAPLSOb0_2^6nNoLDSLmN`0]2_6TOkLBjLZ1\\6TOiLBeL`1b6ROeL^OfLb1g6PObL^OgLb1g6SO_L[OjLRODX2T7CULXOmLnNJ10l1U7:fKPOVMdNO2O41k1V7d0]KkN]MbNO41k1W7m0nHRM10`1o1ZN2X7W1gHnL7IU1Q2eN1Y7`1fHeL?ID0:2GT4W7EfHZL49OFOR4Y7NfHeL1]3Z7k0eHUO]7i0bHXO_7e1`HUJ8n2Y7k2QIoLQ7k2]H^Jf0a2P7P3ZH_Jh0a2n6R3TImLk6S3VIlLk6V3SIiLn6W3RI]JZOS2d7_3SI]JYOT2e7_3RI\\JYOU2g7b3kHYJ^OT2j7k3eHUL\\7m3aHSLb7m3ZHTLh7l3nGQJ0S2V8Z64L1O2N3M5K5L2N4K7I>Bb0^O:F?A9G>VKXDf3h<F;QLnB`3b=D1O?A;E7I5K3M5UNo@c1[?I6J6J2M:G>]O`_OO][7"}}, "object_label": "chair", "attribute_label": ["color:brown", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pattern, transparency, color, pose", "answer": "The chair in the image is a wicker chair with a cushion on it. It is placed on a patio, and a cat is sitting on the chair, looking up."}, {"question_id": 761, "height": 622, "width": 640, "image": "000000218997.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, pattern, pose, texture, transparency", "region_anno": {"bbox": [151.6, 351.68, 14.41, 31.6], "segmentation": {"size": [622, 640], "counts": "hel28Sc06R]OH^b0f0N1O10000000Ia]O^O`b0`08N2O1N5KZbo8"}}, "object_label": "baseball bat", "attribute_label": ["color:blue", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "transparency, texture", "answer": "The image features a baseball bat lying on the ground, with a blue bottle cap on top of it. The baseball bat is positioned horizontally, and the blue bottle cap is placed on the end of the bat. The scene appears to be set outdoors, possibly on a dirt surface."}, {"question_id": 762, "height": 622, "width": 640, "image": "000000218997.jpg", "category": "description", "question": "Describe the sports ball in the following image in detail.", "dims": "color, pattern, size, state, transparency", "region_anno": {"bbox": [341.41, 414.49, 16.2, 16.47], "segmentation": {"size": [622, 640], "counts": "Ya_69Tc03L201N1000000000000001O1N2N2N3J[lZ5"}}, "object_label": "sports ball", "attribute_label": ["color:white", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:full/whole"], "control_dims": "size, color, transparency, state, pattern", "answer": "The sports ball in the image is a baseball, which is a white and brown ball with a red stitching. It is being held in a person's hand, and the person is looking at the ball closely."}, {"question_id": 763, "height": 427, "width": 640, "image": "000000086582.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, material, pattern, pose, transparency", "region_anno": {"bbox": [69.89, 162.76, 65.1, 91.91], "segmentation": {"size": [427, 640], "counts": "eQo06T=3_OKhC7n;HjC387j;2UD1g;0YD2e;OZD8^;J`D;>VOU:?]E?8VOY:<^EV1a:lN]ET1c:nN[ER1e:j000O11O000000000000000000O100O1O1O1O100O10O101O001O001O00100O2N1O2N1O1O1N2O2N1O011N1nMoDV14oNW;i0QEUOP;f0UEZOk:a0[E[Oh:`0T1K6K4N2Ojaa6"}}, "object_label": "potted plant", "attribute_label": ["color:green", "color:red", "material:ceramic/brick/porcelain", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "pose, material, color", "answer": "The image features a large potted plant with a red pot, placed on a wooden deck. The plant is positioned in the center of the scene, and it appears to be a large flower pot. The plant is surrounded by a few other potted plants, creating a lively and green atmosphere. The wooden deck provides a natural and inviting setting for the plants to thrive."}, {"question_id": 764, "height": 426, "width": 640, "image": "000000308631.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pattern, pose, transparency", "region_anno": {"bbox": [487.27, 0.0, 25.84, 55.52], "segmentation": {"size": [426, 640], "counts": "`P[64V=4L8H5K5Kc0bCjNb;_10000000O3M2N3N3L3M3L4M3L4K4J6G9Jjde1"}}, "object_label": "backpack", "attribute_label": ["color:blue", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "pose, pattern, color, transparency", "answer": "The backpack in the image is black and appears to be worn by a person. It is positioned on the person's back, covering a significant portion of their upper body. The backpack is large and has a distinctive shape, making it stand out in the scene."}, {"question_id": 765, "height": 640, "width": 509, "image": "000000185890.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [173.57, 64.82, 49.09, 65.68], "segmentation": {"size": [640, 509], "counts": "bk\\32lc03N2N1N2O1O2M2M3M3N3L3M3O1O1O10O0OBXOh]Oh0Wb0\\Of]Od0MVOTb09m]Ok0Pb0WOo]Oj0oa0e0OO1000000000010O1O100O;E2N2N001O001O1O0N3K5L4L5JWmc5"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, face expression, maturity, pose", "answer": "The image features a man standing in a room, wearing a white shirt and a tie. He appears to be a chef, as he is holding a bottle of wine and a wine glass. The man is smiling, giving off a friendly and approachable vibe.\n\nThe room has a dining table in the background, and there are several wine glasses placed on it. Additionally, there are a few bottles scattered around the room, possibly indicating a gathering or a celebration."}, {"question_id": 766, "height": 375, "width": 500, "image": "000000341094.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [311.24, 172.11, 71.86, 201.89], "segmentation": {"size": [375, 500], "counts": "WRb38^;2L6L3M2O0O1O2O00000O1000100O100O10O10O100O1O01O10O1RJVOn0i0SOWOm0h0PO[OQ1d0nNZOU1f0kN]OS1b0mN^OT1a0POZOR1e0S5M4CnDM_;N2OnH1Q7000lj12VUNMO0000000D1PEOP;1jD2MOX;0iD6W;JjD5V;KjD5V;KPEOP;1PEOP;1oD0Q;0jD5W;JhD7X;IhD8W;HiD8W;GkD8Z;01O4KWZ\\1"}}, "object_label": "person", "attribute_label": ["face expression:fear/surprise", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "maturity, face expression, hair type", "answer": "The image features a person, likely a young man, sitting inside a red metal structure that resembles a mailbox or a small car. The person appears to be enjoying the experience and is smiling, possibly posing for a photo. The red metal structure is located in a park, and there are a few other people in the background, possibly enjoying the outdoor setting as well."}, {"question_id": 767, "height": 375, "width": 500, "image": "000000341094.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "color, material, maturity, pose, size, state, texture", "region_anno": {"bbox": [13.92, 31.1, 219.06, 333.23], "segmentation": {"size": [375, 500], "counts": "cc4e1h9<I7J5L4M4L3K6L3M3M2M5M2M4L6kHdLc5m3gI^LV6c4M3L4N3L3M3M3M3M3M5K5K3N1N2N2N3N1O1N2N2N2O1N2N2N2O1N2N3M2N2N2N2N2N3L3M3M4M2N2N2O1O100O1N2N2N2O1N2O1N2O1O^MTMZLl2f3UMYLk2Z6O001O[MXM\\Lh2d3[MZLd2f3^MYLa2h3`MVL`2g3ZMoIO1OW2i2h3YM`Lj2a3UM`Lj2a3VMTJ2n1g2o3WMRJ2Z1OQOf2e5^MkIJ]1<POY2i5\\MhI22M\\1>QOU2`5^M\\J2EN[1a0UOm1`5dMZJ2o0`0WOh1c5eMYJ0l0f0WOd1`5dMcJ3c0h0[O_1_5hM]JNF3R1j0]OZ1`5lMZJ5e0j0_OT1c5mMPJ`02]O?X1Kl0f5nMoI`0d0i0Gh0`5mMWJ100K;b0V1L`0`5oMWJ0O5LY2=B[5PN\\J010L0O43S2NkM;m1]5QN\\JO01L42\\28@]5QNdJOE41^28[OZ5RN^J0O50<0i1OoM8e1\\5XN\\Jc00a11SN2`1c5YNZJ^33VNe5]NYJ]32SNj5_NSJ<2W4e5XK^Jf0OR4c5XK^Je5b5[J]Jf5c5QK[JY4f5gKYJZ4g5k0000000000OZOTJcK8]OX5P5`JcK8\\OX5R5`JbKk5n3YJgKL>h5i3_JbLb5\\3bJ_L`5a3aJ\\La5d3`JeKC>P6k3hJPLZ5o3eJQL\\5o3cJnKb5Q4_JgKh5Y4k0RNfH_OZ7=fHhM8d1S7a0TI\\Om6b0WI\\Oi6c0YI\\Og6a0dHQNf0]1f6b0dHQNg0\\1e6c0`I[O`6e0aIYO`6g0aIXO_6d0dHTNo00POU1]7f0jIYOW6g0iIXOW6h0iIXOW6h0iHVNf0R1a6h0hHZNKO3L60GS1^7g0aH^Ng0LYOo0_7n0[ISNVO40a0`7U1\\IWN_Ob0U7V1_IVN^Ob0T7V1`IUN^Oe0R7U1RJkNo5T1dIZNnNf0_7o0cI[NlNh0a7l0gIWO[6h0gIVOY6i0jI_NfN;`0BX6d1cJ^NgN:=FY6a1eJ^NbNNL=e0EX6a1gJSOPO^OX6^1iJTOiN[OC5l6Z1kJTOfN]OB6m6X1mJTOdNH^6S1PKTObNH_6S1QKTO`NDe6W1lJTO_NEe6V1nJkNoM1>0c6S1RKTO[NId6Q1SKUOYNJBJo6V1XKUOWNNCGj6V1]KTOUN4_6f0^KUOSN5_6f0^KPOfMN=<FAd6T1eKPOeML>`0]6c0bKPOSN>Z6b0dKQOPN<^6a0cKSOoM:`6c0cKROlM9c6e0aKROlM5g6i0^KQOlM2i6m0[KQOZ5n0hJQOY5n0h2O2O0O2O1N2N2N2N2M2N3M3M3L5LSo[3"}}, "object_label": "bear", "attribute_label": ["color:black", "color:brown", "material:wood/wooden/bamboo/hardwood", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:smooth/sleek"], "control_dims": "size, maturity, texture, state, material", "answer": "The image features a large brown bear statue sitting in the driver's seat of a red truck. The bear appears to be enjoying the ride, as if it were a real driver. The truck is parked in a wooded area, surrounded by trees."}, {"question_id": 768, "height": 640, "width": 478, "image": "000000368212.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [17.26, 43.15, 368.18, 565.21], "segmentation": {"size": [640, 478], "counts": "ja:7hc04L4L2O1N2N2N2N2N2M2O2N2O1N2O0O2N102N1O1N1000000O1O1O010OO1001O100O1O100O1O010O100O010O010O1O010O1N10100O010XNiNS@ANg1i?SOT@UO3h1h?XO[@TO^Of1R`0@Z@h0c?^OY@b0`?RNW@_13d0f?mMW@^13e0f?nMW@]12f0d?D[@=b?G]@8_?Ma@SN0f1_?a20O10O010000OM4E;N1O2O1N1L5N2N1N3O010N101O1O010O00100O0010O010O010O100O010O00010O1bNdAWM\\>j2hAQMY>Q3kAhLU>Z3lAcLU>\\3mAbLT>^3nA^LS>b3PB[LQ>e3QBVLQ>k3QBnKT>Q4n0O010O1O1O1N20O01O^MZLlDe3R;`LlD_3m:kLQET3l:SMQEl2m:YMQEe2P;_MmD_2R;hMiDX2X;jMfDS2[;PNcDo1];WN_Dh1a;ZN^Dc1c;`N\\D_1d;dNYDZ1h;iNWDl0R<WOlCi0T<XOlCf0T<]OjCd0U<^OjCb0T<AkC>U<CjC>T<EkC:U<HjC8T<JlC5R<OlC2R<1mCOR<2nCMS<4lCLS<5mCJS<8lCHS<9lCHS<:lCFU1UMk8W3oECU1\\Mg8R3SFCT1^Mg8Q3lEoLB[2j1hMf8P3jEPMHV2f1mMf8n2lEPMGU2e1PNg8l2kEQMHR2f1RNf8l2kEG^1^Mg8k2jEG_1`Md8l2hEHb1^Me8k2jEE`1eMb8g2nEC`1kM]8c2SFB_1mM\\8P6bGTJ[8m5dGUJZ8k5fGYJV8`3\\FUM^1]OT8f5lG]JP8d5oG^JP8b5PH`Jm7a5RH`Jn7]3fFiL[1Kn7`5PHaJP8`5nGbJQ8_5mGcJS8]5lGcJU8]5jGdJU8]5jGcJ\\5]NlKP7fNdJg4XO_LT6iNdJ`4DcLh5mNdJ[4OcL]5ROcJZ45`LY5UObJZ4;]LR5ZOaJY4e0VLk4@`JY4Q1mK_4J^JZ4V1iK\\4N]JY4[1fKX40]JY4a1cKS43[JZ4e1`KQ46YJZ4k1\\Kl3:XJZ4o1ZKi3<VJ\\4T2UKe3;_HZOg1U5X2UKb3:\\Ja4U2SK_3;\\Jb4X2PK]3>YJd4\\2lJ[3`0WJe4a2iJX3a0VJg4d2jJT3>VJi4i2hJP3>WJj4k2hJm2>VJk4P3eJXMNc3b0SLl4V3aJf2c0SJl4Z3cJ`2`0UJm4\\3dJ^2>WJm4k:RKUEn4l:hJgCJa1^5h:fJ_EZ5d<OPHeJdINN0a7\\5o6NTHiJR1W5QOgJo0W5SOiJo0U5ROjJfJ1f4R5d0nJWI0X11l4P5f0PKTI0Z10l4P5l0oJXJ2oNM`5Q58oJ\\L3kMN`5Q58PKPJOY24lMMb5P55XK^LLgMNe5n45ZK_L2[3e45[K`LOZ3g42^KeLIZ3i4NaKhLFY3j4]OQKVKa0h1YOZN;[5j4YOWLoLgN[N:\\5h4YOXLPMgNZN9\\5i4XOkJUK[1l1mNUN6b5g4WOlJWKY1j1Ah3Z4WOlJWKY1h1Ci3Y4YOjJVKZ1g1Ck3Y4XOiJWKa03EM3f1e0l3X4ZOZKZKC21\\1k0n3X4ZOWKjKFn0k0o3W4\\OjJRL4d0d0U4]4;mJaK2YN<\\2@Q1U5f4mJ]NS5c1mJ^NR5b1mJ_NS5a1nJ_NQ5a1oJaNo4_1QKaNo4`1PKaNo4_1QKaNP5^1PKbNP5^1PKbNP5W800001O000O2O1O00001N1000001N2O001O0O2O001O1O001N101O1O1PF_J_5a5_JfJ[5\\5cJeJ]5\\5`JaJd5a5XJaJi5`5TJcJj5^5RJgJl5[5QJgJo5[5mIgJS6Z5kIgJT6[5kIeJU6\\5jIdJU6^5jIbJV6`5gIaJY6a5eI_J[6b5cI`J[6c5bI^J]OVO^4]6RL_J`6c5[IbJd6_5XIdJh6^5SIfJk6\\5RIfJm6^5nHdJR7^5hHgJV7[5fHhJZ7Z5bHhJ]7[5_HgJ`7]5jGkH\\Oj1j8^5eGmHZOj1P9[5cGVK`4_M`N_7kLSKe4^M^Nd7gLRKi4[M`Nf7bLSKj4ZMbNk:]1UEcNk:\\1VEcNl:\\1TEcNn:[1TEcNn:\\1REcNP;[1REdNo:[1REcNP;[1REdNo:Z1SEcNP;\\1PEcNR;[1PEbNR;[1REcNP;[1REcNQ;l0_EROc:d0gEZO\\:d0eE[O\\:c0eE\\O^:b0bE]O`:b0aE\\Oa:c0_E]Oc:`0_E^Oc:a0]E_Od:`0]E^Of:?[EAf:>[E@h:=ZEBg:=ZEAh:=ZEBg:<[EBh:<YECh:<YEBj:;WEEl:7VEGn:5TEIo:4SEKo:2SELP;2QELQ;1SELP;1REMQ;0QENQ;0QEMR;2oDLT;1nDLV;1mDLV;1mDIZ;3iDG\\;7fDDa;8bDAf;;]DAh;:^D^OQ<3X^l1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "hair type:straight", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "maturity", "answer": "The image features a young child, possibly a toddler, sitting on a toilet in a bathroom. The child is holding a toothbrush in their mouth, possibly brushing their teeth or playing with it. The toilet is located in the center of the scene, and the child is positioned on the left side of the toilet. The bathroom appears to be a typical setting for a child's daily hygiene routine."}, {"question_id": 769, "height": 425, "width": 640, "image": "000000433103.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [522.99, 16.64, 59.46, 92.49], "segmentation": {"size": [425, 640], "counts": "cYh62T=7I7K6J4K4M5K4L8H3M8H0000000[O]NdEc1[:bNbE^1]:gN^EZ1b:f00000001O00100O1O1O01000_NVEb0k:^OUEa0l:n01N10000O101O0O2`NREc0^;jNeDV1g;O1O101N2O1O0N3K5L5M3M2M4L4N1N3M2Nnjh0"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "hair type:straight", "maturity:adult/old/aged", "pose:vertical/upright/standing"], "control_dims": "hair type, face expression", "answer": "The image features a man wearing a suit and tie, standing in a room with other people. He appears to be engaged in a conversation with someone, possibly a woman, as he is holding a cell phone to his ear. The man is positioned in the center of the scene, with other people surrounding him.\n\nThere are a few other individuals in the room, one of whom is wearing a tie, indicating a formal or professional setting. The room also contains a dining table, a chair, and a handbag placed on the floor."}, {"question_id": 770, "height": 427, "width": 640, "image": "000000512657.jpg", "category": "description", "question": "Describe the person in the following image in detail.", "dims": "face expression, hair type, maturity, pose", "region_anno": {"bbox": [399.04, 193.07, 89.54, 233.83], "segmentation": {"size": [427, 640], "counts": "cWV54Q=:I6J6I6J5M3L4M2N3N100004KJ7H7N3YHZNe3i1dKPOY4Q1gJ1W5NTJZNhNR2o6GaI_1X6jNaI]1X6dLaIf1Ok1\\6cLeId5Y6]JhIc5W6^JiIb5U6aJjI_5U6bJkI^5T6cJlI]5S6gJjIY5U6o000O1O10000O10000O10O1O1M3YOg0J6K5L4L5F9O101O03M3N1N2N4M3L6K3LnJmHR4n6lKVIV4e6jK\\I]4]6aKdIf4U6YKlIi4S6VKmIk4S6SKnIm4R6TKmIl4U6QKlIo4W6\\JiIN5f5T7O0000000eKnH]2S7aMTIY2m6dM\\IU2e6iMbIQ2_6lMhIo1Z6mMmIn1U6mMSJn1P9E4L4K8I5K6J6K4K<D8H6I:FSgm1"}}, "object_label": "person", "attribute_label": ["face expression:neutral/calm/serious", "hair type:curly/curled", "maturity:young/baby", "pose:vertical/upright/standing"], "control_dims": "face expression", "answer": "The image features a young woman standing in a room, holding a Nintendo Wii game controller in her hand. She appears to be playing a video game, possibly on a Wii console. The room has a couch in the background, and there is a chair nearby. The woman is wearing a blue shirt, and her hair is in a ponytail. The scene captures her engagement with the video game, showcasing her enjoyment of the gaming experience."}, {"question_id": 771, "height": 361, "width": 500, "image": "000000231822.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, texture, transparency", "region_anno": {"bbox": [322.06, 139.28, 111.95, 75.45], "segmentation": {"size": [361, 500], "counts": "VQb33Q;;F7L2M3N3M3M2N2M3O1N2N2N2O]OWFGg9OYFIO9g9L\\FENN4?`9N^FB;?W9NPG2n8OgFB2=V93TGNj84dF^O<=P95dF_O<<n87eF]O?:l89eF\\O`0<i84dFC3Ma0;h85eFCg09c84gFCf08b86eGJ[85eG@RO:X95jGKV84kGMS84mGLS84nGKR84oGMP81SHNl71VHOj70XH0g7OZH1f7N\\H1d7N]H2c7N^H2a7N_H2`7NaH2_7NbH2]7NcH2]7NcH2]7OcH0]70cH0]71bHO^72aHN_73`HM`74`HL_75`HK`76_HJa77^HIb77^HIb77^HIb77^HIb78]HHd79ZHGf7:YHFg7:YHFg7:YHFg79YHHg78YHHg78ZHGg78XHIh77XHIh77XHIh78WHHi78VHIk76UHJk76UHJk76UHIl77THIm77QHJo76QHJo76QHJP86nGJS87lGIT88kGHV8:gGFY8<eGD[8=cGC_8>^GCb8=^GCc8>RGJo8<dFK]9P10O2O001N101N2N101N2N2O0O3M2N2O1N2N2M3N3M3L5K6Jc\\f0"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:orange", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color, cleanliness, texture, transparency, material", "answer": "The bowl in the image is filled with a mixture of fruits, including sliced apples and oranges. The bowl is placed on a dining table, and there are two spoons in the bowl, one on the left side and another on the right side. The bowl is yellow in color, and the fruits are arranged in a visually appealing manner, making it an attractive and healthy snack option."}, {"question_id": 772, "height": 640, "width": 480, "image": "000000205542.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, material, pose, size, texture, transparency", "region_anno": {"bbox": [206.13, 86.49, 160.0, 175.85], "segmentation": {"size": [640, 480], "counts": "[gT49bc08K3N2M3N2M2L5L3hNPOW_OZ1c`0lNY_OW1d`0mNY_OV1e`0lNY_OU1f`0mNW_OU1h`0mNW_OT1g`0mNX_OT1h`0mNV_OT1i`0mNV_OT1i`0nNU_OS1j`0oNS_OS1m`0Q1N10000O101jNPMYAQ3_>YM_Ag2_>\\M`Ad2^>_M`Ab2^>aMaA_2]>dMbA\\2\\>gMbAZ2]>hMbAX2]>kMaAU2^>lMbAT2^>mM`AS2`>oM_AQ2`>QN_Ao1`>SN_Al1b>UN]Ak1b>WN]Ai1c>YN[Af1f>\\NXAd1h>^NUAc1k>^NTAb1l>`NRA`1n>h110O^OSASLn>l3TAQLm>P4UAlKl>T4`01O00000O101O0O100O10000O100O10000O2O0000000000000000001N6L0O2N1O2N1O1O1O1O1O1O1O1O1N101NkL^An0b>POaAn0_>RObAm0_>SOaAl0`>TO`Ak0a>TO`Ak0a>TO`Al0`>SOaAm0_>ROcAn0\\>QOeAP1Z>oNiAo0W>oNlAP1T>nNnAR1S>fNUBZ1j=cNZB\\1f=aN^B^1c=\\NcBc1^=[NdBd1\\=[NfBd1[=ZNfBg1Z=XNgBg1Z=WNhBh1Y=VNiBi1X=UNjBj1X=RNlBl1U=PNoBo1T=hMSCV2]?O2N2N1N2O1N10000O10001N2N2N2O1N3M3Nb0\\O3M3N2L4M2O2N3M3KTmX2"}}, "object_label": "teddy bear", "attribute_label": ["color:brown", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a brown teddy bear sitting on a chair, which is covered with a metal-like material. The teddy bear is positioned in the center of the chair, occupying a significant portion of the scene. The chair itself appears to be made of a combination of metal and wicker, giving it a unique and interesting appearance."}, {"question_id": 773, "height": 640, "width": 428, "image": "000000292060.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, material, pose, size, texture, transparency", "region_anno": {"bbox": [179.18, 269.85, 25.78, 30.16], "segmentation": {"size": [640, 428], "counts": "lT`37gc03N2N1N3N101N1O2M201N1O1010O100O1O6J1N1O2N1O2N3KUg[4"}}, "object_label": "cup", "attribute_label": ["color:black", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size", "answer": "The image features a small white cup hanging from a hook on a wall. The cup is decorated with a colorful design, adding a touch of vibrancy to the scene. The cup is positioned in the middle of the wall, and it appears to be a unique and eye-catching decoration."}, {"question_id": 774, "height": 640, "width": 428, "image": "000000292060.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, pose, size, texture", "region_anno": {"bbox": [202.5, 359.62, 14.49, 33.7], "segmentation": {"size": [640, 428], "counts": "jcn3>^c05N2N1N2L4L40O104L5K2N1O2N>Ak_S4"}}, "object_label": "bottle", "attribute_label": ["color:tan", "color:white", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The image features a bottle with a white label, which is placed on a table. The bottle is filled with a yellow liquid, possibly a beverage or a sauce. The label on the bottle has a picture of a fruit, possibly an apple, and a strawberry. The bottle is positioned in the center of the image, and the table appears to be white."}, {"question_id": 775, "height": 480, "width": 640, "image": "000000347930.jpg", "category": "description", "question": "Describe the sports ball in the following image in detail.", "dims": "color, material, pose, size, texture, transparency", "region_anno": {"bbox": [209.76, 79.82, 48.5, 45.32], "segmentation": {"size": [480, 640], "counts": "n^S3>`>5K5L2N3M2N2N1O2N101N1O101O0O101O0O10001O001O00000001O00001N100O2N2N1O2N101N3M2O1N3L4M4J7DTob5"}}, "object_label": "sports ball", "attribute_label": ["color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "size, texture, material", "answer": "The sports ball in the image is a large, round, and yellow object. It is placed on a couch, which is the main background of the scene. The sports ball is positioned in the center of the couch, occupying a significant portion of the couch's surface."}, {"question_id": 776, "height": 457, "width": 640, "image": "000000049759.jpg", "category": "description", "question": "Describe the sports ball in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [487.18, 133.19, 33.77, 33.87], "segmentation": {"size": [457, 640], "counts": "c_i63R>8K4K3N2N3L3N2O1N10001O000O10001O000001O000O1O2N2N101M4M2M3N3J7KW]e1"}}, "object_label": "sports ball", "attribute_label": ["color:white", "color:yellow", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:striped/lined/pinstriped", "texture:smooth/sleek"], "control_dims": "texture, color", "answer": "The sports ball in the image is a volleyball, which is a round, rubber ball with a net in the middle. It is yellow and blue in color, and it is being held by a person's hand."}, {"question_id": 777, "height": 426, "width": 640, "image": "000000052996.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [448.31, 225.77, 60.1, 46.69], "segmentation": {"size": [426, 640], "counts": "aPk5;j<:Jb0_O6KO00000001O0001O01OO10000001O01O000000001O00000000000\\OUDIk;6ZDFf;:[DEe;9]DGc;8_DGa;8aDG_;9aDG_;9bDF_;9aDG_;8cDH\\;7eDH\\;8eDG[;8fDHZ;8fDHZ;8gDGY;9gDGY;:gDEY;<fDD[;<dDD\\;>bDB^;?bD@^;`0f01O000\\C]Oa<c04L3M4JTff1"}}, "object_label": "book", "attribute_label": ["color:gray", "color:tan", "material:paper/cardboard", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "material, transparency, pattern, color", "answer": "The image features a person holding a book in their hands, which appears to be a thick, white notebook. The person is positioned in the center of the scene, with the book occupying a significant portion of the image. The notebook is open, revealing its contents to the viewer. The person seems to be focused on the book, possibly reading or studying its contents."}, {"question_id": 778, "height": 480, "width": 640, "image": "000000147740.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [0.0, 284.81, 181.93, 189.12], "segmentation": {"size": [480, 640], "counts": "P9k0f2ZO\\M2?R1f8C]IZO^M25I1X1P9EVIHfM\\O0Z1U9CSIHfM\\O1Z1X9CnHYOhM32GO[1[9BTGROX11]N35V1T9GdF\\Od1BaN34NFV1_9=SH^NbN26V1X98mGdNcN07T1[9:iG_NfN27V1[9:gG\\NhN27Z1Y99fG[NjN22MK5NT1d9>dG[NkN43KKa1b96_GlNPO_ON`1e94[GZNQO1172HMb1f93eG_NmN^1`94aG\\NPO`1a94]G]NQO_1d95XG\\NTO`1d94WG[NVO`1g94kF[NVO0:`1h96\\FXND6LL=_1g9;XFUNF;3FM`1S::VFUNF<OJ2[1T::TFUNH6NL4OO`1V:;mETN601`1m9>hESNj0_1`9g0kEiM6`1Q:f0bERN2H4`1Z:T1fElN]:o0eEQO\\:n0aEaMKb1e:l0]EcM1`1e:k0YEeM2`1f:i0ZEfM0a1h:g0YE]Oi:a0WE_Ok:?TEBn:<QEER;9lDHX;n11O0\\NhD@Y;>hDB[;P23M2N2N2N3M2N1O2N2N2N2N2N2N2N4L1O1O2N1O3M1O1ZNZCP1f<ROXCn0h<e0001O0000001O000000001O0000001O0000001O000000001O001O0000001O00001O0000001O0000001O001O00001O001O1O1O001O001O001O00001O001OO1001O001O001O001O1O1O1O1O002N1O1O1O1O2N1O1O2N1O1O1O001O1O003M4Ldco6"}}, "object_label": "car", "attribute_label": ["color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "material, pattern, transparency, texture", "answer": "The car in the image is a white car parked on the side of the road. It has a green stripe on the side, and there is a mirror on the door."}, {"question_id": 779, "height": 512, "width": 640, "image": "000000232646.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [497.73, 94.59, 97.65, 99.16], "segmentation": {"size": [512, 640], "counts": "bdi743NO1i>V1J3N2N2N2N2N3M2N2N2O0O2N2M3N2M3N3N1M3O1N2O1M3M3O1M3N3N000000000000000000000000000000000000000000000000000000000000000000000000000001N1O2N2N2N2N3M2O1N2M3N2N2N2N2N2N2N2O1N2M3N2N2N3M2N102L3LWlf0"}}, "object_label": "stop sign", "attribute_label": ["color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The stop sign in the image is red and white, with the word \"STOP\" written in white letters on a red background. The sign is mounted on a metal pole, which is positioned in the middle of the scene. The stop sign is located in front of a cloudy sky, giving it a somewhat dramatic appearance."}, {"question_id": 780, "height": 344, "width": 500, "image": "000000239773.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [245.15, 121.6, 49.71, 53.92], "segmentation": {"size": [344, 500], "counts": "T^b23e:1N2O1O0O2N2L4M7I2O1O10O0010N2O1O0100O100N21SFYOh9S1H20N12N1O01N2N2N2N2N00001O1N2JUF]Ok9c06N2N2N3M2N3N1N2Na\\U2"}}, "object_label": "baseball glove", "attribute_label": ["color:blue", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "texture, transparency, color, material, pattern", "answer": "The baseball glove in the image is a catcher's mitt, which is designed to catch fast pitches and provide extra padding for protection. It is white and blue in color, with a red wristband. The glove is being worn by a baseball player, who is holding it in front of his body."}, {"question_id": 781, "height": 427, "width": 640, "image": "000000255917.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [50.5, 329.7, 79.73, 55.26], "segmentation": {"size": [427, 640], "counts": "kce086I^<l0F5N1N2O1N2N2O100O00M2101O1O101N4M0000001O0000O1O1M21000000000000O10000000000000O100001O0000O11N1000O100001O3M1O10O00003M001O3L2O1M5L201O2M1O1O2N2O0O3L9FXgd6"}}, "object_label": "car", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, color, material, texture", "answer": "The image features a silver car driving down a busy highway, surrounded by other cars. The silver car is positioned in the middle of the scene, with other cars in front of it and behind it. The car is moving along with the traffic, and it appears to be a typical day on the highway."}, {"question_id": 782, "height": 427, "width": 640, "image": "000000311789.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [0.0, 108.36, 640.0, 318.64], "segmentation": {"size": [427, 640], "counts": "P9Y4R91O0WOiKmG12NMX4T8hKoG02OKY4T8hK_HX4a7gK`HX4a7iK^HX4`7iKoG02OLX4S8iKoG03NKY4T8gK_HZ4a7fK_HZ4a7gKZHOAZ4T8hKoG1MNO01Y4T8hK[HNAZ4U8fK_HZ4Y8O100001O00000VOhKXHNJZ4n7hKaHX4U8fKWGZ4i8fKWGZ4T8fK]H0_OY4T8iK\\HN@Y4T8hKaHY4X8000VOhKaHX4^7jKaHV4_7iKbHW4_7hKaHX4_7gKbHY4]7hKcHX4]7hKcHX4]7hKcHX4^7fKcHZ4W80UOiKaHX4^7iKbHW4^7iKbHW4^7iKbHW4^7hKcHX4\\7iKdHV4]7jKcHV4]7jKcHV4]7iKdHX4[7gKfHY4Z7iKdHW4\\7jKbHW4^7iKbHW4^7hKdH2ZOm3R8QLdH2ZOl3S8RLcH2ZOm3R8RLbH2\\Ol3R8QLcHX4]7fKeHZ4[7fKeHZ4[7fKeHZ4[7hKcHX4]7hKcHX4]7fKeH5YOl3R8oKeH5YOk3S8QLcH4ZOk3S8QLcH4ZOk3S8QLcHY4\\7fKeHZ4[7fKeHZ4[7fKeHZ4[7fKeHZ4[7fKeHZ4[7fKeHY4\\7gKdH5YOk3S8PLdH5YOk3R8QLeHX4[7hKeHY4[7fKeHZ4[7eKfH[4Y7gKfHY4Z7gK\\HNJ[4j7gK]HMI\\4j7gKfHY4Z7fKgHY4Z7hKeHX4[7hK\\HMI[4k7hK\\HMI[4k7gKfHZ4Z7eKfH[4Y7fK^HNH\\4j7gK\\HNI\\4k7fK\\HNI\\4k7eK^HNG]4l7dKeH\\4Z7eKfHZ4[7fK]HNG\\4m7eKdH[4\\7eKdH[4\\7dKeH]4Z7dKeH\\4[7dKeH\\4[7dKeH\\4[7dKdH]4\\7cKdH]4\\7cKeH[4[7fKeHZ4\\7dKeH\\4T8101O00QNUG^Ok8b0UG^Ok8b0UG^Ok8a2000O10UOcKhH^4W7cKhH]4X7cKhH\\4Y7dKgH\\4Y7dKgH\\4Y7dKgH\\4Y7dKgH\\4Y7eKfH[4Z7eKfH[4Z7dKgH\\4T8001OO1000000000000000O2OOHbKeG^4d800000001O00O1GbKeG^4[8cKdG]4\\8cKdG]4\\8cKdG]4e8000001O0000O11O0000000000000000UOcKRH1`0\\4Y801O001O000000O10000001O1O1O001O001O2N1O1O2N001O1O1O1O1O2N1O00001O1O001O00001O1O001O1O1O0000001O00001O00000000000000001O00000000000000000000000000000000O10000000000000000O100O1O1O1O100N2N2N2O1N2O1O100000000000000JRLoFn3Q9TLmFl3R9ULmFl3R97N2N2K50000LaK[G`4d8400O1O100001O2N5K0000001O1O00O1001iKUGl3k8SLWGl3j8SLVGm3j8RLXGm3h8RLYGn3h8QLXGo3h8QLXGo3i8oKYGP4Q901O001O0000001O3M006J1O1O001O00001O001O002N1O2N9G5K3M2N2N3M2N1O1O1O1O1O1O2N2N1O2N1O2N1O001O1O001O1O001O1O0000001O0000001O00001O0000000000001O0000000000001O000000001O000000001O00001O00001O00000010O0001O0000001O0O2O010O001O00001O0000001O0000O10000000000000000000000001OO1001O001O00001O3M00M3O100O100O10000000000000O1001O0000000000000O100000000O1000000O10000000O100001N10000000000000000O10000000000FbNfD_1c;0000000O11O000000001O1O1OGcNeD\\1[;dNgDZ1Y;iNdDW1];jNbDU1^;lNbDS1^;oNaDP1_;RO`Dm0_;UOaDj0_;WOaDh0_;ZO`De0`;]O^Dc0b;^O^Da0a;e00O1001O00000O100000O1000O101N10000O100O1000000000000O100O1O1LRNkDm1U;501N1O1O1O1O1M3O10O02O0O100000000O1000O1001N100O1O100O10000000000O1O10000O100000000000000000000000000001O0000000000000lNaE\\O_:c0cE\\O]:b0eE^O[:=kEBU:=nEAS:=oEBQ:>PFAQ:=PFCQ:<oEDQ:;QFDo9<QFDo9<QFDYO"}}, "object_label": "dining table", "attribute_label": ["color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "texture, pattern, color, material", "answer": "The dining table in the image is brown and has a cat lying on it. The cat is resting its head on the table, possibly sleeping or just relaxing. The table appears to be a wooden surface, providing a comfortable spot for the cat to lay down."}, {"question_id": 783, "height": 640, "width": 427, "image": "000000450559.jpg", "category": "description", "question": "Describe the skateboard in the following image in detail.", "dims": "color, material, pattern, texture, transparency", "region_anno": {"bbox": [181.58, 215.36, 160.0, 158.55], "segmentation": {"size": [640, 427], "counts": "Xke37hc02N2N2M2O2N1O1O2O0O1O100O010001O1O0O2O001O0O10001N10000O10O10O0010O10O01O00000ZOCh]O?Wb0LZ]O:db0a0000O1001O00O10^OjN[^OV1fa0jNY^OW1Wb0OnMjN]AU1e>kNZAU1g>lNXAS1j`00L32O1O1lNW]OP1jb0POV]Oo0kb013QOT]Og0Tc0M3N1O1O1N2O1O1O1N2O10O0O2@DZ]O>fb0DT]ONL>ob0FW]O;ib0EW]O:fb0`01000N3N1N2O01001O00O1000000000O011O000000O11O000000O11N11O000O20O000000O11O00000000000O101N002N1O100O10000O2OO100000001O0O2O1N2O1N2M4M3L3M5J7GZae1"}}, "object_label": "skateboard", "attribute_label": ["color:black", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, material, transparency, color, texture", "answer": "The skateboard in the image is black and white, with a red sole. It is being used by a person who is performing a trick, jumping in the air while riding the skateboard."}, {"question_id": 784, "height": 480, "width": 640, "image": "000000116206.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [403.42, 126.2, 236.58, 249.17], "segmentation": {"size": [480, 640], "counts": "oal53l>4M2O1N1O2N102M1O100O2N2O0O10O01O10O0001O01O10O100O4M3L100O1O10000O100O100O100O10000O2O00O010O11O0O000100O100O1O03N1N2O1N2O1O0000001N100O10O11O000O1000000O1000001OO11O0O10000000000O11O00000O0101O001O0O2OO1001OO1000O2O001OO11O0000000000001N100000001O01SNPCg1W=OO0O10aNlBR1S=lNPCS1P=kNSCT1m<iNVCX1Y=00001O00000O101O00000000001N10000O2OO11O1O000O1000000O2O00000O1000001N10000000001N10000000000000000O20O000O0101O0000000000O1000000000000000000O10000O100O10000O100O100O100O2N100O1O1O1O100O2N002N1N101O1O1O1N10_E"}}, "object_label": "knife", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "color, size, cleanliness, transparency, texture, length, material, pose", "answer": "The knife in the image is a large, sharp, and silver-colored kitchen knife. It is placed on a wooden cutting board, which is placed on a counter. The knife is positioned in such a way that it is ready to be used for chopping or slicing ingredients."}, {"question_id": 785, "height": 426, "width": 640, "image": "000000253452.jpg", "category": "description", "question": "Describe the fork in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [8.62, 78.5, 42.12, 115.83], "segmentation": {"size": [426, 640], "counts": "c5637a<I_CLN8a<N`CK15]<3aCH34\\<8dCG_;M_D1a0g0k:InD7n:2mDNk:=QEDg:WOZEU2n:O101N100N11KPNPEo1S;nMnDQ2S;oMmDP2g9PNbGT2^8nM`GP2b8RN[Gn1g8TNnFJ[OP2k9VNiFNWOj1S:XNeFj1`9fNPFW1T:mNfEn0a:m01N10O1001O3L6K>@:G:G1N01FkNYD[1i:dN^ES2m:M3QNjDj1\\;N102M8G7Ja0^O`Ze7"}}, "object_label": "fork", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "length, transparency, size, texture, pose, cleanliness, color", "answer": "The image features a close-up view of a fork, which is placed on a dining table. The fork is silver and has four tines, making it a standard eating utensil. The fork is positioned on the table, ready to be used for eating."}, {"question_id": 786, "height": 426, "width": 640, "image": "000000256518.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [85.85, 151.2, 53.28, 13.77], "segmentation": {"size": [426, 640], "counts": "_`S13S=5N2N1000000000001O00000000000000001O000000000000000000001O01O0000000O100O1O100O100O1O100O100O100O101N1O10iX`6"}}, "object_label": "spoon", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "length, texture, size, color, material, cleanliness, pose, transparency", "answer": "The image features a wooden spoon with a handle, placed on a white surface. The spoon is made of wood and has a brown color. It appears to be a large spoon, suitable for serving or stirring large quantities of food. The wooden handle is curved, providing a comfortable grip for the user. The spoon is positioned horizontally on the white surface, showcasing its size and design."}, {"question_id": 787, "height": 426, "width": 640, "image": "000000256518.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, pose, size, texture, transparency", "region_anno": {"bbox": [270.31, 0.0, 242.61, 96.42], "segmentation": {"size": [426, 640], "counts": "Rj`35k<;XO0RD2_;T1D;L4O2N2O10BQE`No:a1RE]No:c1RE\\Nn:d1RE]Nl:d1UEZNl:f1UEXNk:i1YERNh:o19001iDUNl:l1SEWNk:T20K5L40O10001O0O2O00001O\\OSE_NM7P;Y1UE]NO8l:l0XEPO54b:j0nEVOR:i0PFVOP:j0PFWOo9h0SFWOm9g0UFYOk9f0WFYOi9f0YFZOf9d0\\F\\Od9c0^F\\Ob9c0_F^O`9a0aF_O_9a0bF^O^9a0cF_O]9?eFBZ9<hFDX9<hFEW9:kFEU9:lFFT9:lFFT99nFGQ99oFHP98PGHP98PGIo87RGHn88RGJl87SGIm87TGHl88TGHl88TGIk89SGHl89SGGm8:SGFl8;SGEm8<RGEm8<RGEm8<RGDn8<RGDn8<RGDn8<SGDl8<TGDl8<TGDl8<TGEk8;UGEk8;UGEk8;VGDj8<VGDj8<VGDj8;WGFh8:XGFh8:YGEg8;YGFf8;YGEg8<XGDh8<XGEg8<XGDh8=WGCi8=WGCi8>VGBj8>VGBj8?VGAi8?WGAi8?WGAi8?WGAi8?WGAi8`0VG@j8b0TG^Ol8c0SG]Om8d0RG\\On8c0SG]Om8b0TG^Ol8`0VGAi8>XGBh8=YGCg8;[GEe89]GGc88_GGa88`GI_85cGK]84dGL\\83eGM[83eGM[82fGNZ82fGNZ81gGOY80hG0X8OiG1W8OiG1W8NjG2V8NjG2V8NjG2V8MkG2V8NjG3U8MkG3U8MkG3U8MkG2V8NjG2V8MkG3U8MlG2T8MmG3S8MmG3S8MmG3S8MmG2T8NlG2T8NlG2T8NkG3U8MkG3U8MkG3U8NjG2V8NjG1W80hG0X80hG0X80hG0X80hG0X81gGNZ82fGM[84dGL\\84dGK]85cGK]85cGI`87^GJb86^GJb87]GIc87]GHd89[GGf8:XGFh8;WGDj8>TGBl8?SGAm8`0RG@n8a0QG@n8a0QG^OP9c0oF\\OR9f0mFWOU9n0b11N1O01O000000000100O4L4M1N0001O000O2O001O000O101O001N10001O001O00001O001O00001O001O0O2O010O1O001O001O1O001O1O001O1O1O010O1O1O1O2N100O2N2N2M[Qf1"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "texture, size, transparency", "answer": "The bowl in the image is filled with a variety of food items, including toast, eggs, and meat. It appears to be a breakfast meal, and the food is arranged in a visually appealing manner. The bowl is placed on a dining table, and there are two cups nearby, one on the left side and the other on the right side of the table. The presence of these cups suggests that the meal is ready to be enjoyed by someone."}, {"question_id": 788, "height": 480, "width": 640, "image": "000000273711.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [257.06, 235.45, 103.07, 85.19], "segmentation": {"size": [480, 640], "counts": "RUj34i>3M4M2M3N2N2N2L4N2L4N2J7L3M3J6M4N100O10JlB`NS=a1mB_NS=g10WOnBDR==mBDR=U1OaNRCHNo0o<XOUCGM11g0m<@WCFL30LN3062Km<7WCGK24OK?o<HWCIL111N;n<IYCJJ10MOO0`0n<IZCHJ34MI?o<I[CGJ33a0i<DYCJKN8a0d<HWCK=<[<JTCM7IN6G1P=3WCJ7NH0M4m<4WCH90M4c<4jCJB2d<4^CGD::Kd<4^CHB;<Ic<4SCF8?4Ga<4SCG9;KGO2j<6QCG:;KHN1m<9XCGIMON44N2n<9WCE1KL5N2n<7ZCC74C0l<8gCC@3O1j<8hCD_O300i<9\\CI2NJOh<:\\CIFL0O334Mh<<\\CFE52MX=8VCKCNV=7[CF@31Nh<=ZCA74E1i<:YCC92D2j<9WCE<NE3h<:WCE<MF5f<:VCF=JH6e<g0^CWOL3g<f0[CXOM3h<P1UChN38h<P1UCiN28h<o0VCjN17i<o0SCnN33j<X1VChNj<o0UClN33h<o0XCkN35e<o0YClN26e<m0XCoN06h<k0WCAi<?XC@h<`0YCTOKOl<m0XCVOKNl<l0WCCi<=WCCj<<XCTOM2k<j0YCnNKN68e<l0ZCRO02f<l0UCnNOe0l<\\1O010O00]OUCQOk<d1N2N1OJ]CnMe<_1XCnNP=P1TClNn<S1`0H9O1N1G:G:Ea_S4"}}, "object_label": "bowl", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:brown", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, size", "answer": "The bowl in the image is filled with a variety of food items, including chocolate candies, cookies, and fruits. The bowl is placed on a table, and it appears to be a plastic container. The food items are arranged in a visually appealing manner, with the chocolate candies and cookies being the main focus. The bowl also contains a few oranges, adding a touch of freshness to the assortment. The combination of sweet and fruity items creates a colorful and inviting presentation."}, {"question_id": 789, "height": 480, "width": 640, "image": "000000273711.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [345.21, 298.91, 65.11, 69.87], "segmentation": {"size": [480, 640], "counts": "U`R54k>4FKbA<W>EiAc0o=\\OSBk0e=SObBl0Z=TOgBn0V=ROkB0Dk0_=VOPCk0k<UOeB2`0i0j<UOfB3`0h0i<TOiB1`0l0k<SOVCl0e<XO\\Ci0b<XO^Ch0b<XORCN0j0l<YOTCN0h0l<YOVC0Mg0k<YOYC2Je0m<XORCL33IO4k0l<XOSCMOOO1003k0l<WOSCN31LM3m0k<WORCO314i0g<XOQCN325h0g<_OQCL8d0g<KZC4f<GPCA:h0f<FQCC8f0i<MXC2h<^OPC67<i<]OSC63=k<]ORC54=j<^OTC32>k<_OVC0Oa0j<@YCLMe0j<_OZCKEN3h0o<^OXCMFM3h0Q=]OUCNFN4g0P=\\OZCLD02g0P=^OoBN>d0c<]OPCO3M0g0o<[OnB0121c0Y=[OdB42b0Z=YOeB51b0a=_O^Ba0Z=XOhB7Na0a=@`B`0W=XOiB3KO5f0_=\\O]BM4f0_=^OaBMJe0e=^OaBe0`=\\O`Bb0a=_O_B?b=C]B:f==3N2K6L4N1O2N0O2O1N3KSQ[3"}}, "object_label": "bowl", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "size, cleanliness", "answer": "The image features a bowl filled with a yellow substance, likely a sauce or soup, placed on a dining table. The bowl is positioned in the center of the table, and a spoon is resting inside it, ready to be used. The spoon is placed near the top of the bowl, indicating that it is ready to be scooped up and eaten. The dining table occupies the majority of the scene, with the bowl and spoon being the main focus."}, {"question_id": 790, "height": 480, "width": 640, "image": "000000273711.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, length, pose, size, texture, transparency", "region_anno": {"bbox": [56.1, 76.05, 509.93, 403.95], "segmentation": {"size": [480, 640], "counts": "mTo03f30[74cHMZ77bHK]75dHLY71jH2S71kH1S70lH1T70kH0T71mHMR76`F@Z1:T87bFCW15W89bFBX14U8;cFBW13U8<TIDk6=UI_Om6c0SI]OQ7?oHAR7>nHBT7;nHCT7;W3F^B8c=I]B7a=K_B5_=MbB2]=OcB0\\=2eBL[=5fBJX=8iBGV=9mBEQ=;RCDl<=cJDnM<R2ElM;U2FiM:X2GeM7_2K^M4d2M[M1g20WM0j21UMNl23RMDX3>d51O1O1O2N1O1O1O1O1O1O2N1O1O0O2O1O1O001N2O00000000000O10000O100000000001jNXBR1l=O1O1O5KGXO]Bd0d=]O[Bc0f=\\OZB4O3T>GPB7b>Jm`Z24l^eM4N2M3M3L4M3N2O2M1K6N20001eKkNjJS1W5nNjJP1V5POkJo0U5QOlJo0S5QOnJn0S5QOmH2@l0P:XOPFf0m9]OTFb0j9@VF`0g9CZF<a9GaF9[9KfF4W9NkF1R92nFNP94QGKk87XGHc8<_GC]8`0eG_OZ8b0fG^OZ8b0fG^OZ8a0hG^OX8b0iG]OY8`0iG_OZ8>fGBZ7^OVGn0`1Da86`GJh8NYG1h8MYG3i8KWG5j8IXG6i8IWG7j8HWG7j8GWG:h8FYG9d6AfH5f0:i8DYG;i8BXG>e;000001O0000001O002N1O000000001O00]GJ\\26cML\\24cMK_25_MLb23_MKc26\\MJd26\\MHf28UMMYJM\\85ZMNZJN\\84YMO[JM\\84YMO[JM\\84YMMQ33n500000001O1O1O`LMSH3k70TH0k71TH0g75YHKd78RHCVM6g:8SHBVM6f:9]HG`7<aHCZ7b0gH]OX7d0hH\\OW7e0iH[OV7f0jHZOU7g0kHYOU7g0kHYOT7h0jHYOW7g0jHXOU7i0kHWOU7i0lHVOP7MfEm0Z3WOo6LgEn0Y3VOT7j0lHVOT7j0lHVOT7j0lHVOo6o0QIQOo6o0PIQOQ7o0oHQOQ7o0oHQOQ7o0PIQOo6o0QIQOo6o0QIQOo6o0QIQOo6o0PIROP7o0nHROQ7o0oHQOP7P1PIPO`62]Fo0R3PO`65YFm0W3nNa6KaFX1m2mNo6S1RIlNQ6LbGOWOT1V3QOQ6LbGW1\\2nNS3IdL1nM5UOl0U3UOT3IjMR1QOVO\\7h0cHYOS3ISNk0gNSOQM9U6HTNm0eNRORM9U6GVNm0fN\\OS3IXLN_Om0S1SORM9T6IVL1Bh0R1UORM9T6IUL3Dd0Q1WORM9U6GTL6Dc0T1@`5M]Ib0S1A^5O_Ia0R1@^50bI>o0C_5OdI<h0]OUM9^8OfI;f0Jd5KfI;g0Ic5KgI<g0H`5CgG5T2?e0I_5DjG0U2b0b0J`5CUJd0;IS8DQE`0l2LS8CREa0j2MX82hGNZ80fG0Z80fG0[8OeG1\\8ObG2^8NaG3`8L`G4`8L_G5a8K_G5b8J]G7c8J[G7f8JTG:k8ITG6l8JTG6l8KTG4l8\\OgD=]27o8IQG7P9InF8R9HnF8S9GlF:V9DiF=X9BhF>X9BhF>X9BgF?Z9AdF`0\\9@bFb0^9_O`Fb0`9^O`Fb0a9^O^Fb0b9_O\\Fb0d9@YFa0g9CTF>l9DQF=n9GoE9Q:IlE8[7POlIk0dN6a7oNkIn0^N6g7mNjIO\\Mk0R18j7mNiIN\\Mo0o06l7mNlIo0SN6Q8lNnIo0lM6W8kNnIP1gM6\\8kNlIT1\\M7i8eNkIj2V6WMjIg2W6ZMhIe2Y6[MgIc2[6^MeI`2\\6`MdI_2]6bMbI^2^6bMbI]2_6cMaI\\2`6dM`I[2a6fM^IX2d6hM\\IW2e6iM\\IU2d6mM[IQ2g6PNXIo1j6QNUIn1l6RNTIm1m6TNRIk1o6VNbHCVNV2Y9WNaHCVNU2Z9XN`HBWNS2\\9]NiHb1W7`NhH_1Y7aNgH^1Z7cNeH\\1]7cNcH[1_7eNaHZ1`7gN_HX1b7jN\\HT1f7lNZHR1n4YN^Ke0DQ1n4\\N]Kd0Do0P5]N]Kd0Bm0l3]NoJ8]1>Hl0l3`NoJ5b1:Co0n3bNnJ3j15YOT1R4bNZN2eM[1V;0aJcN]M[1U8N2M3NbJlNiL0VKS1R8mNgL2VKo0U8oNeL1WKn0V8QOoLm0S3SOlLl0d8O100N3M3N1O2M2N2N20I4@@fBa0o=@ShS1"}}, "object_label": "dining table", "attribute_label": ["color:red", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, transparency, texture, size, color", "answer": "The dining table in the image is filled with a variety of food items, including sandwiches, fruit, and desserts. There are several bowls and plates containing different types of food, and a few cups can be seen as well. The table is set up for a buffet-style meal, with a large assortment of food options for people to enjoy.\n\nThere are multiple chairs surrounding the table, and a person is standing near the table, possibly preparing to serve themselves or just observing the spread. The table is well-organized, making it easy for guests to find and pick their desired food items."}, {"question_id": 791, "height": 640, "width": 469, "image": "000000276921.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [40.24, 199.16, 202.79, 325.03], "segmentation": {"size": [640, 469], "counts": "TYk0>`c03M4M2M3M3M3N2N2M3N1O2M2O1O2M2O1O101N1O1O1O1O1O001O1O1O010N200N200O1O001O1O00001O1O001O1O001O001O000]KlMnBNZ4U2h8VNSGj1l8\\NoFe1o8_NnFa1R9aNmF^1S9eNjF[1V9hNhFW1Y9mNbFT1]9mN\\CCR2`1c:nNTCKV2W1e:9WEFj:=RECNPNi8_2VGAL[Ni8W2XG^OLaNh8X2VGVO0iNf8S2WGTO1mNg8P2WGRONTOi8l1WGQONVOj8k1kFYO8POm8i1iFVO7UOo8h1gFSO9XOo8g1fFPO7^OS9d1dFmN6CV9c1aFiN4J[9`1^FdNN7c9W1_FaNI=h9S1^FZM]O09h1m9Q1ZFUMCO5n1n9o0ZFSMCO5P2n9o0YFQME03P2Q:o0VF`LBN1E4m01S2R:n0TF^LHL4e0JW2W:k0RF\\LLKMKMk01Y2W:j0RF[LOJNh0JX2Y:k0PFXL1MLi0HW2]:l0lETL7NGS4V:OhEnKh0R4b91eElKh0T4d9NdF1^9McF3_9KaF4a9J_F6c9IbETL>T4Q:GjEVLKR4\\:H^EVL006Q4^:H\\EWLO26o3_:I[EUL135n3`:KcEWLMn3`:KcEWLMm3`:McEWLLk3b:ObEULKl3d:ObESLKm3c:2oEOQ:1oENR:3fEoK_Om3k:5lEKU:5jEKW:5hELW:6fEK[:5]ElKGo3l:5dEK\\:6XEkKOo3j:6VEmKNm3m:6^EKc:5oDmK6m3k:7oDmK3m3o:6nDkK1OLP4V;6mDjKOU4U;1UEIm:6TEHm:9jDjK1l3W;:hDkKOi3\\;=dDjKNj3^;=iDBX;=hDBZ;>gD_O[;a0fDZO^;e0dDUOa;k0`DoNe;Q1]DfNj;Z1WDeNi;Z1ZDhNb;X1_DkN];T1eDQOU;o0lDUOo:k0QEYOl:f0UE^Of:b0ZEBc:=^EF^::dEFZ:8iEJT:5nEOm90UF2h9MZF5c9J^F9_9GbF:\\9FeF:[9DfF>X9BiF>W9@jFb0U9]OlFc0T9[OnFe0Q9ZOPGg0P9VOSGh0o8VOSGhM^Nf1_:b0SGgM_Ng1_:`0TGkMZNe1c:>WGi0j8UOWGk0j8ROXGlLVN`04_2a:2VGoLVN7<f2Z:2UGQMUNNN1e0i2V:6QGSMTOf2m96PGRMUOe2o92ZHJh74oD[MT3_2P83mD_MT21bNY2a:4lDaMd0O71PO5n02oNb1_;b0oFfMcM4f1V1l9n0jFjMcM33Ij1o0j9X1gF[NG3e9[1kF`NDOe9W1PGiN_OKe9U1QGjNDJ_9T1UGkNfLOT?T1UDlNR<R1mCQOT<k0kCQOjL3]?i0d3M3M3L3N2N2O1O1O101N1O101N1O1O2N[`_4"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:yellow", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "length", "answer": "The image features a teddy bear hanging from a string, possibly in a car window. The teddy bear is wearing a red bow and has a plaid pattern on its shirt. It appears to be a cute and playful decoration, possibly for a child or a car owner who enjoys a touch of whimsy."}, {"question_id": 792, "height": 404, "width": 640, "image": "000000014439.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pattern, pose, size, transparency", "region_anno": {"bbox": [57.54, 155.24, 35.36, 18.3], "segmentation": {"size": [404, 640], "counts": "YQg08Z<4N1N2N100O100O100000000O10000000000001O00001N2O1O001O00003M1O002N2Nedg6"}}, "object_label": "backpack", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge"], "control_dims": "pose, material, color, pattern, size, transparency", "answer": "The backpack in the image is black and appears to be a large, possibly a duffle bag. It is lying on the grass, possibly on a field or a lawn. The backpack is open, revealing its contents, which could be a variety of items such as clothes, toiletries, or other personal belongings."}, {"question_id": 793, "height": 480, "width": 640, "image": "000000224664.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, pose, size, transparency", "region_anno": {"bbox": [365.38, 151.54, 18.0, 19.26], "segmentation": {"size": [480, 640], "counts": "lf[53l>001O010O0100O10000001_AOQ>1mA2S>OiA2X>0dA1^>63N3LUkg3"}}, "object_label": "kite", "attribute_label": ["color:blue", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:horizontal/lying", "size:small/little/tiny"], "control_dims": "transparency, size, material, color, pose", "answer": "The image features a kite with a long, curved tail, which is a distinctive characteristic of this particular kite. The kite is flying in the sky, and its tail is visible as it soars through the air. The tail of the kite is blue, adding a vibrant touch to the scene. The kite appears to be a large and impressive sight, capturing the viewer's attention as it gracefully glides through the sky."}, {"question_id": 794, "height": 480, "width": 640, "image": "000000014888.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "cleanliness, color, maturity, pose, state", "region_anno": {"bbox": [0.0, 3.12, 639.31, 438.36], "segmentation": {"size": [480, 640], "counts": "331X40hK240K00000O11O0O2O?Z8l3fGdK16OK0O11OO11Oi0Y8l5M3M00M3O10gJYIY2g6QMYI[N1d4f6QMYI\\N0c4i6n21O001O00O1002N1kHUIUO1g6h6UJXITO0g6g6[1KlG]IU8g600000OYIXIX5h6gJYIY5`4[IcM\\1mMY5`4[IdM[1lMZ5`4[IeMZ1jM\\5a4ZIeMS8[2nGdMOkMP8a4PHeMS8[2mGeMS8[2mGeMS8c41OnGXIn7l61000nMTIPL_4PNkMU1gMd3OWMa3PN[M0^1U1gMd3OWM_4PNkMU1gMf5^4UIkMU1gMf5^4UIiM?hMU7f6mH[IT7c6mH]IC0X7c6UI\\ID1W7c6SI]IG0U7c6SI^IINU7`6cHaI?1Y7^6jHbIV7^6RIaID0b6_6iIbIEOb6b6fI_IHO`4ORMd6fN\\II1_4ORMe6VO\\Ih3ORMe6`N]I2O^6d6]IcI2Ia6c6_I^I5O\\6c6Z1000kH\\In5d6QJ]Io5d6V1000000gMgGkMY8^40O_M]IgLc6Y3]IgLc6k50iH\\IR6d6nI\\IR6e6T10001OO1WM[IWMe6h2\\IXMe6f2\\IZMU4YMVN]5eMZMU4ZMUN\\5fMZMU4YMVN]5eMZMd6a500000dHZIc30ZNf6RN[Ic31ZNe6RNZId32YNe6RNYIe32YNd6d2[I]Me6d2YI]Mg6c2YI]Mh6c2YI[Mh6d2XI\\Mh6b2[I]Me6b2\\I^Me6b2ZI^Mf6d2WI]Mi6nMVIh6j6g0000YMWIWMj6_50[MZIPMe6P3\\IPMd6o2]IQMb6T3YImLg6U3WIkLi6f51^MVIlLj6T3VIlLi6U3WIkLh6V3XIjLh6g50_MXIjLh6aMYIc3OYN2b0i6S3WImLh6U3VIlLj6e500MmGYIS8g6300000kGYIQ8g6nGZI\\5OWMg6c500NYH[IW7e6b00UH[I[7e6eH[I[7e6eH[I[7f6dHZI\\7e6dH\\I\\7d6dH]I[7c6fH[I[7g6]KZInL0c4g6\\KXIm22RM0e4f6^NYInL5`4b6bNXIoL6_4b6iN\\IX1d6b300000TK[ImLMW4g6YOYIg0g6i300O1WLhGj0h3YLf0m2bKj0h3YLf0m2bKj0^3YLZ1m2XKj0^3ZLY1l2YKj0^3YLiL1W4l2cKi0e3\\Lh0k2bKi0Y8o2000O10000KgGcIY8\\6iGcIW8]6hGdIX8m2fG=1hLY8Z6fGfIZ8[6gGbIZ8b2eGW11WLZ8b2eG[1[8eNeG[1[8`2fGdIZ8e2fGRO1M_8P1aGSO2K]8o0dGVOOK]8o0cGXOOH[5^NcMb2TMVOOJZ5^NcMb2UM_MJa141[5\\NbMc2PM^M100Y1OjN4`1Z5\\NbMc2PM^M10OZ10hN5b1[8n0`G_MO^1;6V8m0`G^M0^198X8l0_G]M2]15=Z8i0dGbMLn06h0Z8h0cGkN2=[8h0cGlN0=]8g0_G^M050P14e0^8h0]G_M203i0L\\O3d1`8l0^GZM51I;0J2O2e1`8m0\\G[M5i0KYO5g1_8Q1`GVN2h0_8Q1aGPNKZ1d8a0\\G[M60I:2E8P2]8e0[G\\M5OKO06>j1X8e0YG_M6NI0156INQ2c8d0YG_M5=ODLn1f8i0`GZMJ13U2c8?aGWMHO71L4Mn1e5lM\\Mh2oLYM9OH161K5Nm1e5lM\\Mk2YMXMNNJY2f5fMYMl2XMVM4X2[5gMYMk2XMVM6U2^8e0RHROT8n0mGgNQO`NV9i2RGVM:j1GUN]8k2^GTMM3>Q2CnMd8j2]GUMO0=T2DlMc8k2]GTMb0m1[OTNR9l2nFVMc0f1]OXN1OR9T3`GoN]8Q1QGQM9o1KmMa8^3\\GoNObMf8a3XGPOj8<VG8j8o2000O1O1O11O00000000000000O1000000O1O100O100001O0000O11O000000JRGZJn8[5a0O100000000O100000000O10000O100000`FfJ40l8Z5ZGfJf8Z5ZGfJf8Y5[GgJe8X5b0O1000000LYFoJ7NW9n4hFSKL4\\9l4jFUKU9k4jFVKKIW9Q5oFVKIIX9P5QGVKGJX9P5RGUKQ9k4oFUKFKX9Q5jFPK32KM40m8\\5oFfJ1N22m8Z5QGdJ11O2o8Z5UGdJK3P9Y5UGkJk8X5RGhJn8Z5PG_J03P9V5oFlJ5Nl8U5QGlJ4Nk8W5PGkJ0L12o8c5PG^JP9b5PG^JP9Y5oFkJ0LQ9Y5oFQKQ9_501ODPGhJP9W5RG`JO4o8\\5RG`JO3P9]5QGgJo8Y5QGgJo8Y5QGgJo8Y5QGgJo8Y5QGcJNNb17_NKl6^5TIgJ`1OaNLk0MP5a5XJcJ[13cNMi0LQ5b5WJbJ]1LjN1b0OP5c5WJ_Jm8a5RG`Jn8`5RG`Jn8a5QG_Jj0Ln00]4g5iI]JQ9c5PG]Jo8c5TG[Jk8e5TG\\Jl8e5SG[Jm8f5RGZJn8i530SJTJf2l5ZMTJf2o5T3O1N2003M3SGoIe8Q6[GnI\\21i3R6XLPJh3Q6WLoIi3R6b21^JkIkL0W5U6_31O0000000000O10000001O00000000O100000000001O000000O10000000000000000O10000000000001O001O00001O00003M6J1O00O1000000001O001O0ZM^IoLa6o2eImL[6g2cIjJ8]2U6g2VJXMj5_2^IVKo0Y2d5R1_IgM0lNS1[2^5V2jJjMU5Q1^I_Mf1`1l4l1WKSNi4c1bK\\N^4b1dK^N]4V1_IgLU2S2\\4T1PLlNP4f0^LYOb3d0bL\\O^3a0eL_O[3<jLDU33VMLm2MWM3i2D`M<`2BcM=]2CcM=]2DcM;\\2EeM;[2AiM?W2_OkMa0U2]OmMc0S2WO^IdNa4U2Q2VOTNj0l1nN\\InNm4T2g1gNdNX1]1dNfN\\1Z1oM\\I>[5c1Y1oM\\I>[5c1Y1oM\\I<]5e1W1PN[I:`5e1U1PN]I:^5f1W1mM\\I<^5g1U1nM]I;^5g1R1QN_I9_5f1R1QN_I9_5f1R1QN`I8^5g1S1QN^I8_5g1S1PN_I8_5h1S1mM`I:^5i1Z1UNgNk1Y1UNgNk1X1VNhNj1X1VNhNj1X1WNeNk1T1lM_I9[5m1V1kM^I8Z5o1Y1hM]I9o2GTOZ2_4fM_I7o2KZNNkNg2S6XMmI0M7Y24kMNNNI10X3[6`LmI0L8Q2IkMe03P4X6ZKSJ8`1c5n4\\JkJk5T5VJVIH_1V6k4jImI0L<o0V6X5^ImI1K;o0W6c5^I^Ia09@Fk6c6UI]IQ8b670000O1001O001O0000000000O1OXL]IUOc6d400O1O100O1N200O1O100N2O100O1O1N200O1O1O1O2N100O1O1N2NlHZJR5d5V2O1O1lJgF_4[9\\KkFa4W9dKcFG0Z4_9XLbFm0OP1a9f201_GdJ\\7]5bHeJ]7T5kHjJU7W5eIiJQN4W7o4RKmJQ5P5a2iNmFWLg00R7X4^GhK150e05GV8Q6nH]Ic5R7nInHR6U7kIjHV6W7iIiHW6_7UIcHU7d701O0QJ`H^4c7^K_Ha4g7ZKWHg4m7hJlGl5W8=1O1O;E5K;E4L1O6J3PK_F[4f9=4WK[FH5d3a9cLZFF9f3^9gLiFY3X9hLfFX3[9mL^FT3c9WLTF`04[3P:eLoE[3Q:gLnEX3R:WLlE93_3S:VLkE>O[3^:eLaEDM53R3e:oL\\EH<V3Y:SMhEH_OU3m:PMbELAT3m:UM\\EP3g:oLWEQ3j:RMPEP3Q;?2N1O4L2N1_LeD[3\\;cLREP3`;O3M2N7VMhC001:h1j<N0YNlBb1Q=aNoB_1P=bNPC^1Z=O000000O100000000000^NdB`1_=OM3O100003M00N20000000000001O1OH8ROn0E;JPMZDR3d;6M3L4OnLcDc2[;b0OdLgDL2o2W;\\MgDe2W;c0M3N2nI\\Lh0f0XJn1b4mMR16\\Jm1X4^NfMhNQN2h2X4U1]MmMcNi0R4V1`MnMaNj0MaMd3b3TNPN`Ne0LmMFKc0OR2a3_OlM`Nd0LRNDM[3V3ROjMeN8;jNk1j2@oMaN95nNj1f2_LYMV3e0`N2\\NYO^5f2mMjM`NDXNLf5d2^6CiChMf83mJ]1\\L`N_95aFM^3\\1dLbN^94`FM_3Z1fLeN11P91_JW1U6hNlIj0[:LZLYO]If0^:J9KU<E^UO0h=1oB2VONj=1QCOVO0i=1UCOk<1UCOf1"}}, "object_label": "cow", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry"], "control_dims": "color, state", "answer": "The image features a black and white cow with a white face, standing in a barn. The cow is positioned near a wall, and it appears to be drinking milk from a machine. The machine is equipped with four red cups, which are likely used to collect the milk. The cow is focused on the milk, and it seems to be enjoying the process."}, {"question_id": 795, "height": 427, "width": 640, "image": "000000082821.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, transparency", "region_anno": {"bbox": [417.53, 231.25, 70.59, 30.07], "segmentation": {"size": [427, 640], "counts": "Sd`51R=9O1O01O1O1O00O2N1000000O10010O2N1O3N0O010000O001O010O01O000O10000000O1000O1000O1000000000000O10000O1000001O001O001O001O1O1O1O2L^To1"}}, "object_label": "boat", "attribute_label": ["color:red", "color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque"], "control_dims": "color, material, transparency", "answer": "The boat in the image is a small, yellow and red sports car-shaped watercraft. It is designed to resemble a sports car and is parked in a row with other similar boats. The boat is positioned in the water, and it appears to be a unique and eye-catching addition to the scene."}, {"question_id": 796, "height": 427, "width": 640, "image": "000000082821.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, transparency", "region_anno": {"bbox": [533.22, 225.24, 33.81, 18.0], "segmentation": {"size": [427, 640], "counts": "Y_n61Z=1O000iB0T=13O11N1O001O1O1O1O100O1O100O1O1O10O00000000000O2O1O1O1O1O2MeVn0"}}, "object_label": "boat", "attribute_label": ["color:yellow", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain"], "control_dims": "pattern", "answer": "The image features a yellow boat with a blue stripe on it, parked on a beach. The boat is positioned on the sand, and it appears to be a small, single-engine boat. The boat's color scheme is predominantly yellow with a blue stripe, giving it a unique and eye-catching appearance."}, {"question_id": 797, "height": 480, "width": 640, "image": "000000119038.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, texture", "region_anno": {"bbox": [359.28, 205.25, 70.0, 66.2], "segmentation": {"size": [480, 640], "counts": "c]Y51o>000_A3P>NmA4R>NdA:\\>500O2O00O10010O02N3O2L101M3N2N2N2aBlNm<e1O000000YOVCWOl<g0g01O016I?A0000CeBkN24Z=i0d0000O10000000000O10000O01000O101hBnN`<S1\\CPOd<R1XCPOh<U1mBQOS=^101O0010O1O1O1O1QOnBD^=5mBCV=5SeS3"}}, "object_label": "cow", "attribute_label": ["color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a large white cow standing in a grassy field. The cow is positioned in the middle of the field, with its back facing the camera. It appears to be a healthy and well-fed animal, possibly a dairy cow. The field is lush and green, providing a suitable environment for the cow to graze and roam freely."}, {"question_id": 798, "height": 427, "width": 640, "image": "000000015751.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, pose, texture", "region_anno": {"bbox": [43.51, 347.05, 127.35, 50.15], "segmentation": {"size": [427, 640], "counts": "PTc03V=4F8M4M3N1O2O1N2N101N101N2O00000001O00001O001O1O1O2N2N1O010O`C[OZ<e0fC[OZ<e0fC[O[<d0eC[O\\<e0cC]O]<i0O1O010O01O000010O0001O000000001O000000000O1000001O0H_CFa<b0001O00001O00001O00000O10000O100O101O000O10000O1000000O10000O10000ODDkC;c<0000O10000O10000000000N1O2O100000000O1000RCLe<4[CLe<490PCLi<4WCLi<4WCLi<4WCLi<48LgVS6"}}, "object_label": "bird", "attribute_label": ["color:black", "color:white", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a bird sitting on a wooden surface, possibly a fence or a ledge. The bird is positioned in the center of the scene, and it appears to be a small bird with a black head."}, {"question_id": 799, "height": 320, "width": 640, "image": "000000221502.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, pose, transparency", "region_anno": {"bbox": [14.09, 118.55, 121.87, 138.44], "segmentation": {"size": [320, 640], "counts": "n_41o91N1001OWF2g90fF3a8L\\G:S92N100O2O1O0O2O1N7J4[GPOR8Q1kGSOm0Oi5P1YIQOl01i5Q1ZImNl04h5Q1^IkNN1:5Y6Q1_IkNI2=2\\6Q1^IZO2EMHX6Y1eIC0^O1GY6X1eIFN]O3FZ6X1cIHM[O5F[6o2dIRM\\6m2eISM[6m2gIPMZ6o2=O0O1O101O0aMPIn1Q7oMQIR2o6jMTIV2o6dMSI^2V71O1O101N01000003M1O0000nNdM_J]2a5dM]J]2b5dM]J]2c5dM\\J\\2c5eM\\J]2F^M\\55gJLAc2:^M\\54hJe2GSML5e53gJg2ETMO1d56gJn2FiLd58gJo2^5RMbJo2]5QMcJo2]5QMbJP3^5PMbJP3]5QMbJQ3]5oLcJT3Y5mLfJT3Z5lLfJT3Z5lLeJV3Z5jLfJ?Gi1c5hMeJ72P2Y5jMcJ57P2V5jMdJ66o1X5jMbJ67P2W5iMcJ67Q2V5iMdJ56R2W5hMcJ57S2W5gMbJ67S2X5eMcJ66T2Z5bMbJ:4S2n5lMRJS2d5eMQJ6<T2c5hMPJ4=Q2e5mMmI2>n1g5RNjI0?m1g5UNhIOa0k1g5WNgINc0k1f5WNgINc0k1f5VNhINc0k1e5YNgILd0k1e5YNiIIc0o1c5XNkIHc0o1c5XNjIHc0Q2e5VNdJk1]5SNfIGh0W2b5WN]Ji1c5WN^Ji1b5VN`Jh1`5XN`Jh1`5XN`Ji1_5WNbJh1^5XNbJh1_5WNaJj1^5VNbJj1_5UNaJl1`5RN`Jn1a5QN`Jo1a5oM_JQ2a5nMaJR2_5mMaJS2`5kMbJT2_5jMbJV2g6L9gNlG5Y8EkG9f8TO]Gk0m8N6[OiF7Y9GkF5c9L_bm4"}}, "object_label": "potted plant", "attribute_label": ["color:green", "color:white", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "transparency", "answer": "The potted plant in the image is a beautiful arrangement of flowers, including white and orange flowers, and possibly some daisies. The flowers are placed in a vase, which is sitting on a wooden bench. The bench is located in a grassy area, providing a natural and serene setting for the flowers."}, {"question_id": 800, "height": 471, "width": 640, "image": "000000016010.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose", "region_anno": {"bbox": [280.51, 259.23, 27.59, 30.97], "segmentation": {"size": [471, 640], "counts": "\\oQ41e>3_A1U>9N101M3M3O1OMSB^Om=`066IHTBGk=?4N2O1N2O1N2O1N2K6N1O10j[i4"}}, "object_label": "cow", "attribute_label": ["color:black", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "maturity", "answer": "The image features a large, horned bull standing in a grassy field. The bull is positioned in the center of the scene, with its head slightly tilted to the left. The horns on the bull's head are prominent and noticeable, adding to its imposing appearance. The bull appears to be walking or running across the field, possibly in search of food or exploring its surroundings."}, {"question_id": 801, "height": 480, "width": 640, "image": "000000103548.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, maturity, pattern, pose, texture", "region_anno": {"bbox": [472.94, 233.6, 37.21, 34.59], "segmentation": {"size": [480, 640], "counts": "aYP74l>1O1N2fALf=6UBLk=6oAOP>>3N101N1011O1O2M2NGSBGg=9YBGg=<TBEm=g00O1N2M3N2N2O1O2001gA^OP>h02JlA[OX>b06K8I]Wl1"}}, "object_label": "sheep", "attribute_label": ["color:tan", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a herd of sheep walking down a dirt road. There are at least 13 sheep in the scene, with some of them being closer to the foreground and others further in the background. The sheep are spread out along the road, with some walking in pairs or small groups, while others are walking individually. The scene captures the natural movement and behavior of the sheep as they travel together."}, {"question_id": 802, "height": 331, "width": 640, "image": "000000152740.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pattern, pose, texture", "region_anno": {"bbox": [300.76, 148.12, 70.97, 51.67], "segmentation": {"size": [331, 640], "counts": "iiQ33o9:O00O001NN21001O006I2OM21O1O1O10O02N2N2O2O0O2N1O103M00L4O010O100O01000002N5J6KL4M3K5O1L400004L0000L4N201O02N2N5J2O015J1O00J7L3N3K5L5F:Ihif2"}}, "object_label": "cow", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern", "answer": "The image features a large black cow with a white face, standing in a grassy field. The cow is grazing on the grass, and it appears to be the main focus of the scene. The field is filled with tall grass, providing a natural environment for the cow to graze."}, {"question_id": 803, "height": 331, "width": 640, "image": "000000152740.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [457.17, 147.11, 52.23, 46.15], "segmentation": {"size": [331, 640], "counts": "bVd43V:3F9N2O1O0100O1013M6I3M5fFQOn8V10O001E;0O01000000O100005J3NO100O1L400000000O100008G1000N2O1M4L4O2O04L^OnFJS90WaZ1"}}, "object_label": "cow", "attribute_label": ["maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, size, pattern, maturity", "answer": "The image features a black cow standing in a grassy field. The cow is positioned in the center of the scene, with its head slightly turned to the left. The cow appears to be looking at something, possibly a person or another animal. The field is filled with grass, providing a natural environment for the cow to graze and roam."}, {"question_id": 804, "height": 425, "width": 640, "image": "000000205776.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "color, maturity, pattern, pose, texture", "region_anno": {"bbox": [91.89, 28.24, 442.23, 240.26], "segmentation": {"size": [425, 640], "counts": "[hX14P=7K4N3M6I4M2M3M3M3N1M4M2O1O1N2N2O2N1N2O2N1O2N1O2N101O001O0O2N2N1O1O2N2O001N101O0O2N101O001N101O0O2O0O2N1O2O1N1O2O0O2N101O3TFhLa9b3N1N2O001O1O0O2O001O2N001N101O001O0000O1O1N2O1O1O1O2N1O1L400O020O01O1O2N1O002N3M8H8I1N2N100O1O2O0O3M6K3L5K1O1O01O01O2N4M1N2N2N1O2O1N001O1O1O2N00000001O01O1O2OO10O010O0100O000100O1O010O0100001N100O10O00001O01O01O01O00010O001O0001O01O0001O01O0001O000010O01O010O000100O10O1O01OO2O01O1N10000O2N1O1O2N1N2O1O1O2N1O1O101O00000O1000001O001O00000001N1000001N2O001O0O2O1O1O1O1O1O1O2N1O2N3M1O2N2O0O2N3M2N4L3N0O1O1O1O1O2O0O001O1O00100O1O1O100O1O001O0010OO2N2N102N001N2O1O1O1O2N1O10O01O1O4L00O1O2OO10001O001O000O3N1GoFWLR9i39N0011NTMfFj1OXMV9n0lFj1MXMX9n0kFi1X9XNfFi1[9R10SNdFM\\9Q2OTNeFJ[97dFJ[98eFGZ99fFC0]NZ9g3fFYLZ9R2iF_OY9a0gF^OY9c0jFXOW9i0iFVNM?[9[1hFWNK=^9]1gFQOZ9o0gFjMJQ1`9U1lFgNV9Y1kFeNV9[1kFcNW9\\1lF`NU9_1mFPN\\O7h9j1lFnMDNc9Q2UFnMe02c9o1bFnM_9R2l0FQEXNQ;g19O10000O0100000O10O1001O0O010O10000000000O1000000O2O0000000O2O001O0O10000O100000000O2O1O1O001O1N101N1L5L3O10000O2O1O0O2O1O000O2O0O3N1O1O1O1N10000O2O1N3N3Ln\\`1"}}, "object_label": "bear", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pattern:plain", "pose:horizontal/lying", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, maturity", "answer": "The image features a large brown bear lying down on a wooden structure, possibly a bed or a bench. The bear appears to be resting or sleeping, with its head on a pillow. The wooden structure is covered in nails, giving it a unique and rustic appearance. The bear is positioned in the center of the scene, occupying a significant portion of the image."}, {"question_id": 805, "height": 375, "width": 500, "image": "000000067406.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, state, texture, transparency", "region_anno": {"bbox": [231.63, 193.44, 90.73, 80.73], "segmentation": {"size": [375, 500], "counts": "kTe22e;001O001N101O1O001O1O1O1O2N1O1O2N1O2O1N1O1O10O0001O000001O000010O01O000010O000100O010O1O21N7I2N001O01O0O101N100O2O000O101N101O0O101O001N10001O1O001O001N2O1O001O100O1O1O1O001O1O1N^mP2"}}, "object_label": "kite", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plaid/tartan/checkered", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency", "answer": "The image features a kite flying high in the sky, with its tail end visible. The kite is black and red in color, and it appears to be a large, multi-colored kite. It is flying in the air, possibly in a park or an open area, with a clear blue sky as the backdrop."}, {"question_id": 806, "height": 480, "width": 640, "image": "000000145597.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "length, material, pattern, size, state, texture, transparency", "region_anno": {"bbox": [300.06, 303.75, 55.34, 56.97], "segmentation": {"size": [480, 640], "counts": "h^\\42i>6M3N2O01002M4M3M3MO2O0O01O0O2O1O1O2N1O1O100O010000O100O11N0100002N1OO100O101N002OO02O0O100O1O1N2N1O2N2N2M4M2MZXU4"}}, "object_label": "bottle", "attribute_label": ["length:short", "material:glass", "transparency:transparent/translucent", "pattern:plain", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, length, state, pattern, transparency, texture, size", "answer": "The image features a bottle, possibly a wine bottle, sitting on a table. The bottle is placed on a red tablecloth, which adds a vibrant touch to the scene. The bottle is positioned in the center of the table, and its shape and size suggest that it is a wine bottle. The tablecloth and the bottle create a cozy and inviting atmosphere, possibly indicating a relaxing and enjoyable setting."}, {"question_id": 807, "height": 428, "width": 640, "image": "000000459809.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, state, transparency", "region_anno": {"bbox": [373.91, 253.14, 204.3, 125.6], "segmentation": {"size": [428, 640], "counts": "Ubl43Y=1O001O001O010O00010O0010O010O01O10O01O10O01O010O100O1O001O1O2N1O1N3N001O2N1O1O1O1O2N1OBiCIU<5nCKQ<4RDLl;3VDNg;3ZDOc;0_D0`;ObD1];OeDO[;0hDOW;1jDNU;2mDMS;3nDMQ;2QENn:1TEOl:MXE3h:KZE5o;0O0100000O01O1000O100000O0100000O10O100O010O01O10O010O001O00010O10O2N010O00010O01O10O0100O010O10O00010O1000O010O100O01O10O01O01000O00010O000010O01O2OO100O10O010000O1000O1000O001O100O0101O1O0000000O0010O100O1O01O00010O00002M2O1O\\=0dB0O11O00000000O1O1N2O10001O01O1O000010O1O1O0011N2Ngij0"}}, "object_label": "kite", "attribute_label": ["color:red", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "state:folded/bend"], "control_dims": "state, transparency", "answer": "The kite in the image is a large, white, and possibly butterfly-shaped kite. It is flying high in the sky, with a long tail trailing behind it. The kite is soaring above the ocean, creating a beautiful scene with the water and the sky in the background."}, {"question_id": 808, "height": 333, "width": 500, "image": "000000257084.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, material, pattern, pose, state, transparency", "region_anno": {"bbox": [122.97, 183.01, 34.99, 36.72], "segmentation": {"size": [333, 500], "counts": "gUX1124Oe0X9;2M6J1O1M3N1O1O2N102M1O2N2N1O100011M2OIRF0m91SFOl92TFNk93TFMk9=NHXFKh95XFKh95YFJf98YFGg93WF6h9JZF4f9:0O1O1O=DRf^3"}}, "object_label": "chair", "attribute_label": ["color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole"], "control_dims": "pose, material, pattern, transparency, color, state", "answer": "The image features a blue folding chair with a metal frame, which is placed on a concrete floor. The chair is open and ready for use, and it appears to be a comfortable and sturdy option for outdoor events or gatherings."}, {"question_id": 809, "height": 427, "width": 640, "image": "000000052891.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [146.08, 125.33, 372.54, 301.67], "segmentation": {"size": [427, 640], "counts": "j[n1>g<8L3I7K5J5M3O1L4_OaNoDg1k:`0J5N3L4K6K5L3M5I;F6L102N2M1O2OO2O00001OO10O10O1O1O1O1O010O1O1000O01O1001O00O100001N101O100O13M001O2N2O3L6I3N3L2N2N3M1O2N1O1N2O1O1N10O001000O2O3M1N101O000O101O001O1O1O000000SO\\HSLd7l3^HSLb7n3\\HSLd7j400000WO^HiKb7X4]HhKc7P5000XO^HgKb7Y4^HfKc7Z4]HfKb7[4^HeKb7[4_HdKa7\\4_HdKa7\\4aH_KKDd7n4`HaK`7a4^H^Kc7b4[H_Kg7Q510000YOYHjKg7l41KYHeJh7Z550001N1N2O100001O0000O100O1000O00001O3N1N2N4K5G9K3O2N101O1O1O1SKmI_2V6ZMnIf2V6SMlIm2Z6fLmI[3W6[LnIe3X6nKPJQ4e70000O1O1O1O1O100O100O10O001O0O205J2O001N2N1M4M4J5K4L4M3N100O2N2N2M300O1N2N2N3M2N2O1M3O1]OkIlIY6R6a0L4N2N2M3O001O00100O0000001O010O1O1O001N2N2N2N2N2O0O2N2N1O2O1N1N21ON3N1O1O1L`G]Kb8\\49J7L3J7KeFXL]9]3dFcLe9Y39H7H9L40O101O001O1O1O000O10DfEfMZ:X2lEeMT:Y2`0N1O2N1010000O1O1000000001O1O10O01O00010O1O10O01O01O01O01O001O010O1O010O10010O1O1OO1O0010O000O1000010O0O1L4K6O00001O001O10O01O1O001N101O010O11N01O1N1O2N101N101O0O2O0N3N1O2O001O001N2O1O1O1O0O2O1N4YO^C>j<M5GYnc1"}}, "object_label": "dog", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose, texture, state, maturity", "answer": "The image features a dog standing on a sandy beach, holding a yellow frisbee in its mouth. The dog appears to be a small, black and white dog, possibly a border collie. It is positioned near the water, enjoying its time at the beach. The frisbee is held firmly in the dog's mouth, indicating that it has been playing fetch or catching the frisbee. The scene captures a fun and active moment for the dog on the beach."}, {"question_id": 810, "height": 480, "width": 640, "image": "000000060823.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [274.78, 328.87, 24.6, 35.46], "segmentation": {"size": [480, 640], "counts": "YSS47i>001O3^AKS>c0N100001O2OO01O1O1N5K1O1O1O1O2LP`o4"}}, "object_label": "bird", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, pose", "answer": "The image features a large group of birds, predominantly green and white, standing together in a flock. They are gathered in a line, with some birds standing closer to the front and others further back. The birds are of various sizes, indicating a diverse group. The scene captures the beauty and harmony of these birds as they stand together in a visually appealing arrangement."}, {"question_id": 811, "height": 426, "width": 640, "image": "000000219440.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [485.43, 172.22, 154.57, 252.23], "segmentation": {"size": [426, 640], "counts": "a[[647Nf<2YCOZW12chN2e<<J9aCUOU<n0iCTOS<S1I7N30OnDcNd8:lGQ1@eN`8c0nG\\OmN6Me0d0VO^OOU9i0cGXOZOZ1>hNb8j1nF_OOdN<6b8k1RG\\O0dN;5`8^3TG^L<2`8b3TG\\L:35KF1k7n3YHUL<OW7P4\\HQL=1T7P4_HnK;5S7d2\\HZNo0SOc6d2fHPNg0^Oa6e2cHQMLQ1h0\\Og6f2bHoLNV1`0WOo6\\4gHiKW7V5O1O1N2O1O]MiHhL0V2U7S1mHeLOX2l6fMWI^3MeL0W2g6h1XIXNe6k1[IUNc6Z4N200N2O1O1O100O10000O1000000000000000O1H8J6M3M4IQIoIQ7k5:L4N2K6NgHhJc6V5QI[Kk6d4UI`Ki6_4UIfKh6Z4XIhKf6X4YIlKe6a5LO0000O1O2N1O1O1000O1000OL5L4L3O2L4UOSISKS7m4mHmJY7S5hHeJ^7\\580O100O2N1O10000O100O2O0O100O010O10O10O01O10O100O00mJcH[4]7eKcH[4\\7j000O10O0100O0010O0100O01000O1O10OO20000O1O1O100O0100O0010O010fJ"}}, "object_label": "cow", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state, texture, pose, maturity", "answer": "The image features a large brown cow standing in a grassy field. The cow is looking down at the ground, possibly grazing or observing something. The cow is positioned in the center of the image, with its head and neck visible. The field appears to be a lush green pasture, providing a suitable environment for the cow to graze and roam."}, {"question_id": 812, "height": 426, "width": 640, "image": "000000219440.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [231.78, 142.92, 370.12, 278.5], "segmentation": {"size": [426, 640], "counts": "]aQ3:m<6K3N1O6J8J2M1O2N3M2N1O1N2O1O2M2O00001N10001N1O101K4O101M2O2O0O2O1O0O3M2M3O1O1O1N2O1O1O001O2N001O1N3M2O1O1O1N2O1O1N2N3M2N1N3N2N2N1O2N2N101N2N3N0O2O1O1N2O1O001N2O1O2NWLWGR3h8lLZGT3f8j0M2O1O1O0O2O3M1O001O1O1N2O001N100O2O0O2O1N2O1O0O102M3N000O2O001O001O001O1O1N1000001O001O010O001O00001O0000010O1O2N1O1O00100O1O010O010O100O100O2O001N3N2`IjIg5V7GeHVJX7f5hHZJ[7i53M2N4L\\H_Ja7`5^HaJd7]5ZHeJg7`5011M000O02N0000001O000000O10000O100O100O100O100O1O1O100O100O1O1O100O100O10000000000O0100O1L4L4O1000000001O0000001O1O1O010O1ORNjJhKW5W4fJlKZ5S4fJoKY5h3fJaJ2MNe1[5j3RK_JFe1X5k3SK`JFd1X5j3ZKULg4i3[KWLe4g3`KULa4h3jKoKW4o3lKnKV4Q4lKmKU4S4lKkKU4U4lKiKU4W4kKhKV4Y4jKeKW4[4iKdKX4[4jKdKU4\\4lKdKS4[4oKeKQ4Z4QLeKn3[4SLdKn3\\4RLdKm3\\4TLcKm3]4SLbKm3_4SL`Km3`4UL^Kk3a4WL_Ki3`4XL_Kh3]4^L_Kd3`3ZJdL0A\\29[3]3gJ[LW28R3Z3fMeL[2Y3gMfLZ2X3hMfLZ2V3jMiLW2T3mMiLSMMS4V3nNlLgLO_O2k4m24SMLl26TMJh2:XMFf2`5N2O1N2N2O1M3O1O1O1OPKfMROX2P1hMoNW2S6M3I7L3M4N2N2O100O010O1O10O0100O01000000RKdNmM]1S2cNmM]1m1bN\\I2g4\\1m1bN\\I2g4\\1l1bN_I1e4]1P700O11O01O01SJ`NN`11bNN^1o5010O010O00010O0001O0O2O1N1O2O1N101N2O1O1O1N101O1N2O1O1N101N3N1N3N1O2M2O1N3N2N2Ml[c0"}}, "object_label": "cow", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, pose, texture, maturity", "answer": "The image features a group of cows standing together in a grassy field. There are three cows in total, with one cow being the main focus and the other two cows standing behind it. The main cow is looking at the camera, while the other two cows are looking in the opposite direction. The cows are positioned close to each other, creating a sense of unity and companionship among them."}, {"question_id": 813, "height": 316, "width": 640, "image": "000000224093.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [414.98, 118.62, 16.18, 24.16], "segmentation": {"size": [316, 640], "counts": "i_P4<`92N4K2O2M100000000001O2N3M=Bc[P2"}}, "object_label": "cow", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, state, texture, pose, maturity", "answer": "The image features a cow standing in a field, with its back facing the camera. The cow appears to be looking down, possibly at the ground or another object. The cow's body is positioned in the center of the image, and its legs are spread apart, giving a sense of stability and balance. The scene captures the cow's natural environment, showcasing its presence in the field."}, {"question_id": 814, "height": 428, "width": 640, "image": "000000364297.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "color, maturity, pose, state, texture", "region_anno": {"bbox": [22.14, 91.73, 612.48, 313.62], "segmentation": {"size": [428, 640], "counts": "lg78R=5K4M3L3N2N2N2N2N2N2O1N2N2O0O2O1O001N101O001N101O001O0000001O00001O001O0O2O0000010O000000000001O00O1001O00O2N11O1N1001O00000O1O1H90QNiDf1`;O1O00000001GYNkDg1S;]NhDf1W;80TNiDc1Y;XNlDf1U;YNkDf1V;ZNjDf1V;ZNjDf1V;ZNjDf1^;001GYNjDh1S;\\NlDd1V;YNlDf1];O2O00O10000O100000000000000000O10IZNhDf1X;[NfDf1a;O0000000000000000O11O1O1O00001O00000000[EfNY9X1eFPOV9P1gFTOX9l0eFXO[9g0cF\\O\\9d0aF@^9`0aFB^9>`FE`9:_FH`98_FIa97^FKb94]FMc93]FNb92]FOc91\\F1c9O]F1c9O\\F2d9OZF2f9NYF4f9LYF5g9KXF6h9IXF8h9HWF9i9FWF;h9FXF;g9FXF:h9FVF<j9EUF;k9b101000000000000O100O0100O1O01000000O1000O02O000000000O1000O10eN`LjH`3V7aLiH_3W7aLiH^3c80gNaLeH^3[7cLeH]3[7cLeH]3[7dLdH\\3\\7dLcH\\3^7dLbH\\3]7eLcH[3]7eLcHZ3_7eLaH[3h8O1O010O100O001O1O1O001N2O100O10iNnLTHR3n7mLQHS3o7mLQHR3P8nLPHR3P8oLnGR3R8nLnGR3R8nLoGQ3Q8oLoGP3R8oLnGR3V9000O010000O100O1O1NTOSM\\Gk2g8VM`FOd0f2Q9[MZF0d0e2Q9aMoF\\2T9^M[FO`0a2T:0mN_M]G`2c8bMZG`2e8aMZG`2f8`MhFN2b2X9^M^FOM111;a2Z9^M\\F5NM0M8c2^9^M^F9KG7c2a9]M]F<2W2a9]M^F73]2`9\\MoFd2R9\\MmFe2S9[MlFe2U9[MjFe2S9[MYF0c0e2T9aMZFI<f2Z9bMZFI;e2[9bMZFI:e2\\9cMhF]2X9dMgF]2Y9cMfF\\2\\9cMdF]2]9cMbF^2^9cM`F^2a9`M_F`2e9]MZFd2g9ZMYFg2f9[MYFd2c9YMTF47e2e9VMVF35h2e9UMWF13l2e9TMYFO2m2d9UMZFN1n2e9TMZFN0o2f9SMZFN0P3e9RM[FM0R3e9QM[FNNR3g9PM[FNNR3g9QMZFMOS3f9oL`FR3`9nL_FS3a9lL_FU3b9jL]FW3c9iL\\FY3c9gL\\F[3b9fL]F[3c9eL]F\\3a9eL^F]3a9dL^F\\3c9aL_F`3e91O2O001N100O1O010O1O2O1O1N101N2O001O1N101O001O0O101N2O001O00000O10001DdKeG]4Y8gKcG[4\\8gKbGY4_8:N2N2M3O0O2N10cKkGd3U8\\LlGd3T8]LjGd3U8]LkGc3T8k0O2N100O1O2N`KSHc3l7\\LVHd3j7[LWHe3i7[LVHf3i7\\LUHe3j7\\LVHd3i7P100O010O10[KYHe3f7\\LYHf3f7ZLZHf3f7ZLZHf3e7[L[He3e7ZL\\Hf3d7ZL\\Hf3c7[L]He3c7ZL]Hg3c7YL\\Hh3d7XL\\Hh3d7XL\\Hh3d7XL\\Hh3c7YL]Hg3c7YL]Hg3b7ZL^Hf3b7ZL^Hg3a7YL_Hg3a7YL_Hg3a7XL`Hi3_7WLaHj3^7VLbHk3]7S1N2O0O2O001O1O2N2N00hJmHW4S7P10MYIoIG1N:ODl5Q6_JTKZ5m4]JaK]5Z6M2N1O1N2O1O002M2O2N1O10]HRKf6o4YIQKh6m4YISKh6l4XITKi6k4m0O010N2O01O10O001N101O00001O0001O00O101O000000001O000000000000001O0001O01O0000001O0000001O000O101O0000001O000000001O000000001O0000010O001O01O01O1O1O\\IhKT4X4lKhKT4X4gKhK_4X4`KhK`4X4`KhK`4Y4^KhKc4W4Y20001O01O00001O01O010O010O01O010O1O01O02O0O10O0100O1O100O001O1O1O1O10O02N1O01O02O000000O1001N1O001O2N1O1O00[KcG\\4[8cKhG]4W8=N2O1N2O00YKlGW4S8hKnG\\4n7dKRH\\4n7eKQH\\4m7g0K0O1O010O0100O10000O1O1O1000000O0100O001O1O1O010O1O1N101O1O001O1O10O01N2N2O100O2iIWJh4j5RK\\JSOEe5Q6SKdJl4]5RKeJl4]5PKgJo4[5kJoJn4U5eJWKY5_6O1N2O2M3M4M2N2N2M4M1O1O1N2O3M3M1N2O1N:G9F2O7H10jG"}}, "object_label": "cat", "attribute_label": ["color:brown", "color:white", "maturity:adult/old/aged", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, texture, maturity", "answer": "The image features a gray and white cat lying on a computer keyboard, taking a nap. The cat is positioned in the center of the keyboard, occupying a significant portion of the space. The keyboard is located on a desk, and the cat appears to be resting comfortably on top of it."}, {"question_id": 815, "height": 640, "width": 443, "image": "000000017115.jpg", "category": "description", "question": "Describe the zebra in the following image in detail.", "dims": "color, maturity, pattern, pose, state", "region_anno": {"bbox": [242.71, 122.44, 197.92, 479.64], "segmentation": {"size": [640, 443], "counts": "]ej44bc0c0C>A:H6H8I8J4K6K3M3N4K3L6I6K4K6J5J6L4M3L4L4M3M3N2N2N2M3N2N1O2N2N3L3N2N3M2N2bAeJT>g5L3M2N3M6J4XGgIb3_6VLiId3^6TLeIj3b6oK`Io3l6]HXIP2Nb5U8eI`GcN=f7W8\\IfGkN3S6IkJg8SOjFNV2S6[NjJ^;[OSDV5b0_K[;ZOUDR5:cJB02P1n;YOVDT58fJEm0m;XOWDQ5;iJAn0n;WOWDQ5;jJ@OMi0Q<\\OYDQ5:RK^O?P<[O[DS58QK_Oa0m;WOaDW53QK_O1L3Q<DbDV53RK^O1N1n;GcDT54SK\\O`0e<]4nCQLS<n3kCkJ]OV1k9ROgGKYOR5KQLn8C\\GWOUO2g0S5JPLi81QGTOFFf0V5JnKf89nFoNj0k4BlKb8T1PHQ3^OjK_8W1THP3\\OhK`8U1XHT3WOgK_8U1\\HT3TOhK`8k0eH\\3lNhKa8b0lHf3bNiKc8:QIm3\\NhKh8LWI\\4RNgKW9SOQIY5eMcK]<^4bCaK_<_4aC`K`<a4_C_Ka<a4_C^Kb<e4`CVK`<j4fCoJZ<R5jCiJW<Z5eCfJi;EoCh56bJi;3gCd52^JV<P7M4[JTIcM_7[2kH\\MV7b2RIdLa7\\3eHnKbNbMU9\\6`H[KY8a4lG\\KU8d4oGUKU8k4nGPKT8U5jGbJ\\8`5X2`IRDf6g;[IYDg6e;YI[Di6c;WI]Di6e;UI[Dk6e;UI[Dk6\\OVIl<k6SCUIm<k6RCVIn<i6TCVI_<6cCc6X<XIdC0173`6X<YIjC32e6R<YIkC24e6P<]IZDb6e;aIZDb6c;]I]Dc6a<O001LTE_I`8Z6XE`Ij1n0h8]5lEeIFi08=U:U5kEfIG^2^:l3jEgIF`2^:j3kEfIFd2]:e3cEfI8o2R1SM^7\\6_GeLc0cMf7g5gG\\NV8d1jG^NU8c1iG^NW8c1gG^NX8h6NO001N1N3O2N010N2nMbGfFLg1c8[7iHgGW7Y8mHbGU7]8oHVG[7k8bHbGPO]O^7Q:_HiFCXO2b0[7^9dHUH\\7X:0O1O1O001O001O2N001O1O2N1]LfI_IZ6\\6nI`IS6^6RJ^In5`6WJ]Ij5U5fHkIe1MPN5f7m5nKbIdL`0_7j5jLTJX3g5nLVJU3d5nL\\JS3^5UM^Jm2\\5]M_Jd2\\5bMbJ`2R5mMhJW2j4g6M4I6M4K4N4J6I6L4J7J7Ic0[Od0fMR^O]1bb0G6Ja0UOlf4"}}, "object_label": "zebra", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pattern:striped/lined/pinstriped", "pose:vertical/upright/standing", "state:dry"], "control_dims": "pose, pattern, state", "answer": "The image features a zebra standing in a grassy area, with its back facing the camera. The zebra is positioned near a fence, which suggests that it might be in a zoo or a wildlife park. The zebra's distinctive black and white stripes are visible, making it easily recognizable as a zebra. The grassy area provides a natural environment for the zebra, and the fence adds a sense of confinement or enclosure."}, {"question_id": 816, "height": 427, "width": 640, "image": "000000402615.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, transparency", "region_anno": {"bbox": [474.79, 209.58, 50.31, 22.12], "segmentation": {"size": [427, 640], "counts": "^fV67R=3M3N2N2O0O2O00001N10000001O001N101O1N2O1O1N2O1N2O001O1O001O001OQ]f1"}}, "object_label": "tennis racket", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying"], "control_dims": "transparency, pattern, color, cleanliness", "answer": "The tennis racket in the image is white and blue, with a yellow handle. It is being held by a person who is playing tennis on a clay court. The racket is positioned in a way that it is ready to hit the tennis ball, which is visible in the scene. The player's stance and grip on the racket suggest that they are actively engaged in the game and focused on their performance."}, {"question_id": 817, "height": 426, "width": 640, "image": "000000448256.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, state, transparency", "region_anno": {"bbox": [157.06, 262.51, 16.86, 33.47], "segmentation": {"size": [426, 640], "counts": "kbQ2=e<8N2N3N1O1O1O100O13M1O1O1N=\\OSC1]jR6"}}, "object_label": "bottle", "attribute_label": ["color:blue", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole"], "control_dims": "material, pose, state, transparency, color", "answer": "The image features a clear plastic bottle with a blue label, which is being held by a person. The bottle is filled with water, and it appears to be a sports drink bottle. The person is holding the bottle in their hand, possibly preparing to drink from it or share it with someone else."}, {"question_id": 818, "height": 640, "width": 481, "image": "000000017436.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "material, pose, state, transparency", "region_anno": {"bbox": [229.7, 480.88, 28.93, 25.84], "segmentation": {"size": [640, 481], "counts": "Sc_43lc04M2N0O2O001O001O2N4L4MO003M3N3L10O000000000000O1N1O2M4M2NeXZ4"}}, "object_label": "bench", "attribute_label": ["material:asphalt/cement/clay/concrete/stucco", "transparency:opaque", "pose:horizontal/lying", "state:empty"], "control_dims": "transparency, material, state, pose", "answer": "The image features a black bench with a piano keyboard on it. The bench is positioned in front of a piano, and it appears to be empty. The piano keyboard is placed on the bench, indicating that it is ready for use. The bench is situated in a room, possibly a music room or a practice area, where people can sit and play the piano."}, {"question_id": 819, "height": 427, "width": 640, "image": "000000528578.jpg", "category": "description", "question": "Describe the clock in the following image in detail.", "dims": "color, length, material, pose, size, transparency", "region_anno": {"bbox": [528.1, 197.2, 14.5, 19.7], "segmentation": {"size": [427, 640], "counts": "j[l69o<6L2N2O001O000001O0O2O2M3K^eX1"}}, "object_label": "clock", "attribute_label": ["color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge"], "control_dims": "transparency, length, pose, material, size", "answer": "The image features a large, ornate clock with a blue face and black hands. The clock is prominently displayed on a wooden surface, possibly a door or a wall. The clock's face is surrounded by a decorative frame, adding to its elegance. The clock's design and size make it a prominent and eye-catching feature in the scene."}, {"question_id": 820, "height": 404, "width": 640, "image": "000000036936.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pose, state, texture, transparency", "region_anno": {"bbox": [152.16, 290.56, 26.17, 42.8], "segmentation": {"size": [404, 640], "counts": "P_k11b<2N4L4L=C2O00O1000000000000001O0O2O7J7H000000O100O1\\Oe0F:IUce5"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, state, transparency, texture", "answer": "The image features a clear plastic cup filled with a red liquid, likely a drink. The cup is placed on a table, surrounded by other cups and bowls. There are three other cups in the scene, with one located to the left of the main cup, another to the right, and the third one further back. Additionally, there are two bowls in the scene, one positioned above the main cup and the other one below it. The arrangement of the cups and bowls creates a visually appealing and organized display."}, {"question_id": 821, "height": 333, "width": 500, "image": "000000139684.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "material, pose, state, texture, transparency", "region_anno": {"bbox": [184.16, 201.18, 42.19, 12.96], "segmentation": {"size": [333, 500], "counts": "c[l14X:2O01OO101O01O001O01O0000000000000000001O00O100000IKVF6i9JWF6i9JXF5h9KXF5h9KXF5g9LYF4g9LYF4g9MXF3h9MWF4i9LWF4i9MUF4k952N2O1MVmh2"}}, "object_label": "book", "attribute_label": ["material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "state:closed", "texture:smooth/sleek"], "control_dims": "transparency, texture, state", "answer": "The image features a wooden table with a variety of books and magazines on it. There are several books of different sizes and colors, some of which are placed on top of each other. A few of the books are placed in the center of the table, while others are scattered around the edges. \n\nIn addition to the books, there are two cell phones on the table. One cell phone is located towards the left side of the table, while the other is positioned more towards the right side. The combination of books and cell phones suggests a blend of traditional and modern reading materials."}, {"question_id": 822, "height": 424, "width": 640, "image": "000000271116.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "material, pose, state, texture, transparency", "region_anno": {"bbox": [329.67, 199.5, 22.02, 36.63], "segmentation": {"size": [424, 640], "counts": "d]X4?f<7K3N2N2N2N1O1O00O100O100000000O101M2O1M4MP_g3"}}, "object_label": "wine glass", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, texture, transparency, state", "answer": "The wine glass in the image is filled with a dark red liquid, which appears to be a type of tea. The glass is placed on a table, and it is positioned in the center of the scene."}, {"question_id": 823, "height": 480, "width": 640, "image": "000000336053.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "material, pose, state, texture, transparency", "region_anno": {"bbox": [241.63, 134.19, 59.15, 89.54], "segmentation": {"size": [480, 640], "counts": "bba321`0U>?G6K4M3M2M4M2N2N2N2O1N2NVNPCe1P=YNRCg1S=101M2O0H9NPNYCj1f<UN\\Cl1b<TN^CX2U<jMiCX2V<hMjCX2V<hMjCX2V<hMjCX2U<iMkCV2V<jMjCV2V<jMkCT2V<kMkCV2T<jMlCV2U<iMkCV2V<jMjCV2V<kMiCU2W<kMhCU2Y<kMgCT2Z<lMfCP2^<PNbCk1c<UN]Ci1e<WN[Cg1g<YNYCf1h<81O1O1O2N1N2N2N2N3M3L3N3M3hN^Bk0S>SOQB:\\TP5"}}, "object_label": "wine glass", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, state, texture", "answer": "The wine glass in the image is filled with a red drink, possibly a glass of wine or a cocktail. It is placed on a dining table, and the glass is almost empty. The glass is positioned in the center of the table, and the drink appears to be the main focus of the scene."}, {"question_id": 824, "height": 559, "width": 640, "image": "000000099053.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "material, state, texture, transparency", "region_anno": {"bbox": [37.69, 81.27, 585.38, 463.53], "segmentation": {"size": [559, 640], "counts": "b\\c02i`0Q1YOd0A=E6K4L5I7J6K6H7J5L5J5K5L4M3L4K5M3L4L3M4L4M2McMnCPNMg0S<V1_DeMBV1k;W1WD[M17OIJZ1k;\\1UDbM7M6U1\\;\\1XDcM9HGN7]1];[1]DYMN1N0o0\\1d:[1bDXM12d0NXO]1_;\\1dDVM239MH1M[1Z;^1eDWM526MH2N[1W;_1TEVM:O\\O\\1T;`1VETMd0^1S:_1aFaN\\9a1dFaNX9a1hF`NV9`1kFaNS9`1VEmL;1h0c1e9`1WEnL1O50n0e1b9d1[EgL50n0f1_9f1\\EdL91j0f1`9d1RG\\Nl8a1`EgLe1j1g8\\1dElL0Nf1j1d8]1eEmLi1g1`8]1gEmLh1f1`8\\1jEoLe1f1_8[1mEPMOK^1l1b8[1QFnLON\\1i1c8Z1SFPMLM_1j1`8Z1TFWM\\1`1^8Y1ZFkLL0]1l1[8Z1^FhLK0^1n1W8[1aFfLJ1^1o1T8\\1[FcL52OO]1Q2R8\\1]FcL40e1R2j7[1]FcL41i1m1d7`1_FbL11N02Nh1o1f7a1aFaL11N01Om19SNU1]9Q2iFfLKJl1m1_7c1hFgLm1h1Y7b1mFdLj1j1W7c1oFcLk1j1S7NRG@IdN3OM2R26mM^1T92[GHFdNl1n1R7E`GGBeNl1Q2P7DdGD_OiNl1NUN2K_1P94gG\\OYOPO33n1JWN1Ib1m84mGXOXOQO11L11MX22hMN2_1j8:oGVO]OZOe1JYN0IN4_1f8:RHUO\\O[Of1IXN41V1b8>THTO\\OXOf1KWN35X1\\8?WHRO[OXOV1JQO0F5;T1T8d0YHQO[OSOH1]10YO2KV1Q8c0\\HfNSODOJ54T2OWNV1Q8d0]HcNUOENL34T20VNLAU1a8g0_HaNVOEMNO7X2L[NQ1j7h0bH`NVOFL0N3[2L^NP1c7l0eH^NUOFM1MOOOn1O^N0FOi0P1a7o0fH]NVOGL;j1C]N2EOi0o0b7o0gH[NWOHJ0N5l1ISN179?g0e7n0hHZNUOJLNM6n1IZN:?f0a7P1lHVNTOMMMM4l1LZN3g0MQOk0W8U1`ITN\\NM0NN0m11\\N1f0NPOl0W8U1`ITN[NN1M[23kMO90]Ok0V8T1dISNYNO2NX21mM28n0b7P1fIRNYNO00X2NSN2:j0Z7V1gIRN[NL01MNT20lM2>1<g0T7[1jIQN`NMGOT2NmM2`0O:j0S7Z1kIQN`N0P2KXN0E0=i0Z7\\1kIRN_NOS2KTN2DOe0d0U7_1lIRN`NNg2JUM2d0e0R7a1mIPNbNNT2JZN01g0R7a1mIPNbNNT2KTOf0W6b1oIoMbNNh3a0f3c1PJnMcNLk2LnL0c0h0o6c1QJnMcNLj3b0a3e1RJmMbNNk3`0`3e1SJmMbNJHOT4d0^3g1TJkMcNNl3a0Z3h1WJiMcNNl3b0Y3g1XJhMdNOl3a0W3i1ZJeM`NKL5T4c0T3i1_J_M^N1J5U4a0S3k1iJ`MoM3V4b0R3k1hJaMQN1T4e0Q3j1lJ]MPN4T4e0o2l1aJ[MfN0P4h0h2o1`JZMgNOn20hMf0R6S2]NWMaKf0Q6T2RKWMY2d0e2V2PKYMZ2a0d2X2PKXM]2`0kK[O[6m2]KYM]2?iK]O[6l2_KXMm1J_Le0K[O[6n2_KVMl1NVLN1e0h6Z2QJQM34^3a0]2Z2RJSMSON`00F1JO_4e0Z2[2SJXMCIFOa4d0Q2]2TJXMDH`4c0UK]OZ6P3]JWMFJ[4c0WK]OZ6P3^JWMFH\\4d0h1\\2XJRMROOm00g3b0Q2]2ZJQMQO0l02f1L]Oc0`N^Ob5j2oIXMe0MC2H0l02f1M\\Oc0e4V2`IVMc00A6g0N]1NhMOf1OXNd0b6U2YJXM[O6g0L]1OhMOj1d0d4U2[JWM[O7]3L\\LM10d1b0k4W2QJVMH1N7\\36SN5i4W2hJ_M\\2L\\L2g1<i4W2hJ_M]2K\\L1g1>g4W2cJVMSO8`3M[L1i1<f4X2cJWMTO4`39RN5f4V2dJYMPOO02e3:bMCUOd0n5V2fJXMPO6m5<=U2gJYMoN2Q6`08V2gJYMPO2b3KiNc0n3W2gJZMnNO0OP1OW11lM1Y2a0m3W2hJZMoNM20m0OP1OTN=Z26l3W2iJ[MnNNT1Nk0OUN2c2a0a3X2jJZMPOMP30SMOc2c0_3W2lJXMQONn20TM1a2b0`3W2lJWMQOOX35XO>a3W2oJWMPOOX36XO<a3X2nJXMRONV31gNOaNc0a5X2oJXMQOMW1Oc02COmN1DN;e0g5V2PKYMPOLn21UM1Z10hNNI2OO=d0e5U2QK[MnNKQ3>\\NEkN1IL=c0c5V2QK]MnNJ^11J0iN=\\1EkN0KN9c0c5U2UK\\Mk1LSM;\\1GiN3IJ?c0`5U2VK]M?LB0lN5a1NdN2IJ?d0_5S2UMZMSN0lN6`1LfN3;>Z5T2hNaMZMKgN?W5T2UMYM^N9^1:m2T2lN_MVMJSOc0k4^1^JWNV1I30^N0X13<M`N1l0b0j4[1dJVNg2KmL1k0O[O3[10]N3P1=i4[1jMSNbL0n01VONZ13^N4o0<h4Z1lMTNaL0n01m00nM:Q17i4Y1VNVNUM0m0>oN3h4Z1WNUNUM0m03nM4R19g4Z1YNTNTM2l02SN0n0?d4Y1YLTNY11PM0_1OcN1g0c0e4X1YLTNZ10nL3m1NlNc0f4W1ZLUN=0\\N0_O2l1OmNc0c4X1\\LUN;0iN1c0ObN0h0c0c4X1kNUNYL1^O0a10bNOh0c0b4X1`NVNQM4lNNf1NYNO80j0c0b4W1aNXNnL5mNLg1NYN07Ok0c0b4W1bNVNnL6mNMg12]NLm0b0a4X1cNUNTLOa02V11PNO00S1c0^4W1dNUNRM0lNOn11nM2T1b0^4W1dNUNTMOiN1R22nNb0^4X1eNTNTMOiN1T21jNe0_4V1fNTND2UMd0a4U1YOTNfK2X21WNd0b4U1KTNnJ1S22bNd0b4U15WN`LMSOg0V4V17VN`LMSOh0U4U1MTNoJ0W3g0m1U1AXNWKMONU21RN1F0c0g0i4U1@YNVKJl2OSM2b0g0h4V1oNRNVL4BLn3c0Z1[1oNSNWLO@11OQ4a0W1_1oNQN\\LO^O0X31YM`0f4_1oNQN[L0_OO7Ob28^MIJa0V5`1_OoM[K1<N]28cM:i4a1_OTNXKK^36dLI:a0l4b1_OSNYKKa0N[23TM4<;l4c1^ORNZKKa0N[2=_M5m4d1]OUNlKE]2=\\M5m4d1^OoM]KL`0O^28]M:i4f1^OjMbKN<0`24]M>g4f1^OjMbKO;0U3a0`1g1]OiMcKNU4b0j0h1TOfMoK2[4`0b0i1]OgMcK1U4?j0i1^OgM_K6?HW3b0\\1k1^OeM_K7?IW3`0]1l1]OoMPLEU3`0^1l1]OfMaK2`0KT3a0^1m1\\OcMdK4>KT3a0^1o1ZO`MiK3S4?h0o1\\O_MiK2T4`0g0P2\\O]MiK4S4?h0P2CbMnKKS3c0\\1Q2cL\\MX17\\1<h0R2dL]MU17_1:g0S2aL`MV16a17h0S2bL_MT17c17g0S2bL^MU18b17g0S2aL`MU16d16e0V2aL^MW16b16f0V2aL^MX1KZM2OOX4`0f0V2aL^MX15a18e0U2aLaM<MiN3^OHf0Of2c0`1U2^LfM?FiN9d35f0W2\\LgMY1Nd14g0W2[L_MhNOb28QNAm2b0\\1X2]LgMX1NRNCl2?]1Y2^LfMX1NRNCk2`0]1Y2_LfMW1Md14f0Y2`LhMU1A`M3T4<f0X2bLgMU1@dM1P4?d0Z2cLfM\\1D\\1<e0Z2dLeMfNC\\23d1;f0Z2dL`MW1I\\M5R48g0Z2eL_MV16^11f0[2gLXMbNLd2a0\\10g0[2hLWMY1>X10g0[2lLTMT1`0WN@Q2a0h1[2HcM_LAQ2a0h1[2hLUM]11SMO020MQ4b0f0Z2iLUM]10YM0KOP4b0f0Y2jLVM\\11XMNQ4b0a0Y2jLWM\\10]NNgN2i2`0l1Z2LVM`K2T1Nd1a0k1h1aKmMb1H_N1T22dM42Jo3b0PM_O`2W2iLmM`1K\\N1V21dM42JP4a0nLAUONT3X2QMmM`1J]N2V2:dMEQ10k1a0SNAUONT3W2RMnMm0K@2d1<gNCnNOg2a0YN@`2V2kLmMh1L9?fN@PO0e2b0YNASONU3W2SMmMh1L9:dMGQ4`0fLA[O3OLU3V2WMkMg1N88fMIo3`0_L^OC5N10NS3T2YMhM^10^N1T26gMJm3a0gL@[O3NNT3U2UOjMoMOT24m1=fLCROLT3V2\\MjMT11aN1f6a0RJASOKU3V2[MlMT13^NN`127M_NOY2c0RN^O_O4MKV3T2\\MmMk0NgN7LM3OV12a0N]N0Z2a0^M]O`03C1OLU3T2\\MmMS16ZNJ61U1Ne01RN1M1c2?QNAA00LS3U2\\MmM?N_O4^OO:1V3NbL90E\\2c0UNBDMX3R2WMmMQ13ZNL<2T31`L8a28SNB_OOZ3P2XMlMS13^2OjK6c2;lM^OB5000MS3Q2^OnMe1OjK5d2<iM@C4000OQ3n1AoMd1OjK00Oe2b0hM@C4000MS3o1@PNh1N^Nc0eM^OD3N3NMU3m1AQNc1OeNb0bM^OB501NMU3m1AQN[MO60V21dMNU12h1b0aM]OB7OO1MT3m1cMoMT12TN07OU26[NN[OK123N`2d0iM]OB`00CT3l1BRNYM07OU26ZN0AKMOb2c0jM\\O@a02CS3l1BRNZMN71T26ZN1AIL0d2c0jMMADS3k1BQN[MO60U26ZNN[OLV3c0XM]OAh0T3X1Y1PNgL5CMf2a0QM^OC6N10NR3k1[1QNfL2GMe2b0PM^OC50;n2`1d2SNVKNd2a0QM^OC6O;n2_15oMZO4\\NNd2a0QM^OC6N=n2]1JoM24PNNd2a0QM^OC6N<o2]1IQN31WMNW4c0RL]OG1O7O8R3_1FSN4OVM0]1OX1c0cM^OG2O507S3`1ESN40UMNX4c0VLIA3S3`1ESN43]1>WLOAER3g1GSN22TM0V4?[L<`2P1ISN76SNJnNOf2b0gM_OBk0o2Q1FTN\\M0P35QNLoNOe2a0hM_OC`0NHn2e1HSN\\MOS34nMOh1?dM_OCk0l2R1HWNROKa00QN2a2?jM;Y2S1GRN2OS2`0kK<Y2U1\\2TN^O;dK@F1Ok0n2V1Z2SNoNLUL?NGE`0T3\\1S2SNmJKm3O]L`0MBEk0S3X1\\OkMYO0RO5ZOMO2c3MiL?2<a2Z1R2oMQKK]4`0lK`0BQOn2W2i0kM[LM10j05k3<eKDCh0n2]1h0hM[L01Nk05k3<eKCE3N<n2g1R2kMH<eKCE3N=m2f1\\1fM\\L4T4=eKBD4N=m2f1\\1fMZL7U4:fKBD4N>l2d1_1iMoKOG8g48dKDE3O=l2d1[1hMjK180G9m3GhL`0FCG3N=l2d1\\1lMRLLF:l3HiL?H@Fm0i2Y1]1kMhKN:;^3HmL>C_OIO25Mb0k2a1]1kMVL9Z3GnL?N<W2Z1\\1jMQLNJ3O7a48mK_OCm0h2Z1]1jMPLOK243[4<nK_OCm0h2Z1]1iMRLOI440l1NWNNM1^1b0kN]OEm0f2[1]1iMRLOI45Mb10WN1042JO2O0O1d1`0TO9S2[1^1jMPL0J?j1AUN55K1O\\1d0TO8S2[1j1jM^K?P2C7a0]N9T2Y1j1lM^K>U3ATMO=d0M:U2W1l1lM\\K?Q3@mL2V1b0_O_O[Oe0j2]1Q2ZNdKAH0Q27mN=_O@\\Od0j2\\1R2UNiKHAOS26lN>_O<U2R1U2RNlKLo01QO0<c0^O<U2n0Y2UNiKMA1=3_OOk1a0aN<U2m0Z2VNhKNVO052`03@0k1=dNL^OLf2a1\\2UNfK8XOKOMN060K641k1;fNI@Nc2a1]3\\NoILMO<5H0j1<eNIBNb2a1a3WNlIO0O;5IMf1a0[N^OK;2Ma2a1b3XNkIO0O=4FOf1`0\\N_OJ85O`2_1m3YN_IO=6CNi1?[N@J671_2^1=XN53hLN?6^OJN5j0K7c0ZO_OJ2;5[2^1m4lNWJN^NBE3>JA4j2c1?XNV1?`M3]NM8DW2e1>XNW1>_M4]NM8DW2e1Q5[NYH0j1?]NM8DW2e1<XNR11fK1206Ob0O:c0ZOK7EW2e1h4]N^HMY2a0SNM3E[2c1k3ZNjIOD5LK[2a0RN2OB_2b1X3YN[J22NE2\\2?lM4M@b2`1X3[NPNa0YL6FCi2[1X3\\NfK0:`0YN6DDl2Y1`7mNPFf0`2<h2\\NdJ0Q4b0SLf0`2<g2^N_JNN2Y4?SLg0`2<a7nNoEf0`2;f3^NUMa0eLf0`2:g3_NTMa0eLe0a2;W2aNhKNWO2f3?cLEBf0P3d0W2cNfKMVO40Ma3?kLFAL0d0Q3j0W2`NnK4mNL`3a0lLIB<P3j0a3dN`IL`0O]2b0`MIC:P3l0b3bN^INa3a0mLHB;Q3k0i3`NgLb0oLFA<P3l0\\3aN_Mb0eLDA<o2m0]7ROUFE^O<P3m0i3`NfLb0TMD\\O>Q3l0i3`NfLb0TMC\\O?R3l0_3bNcI1X3?SMHA:R3m0c1`NnL5\\NK03\\3>SMIA9T3m0b1aNYK0a15bNNY3=UMH@:T3m0b1gNiLNbN0Z3<UM?d2`0c1`NoL2aNNT3b0VM=d2`0X7SOTF@Bd0R3i0X7ROUFAA=LFU3[1X7QOWF_O@g0R3i0W7QO^F6[2j0V7PO^F6]2k0Y3^NeI2Y3?[M7^2j0Y3^NcI4OKX3b0WM_OCi0S3j0^3aNiL<TM@@j0V3i0^3`NhL=PM_OD10j0V3j0\\3_NkL=nL@FONl0X3h0Z3`NlL>UM<e2i0W3\\NPM>nL_OFo0U3h0W3ZNRM`0kLAFm0V3i0c3XNVI1o2`0[MBFl0X3j0a3WNWI1o2`0ZMDEk0Z3j0`3YNYL>WMg0P3c0V2ZNbKNQ2>UMi0S3`0U2[NXKK@3j2>WMh0S3a0o1WNgJ4f0L^O5i2<ZMd0GkN\\3j1T2YNXKLf2b0kLg0S3b0T2ZNfN>TLe0R3d0f1UNXK4l3=ULf0R3c0e1VNXK4k3>VLe0R3d0Q2YNgN>RL]OJY1\\3c0b1UNRK511R4<RL_OJV1^3e0_1_NSKOn0FQ2c0VMh0Z3b0\\1mNoKUOVO3n2`0XMh0Z3d0Y1mNRLXOS2?XMg0\\3e0V1UNYK3O6j0GELC1V2b0mMg0^3f0T1SN\\K3M7k0EJNc1c0mMg0^3h0T1oM_K2J;m34ZLg0\\3j0]1oMQK8OGm3a0ZLAIi00[Ob3m1^1lMUK0R4a0PLi0\\3k0l5\\NgFj0^3j0P1kM4a0]Kj0`3m0i0lMfKLZ13QOMn1a0gMk0a3m0f0nMgKJY15gNJ84o1=lMd0KPOf3U2c0lMjKKZ13PO1l1<lMc0LPOf3V2f0hMVM3iNOn1=kMc0LPOf3W2f0eMYM1gN4m1<lMEJe01XOg3Y2l2iMeK<RN@G501N02Kf3[2k2hMfK<WNEB0000Lf3\\2k2eMfK?WNDB0000Kg3_2i2bM`IN03l1?bNBC2ON2Nf3_2l2gMVK;dN_OF1OO0Of3c2h2dMYK;eN]OF2O00Nf3g2l1YMnJ7U1<\\N_O0N02O0n3i2\\4hMgG^O;OE2m3k2Z4fMgH_OP3m2U4eMlH]Oo2Z3h0mLVKJ]2a0gN]OmN0l3]3k0kLWKK^2`0SN]O15\\3X3k0eLVK02O]2c0hNAi2Y3g3VMaI@i2Y3f3XMlH[OO2a3[38cLnNd0[M\\OC011m3[3JdLZL1e2OXMd0>]OB11On3Z38eLjNd0^M\\OA22Nm3[3b3YMWI^Ob3Y3V3YMZI\\OYO0m3Y3a3[MdI]Ok2X3`3[MeI^Ok2W3`3[MdI^On2V3^3\\MdI]Oo2V3]3]MeI]On2V3m2jLVIc0<\\O^O10OU4V3j2lLVIc0<\\O_O1ONV4V3k2jLVId0=\\O]O2]4T3l1kLcJc01^O_3U3l1jLdJc01^O`3T3Q3]M`IEY3n2V3^MaIDY3n2V3^M`ID[3n2U3^M`IC]3n2R3_MYI\\O[O4^4P3j1lLlI09e08[O[O2a4Q3e1oLnIN8e0:[OZO1b4R3d1oLcJc0M[OYO2c4R3c1mLeJc04^Of3Q3d2bMfI^Oe3P3e2bMfI^Of3o2P2nLfIf0d0]Of3o2c2cMhI^Oe3o2b2cMjI^Od3o2b2cMcI[OUO2h4n2_2fM[IZOA0L2j4n2]1PMoI09f04ZOA0L0l4o2\\1QMbJf0]5X2Q1hMoNW2R1hMgI[OR4m2c1SMhIf0b0]OR4h2d1VMgIe0>ZOVO4P5f2g1VMeIf0d0]OR4e2X2mMgI]OR4d2X2PNeI]OT4^2Z2UNcI\\OT4]2[2WNaI[OV4[2Z1dMZJe07\\OU4X2\\1hMWJe08ZOW4T2^2bN[I[OW4o1b2fNTI^O[4g1d2lNPI^O\\4c1g2nNoH\\O]4b1f2ROdNl0\\1UOdNg0_1YOgH[Of4Z1V2dNVH14e0k0[Og4Y1c2\\OgHZOg4X1d2^OaNa0`1^OdH\\Oh4S1aLROS3JlJf0h0[Oh4Q1lKPOYN1;7R5GmJe0i0\\Oi4n0gK^OeNLW5FfJ0Mg0Q1[Oi4l0cKFiN_OI0m4NgK1\\Oe0R1ZOk4k0\\K0kN^Oi4GfKk0a6OoI9POWO`5`0c1MmI>POUO_5`0e1LkIa0QOSOi4FgKi0e6JjIg0POhNO1k4MgKh0g6IfIl0ROeNO1k4LhKh0g6IeIn0ROcN02W5LnJh0g0YO\\5=fJT1QO_N00N2Y5NnJh0h0XO\\5<fJV1WObNR5KmJh0i0YO\\5:dJZ1XO_N\\5d0\\KYO]57cJ_1VO`N\\5a0P2^O]Ic1SObNX5EjJi0`7ZO[Ih1ROaNY5DiJj0b7WOZIk1SO_N]5>X3T1[G^N[1EfN0h3h0l4V1[G]N\\5>W3W1]G[N[5?W3W1^GQNO0O1[5h0_KVOl6Q2]HnMO7X5d0aKVOj6R2dHRNP1Le2j0mLVOh6U2^HlM24U1Ke2j0c4]1aGjMO101X1Me2i0c4_1`GjM1OO2X1NSONS3j0R5`1aGhM33T1Ld2h0d4b1iGeMH2W1OUO1n2f0U5d1aGeM71P1OVO0m2g0U5d1aGeM71P1O`20XLg0`8e1aGdM71P1NF4g1f0SNVOn6^2hHbMa10XN4_2d0SNXOl6_2jJbMcMO06b2a0VNYOi6a2lJ`MlMOZ2g0i5k1lG`M\\4NhKf0Q8m1aG]M72KN_41lKe0S8n1gG]Mo4e0[3n1fG\\MR20iM20NW21mMd0]8n1dG]Mg42VKc0a8n1`L`MnJb0d8m1oH^MaN1h20RM30b0f8l1YL_Ni3`1WL_Nk3a1iH`Mc1o0f5`1fHjM`NI_2Q1\\6\\1eHkM_NH\\2U1a6X1cHlM`ND]2X1a6X1cHkMo0m0`6W1`HoMk0l0g6T1^HSNd0l0P7P1\\HTNc0l0R7R1[HRN>n0Y7o0ZHTN9n0_7n0WGbM;d0j0o0g7j0dFdM56IJg0h0b0S1W8`0bFeM1ON<`0E@k05UO100W2V3hMe2]2WJQNMB2d1Le0_93fFeMG<0K3k3b9ZNfF`2[9aMdFgMI<N]3g9`NbFeMK=L]3l3TLl1^2`JdML90`3i3ULl1]2iJcM]O76c3j3ULk1_2jJhM@d3j3WLn1]2eJiM^Og3o3TLo1\\2RJcM>U4b3kKP2`2_Jc1c3lKo1a2bJ]1e9fNRF^1o9fNlEZ1V:n22N2M3N3M3M1O2N2M3N3M2N3L3N3M2L4O1N2N3L3N2N3K5L3N3L4L4M2L5L3bLSCh0NDR=BPCW2U=fMjB[OOd2\\=S16K4L4VMVBi1n=UNSBg1R>WNnAg1V>PNkAE1V2g6iMg02`HL330S2f6RNd0JTIP2\\6PNa1f1dNYN^1_1`7I4H8M=]ORe`0"}}, "object_label": "bowl", "attribute_label": ["material:ceramic/brick/porcelain", "transparency:opaque", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a bowl filled with a delicious meal consisting of noodles, broccoli, and meat. The bowl is placed on a dining table, and a fork is resting on top of the food. The bowl is positioned towards the center of the table, and the fork is located towards the right side of the bowl. The meal appears to be a hearty and nutritious combination of ingredients, making it an appetizing sight."}, {"question_id": 825, "height": 480, "width": 640, "image": "000000071938.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "color, material, state, texture, transparency", "region_anno": {"bbox": [48.59, 1.19, 591.41, 472.88], "segmentation": {"size": [480, 640], "counts": "YP\\11n>1O1N20001O0Sn0NjQO6N100ON]AJa>7_AIa>;00OLaAI_><O1O2O0cA@Y>a0gA_OX>a0iA_OW>a0iA@V>`0jA@V>a0iA_OW>e001O1N3N000O2O00000O2O0SBPOi=T1O101N101OKZBPOf=o0[BROd=n0\\BQOe=o0\\BoNd=h0[B^O1Ie=`0YB12_Oe=`0YB12@d=i0ZB]O2Jd=a0cB_ON0_=a0mB^OE0U=c0UC]OU=d0jB\\OW=c0c0FfANZ>2fAN;Ia=9TBNZ>3eAMe0Jm<:^BMe0Hl<<_BL6Hi=<SBL3I<Oj<3eB4213Hj=2RB520T>JjA64MS>NhA0<No=5QBKo=5QBKn=7fA01JY>6fAO3JW>6gAM5MT>6gAM5MT>5iAL4O10h=1WB0:O]>000WO0bB0^=1h00ZAO]>19OVA050\\>0cA1\\>0dA0]>OcA1:0_=OkB1U=OlB0T=0n01JO[A1j>00O100000WB1h=01Ohh20WWM1P<ObYO2l5ORJ2fKMS:1XJ1m50a4NeE0]:000^=0lSO0^;0W3100001OYA0SR10[\\O0bA0g>0YN0QC0S11b=OG0VL1WIOi63fHMj73lDMQ30Ui11h_NOcD05041UY2O_RO0SdN0V<0eC00051f;OfC0420N02:N52V<NfC1OO51_=OnA0[<0jE1kMOn00YO0e:0YG1YO1]9NYG2^NN43_<N]CO34`<MSD7m;IRD8]:H_D1o0N3;^:G`D10M21c1:U:HRFMWN<c<F[DNPO>e<D[DNoN?f<D`D>e:@gD3b0>g:_OiD1>b0i:]O`DOG0n0g0k:ZO`D0FO>0Ih0b;[O_DOHNl0j0V:VOSE0K6LKO64Il0k0V:WO\\E1CML90Go0k0U:XOoE6lNGm0n0X:UOoE7Jf0W:SOoE6DJVOo0W;QOnE7AQ1a:hNnE6AS1b:eNoE3BY1i;gNUD[1b:aNSE0L0658[1b:bNiDN71J6OI2;b0V1d:_NYE4E8>U1c;mN]DS1c;cNhC3c0O]OV1b;dNRE:]OFb0d1o:\\NQE:4Z1b;_N`Dd1b;YN^Dh1Q<XN`Ch1`<XN`Ch1g;XNdD1Fg1f;XNdD2Ef1g;YNcD2^OM2i1m;YNYDOK3LN2g1];XNnDO55_OK1j1];XNaE5UOc1U<VNlC9Kd1X<TNiC<Na1U<SNkC01=O`1V<VNkC:O`1W<SNlC<O`1\\<_NeCa1\\<YNaCK3m1]<RN`C21N2n1\\<XNhCh1W<[NfCf1Y<\\NeCe1X<_NfCb1Z<b0OlMgCc1X<]NiCc1W<oMgC;2f1j;nMcD9Ei1g;PNdD2AN4o1h;PNcD8Dj1X<YNgCg1j;mM`D=Dh1l;lM_D<Eh1l;lM[DOK=Nh1k;mM_D<Fg1k;mM^Dd2b;\\M^Dd2b;\\M]D>He1k;mMWDN1a0Md1j;nM]De2c;[M]De2c;^MYDc2g;^MXDb2i;^MUDc2j;:001O000PMUDk2k;5OSMVDf2j;80000O1000000O10000O1000000O10000O100000000O10000000000O10000O100000000O1O1000000O100000000O10000QE`LG0^:a3kE_LG2\\:_3k00\\E_Lh9b3mE_LF4[:^3fE^LM500]:]3oE_LE3\\:^3l000000SE^LJON1Q:b3XF]L12f9a3U10hE]LS9c3jFaLU9_3QF]LL1O061K4S:]3dF]L[O5Q:NkE[3[;dLgD[3Y;eLgD[3X;gLfDZ3?bLI000l9e3XG[L_8e3^10TF[L]8e3_G_La8a3\\F[LL10O60O2K4g9_3ZG[LQO4e9b3_10O1O1oDYL2O;0E11OU9h3hFYLY10o7g3ZHXLf7h3ZHXLf7h3XH[Lg7e3jFXLL1O11O0O?2A4Z9b3WH]Li7c3j100000cEXL21[O1l8g3mHYLS7g3nHXLQ7i3oHWLQ7i3UGVLY10fN4k8W1PGR15dMM1N02OO11OO07OK6O1l8U1SGP15dM10100091D3j8X1QGQ1S;^10000SEULL010411Od00YO3a8Y1ZGQ1i0cMd03Y7h3bIXL^6h3bIXL]6i3bIYL]6g3bGTLL2NO8O000000L0L324a8V1]GP1;cM_15j6c3\\GZLR;f3nDZLR;f3nDZLc2Ni5i3dGYL?NI000l02QO1U8e3gGZLh0Ng00eN3U8d3hG[La20g5d3iG\\L`20g5d3hG]L_22h5a3jG\\L<NI000O11O00N3L3W8`3jG\\LX2NiM5U8b3gG]Lc2Ng5k3g200GoDcL5J2O10O1W1On6c3fGcL4Je00P9n3U100000VERLL10O60000000:0C4S8j3[JTLf5l3g2000mGRLT5`3oGlL6D1010O11O00d00YO1l7^3PHmLk2ET5_3QHlLn:S3QEoLn:R3REnLl2CS5o3jHPLZO1OO6000:0D3MOl7n3eJQLaM0j7o3nJPLR5P4nJPLR5[3QHXMl2^OR5[3UHTM<@I0`12]NOi7[3UHTMi2AR5[3THUMj:a30000WFnK21QO1o7P4VJnKT6R4]20000XOUE[M5[O10U:X3fE]M4[O^:Y3^E\\Mj:]3O100[EmKm10QN4P8W3lG[Mc2\\Oa5Y3lG[Mk:]30000`GmKkM2n7S3PHcM_2XOc5V3lGcMh:[3N2kGjKa5U4]JoKa5Q4`JnK`5R4h2O1O00nEmKW9S4j0100O100ZFkK:3f6Q4g201O0000[EmKY10]O0YO1g7P3THoMl2QOP5R4o2000PHQLo4o3hImKaN0?0F0K5g7_1VHi0k2gMo4o3P310gNWE[Ni:e1XEZN3lN<OG0]9k2]FZN4kN\\:T480N2VHkKVM2Y7T4RIiKI00000U14eN1Z7R4gIiKUO0W11eN3X7S4\\3O1N02]EjK10011O00P9S4hFoK6N1010d9S4TFoKg:Q4YEoKg:P4ZEPLe:V4iEhKI000R23h4h0nH`2f:`MZE`2e:n0OK\\EPLd:V4bEfKL010411OV9[4[GeKn8S4YFTLb:U4O100nEcKI0K1OO60d00:0XO3k5Z4jJcKY8]4U100000nEcKI0:0`8P1nFXO001OOV2n9eM`Fc1BR1l9]M_F]4`9dK_F]4U4^Kk06jJa4;YK30n0073`3n1iJVN20Nh10]N?D_31Z1P2hJWN1OOV2i9h2000WMWFlM1T25dML10O6000[8i1]G_N001N1c1NhN6_O10P9V5?2O100aFgJ1010f32i0e4YKjKk4_OLZ5m40O10XO]FSL:[OHO60`8c4XGSLb9m3_FSL^9o3cFQL\\9P4bFRL\\5[O`N^5cL_J[44\\KL]3e4^LUL[5YOjJN\\3d4_LULZ9k3gFULX9l3hFTLe5WOiMd4cLUL2WOMO1050\\40aK55Le2e4TMTLc5[OcJMf2d4TMTLc5[OdJLa2i4UMSLf5XOeJK]2l5m2ZJ`JLLOf2l5n2YJ`J0`2T1[MW21^Md5WO`J1_2f4]MRLe5UOaJ2]2g4]MRLf5SOaJ4Z2h4_MRLe5TOaJ3Z2g4`MRLe5TOaJ9S2e5\\3QJbJ;Q2d5^3nIcJ?j1g5o3[JmK`4QNSLf5nNaJb0d1]4VNSL=lNf44RKf0^1X4]NRLe5nNaJj0[1V4_NRLR6IZKW4eNPLR6MSKT4iNQLT62lJm3oNRL6iNL1Z5OnJ_1?g3WOQLU6:aJo4`5TK[Jm4e5`IjIP20U31SLU6hNjIX71PJT5gN\\K1J0EW72QJT6gNlIW70RJX6n5hIRJX6m5iISJm5hNWJU7KTJ4fNL10Ob40UL1^OT7LUJm5gNWJR7KZJX6f5gI[JZ6d5fI\\JZ6c5gI]Jn5cNXJP7J]Jo5cNVJo6L^Jn5dNVJm6L_Jn5dNVJl6KbJo5cNUJk6KcJ5_Ne00k20bL0a06[Of6MgJP6aNUJg6KhJQ6]NWJk6HhJ\\6W5eIiJo5_NWJh6IjJo4\\NnK4YOe6KkJo5^NWJf6KlJ[6R5dIPK]6n4dIiIMj0_6\\5dITK7YN_40_Lb6kNVK\\6j4dIVK\\6j4cIWK^6h4`IZK`6f4`IZK`6c6000PN`I`Kd6\\4\\IdK:RNm5Z6jIdK9SNc50YJX6LeKa6[4_IeKb6Y4]IiKc6U4_IdJM<e6i1[I53gMM;e6XO^Ig0M12TONO0:0V14ROL;e6XO^Ig0M13ROOO01O000O1000b040L;2"}}, "object_label": "bed", "attribute_label": ["color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color", "answer": "The bed in the image is a white bed with a white pillow. The man is lying on the bed, and he has a cell phone placed on his face, specifically on his ear."}, {"question_id": 826, "height": 428, "width": 640, "image": "000000160556.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, material, state, texture, transparency", "region_anno": {"bbox": [564.29, 141.62, 38.45, 43.74], "segmentation": {"size": [428, 640], "counts": "gl[73W=3N0O2N1O1M3`CDQ<<oCEQ<:`01O00O`CFR<9nCIP<7PDHR<7nCJQ<6oCKQ<3PDMP<3PDNP<0QD0o;0PD2P<NnC3R<MmC4T<LjC5V<LhC6X<LeC4[<ObC1_<>0O001O100O100O2O0O3M2N6K9G`l>"}}, "object_label": "cell phone", "attribute_label": ["color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "state:on", "texture:smooth/sleek"], "control_dims": "color, transparency, texture", "answer": "The image features a person holding a cell phone in their hand. The cell phone is positioned in the middle of the scene, with the person's hand holding it securely. The phone appears to be a smartphone, as it is described as a \"smartphone\" in the image description."}, {"question_id": 827, "height": 427, "width": 640, "image": "000000225670.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, material, state, texture, transparency", "region_anno": {"bbox": [358.93, 287.36, 58.41, 5.44], "segmentation": {"size": [427, 640], "counts": "Sbe44W=0000000O100000O11O0000O100001O00O100001OO10000000000000000000O100001O00O100001OO1000000001O000000O11N100001N11N2NPTm2"}}, "object_label": "bench", "attribute_label": ["color:white", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "state:empty", "texture:smooth/sleek"], "control_dims": "color, state, transparency, texture, material", "answer": "The image features a bench with a yellow and black striped design. It is situated in a gray setting, possibly a park or a similar outdoor area. The bench is positioned in the middle of the scene, providing a comfortable spot for people to sit and relax."}, {"question_id": 828, "height": 427, "width": 640, "image": "000000225670.jpg", "category": "description", "question": "Describe the frisbee in the following image in detail.", "dims": "color, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [438.18, 159.0, 30.87, 18.61], "segmentation": {"size": [427, 640], "counts": "VWg56T=2N2N1O2N1O100O1O10O010000O10O10O10O100O100O100O1O2N2N2NTbW2"}}, "object_label": "frisbee", "attribute_label": ["color:pink", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pattern", "answer": "The image features a close-up of a frisbee with a red and blue color scheme. The frisbee is circular in shape and has a slightly curved edge. The red and blue colors are distributed evenly across the surface of the frisbee, creating a visually appealing design. The frisbee appears to be in good condition, with no visible damage or wear."}, {"question_id": 829, "height": 480, "width": 640, "image": "000000018575.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pose, state, texture", "region_anno": {"bbox": [527.54, 52.29, 78.84, 91.19], "segmentation": {"size": [480, 640], "counts": "_hl7142k=9^BN^=6`BK]=:`BF^=>_BD_=>`BC]=a0aB_O_=R1N1O1N3M2O2M2O1N2O1O1N3N1O1O100O1O1O1O100O1000O10O10O100O1O101N1O1O1O100O1N2O2M2O1J7N1O1O2N1O2O1N2N1O2N2N2N2N2N3K4N4J6Jjk?"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:white", "material:glass", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "state, cleanliness", "answer": "The image features a white bottle with a white lid, placed on a white surface. The bottle is filled with a red substance, which is likely a sauce or a condiment. The bottle is positioned in the center of the scene, and the white surface it is placed on appears to be a table or a countertop."}, {"question_id": 830, "height": 480, "width": 640, "image": "000000109976.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, texture", "region_anno": {"bbox": [113.26, 170.43, 265.35, 118.65], "segmentation": {"size": [480, 640], "counts": "lcf12l>4N2N0O2O1O1O0O1000001^OIXB8h=HXB8i=EYB;V>0O101O0^OAcB?\\=BdB>]=AcB`0\\=@dB`0\\=@dB`0\\=@dB`0\\=AcB?]=AcB`0\\=@dB`0\\=@dB`0\\=_OeBa0m=0O2O0013L1O0001O000O110O001O0000001O001O0001O01N100000001O00000GYOYBh0f=XOZBh0e=YO[Bg0c=\\O\\Bd0d=\\O\\Bd0d=\\O\\Be0b=\\O^Bd0b=\\O^Bd0b=[O`Be0_=\\O_Be0a=[O_Be0a=\\O^Bd0a=^O]Bd0b=]O]Bc0c=]O]Bc0c=]O]Bd0b==O2O00000010O1OO2N^OaBE_=:bBF_=m00[O_BKa=5_BL`=]O`Bd00O`=]OaBa030\\=B`B;63Z=@bB;82T=EdB973U=DcB:83S=5kBMS=4lBNS=_OgB=65S=]OjB<65o<_OmB:56o<^OnB;37P=]OmB<38Y=GgB9m<]OQC;28m<]OQC;28m<\\ORC;1:S=\\OfB95>Z=AgB?Y=AiB=V=DkB;U=EkB<T=DmB;S=EnB:R=FmB;S=EmB;g;@QE5XO;b;FUEN[O;];JWEL]O8Y;_OXD>R1K[ONHKa;2ZD8R1M[OMJJ^;7ZD61Jf02FMMIZ;:\\D50Kd01IKb;6QD`0b0_OKId;X1`DPOKHd;[1VDaN1<5Ic;]1RDaN596Ib;d1XDcN6Ib;e1WDbN6Jc;c1XDcN6Ib;d1XDcN6Hc;f1VDbN7Hc;g1SDcN9Fd;Z2\\DfMd;Z2\\DfMd;Z2\\DeMe;[2[DeMd;\\2\\DdMd;]2[DcMe;]2[DcMe;]2[DcMe;]2[DcMe;^2[D_Mg;a2;100000000lC^Mj;c29000kC]Mm;e2QD[Mo;k20O01000MoCXMP<g2QDYMo;h2oCYMQ<k20_OQDQNo;n1TDPNl;P2TDPNl;o1UDPNl;P2UDoMk;Q2UDoMk;Q2TDoMm;P2TDPNl;P2TDPNl;P2TDPNl;o1UDQNk;o1UDPNl;P2TDPNl;P2TDPNl;P2TDoMm;Q2SDoMm;Q2SDoMm;Q2RDoMo;Q2SDmMm;S2SDmMm;S2TDlMl;T2UDjMl;U2`01O0000000000000000000001O01O0000000_CiMY<X2eCjMZ<V2dCkM]<V2aCkM_<Z2101O00000001O000001O000O1000001N1000000O101O00000O101O0O100000001N100O100J7I6M3G90001O0000001N1O10001O1NZbk3"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The image features a white oven with four burners on top, located in a kitchen. The oven is situated next to a counter, and there is a coffee maker placed on the counter as well. The kitchen also has a sink nearby, and a microwave can be seen on the countertop. The overall scene gives the impression of a well-equipped and functional kitchen."}, {"question_id": 831, "height": 480, "width": 640, "image": "000000109976.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, size, state, texture", "region_anno": {"bbox": [190.4, 172.58, 16.7, 26.15], "segmentation": {"size": [480, 640], "counts": "^hh2;d>:G2N01O1O0010O001O00O100EhANY>0kV\\6"}}, "object_label": "bottle", "attribute_label": ["color:black", "color:orange", "material:glass", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "texture, size, material, color", "answer": "The image features a close-up of a bottle with a red substance inside it. The bottle appears to be a small, dark-colored container, possibly a vial or a tube. The red substance inside the bottle is likely the main focus of the image, as it stands out against the dark background."}, {"question_id": 832, "height": 480, "width": 640, "image": "000000109976.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pattern, pose, size, texture", "region_anno": {"bbox": [177.26, 143.85, 12.52, 35.21], "segmentation": {"size": [480, 640], "counts": "cSc2?[>7O0QB]Oa=c0`B\\O`=c0aB]O_=c0`B^O`=b0_B_Oa=`0`B_Ob=?^BBQ>NPB1Tdd6"}}, "object_label": "bottle", "attribute_label": ["color:black", "material:glass", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The image features a bottle with a blue label, which is placed on a table. The bottle is positioned in the center of the scene, and it appears to be the main focus of the image. The bottle's label is visible, providing information about the contents of the bottle."}, {"question_id": 833, "height": 500, "width": 452, "image": "000000255483.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [18.18, 123.38, 216.88, 284.41], "segmentation": {"size": [500, 452], "counts": "a\\<;X?7I:G4K3N2M5K4M2N2M4M1O2M2O1N100O2O0O2O1N2O1O2M2O4K8I5J6K6J3L3N4K5L3L4M3L5L3L4M3L5_FjK[7Y4\\HUL]7o3[HWLc7l3WH[Ld7j3VHZLh7i3SHZLk7l3lGYLS8e5N2O001N10O10O100O10O1000O01000O010O1000O0100O100O01000O10O10O1O100O1000O010000O10001N10O00100O01O1000O001O10O10000O100O10O10O100O10000O10O10O10O0100O10O01000O010000O01O10O100O10O10001N3N2N4L3[MjGfMX8X2iGfMY8X2hGhMZ8V2fGiM^8T2bGlMa8Q2_GoMd8m1\\GTNh8h1XGWNn8d1RG\\NP9b1PG^NR9_1oF`NU9]1kFcNX9Z1hFfNZ9W1gFiN\\9T1dFlN`9P1_FPOf9l0ZFTOh9j0XFVOj9g0WFXOm9e0RF\\OQ:`0PF_OT:>lEBX::hEF[:7dEJ`:2`ENb:0^EOe:N\\E2f:LYE5i:HXE8j:FVE9n:DRE<Q;AnD?V;^OjDb0Y;ZOhDf0\\;VOdDj0a;QO_Dn0e;nN[DS1h;jNXDV1k;gNUDY1Q8fMdKo0[LZ1Q<cNnCHL^O1N140o0W<ElCK?>b7QOlG20O`3c0dLEi0a0_7VOeG1c3?`LHl0`0d7XOSK=cLAk0i0_;BREFXNb0T9B\\J2mLIR1`0_;C`CNS1<^;E_COV18m7J_F13Nk2OXO7Z7a0VIWOB6_7>nH\\OD5`7<mH_OE2P8N[H0k<10000WN0]B0Y10S<ObB5N`00\\O413NM160V=b0jB^O40L0`=OiC0n=000YT[3"}}, "object_label": "book", "attribute_label": ["color:white", "length:long", "material:paper/cardboard", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "state, length, color, material, transparency, pose, size, texture", "answer": "The image features a book with a hand holding it open, revealing its contents. The book appears to be a newspaper, and the hand is positioned on the left side of the book. The hand is holding the book in such a way that it is open to the middle of the book, allowing the viewer to see the content. The book is placed on a table, and the focus is on the hand and the open book."}, {"question_id": 834, "height": 360, "width": 640, "image": "000000300659.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [311.98, 222.2, 28.36, 47.42], "segmentation": {"size": [360, 640], "counts": "cX^33V;0B1bEOKO[:4iE4X:MfE3Z:NeE2[:OcE6Z:JdE7]:74J6M3000O2N3L3M4L2N^OjE2V:MRFLn93e0O0O100O2O2N[WY3"}}, "object_label": "airplane", "attribute_label": ["color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, texture, pose, size, length, material, state", "answer": "The image features a red and white airplane flying through the sky. The airplane is in the middle of a maneuver, as it appears to be banking or turning. The plane's wings are spread out, and it is flying high in the sky. The scene captures the excitement and skill of the pilot as they navigate the aircraft through the air."}, {"question_id": 835, "height": 612, "width": 612, "image": "000000402720.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [212.64, 462.52, 39.04, 70.59], "segmentation": {"size": [612, 612], "counts": "cPn38kb04L1M4K4K5M2L5D<K5N2N1H9L3000100O100000O0100001N2N2O1N2N3M;E4L6oNP^Oc0ib0_OQ^k6"}}, "object_label": "bottle", "attribute_label": ["color:black", "length:short", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "state:closed", "texture:smooth/sleek"], "control_dims": "state, color, material, transparency, length, size", "answer": "The image features a bottle sitting on a wooden table. The bottle is made of glass and has a white label. It appears to be a water bottle, possibly containing a beverage such as water or juice. The bottle is placed on the table, and there is a plate nearby, suggesting that the table is part of a dining setup."}, {"question_id": 836, "height": 480, "width": 640, "image": "000000107851.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pose, size, state, texture", "region_anno": {"bbox": [301.86, 292.03, 102.82, 175.6], "segmentation": {"size": [480, 640], "counts": "no]48f>3L3O2L3M4M2N3L3N2N2M3K5J6D<XOg0[Of0J400N10M4L3N4J5011O1OD_D[M_;e2?N001O2MQEjMX9V2fFQNW9n1eFXNY9j1cFYN\\9i1_F[N`9f1\\F^Nd9c1YF_Nf9d1PFdNo9V301000O0010000O0O2K5M3L4K5E;J6N2O2M2M3N2N101N3N2N3L8H4NhCiMh;h20O0001O1O001O0O00K6L4M3L4K5K5M3N2M3N2M4M4L3N2N3M2M3N2L3N2M4L5FiW_3"}}, "object_label": "elephant", "attribute_label": ["cleanliness:clean/neat", "color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "size", "answer": "The image features a large elephant with several people riding on its back. There are at least four people visible, with some sitting on the elephant's back and others standing on its sides. The elephant is walking through a grassy area, providing a unique and exciting experience for the riders. The scene captures the adventurous spirit of the people and the majestic presence of the elephant."}, {"question_id": 837, "height": 427, "width": 640, "image": "000000271728.jpg", "category": "description", "question": "Describe the cat in the following image in detail.", "dims": "cleanliness, color, maturity, pose, size, state, texture", "region_anno": {"bbox": [114.11, 210.28, 142.64, 83.74], "segmentation": {"size": [427, 640], "counts": "ai_18o<6J5L5K4N2M3M2O2N1O2N1O2N2N1N3N1O2M3M2O2N10001N10000O2O0O10001N1000000O10000O1000000O2F9N2N2O10000001O001O1O100O1O2N1O00001OO1000000000000000010N10000O1O1O1O100O1O100O11O0mM\\E_1d:]NbEa1`:WNgEh1n:EcDhN];W1fDgN[;W1gDfN[;Y1=O0O2M2M3N3N100O2M2O1N2GaC@e<>5O1000001O000O10000000000001O0000000010O000001O00100O1O00100O01O00001O1O0O2O1N4M3K[im4"}}, "object_label": "cat", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "pose:horizontal/lying", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, cleanliness, color, pose, maturity", "answer": "The image features a large orange and white cat sitting on a couch. The cat appears to be staring at the camera, possibly with a glare in its eyes. The cat is positioned on the couch, occupying a significant portion of the space. The couch itself is black, providing a contrasting background for the cat's vibrant colors."}, {"question_id": 838, "height": 426, "width": 640, "image": "000000290592.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "cleanliness, color, maturity, pose, size, state, texture", "region_anno": {"bbox": [199.24, 105.61, 122.36, 225.81], "segmentation": {"size": [426, 640], "counts": "aob2:f<`0Gk0VO7I6K3L3N1N3N1N3cEkMa9[3D4L9F;F:G2M1O1O1OSOnGcLR8b2PIWMP7d2n1M2O2HdEcMZ:h2N3M101O000O2PFmLg9S3800O10O1001OO100O100001O00_F\\M]8c2_GfM]8Y2`GXNR8h1kGdNl7]300000000000VOQHXLP8_3R1G9M3N2N3M2N2N2O2N1002N10O001O0000001M200O2O00FoL\\Fo2b8oLlG`0@a2\\8oLdG23O1b0J]2^8PMcG5021<N\\2_8RM`G\\11b1^8SMaG\\1Ob1`8SM_Gn00\\O0b2b8WN^GUO2X2NaMg8^1_G8]9HcF5`90[FLj94VFHo93ZFEi9;YFAi9a0kE_N5m0o9P24N2ROiEfNZ:Y1jEcNX:^1eEbN]:S23O1M6[OXE_Nf:EXE[2h:gMWEX2j:hMVEW2l:hMTEW2m:hMUE_1NiN1I06Q;e1oDZNT;e1kDZNW;n0jDHV;8jDoN1b0W;>oDAS;2[EKi:M\\E1h:K[E2S<K4Mi[U4"}}, "object_label": "sheep", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, size, pose", "answer": "The image features a large group of sheep gathered together in a grassy field. There are at least 13 sheep visible in the scene, with some standing closer to the foreground and others further in the background. The sheep are of various sizes and are spread out across the field, creating a sense of depth and movement. The scene captures the essence of a typical day on a farm, with the sheep grazing and enjoying their surroundings."}, {"question_id": 839, "height": 640, "width": 482, "image": "000000022705.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "cleanliness, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [179.41, 210.82, 25.14, 82.36], "segmentation": {"size": [640, 482], "counts": "Pm^32mc0101O1O0gM0a@1_?OV_O57Nc`0NT_O76Lf`0MS_O;3Ij`0Nn^Ob0KGVa0Im^O]1Sa0h0000VOi^O]NG;`a0T1S_OiNn`0S1W_OkNl`0o0X_OPOk`0k0X_OTOi`0i0Y_OWOg`0f0]_OXOg`0a0]_O_Oe`0:`_OFe`0Mc_O3Vb0NQ[_5"}}, "object_label": "wine glass", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "cleanliness, material, transparency, state, pose, texture", "answer": "The wine glass in the image is filled with a yellow liquid, which appears to be a cocktail or a mixed drink. The glass is placed on a table, and a person's hand is visible in the background, holding the glass. The person's hand is positioned behind the glass, and their fingernails are painted red. The scene suggests a social gathering or a celebration where the person is enjoying a refreshing beverage."}, {"question_id": 840, "height": 470, "width": 640, "image": "000000087470.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, pattern, pose, state, texture", "region_anno": {"bbox": [290.15, 153.96, 28.66, 16.35], "segmentation": {"size": [470, 640], "counts": "jUV48[>4M2O0100000O01000000O10001OO10000001O0L4N2O1N2O0010kUc4"}}, "object_label": "cow", "attribute_label": ["color:black", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a cow with a black and white face, standing in a field. The cow appears to be looking at the camera, capturing the viewer's attention. The field is surrounded by a rocky landscape, adding a natural and rugged backdrop to the scene."}, {"question_id": 841, "height": 470, "width": 640, "image": "000000087470.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "color, maturity, pose, state", "region_anno": {"bbox": [32.47, 91.86, 17.34, 24.85], "segmentation": {"size": [470, 640], "counts": "\\i>7T><N1N2N200000000001O2N1O2M2O1O2N1O2MfW^8"}}, "object_label": "horse", "attribute_label": ["color:brown", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry"], "control_dims": "maturity, color, state, pose", "answer": "The image features a brown horse standing in a field, with a person riding on its back. The person is seated on a saddle, which is positioned on the horse's back. The horse appears to be calm and well-behaved, as it stands still in the field. The scene captures the bond between the rider and the horse, showcasing the connection between humans and animals."}, {"question_id": 842, "height": 427, "width": 640, "image": "000000240754.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, pattern, pose, state, texture", "region_anno": {"bbox": [22.5, 195.87, 166.12, 98.46], "segmentation": {"size": [427, 640], "counts": "ln81Z=1O0d06TO7J6J5J6K6I6K3M2O0N3N2O000010O1O4L5L3L5K5K3M5K5L4K4L5HTV15jiN6J4K5L5K4K7J5K5J7J3M2O11N3M3L5LXDbNf;[1XDeNm;W1RDhNS<U16KkCPOT<k0kCWOY<f0dC\\O`<e03L7I7HlMMX27I5L6J5K6J5K4K6K7H6K4M212NN3L5K5H6K6K6J5K6I6H9Igh02XWO4L7I6J6J6J5L5O0021L2N05ML320J5J5K6K5J8GdMMhGLY8<W26J9H4M3O24LO22JcCSO\\<n014MO42LN2K5JkMYOnG?Q8FTH1l7;kGBU8d0W2251K7J21N6H030010MN4J3KiMDkG1V80d2MoB1Q=;MH3MoBOK1O2U=1f=KhB0E2hB:R=KV;LnD01OVQP6"}}, "object_label": "cow", "attribute_label": ["color:brown", "pattern:plain", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, pose", "answer": "The image features a cow standing in a pen, which is enclosed by a metal fence. The cow is positioned near the fence, and it appears to be looking at the camera. The cow is standing on a bed of hay, which is a common feeding and resting area for livestock. The scene captures the cow's curiosity and interaction with its surroundings."}, {"question_id": 843, "height": 612, "width": 612, "image": "000000290081.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, pose, size, texture, transparency", "region_anno": {"bbox": [344.25, 433.5, 267.75, 170.53], "segmentation": {"size": [612, 612], "counts": "Vek52Qc01000000O10000O100O1000000O10000000000O1000000O1O1O100O10000O100O10000O1O100O1000000O100O1O100O100O100O100O100O1O100O10000O1O1O1O1O1O100O1O100O1O1O1O1O1O1O100O1O1O1O1O1N2O1O100O100N2O1O1O1N2N200O1O1N2O1O1N2O1N2O1O1O1O1N2N2O1N2O1N2N2O1O1N2N2O1N2O1O1O1O100O1O1O1O1O100N200O1O1O1O1O1O1O1O1O1O100O1N2O1O1O1N2O1O1O1O1O1N2N2O1O1N2O1O100O1N2N2O1O1O1O1O100O1O1O1O1O100O100O100O1O100O100O100O1O1O100O100O100O100O100O100O100O1O1O100O1000000O1000000N2O10_JaB]5c=000000000HbJjB^5V=bJjB^5V=cJiB]5W=bJjB^5^=00000000000000000000000000000IeJeB[5b=00000001O00O1000000000000001O0000O10000000`LkBQ1U=kNSCQ1m<oNTCP1m<nNUCQ1k<nNVCR1j<mNXCR1h<mNYCS1g<lNZCT1f<lNZCT1f<kN\\CT1d<lN\\CT1c<lN_CS1a<mN_CS1a<mN_CS1a<lN`CT1a<kN`CT1a<kN_CU1a<jN`CV1`<jNaCU1_<jNbCV1]<jNdCV1\\<jNeCU1[<kNeCU1[<jNfCV1Z<jNfCV1S<POnCP1m;]MiBd1[1n0S<oNmCQ1Z<hNfCX1Z<gNgCY1"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, texture", "answer": "The dining table in the image is wooden and has a glass vase placed on it. The vase is positioned in the center of the table, and it appears to be empty. The table is surrounded by chairs, with one chair on the left side and another on the right side. The scene also includes a cell phone placed on the table, slightly to the right of the vase."}, {"question_id": 844, "height": 240, "width": 320, "image": "000000343466.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, pose, size, texture, transparency", "region_anno": {"bbox": [146.7, 122.43, 81.43, 114.87], "segmentation": {"size": [240, 320], "counts": "TcR139Oi6=N8I9F<gIeNg5d1N:F7I2N1O1O1N2O1O1O1O1O1O1O1N2O1O1O1O1O1O1O1N2OjMaK\\1^4]NWL_O\\Ob1]4nNkLc0U3]OWMA\\Na0]4N_20O10000000OE@hI`0T6EjI<T6GkI9U6LdI6\\6?0O10000O10001O000N20000000001O000000000000001O000O1000001O00001K4F::ele0"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "transparency, cleanliness, pose, material, size, texture, color", "answer": "The image features a small white oven with a stove top, located in a kitchen. The oven is positioned underneath the stove top, which has four burners. The stove top is white, and the oven is also white, creating a cohesive and clean appearance. The kitchen appears to be small and compact, with the oven and stove top being the main focus of the space."}, {"question_id": 845, "height": 481, "width": 640, "image": "000000376264.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pose, size, texture, transparency", "region_anno": {"bbox": [0.0, 22.55, 47.35, 84.74], "segmentation": {"size": [481, 640], "counts": "h0Z2g<0100O1O010O100O1O010O1O1O100O1O1O100O1O1O1WNXCW1\\=M2N2N2N1O1O2N0O2O1N2N2N2N2N2N2M3N2N3M3M2Nmkg8"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material", "answer": "The image features a bottle of Halo Top ice cream, which is placed on a table. The bottle is filled with a creamy substance, likely ice cream, and is accompanied by a bowl of food. The bowl is positioned next to the bottle, and the two items are placed on a surface, possibly a table or counter."}, {"question_id": 846, "height": 427, "width": 640, "image": "000000026204.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [253.89, 198.59, 147.14, 105.79], "segmentation": {"size": [427, 640], "counts": "aoZ31a<3cCl0l;<J6N2N2O1O1N2O2N1O001N2O001N100000001O6I2O1O001N2O2N000O6K1O2N3M0O1000001O0O10000000000O101O000000000000000000000000000000000000000000000000000O10000001O01O0000O10000000000000000000001O0001O0000O1001O001O3M2N001O0001O00000O1N2I7N2O1F:N2O2O0O1M3O1O10000O101TNlD_1V;ZNUET1DROo;8QDE;0g;7n0J`cW3"}}, "object_label": "bus", "attribute_label": ["color:green", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color, pose, length, transparency, state", "answer": "The image features a large city bus driving down a busy street, surrounded by traffic. The bus is positioned in the middle of the scene, and it appears to be a public transit bus. There are several cars on the street, with one car in front of the bus, another car behind it, and a few more cars on the right side of the bus.\n\nIn addition to the bus and cars, there are two traffic lights visible in the scene, one on the left side and another on the right side of the street. A person can also be seen standing near the right edge of the image, possibly waiting to cross the street or waiting for the bus."}, {"question_id": 847, "height": 480, "width": 640, "image": "000000296231.jpg", "category": "description", "question": "Describe the book in the following image in detail.", "dims": "color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [569.27, 363.83, 22.88, 64.18], "segmentation": {"size": [480, 640], "counts": "na[8\\1^=6N3N1O1O2N1O1O1O00A?C>I6J7K6L4N1N101O1O2M2000bVe0"}}, "object_label": "book", "attribute_label": ["color:black", "length:long", "material:paper/cardboard", "transparency:opaque", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "state, color, texture, material, pose, length", "answer": "The image features a large blue book, possibly a textbook, sitting on a table. The book is placed in the center of the scene, occupying a significant portion of the image. The table appears to be a dining table, and the book is the main focus of the scene."}, {"question_id": 848, "height": 334, "width": 500, "image": "000000312237.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [92.62, 222.05, 18.81, 20.03], "segmentation": {"size": [334, 500], "counts": "bWn0240S:OlE2U:4N1M3N2ID[F=k9O01O001O10O01O10O002N9CTen3"}}, "object_label": "boat", "attribute_label": ["color:green", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, length, color, state, pose", "answer": "The image features a large white boat with a blue sail, floating on the water. The boat is positioned in the middle of the scene, and the sail is prominently visible, extending from the top left to the center of the boat. The boat appears to be a sailboat, and it is the main focus of the image."}, {"question_id": 849, "height": 334, "width": 500, "image": "000000312237.jpg", "category": "description", "question": "Describe the umbrella in the following image in detail.", "dims": "color, material, pose, size, state, transparency", "region_anno": {"bbox": [424.42, 183.0, 58.23, 46.48], "segmentation": {"size": [334, 500], "counts": "d_Z41\\:2N2N2N5L0OL41O1oEGm993100O101N10O1000O010O01O1OSFFg9;XFGg9g0VF^O[9k0kFoNk8Q1TGoNn8k0=00BaFIc97_FFb95>004MO00000000001O00001O0O100O101O0O101O01O010O00O2O1M_[5"}}, "object_label": "umbrella", "attribute_label": ["color:blue", "color:yellow", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:open"], "control_dims": "state, size, color, transparency, material, pose", "answer": "The umbrella in the image is large and yellow, providing shade for a group of people sitting on the beach. It is positioned above a group of people, with some of them sitting underneath it. The umbrella is open and spans a significant portion of the scene, covering the people and their belongings, such as a handbag and a backpack. The beach setting and the presence of people enjoying their time under the umbrella create a relaxing and leisurely atmosphere."}, {"question_id": 850, "height": 403, "width": 640, "image": "000000345027.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [115.99, 335.23, 104.55, 51.76], "segmentation": {"size": [403, 640], "counts": "]\\^1Q1_;5E:N10000000O2[Od0D^DFc;9^DGb;O\\D111c;N\\D111c;O[D021c;0YD040c;0YD040c;0YD040c;0YD031c;0ZDO31c;1YDN41c;8]DHc;8]DHc;8^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9^DGb;9_DFa;:_DFa;:_DFa;:`DE`;<_DDa;>\\DCd;>[DBe;>\\DAd;?\\DAd;?\\DAd;>\\DCd;<]DDc;<]DDc;=]DBc;>\\DCd;=\\DCd;=\\DCd;=\\DDc;<]DDc;=]DBc;?\\DAd;?\\DAd;1[D52Jc;0]D32M`;1]D24M^;=bDC^;=aDD`;;`DE`;;`DEa;;^DEb;;^DEb;;^DEb;;^DEb;;_DDa;<_DDa;<^DEb;;^DEb;;_DD`;=`DC`;=`DC`;=_DD`;=`DCa;<_DDa;<_DDa;<_DDb;;^DEb;:_DFa;:_DF`;;`DE`;;`DE`;;`DF_;:aDF_;:aDE`;;`DDa;<_DDa;;`DE`;;`DE`;;]DHc;9[DKb;R1BO00O2N2O0000000000N3lN\\cT5"}}, "object_label": "bench", "attribute_label": ["color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The image features a wooden bench situated in a sandy area, possibly a beach or a park. The bench is positioned on a brick walkway, and it appears to be empty. The bench is located near a truck, which is parked in the background. There is also a bird perched on the bench, adding a touch of life to the scene."}, {"question_id": 851, "height": 403, "width": 640, "image": "000000345027.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, length, material, size, texture, transparency", "region_anno": {"bbox": [150.33, 288.74, 126.79, 74.26], "segmentation": {"size": [403, 640], "counts": "Ral18Z<2N2M2O1N2O1O1N2O1N2N2N2O1N2O1O1O1N2O1O1N2M3N1100001N1000000000O100000O1000000000000000000000000000000001O00000@lDAT;>nDAR;:SEFm:<REBQ;FlDa02IQ<0000000000002[DKh:S1M00000000O100O1O1O1O1O100000000000001O0000000O10O01O1O1N3M20000O0100000O1M3K5O10000000000004L3MO1O2O0J6M4M7Jjm^4"}}, "object_label": "truck", "attribute_label": ["color:black", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color, length, size, texture, transparency", "answer": "The image features a small truck parked on a sandy beach. The truck is positioned near a wooden bench, and it appears to be a flatbed truck. The truck is parked close to the water, possibly for a beach cleanup or other beach-related activities."}, {"question_id": 852, "height": 403, "width": 640, "image": "000000345027.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "length, material, size, texture, transparency", "region_anno": {"bbox": [207.79, 272.69, 60.4, 13.38], "segmentation": {"size": [403, 640], "counts": "bn`21a<2O000O1O1O100O2N1O1000000001O000000000L4O1000O10001O000O2O00000O1001O0000O10000000000000000000000000000000O100O010000001N2O1O0OS[a4"}}, "object_label": "boat", "attribute_label": ["length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "length, texture, size, transparency, material", "answer": "The image features a long, narrow boat with a white hull, which is floating on a body of water. The boat appears to be a small fishing boat, possibly used for recreational purposes or fishing. The boat is positioned in the middle of the scene, with the water surrounding it."}, {"question_id": 853, "height": 426, "width": 640, "image": "000000057027.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [180.79, 262.04, 182.7, 142.32], "segmentation": {"size": [426, 640], "counts": "P]Z23U=2N0M5L3N010OO0N22M31M0110fD1Z91cF5W9MiF6T9GoF;l8GVG;d8G\\G<`8EaG=]8CcG?Z8BeGa0Z8_OdGd0[8YO[GV1b8mNSG]1k8gNoF]1P9iNaFUOJX2c9[1O1O1O1O1O100O@gFQMX9m2oFoLo8o2WGnLi8P3i0N2M3O2M2O2O0O2OSF`MQ9c2eFjMV9[3I5L1N2O1O0O10000O2O00O10000O10O1000kNcG]M]8_2jG]MW8`2nG^MR8`2QH^MP8_2TH`Ml7^2WH`Mj7]2YHcMg7[2]HbMd7]2e100001O000000000000000O100000O1000000O1000000O101O000O100O100O10QGeMo6[2oHiMo6V2QIlMn6T2nHQNQ7T2gHPNX7T2bHnM_7S2\\HPNd7W2kGSNU8a30000000000000000001O00000_O]G[Lc8c3aG[L_8c3eGZL\\8d3g0M3M2O1013cF]Ll8S4M0MlKQGS4n8nKRGR4o8mKRGR4T9O00JoKSGQ4m8oKSGQ4m8oKTGP4S9nMnFLS93RGHf8\\NTGm1=_O^8eNVGk1c0YOX8kNUGl1h0TO]8k0iGoNm7VOVGl1Z1`N_7EVGn1[1[N_7GUGQ2\\1VN_7ITGS2]1SN_7KSGR2_1RN^7LSGS2_1PN^7MSGT2_1nM^7NQG01P2f:PNaEP2^:PNcEo1]:RNbEo1]:TN`El1`:TN\\EQ2c:PN]Eo1c:QN^EQ2_:PN`EQ2_:>OgM`Ei1`:PNaEK0U2^:PNcEI1W2\\:oMbEK2Z2Y:oMhEV2R:iMoEZ2n9fMRF_2j9_MYFb22XMT96dFi26SMV93cF[3[9fLdFZ3]9dLeFN9k2S9VMZGj0^Od0Z9]NaGc0M>P:SO^Fa0\\;GZYc3"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:young/baby", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, maturity, state, texture, pose, color", "answer": "The image features a baby elephant standing next to a larger elephant, likely its mother. The baby elephant is positioned in the foreground, while the larger elephant is in the background. The baby elephant appears to be walking on a dirt ground, possibly in a zoo enclosure. The scene captures the bond between the mother and baby elephant, as they share the same space and walk together."}, {"question_id": 854, "height": 426, "width": 640, "image": "000000057027.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, maturity, pose, size, state", "region_anno": {"bbox": [0.96, 174.23, 88.07, 201.99], "segmentation": {"size": [426, 640], "counts": "]5g3c900000000O1000000000000000000000000001O00000001O000O2O000010O00001000000O100UH]Lm5f3mI`LP6b3iIcLX6`3dHVL<a0P7k3`H`L`7f400O1O10O001O0000000O2N1M4N1M3M3L5L3N2L5N1N3M2N2N2M4M2O2WLnFR3X9]OUGfMl8U2_GZMm8c2n0M3O2N101O00001N1O1J7ROn0VO^lU7"}}, "object_label": "elephant", "attribute_label": ["color:gray", "maturity:young/baby", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry"], "control_dims": "maturity, pose", "answer": "The image features a baby elephant standing next to a larger elephant. The baby elephant is positioned on the left side of the scene, while the larger elephant is on the right side. The baby elephant appears to be walking in front of the larger elephant, creating a sense of depth in the scene. The two elephants are standing on a dirt road, which is the main focus of the image."}, {"question_id": 855, "height": 481, "width": 640, "image": "000000285788.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [406.56, 249.59, 44.78, 78.19], "segmentation": {"size": [481, 640], "counts": "o_n59f>9F4M3M3N1O101K7L2N2O1O1O1O1O3XCaNi;e1mC_NQ<Y2000O1TOiCnNW<l0R10O20O01O1O00O20O2RChNP<]1`CnN_<j1001_ObC\\N_<Y1RDaNo;V1[CjNc=S17O2N2N2M4M2M4N2O2LcQh2"}}, "object_label": "bird", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state", "answer": "The image features a large bird with a mix of black and white feathers, standing on a dirt ground. The bird appears to be a hybrid, with a combination of features from different species. It has a long neck and a tail, which are both visible in the scene. The bird is standing in a grassy area, possibly in a zoo enclosure, and seems to be looking down at the ground."}, {"question_id": 856, "height": 480, "width": 640, "image": "000000302165.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [310.6, 208.37, 209.97, 75.26], "segmentation": {"size": [480, 640], "counts": "kYl45j>2O2L201O0100O00000000O10000000000O1000001N100000001O0O1000000O1000001O0000000O11O0O2O1O1O2N2M3J7MD0iA0S>4;2O1O2N1O004fABj=?UBBk=>TBBl=a0PB@P>a0oA]OS>c05001fA]OU>g0000O1O12M1001O00oAXOj=h0VBXOj=h0VBXOk=g08O0O11O000001N100000000000000001O0O2O0N4L4N2M101O1O001O1O1O001O2N011N1O1O1O1O]OiB^OV=c0gB_OY=U1N2O010O1O1O002N001O00iNjBe0U=>kB`NU=_1kBaNU=_1kBbNU=e10O0HlBeNS=[1nBdNR=e110O001O2N0010KoBZNP=f1QCZNo<d1RC\\Nn<d1RC\\Nn<d1SC[Nm<d1TC[Nn<e1600O3N2N2N1O0O2N10001O000O2O001O10O010O010O00O2O001O1O00001N1N2L5M3M4JZBAT=<mBGT=3U_1KnaN000001O00Whc1"}}, "object_label": "cow", "attribute_label": ["color:black", "color:white", "maturity:adult/old/aged", "pose:horizontal/lying", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features a herd of cows in a barn, with some of them lying down and others standing. The cows are of various colors, including black and white, and are arranged in a row. They are all gathered together, occupying the majority of the space in the barn. The cows are positioned close to each other, creating a sense of unity and togetherness within the group."}, {"question_id": 857, "height": 480, "width": 640, "image": "000000306582.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [589.63, 257.47, 50.37, 66.78], "segmentation": {"size": [480, 640], "counts": "ZZe82k>9I6H4N1iA_OP>8YBHj=2\\BJh=1\\O2U16K2N4L4L5K4L3M1O100O00000000001O00000000000001O00000O100000001OO10001_BPOE7o<f1O0000O1DWCaNe4"}}, "object_label": "cow", "attribute_label": ["color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "size, state", "answer": "The image features a cow standing in a field, with its head and neck visible. The cow is positioned near a wooden post, and it appears to be looking at the camera. The cow is standing in a grassy area, which suggests a natural and open environment."}, {"question_id": 858, "height": 480, "width": 640, "image": "000000314034.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [14.0, 126.0, 611.4, 152.4], "segmentation": {"size": [480, 640], "counts": "T4o1j0Hf98hERN9f1o9b0oE_OQ:a0nEAR:>nEBR:>mEBT:>kECT:<nEDR:9PFHP:7QFIo96QFKo94RFLn93SFNl92TFNASNV:n1ZFO@TNU:m1[FNATNU:m1[FNAUNT:m1[FO_OVNU:k1\\FO_OVNU:j1^FO]OWNU:j1^FN_OVNT:l1]FN_OVNT:l1]FN^OWNU:k1\\FO_OVNU:k1\\FdN^Of01kNU:k1\\F_NDj0V:h0VF]NFj0T:i0VF]NFj0T:h0WF]NGj0S:h0UF_NGj0T:g0UF_NGk0S:f0VF^NGm0T:d0VF]NGo0IjNR:j1^F[NIQ1FkNS:i1^FYNKT1DiNS:i1UG^OR9b0nF^OQ9c0oF]OhNiNQ:k1WG\\OhNiNQ:k1WG[OiNjNQ:j1VG\\OiNjNQ:j1VG\\OiNjNQ:j1VG\\OiNjNP:k1WG[OiNjNQ:2jEc1]1@hNkNX:c1PGBhNkNX:c1PGBX9>iFAW9`0hF@hNlNU:g1TG[OT9g0lFXOT9i0kFVOV9k0iFUOW9W1]FiNc9X1[FiNe9W1ZFiNg9W1VFlNj9T1VFlNj9T1VFlNi9U1WFkNi9U1VFmN\\OjNU:Y2_FmN[OkNU:Y2`FlN[OkNU:Y2aFkNg9U1YFkNg9U1YFkNg9T1ZFlNf9T1ZFmNe9S1\\FlNd9T1\\FlNc9U1]FkNc9U1]FkNd9T1[FmNe9S1ZFnNf9R1ZFnNg9P1ZFoNg9Q1XFPOi9o0WFQOi9n0WFSOh9n0YFQOg9o0[FoNe9Q1\\FnNd9R1]FmNc9S1^FlNb9T1^FlNb9T1_FkNa9U1`FjN`9W1_FiNa9W1_FiNa9W1`FhN`9Z1`FcNa9_1^F`Nb9Q2mEoMT:U2gEkMY:V2fEjMY:`3O000OnK^Eh3b:XL^Eh3c::0gM]E5c:nM`El3`:SLaEm3_:SLbEl3]:ULcEk3[:VLfEP22ZOZ:eNcES20YO^:cNaEU21XO^:dN`ES23YO\\:fN`Eo16[OX:P1jEPOV:n0lEROS:l0QFSOo9k0SFUOm9j0TFVOk9j0VFVOh9k0YFUOg9j0YFWOg9h0ZFXOf9g0[FYOe9g0aFSO_9lNdEh1m0\\O^9lNgEf1k0_O_9iNgEh1k0^O^9iNhEi1j0^Oh9b0XF]Oi9b0YF]Oh9b0XF^Oh9b0XF^Oh9b0XF^Oh9b0XF^Oh9b0XF^Oh9b0WF_Oh9b0YF]Og9c0YFhNTOKc:]1YFfNXOK_:_1YFdN[OL[:`1[FaN]OOT:d1_FZN@2h9FgES2Q1QND6d9m1hFlME7c9m1iFjME9b9n1hFhMG9b9n1hFiMF9b9n1iFgME<c9l1aGUN_8k1`GVN_8j1bGVN_8i1`GXN`8h1_GYNa8f1^G\\Nb8e1]G[Nc8e1]G[Nc8e1\\G\\Nd8d1[G]Ne8c1[G]Ne8c1[G]Nd8e1[G[Nf8d1ZG\\Ng8c1bGTN_8l1aGSN_8m1`GTN`8l1`GTN`8l1`GTN_8m1aGSN]8o1bGRNb8j1^GWNb8h1[G[Nd8f1[G[Ne8e1YG]Nf8d1ZGZNi8e1XGZNh8f1ZGXNf8h1]GTNVNFZ:V2eGoMQNKZ:V2fGmMQNMU:1iEU2R2lMPNNT:[2RHfMn7Z2lGeMRN0R:[2lGgMPNNT:[2kGiMPNMS:[2^GgMfN2HMT:9kEd1b1fN^N]OV:Y2\\GZN^N]OW:X2[GZN`N]OV:X2[GZN_N^OV:X2[GZN^N_OW:W2[G[N]N^OW:X2\\GZN]N^OW:X2\\GZN]N^OV:Y2]GYN]N^OW:X2\\GZN]N]OX:Z2ZGYN_N\\OW:Z2[GZN^N\\OW:Z2\\GXN^N^OV:Z2\\GWN_N_OU:Z2\\GWN^NAU:X2\\G^Nd8c1[G]Ne8c1[G]Ne8c1ZG^Ng8a1XG_Ni8a1WG_Ni8a1VGaNi8_1WGaNi8_1VGbNj8^1WGaNi8_1YG_Ng8b1YG]Ng8d1ZGYNg8h1[GjM]N1Y:X2iEaMb16e8`2\\G_Mc8b2]G\\Md8d2]G[Mc8e2^GZMa8g2^GZMb8e2^G\\Ma8f2_GYMa8h2_GWMa8j2^GVMb8i2^GYMb8e2XGZMbN1V:d2VG_McNMW:b2cFVNVOWOY:a2`FZNWOUOY:a2`FaN_9^1cFaN]9_1cFaN]9^1cF]NUOSOY:`2bF]NWOQOW:a2cF`NTOoNY:a2cFcN]9]1cFcN]9\\1dFaNSOoNY:`2dFaNROPOZ:^2eFfNZ9Y1gFgNY9X1iFgNW9W1lFdNkNSOZ:W2mFdNkNSOX:Z2oFbNhNTOY:V2SGfNcNUOZ:T2VGhNj8V1ZGeN\\NYOY:Q2_GdNXN[OZ:o1aGhN^8X1cGgN]8X1fGaNRNBX:l1mG[NX8f1a2O1O10001OO10000000000000O1000001O00O100000000000bNoBm0Q=ROQCm0W2kNW88bEm0m1WOQN@Z:;iEn0l1[O[8GiEn0m1ZOZ8GjEo0m1YOY8HjEo0P2WOU8JkEo0R2UOS8LkEo0^2hNh7:hEP1o<`001O1O3M1O1O00O1010O001O0O100O2OO2O0002O4XCTNQ<b2L2NO2N1O1N2O1O1O1O2O0O10VE]MX9b2gF_MZ9_2gF`M[9_2c1O1000O011O000000cMeCU2[<800TEcMT9_2f11N2O1O1O10O01O001O01O00001OQE^MlNK_:f2cFbMmNI_:e2bFiM`9V2`FjM`9V2`FjM`9V2`FiM`9X2`FhM`9Y2_FhM`9X2`FhM`9X2`FhM`9X2`FhM`9W2bFgM_9Y2aFgM_9Y2aFfM`9Z2aFeM_9[2bFdM^9\\2cFcM\\9^2eFaM[9^2fFbMZ9^2fFcMY9]2hFbMX9^2hFaMY9_2gFaMZ9^2fFaM[9_2dFbM[9_2eFaM\\9^2eF_M^9_2b100000001OO2O000L401O1O1O1O01O000O10000O100YMnC`2S<]MPDa2X<00000000O10O2N1O2M3N1VEWM]9j2UFfMh9\\2SFiMk9X2TFhMl9Y2PFjMo9V2UFfMl9Y2UFgMk9X2WFfMj9Y2XFfMh9Y2[FeMf9Y2]FcMe9\\2`100O001O100O1]MhC]2Y<cMgC\\2Z<41O1O100O1O1M3O]EgMa8X2aGgM_8W2V2O1M3O2N1O10SEVNd8i1WGaNd8_1YGeNh8Z1[FSNLe0i9X1ZFTNKf0k9U1[FUNJf0k9U1[FUNIf0m9\\O]Ec1o0ZNGg0m9T1TGlNl8T1TGlNm8S1TGlNl8T1ZFWNIe0m9T1ZFWNIe0m9S1[FXNHe0l9T1]FWNFd0n9T1_FWNBe0n9U1eFWNWOd0T:U1bF\\NWO`0W:T1aF^NWO>X:T1`FaNVO;Z:T1YFWNWO>28^:S1XFJh96XFJh95YFKg95YFKh94YFKg96YFIg97ZFHf97[FIe97\\FHd98\\FGd9:[FGe99ZFHf98YFIg98WFHj98VFHj98VFHj97XFHh98YFGg99ZFFf9:ZFFf9:ZFGe99[FGe99[FHd98\\FHd98\\FHd98]FGc9:^FDb9<^FfNSO8_:S1\\F^N^O>V:T1^FXN@d0R:T1UGkNj8W1UGiNl8X1RGhNn8Y1QGgNo8a1aERNi0=g9U2SFkMm9V2RFjMn9V2RFjMn9V2QFkMo9V2QFiMo9W2QFiMo9W2RFhMn9W2TFhMl9X2UFgMk9Y2VFfMj9Y2XFeMi9[2XFdMh9[2`FZMd9f2]FVMf9i2Y100O10006J0000000O11O0O1O10O02mD`Md9`2[FdMb9]2XFiMh9V2XFjMh9V2XFjMh9V2YFiMg9W2YFiMg9W2YFiMg9W2YFiMg9W2YFiMf9X2ZFhMe9Y2[FgMd9Z2]FeMc9[2]FeMc9[2^FdMb9\\2^FdMb9\\2^FdMb9\\2^FdMa9]2^FdMa9]2_FcMa9]2_FdMa9Z2`FfM`9Z2`FfM`9Z2`FeM`9\\2`FdM`9\\2bF`M`9`2cFWMc9i2[1N1DkCmMV<R2kCmMV<S2kCkMU<W2jChMV<[2hCdMX<]2iCaMW<_2jC`MV<a250O2N1O2M3N1O]1cN1O0O10nK\\Eh3d:YL[Eg3e::00000O11O00000MgK_EY4d:0000001O000001O0mM\\EHf:7]EFd::]EDd:;_ECa:=`EB`:>`E\\OGdNi:P2aEZOJcNe:S2aE[OJaNe:T2`E]Oe:b0[E@d:`0YECg:<XEGg:1aEO_:JUE_N`0e1[:JnE6P:JZFMe93]FMa92`FN`91bFN]93dFL[95eFJ\\96dFJ\\96dFJ\\96dFCb9>]F_Og9b0XF\\Oj9c0WF]Oi9b0WF^Ok9^OoDa0V1IS:EhDa0V1IT:DhDa0U1JT:]ObD26g0T1HV:^ObD15i0S1FY:_O_D07k0Q1Ek:;UECn:<RECo:>QE@Q;`0oD^OS;a0nD]OT;NaC=Z1DW;KdC?U1Ea;:aDDa;:aDD`;9f1OjJ"}}, "object_label": "cow", "attribute_label": ["color:brown", "color:white", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity, state, color, size", "answer": "The cow in the image is brown and white, standing in a grassy field near a body of water. It is grazing on the grass and appears to be enjoying its time in the field. The cow is surrounded by other cows, creating a herd of cattle in the area. The scene captures the peaceful and natural environment where the cows are grazing and resting."}, {"question_id": 859, "height": 505, "width": 640, "image": "000000329447.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, maturity, pose, size, state, texture", "region_anno": {"bbox": [3.41, 134.21, 76.21, 315.06], "segmentation": {"size": [505, 640], "counts": "X4_7Y810N2N2N2L4L4J6K5M3nNWGRKk8l4^GjJe8T5Q1N2N2O1N2O1N2N2O1N2N2N2O0O2O1O1O100O100O10000O2O00000O101OhIcKT1^4fNgK[1Z4_NkK`1\\4SNjKm1]4dMkK]2_4oI]KZ27g3n5`KUJa4U6QKmIP5X6eJnI\\5Z6oIRJQ6k71O1O001O100N2O1O2O0N2N3YNSJ\\IP6X6P2I6K6J5G:E;oN\\F_Ko9X4[FbKj9Y4o0I<VLiD`2`<D:G:I?_O7E;C`0C_nb8"}}, "object_label": "cow", "attribute_label": ["color:gray", "maturity:adult/old/aged", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state", "answer": "The image features a cow standing in a grassy field, with its back facing the camera. The cow appears to be grazing on the grass, and it is positioned near a fence. The cow is the main focus of the scene, and it is the only animal visible in the image."}, {"question_id": 860, "height": 428, "width": 640, "image": "000000078266.jpg", "category": "description", "question": "Describe the refrigerator in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, state, transparency", "region_anno": {"bbox": [55.78, 96.24, 93.3, 108.69], "segmentation": {"size": [428, 640], "counts": "mZh0e0f<k0UOo0WDbMh:l2E1gEXMl9h2SFYMm9g2SFYMm9g2SFYMm9f2TFZMl9f2TFZMl9f2TFZMl9f2TFZMl9f2UFYMk9g2VFWMk9i2UFWMk9Y2nEQN8Ek9m1oEYN0L015Nk9l1PFXN164Fl9j1PFYN173Fl9j1PFYN083Fm9i1oEYN282Fm9i1oEZN085Cm9l1lEmN_:o110001L3I\\EbMi:a2O5J101O00hN_EEa:;bEB^:>bEB^:>bEB_:=aEC_:e1000001O0001O00000000001O00000000000001O0000O2J500O100000001O000000000000000010O000001O1Oj0UObP`6"}}, "object_label": "refrigerator", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed"], "control_dims": "pose, pattern", "answer": "The image features a large, industrial-sized refrigerator with a metal door. The refrigerator is located in a room with a white wall, and it appears to be empty."}, {"question_id": 861, "height": 428, "width": 640, "image": "000000078266.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "color, length, pattern, pose", "region_anno": {"bbox": [15.4, 194.19, 156.13, 34.49], "segmentation": {"size": [428, 640], "counts": "el66U=101O000000001O0000000O1000001O000000000000001N1000000000001O0000000000000O1O10CUC:j<EXC:h<FYC9g<GYC9g<GYC9f<G[C9e<H[C7e<I[C7e<I[C7f<G[C:d<F\\C:k<00000000001O00000001O0000000010O0O100000000\\OEXD;f;HXD8h;HXD8h;GZD8f;G[D9e;G[D9e;HYD9g;GYD9f;HZD8f;HUD=k;DSD=m;CRD>n;CQD=o;BRD>n;BRD>n;BRD>n;CRD<n;EQD:P<EQD;o;EQD;o;EQD;o;HnC8R<ImC7S<JlC5U<KkC5U<KkC5U<LjC4V<NfC4Z<?00001O000O10000000000O100DdCH\\<7fCHZ<8fCHZ<6hCJX<6hCJX<5iCJX<5hCLX<4hCLX<3iCMW<3iCMW<4hCLY<4eCM[<4cCM]<`01000000000000O1000000000000O10001O0000000O1K5O101IUCJl<1UCMSeT6"}}, "object_label": "sink", "attribute_label": ["color:tan", "length:long", "pattern:plain", "pose:horizontal/lying"], "control_dims": "pattern", "answer": "The sink in the image is a large, white, and clean sink. It is situated in a bathroom, and there is a mirror above it. The sink is surrounded by a wooden countertop, which adds a touch of warmth to the bathroom's design."}, {"question_id": 862, "height": 428, "width": 640, "image": "000000078266.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material, state, transparency", "region_anno": {"bbox": [374.58, 211.16, 46.05, 15.15], "segmentation": {"size": [428, 640], "counts": "nXk43X=2O0N2O001000O10O10002N1O001N100000001O000001O000001O00000000000000000000O100O1N3N1N2O1O10000OXUl2"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:tan", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "state:empty"], "control_dims": "color, material, cleanliness, state, transparency", "answer": "The image features a large, golden bowl placed on a table. The bowl is made of metal and has a shiny, reflective surface. It appears to be a decorative piece, possibly used for serving food or as a centerpiece for a table setting. The bowl is positioned in the center of the table, drawing attention to its elegant design and craftsmanship."}, {"question_id": 863, "height": 480, "width": 640, "image": "000000030494.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, pose, size, state, texture", "region_anno": {"bbox": [106.67, 29.09, 179.39, 192.97], "segmentation": {"size": [480, 640], "counts": "WWb19^>>H5L4J6L3N3L3N3L3M5M1N2N3L3N2O1NQO_CB_<:hCFU<6RDIED_;a0REI\\OL^;9ZEMQO1a;1aEi0[:WOhEj0T:TOQFl0VObNQ:a0kFm0ROgNo9;QGn0mNkNQ:3UGT1gNjNV:MWGY1aNlNJ@^<f1dCQOY<m1O0O1O0O2O1N[OUDZNg;f1\\DZNa;f1aD\\N\\;c1eD`NW;a1gDdNV;]1gDfNW;\\1gDfNW;\\1fDhNX;c2M2M2O1OOPEYLh:S3WE[MOFh:k2aE\\MFJh:h2hEZM@Og:e2mEZM\\O1f:e2PFYMZO2f:c2SFYMXO3f:c2TFZMVO2e:d2VFZMVO0e:e2WF[MQ:d2PF\\MP:c2RF\\Mn9c2SF[Mo9c2X100N2O1N2O1O1O1O1M3MnNmM]EQ2e:PNZEo1g:QNYEo1g:QNYEo1g:QNYEP2f:PNZEP2f:PNZEP2h:oMWER2h:nMYEQ2g:PNXEP2i:nMXER2h:nMYEQ2k;1O0001O0000010O00001O01O010O1O2N1O2O0O2N3M2N2N2O1N2N1O2N1O1OVOoCfNQ<Y1PDgNo;Y1TDeNk;\\1VDbNj;`1VD^Nj;c1WD\\Nh;e1YDYNg;g1ZDWNh;i1YDUNg;k1[DTNe;k1]DSNd;m1\\DRNd;o1\\DPNe;P2[DoMe;R2ZDmMg;T2YDjMh;W2`01O001O00\\O\\CmNc<m0dCSO[<i0jCVOW<h0kCXOT<g0nCYOR<e0PDZOP<e0RD[Oo;b0SD]On;c0\\CnNc0?Q<b0[CQOd0=Q<f0oCYOR<f0oCZOP<f0[CmNc0=Q<g0RDYOm;g0TDYOk;f0WDZOd;i0^DWOa;i0`DVO_;k0bDTO_;k0aDUO`;k0`DSOc;l0]DSOe;n0YDPOj;U1QDiNQ<X1lChNU<Y1jCfN\\<U1eChN]<W1h0M2oNYB1N=k=A[BNJ?n=BXBOJ?o=Am00P`Z5"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:tan", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "pose, size, color, state", "answer": "The image features a black and brown dog standing on a dirt ground, possibly in a park or a forest. The dog appears to be playing with a frisbee, as it is holding the frisbee in its mouth. The dog is positioned in the center of the scene, with the frisbee close to its mouth. The dog's mouth is open, indicating that it is either about to catch the frisbee or has just caught it. The scene captures the dog's playful and energetic nature."}, {"question_id": 864, "height": 457, "width": 640, "image": "000000033759.jpg", "category": "description", "question": "Describe the sports ball in the following image in detail.", "dims": "color, length, material, pattern, size, texture, transparency", "region_anno": {"bbox": [596.33, 129.28, 27.43, 25.36], "segmentation": {"size": [457, 640], "counts": "^P[8;m=2N3M2N2O0O2O000O10000000000000O100O2O1N1O2N3M2Nb^7"}}, "object_label": "sports ball", "attribute_label": ["color:white", "length:short", "material:leather", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "pattern, transparency, material, texture, length, size, color", "answer": "The sports ball in the image is a baseball, which is captured in a close-up view. The baseball is round and has a golden color, giving it a shiny appearance. It is positioned in the center of the image, surrounded by a chain-link fence."}, {"question_id": 865, "height": 375, "width": 500, "image": "000000105912.jpg", "category": "description", "question": "Describe the fire hydrant in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, transparency", "region_anno": {"bbox": [109.66, 97.15, 99.45, 224.37], "segmentation": {"size": [375, 500], "counts": "XnX18^;2N2O1N1O2BC^E?l7A]Jl0a5YOZJj0Z3RO_L83h0\\3TO^L63h0_3SO\\L64h0`3VOWL4KT1l3kNVL8oNYOZO[2a5TNQLb3n3`L^KS4b4mKmJd4R5]KdJn4[5RKcJP5]5e0O10000O101N1O011O0O10000O100O100O1000000O10000O1000000O1M3J6000000000000000000001O9G001O0O2O001O001O001N101O001O0O2O001N101mM]KPMd4]2PLoL`NOa5b2aLZMRN3^5`2eLWMPN8]5`2RM_Mn28\\JKO5a0LX2Jn28^JB;636W2Im2:RLJT1Il2<QLHU78oHBT7=S2N3N1M4N2N3LV^Z3"}}, "object_label": "fire hydrant", "attribute_label": ["cleanliness:clean/neat", "color:red", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge"], "control_dims": "color, pose, pattern, material", "answer": "The image features a red fire hydrant sitting on a brick sidewalk. The hydrant is positioned near a street, and there is a truck parked in the background. The fire hydrant is located in a city setting, and it appears to be in good condition."}, {"question_id": 866, "height": 566, "width": 640, "image": "000000338219.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "cleanliness, color, length, material, pose, state, texture, transparency", "region_anno": {"bbox": [354.39, 151.06, 276.62, 179.74], "segmentation": {"size": [566, 640], "counts": "hXX61ca03a_OMY?4S11O2O1Y_OHm?:Q@Hn?8R@HP`06Q@IM0b?2UA0k>Oc@1E1``04^_OLf`00Z_O0T`0NQ@2J0T`00R@0JOT`02Q@4EKZ`09j_OMIK]`08X@El?4a_OJn`00S_O131LNRa02Q_O6n`0KP_O70Gi`02X_O5OLh`0Mg_O5W`0Jj_O8CMT`0KY@8B0S`0H[@8^O5V`0DX@0A71J06l?HV@001;<BC83d?OU@O21O043M0W`0Mg_OO21M440N1V`0Ki_OO2:OL008JG0f?1Z@O2P1U`0QOi_OO200j0U`0WOj_ON8k0m?WOk_ON8Q1h?oN]@R1b?nN]@T1a?mN_@S1a?mN\\@W1c?iN]@X1c?gN]@Z1a?hN]@Z1a?gN_@Z1`?fN_@\\1`?cNa@^1^?aNc@a1[?^Nf@c1f?2N1O001O1O4L2K3L4M3N2O2N1O1O1O1O2O0O1000000O100O101NTOSAQOm>l100O101O1N1000001O0O10FYAeMg>[2YAeMg>[2YA`M00f>U2ZASN4Hb>d2]A[Mc>e2]A[Mc>e2]A[Mc>e2]A[Mc>S2]AXNOFd>S2]AWNNEf>W2ZATNOEf>T2_AUNNFc>U2^AUNh>l1XARNj>n1VARNj>P2TAPNl>Q2RAnMo>U2TAdM]>0mA]2a>cMWA^2g>cMYA]20bM_>2_A^2h>cMVA`2i>60YMWAb2i>\\MXAf27ZMX>i2eAWMZ>n2bAQM_>o240000O1E^A_Me>X2WAlMS?[2001O0010O0001Kk@gMU?Y2XAfM]>j1XA`N5Lc>S2]AlMd>i1XAWN0LM3m>j1UAWN03l>g1TAaNm>_1SA_No>b1RASN1Mo>P2RAPNV?P281O001O1`AmMZ=U2[BYN\\=l1_B\\N]=_1SBmM<k0^=X1XBkM9o0_=V1WBjM:Q1^=Y1cBhN[=Y1aBkN]=W1bBlN\\=T1dBmN\\=J]B14;^=^OgB2Id0^=YOmBj1R=UNQCF_Oa1^=iNUCD]Od1^=dNbBYOd0>]Oe1\\=dNdBXOf0d2e<SNcCj1]<UNdCk1[<UNiCh1V<XNhBZOo0^2W<]NoC^1n;eNSDZ1k;hNmBQOU1W2n;jNSDU1m;kNTDU1m;iNTDV1m;iNTDW1l;iNWCVO:P2_<jNZCSO8R2T<lM^CS12nN=S2Q<mM_CR1P1Q1_;oM`Cl05ROI8<g1V<SN_Cm04TOI:=`1V<UN`Cm03WOH7a0^1T<VNbCn0KQOO6O7b0]1S<WNdCk0KSOM7O;?X1V<XNhCg0L]OG=c0R1R<]NmCb0HAF?g0m0m;bNnC`0GCGa0e0i0n;dNoC?GBHc0f0e0l;gNPD?EBHh0g0<k;lNRD`0A^OKn0OPOe0W1l;nNUD?\\O\\OO10S1g0Oi;ROVD>[O\\O5U1a0Oi;ROVD>[O\\O6T1a00g;ROWDc0_O?b0Jh;TOlCJLj0N?a0Jh;SOlCLLi0N?a0Ii;SOlCMKh0O`0?Jk;POlCNKk0L>a0Il;QOjCOLf0KVO2]1>Io;mNkC2If0NUO0_13cNOV1\\<kNkC3Hd00VOOi1OAa<gNmCOFj02]2[<hLUDk0@P1K_OX=BhBTO1X3X=cMfBVO3V3W=dMfBVO3V3W=dMfBVO3W3V=fMjBZ2V=cMgBVO2X3W=bMhBUO1Y3W=bMkB_2V=`MjB`2V=_MkBb2T=^MmBa2S=_MiBWO0Z3W=[MgB\\O200Y3W=\\MPCd2P=\\MPCd2P=[MQCe2P=YMQCg2P=TMUCk2k<SMWCm2i<kL_CU3b<hL`CY3_=O000000000O100000001O\\NiLkDU3U;kLkDU3k<01O1O000O10000O2O00000O100O10LRM`An2`>RM`Am2d>0O101OUM]Ae2b>7L4003VM^A\\2c>ZM`A30`2h>]MZAa2g>_MZA_2g>bMZA[2g>eMYAZ2g>gMXAZ2i>dMXAZ2T?N1O000O4UNb@F1\\1i?cN^@Z1R`0L4L4K5IKZOo01V]1"}}, "object_label": "motorcycle", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:off", "texture:smooth/sleek"], "control_dims": "pose, material, texture, transparency, color, state, cleanliness, length", "answer": "The image features a row of motorcycles parked in a grassy area. There are three motorcycles in total, with one being a BMW motorcycle. The BMW motorcycle is positioned in the middle of the row, while the other two motorcycles are on either side of it. The motorcycles are parked in a way that they are all visible, showcasing their different styles and designs."}, {"question_id": 867, "height": 500, "width": 394, "image": "000000249025.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "material, pose, size, state, texture, transparency", "region_anno": {"bbox": [107.87, 196.63, 191.01, 247.19], "segmentation": {"size": [500, 394], "counts": "\\cd1`0o>;F8I7J3M4L4L5L2M4L3M3N3M2N2N3M2N2N2N2N2O1N2N2N2O001N2O1O1O1N2O1N1O2N1O2]LbLmJ`3Q5aLnJa3Q5_LoJa3Q5bLjJa3R5[LgG4U3b3P5^LkG0T3d3o4fLlGAR3j3Q5gLnJZ3R5[LnGK14m2g3R5[LPHI36h2g3U5XLPHL46g2e3U5YLPHL49d2c3V5_LUHMb2g3Y5\\LUHN`2g3Z5\\LVHN_2g3Z5[LTHDO<a2e3]5oLbJP3^5VM\\Jk2d5^LSH3Y2]OgMo3m7bLRH3Y2\\OhMo3l7eLSHMZ2_OgMo3l7UMSHmN2OO11OP13EMZOo3l7\\MTHZO3]O43;K_O0Oo3l7\\NZHkM`0JZOP4k7dLYH\\OL20V17mNb0k3R7dL]H\\OJW15oNa0j3S7eLVH\\O8T1MROb0i3S7cLkH>^OVOd0i3S7\\LSIGQOi03\\Of0h3S7\\LTINPO:3Df0h3S7\\LTId0SOXO?H@0OP4k7\\LWHDi00UO50>3Eb0H[OP4k7[LXHF02b01[O1O57Lc0j1[OIg7bN`HG;1ZO2O57Lc0i1\\OJf7aN]I0lNK21c0h1]OKe7aNeIHdN322b0f1_OLd7\\NjIMaN104b0c1CN`7]NkIKbN3M4c0c1CO_7\\NUHKP24UN3?I_Oi1:0^7\\NbJ1]Nb1C2^7ZN\\HN7NT17XO`1D3]7ZNZH0m13hN`1C4^7YNYH2c0Ja07B_1D5]7VN[H79IE0M0S15F]1H7`7bN[HGD4R1OF]1K6_7`N]H3GGINd055]1K6e7YNYH9_OG06b0N6]1J7[7WN[H0H0<n03WO9]1G:^7XNWHLK4:LFn0>VO;^1F;^7XNZH07JCl0<YO=]1D=_7WNZHO<j0FVOa0]1D=^7[NYHK=m0DSOc0^1_O]NKP2h7\\NVHEO11Na0W1_OmNi0_1^O_NHo1k7bNWH]Oc0T1\\OPOi0_1^Ob0c7]NQIa0TOROj0]1^Oc0c7^NYH@2O3W1a09^Oc0c7_NWHK7i0a0:^Oc0c7^NYHBLM019V1`09^Od0d7_NWH@NM028U1<gN_Oc12d0e7VO[HK=lN_O`10f0i7VOXHH`0P3X7YMWH[O0\\Ob0P4W7WNZHhMNJ:X4^7VN[HnM2n3d7TN[HQNLl3i7SN[HSNJj3k7PNVHdM5P5f7[M]He2c7iLTHgN8;JW3j7gMTHgN7;JY3k7dMVHhN4;MWOOj3j7dMWHbN2=O<>j2Y7jMYHdN29Oa0>d2Y7UMTHN7@15M:1_O5NKa3f7UMTHM8]OI177O4LDj0b3o6bMWImNXO2l0`3e6SMUHAOJU1OVO3k0a3f6RMUH]OONe13@a3g6QMWHZOf14\\Oa3g6PMSJ_OVOa3h6oLSH\\OP10K4:a3h6nLSH^OP1OK4:a3h6nLSH_Ol11[Oa3f6oLSH@X3`3e4VM[Ki2e4XMnIWO^Oa3d6XMmIYO[Ob3h6UMlIZO[Ob3i6TMlIZO[Ob3i6TMmIYOZOc3i6oLSH^Oi10[Od3i6nLTH]Of1N[N1j0OYOg3i7nLSH]Oi20YMe3k7nLRH^Oj2OYMe3k7SMlJYOWMe3m7RMlJYOVMf3n7lLRH]Ok2l3S5gLQKX3P5iLoJ]ORMe3o7nLnJ^OSMd3o7mLoJ_ORMd3o7kLQKZ3P5eLQK[3o4cLSK]3m4bLTK]3n4aLSK_3m4_LUKa3k4^LVKa3k4_LUK`3l4^LVKb3j4\\LXKc3j4[LWKd3k4YLXKf3[8O2N2N3N2M101N1O2N1O2N2N2N2O1N2N1O2M3N1O3M2N3M2M3N2N3M3M2M3N3M3K4N3L3N3M4K4L4J8E[P_1"}}, "object_label": "vase", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "state, material", "answer": "The image features a clear glass vase filled with water and a single yellow flower. The vase is placed on a table, and the flower is positioned in the center of the vase, creating a visually appealing arrangement. The vase appears to be a small, elegant glass container that holds the flower beautifully."}, {"question_id": 868, "height": 480, "width": 640, "image": "000000430073.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, material, pattern, state, transparency", "region_anno": {"bbox": [290.34, 196.43, 111.94, 55.45], "segmentation": {"size": [480, 640], "counts": "XTX43l>100O100O10O0100000O100O10000O2O00Qd5OP\\J001O001O1O1O1O1O1O0000000000000000O10000O1000000O2N1Okm00ZcN0S1O`<4_CNb<0^C0b<0^C0b<0^C0b<0_CNb<2^CNc<2\\COc<1]C0c<OW101OQn02mQO2N1O1O001O000000000000000000000000010O0000001O0000000cANl=2TBO33P=NmBO08Q=JfB75OX=n04L4N2O2N1O1Kk[_3"}}, "object_label": "dining table", "attribute_label": ["color:blue", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "state:empty"], "control_dims": "transparency", "answer": "The dining table in the image is red and blue, with a blue top. It is placed on a concrete surface, and there is a cow standing next to it. The cow is leaning against the table, and it appears to be rubbing its head on the table. The table is surrounded by chairs, with one chair on the left side and another on the right side. The scene creates an interesting and unexpected juxtaposition between the cow and the dining table."}, {"question_id": 869, "height": 480, "width": 640, "image": "000000430073.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, pattern, state, transparency", "region_anno": {"bbox": [148.59, 134.82, 10.53, 21.25], "segmentation": {"size": [480, 640], "counts": "boU28f>2G9101N2N2N4D[A5i>OZiQ7"}}, "object_label": "handbag", "attribute_label": ["color:white", "transparency:opaque", "pattern:plain", "state:closed"], "control_dims": "state, pattern, color, transparency", "answer": "The handbag in the image is white and has a strap. It is being carried by a person, possibly a woman, who is wearing a white shirt. The handbag is positioned in front of the person, and it appears to be a casual, everyday accessory."}, {"question_id": 870, "height": 480, "width": 640, "image": "000000039405.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "color, pattern, pose, state, transparency", "region_anno": {"bbox": [180.62, 327.44, 28.49, 42.72], "segmentation": {"size": [480, 640], "counts": "mhc21k>:I2N4D:M6KO2OO2O0100000000000000O1002N2N1O1O1OF:000010=CKjUZ6"}}, "object_label": "chair", "attribute_label": ["color:black", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty"], "control_dims": "state, color, pose, pattern", "answer": "The image features a chair with a pink seat and a brown back. The chair is placed on a grassy field, and it appears to be empty. The chair is positioned in the center of the scene, with the grass surrounding it."}, {"question_id": 871, "height": 427, "width": 640, "image": "000000217285.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, pose, state, texture, transparency", "region_anno": {"bbox": [560.02, 86.96, 36.26, 17.75], "segmentation": {"size": [427, 640], "counts": "S^Z78n<6OO10000001O0000000000000000001O0000000000001O00000000O101O0N2I8M\\Xb0"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:green", "transparency:opaque", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "texture, cleanliness, state", "answer": "The image features a close-up view of a blue chair, likely in a stadium or sports venue. The chair is empty and appears to be made of plastic. The chair is situated in the middle of the scene, with the focus on its backrest. The chair's design and color suggest that it is part of a stadium seating arrangement, providing a comfortable and convenient seating option for spectators."}, {"question_id": 872, "height": 427, "width": 640, "image": "000000217285.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, pattern, pose, state, transparency", "region_anno": {"bbox": [626.03, 90.42, 13.97, 18.79], "segmentation": {"size": [427, 640], "counts": "inU8=m<2N2O00000O10000000000VM"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:green", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:empty"], "control_dims": "color, pose", "answer": "The image features a blue chair with a silver metal frame. The chair is positioned in the foreground, and its back is facing the camera. The chair appears to be empty and is situated in a room with a blue background."}, {"question_id": 873, "height": 640, "width": 580, "image": "000000056127.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "cleanliness, color, material, state, texture, transparency", "region_anno": {"bbox": [331.67, 410.83, 248.33, 170.0], "segmentation": {"size": [640, 580], "counts": "cPe6>Wc0DP]O?`b0h0]MoNY@IQ1g1f>\\Nn_OM<0h0o1d?QNX_O83K0W2f`0RNY_OW2h`0hMW_OZ2h`0fMX_OZ2h`0fMX_O[2f`0fMZ_OY2g`0hMW_OY2j`0?O1OO10HlLd_OT3n?lLS@5Oo2m?PMn_O54l2m?[MS@d2n?nLn_O95JKf2R`0WMn_O95JKf2R`0WMn_O95JKf2R`0eMS@EKf2R`0WMn_O86KJg2Q`0VMo_O86j2k?nLP@N028R3h?nLP@NO39Q3i?mLQ@36P3i?mLR@44OHh2R`0TMT@51OIg2S`0UMS@51OIg2S`0UMQ@73MIh2R`0UMQ@64MIh2R`0UMQ@64MIh2R`0UMR@53m2k?nLS@42n2k?mLS@63l2j?nLR@75j2i?oLR@74k2j?oLo_O96h2j?PMP@85i2k?oLo_O96h2k?]MU@c2k?]MV@b2j?PMo_O97g2j?PMo_O97g2k?oLo_O96i2j?nLQ@86i2i?^MV@b2j?^MV@b2i?`MU@CLe2o?hMV@BKf2o?hMV@BKf2o?hMV@BKg2n?gMW@CJf2o?gMW@CJf2o?gMW@CJf2P`0fMV@CKf2P`0gMU@CKe2Q`0hMT@CLb2R`0kMR@CL\\2X`0QNl_OCLW2]`0VNg_OCLn1f`0_N^_OCKi1m`0eNW_OCKb1Ta0kNQ_OCK^1Xa0oNm^OCKX1^a0UOh^OBKP1ea0^O_^OCLi0ka0DW^OEM>Vb0Mm]OEN4OF[b0b0h]OB4J_b0d0d0Mng0B^XO6K4K5L5J5K5K5K5I7J6J6J6J6J6I7L4L5J5]OVMn_OMLe2R`0cMP@HOe2o?eMS@FMe2o?fMU@DLf2o?eMU@FLe2P`0dMT@GLe2P`0eMR@f2n?ZMR@GNd2P`0eMS@ENf2o?eMS@FMe2P`0eMS@FMe2P`0eMS@FMe2P`0fMS@DMg2o?eMT@DMg2o?_MR@E35Lg2o?_MR@D45Lh2n?_MR@D45Lh2n?_MR@E34Mh2n?dMU@DMh2n?dMU@DMh2n?dMU@ELg2o?dMU@@L10k2o?eMT@_OM10l2n?dMU@_OM10l2n?cMV@DMi2m?_MR@D44Mi2m?_MR@C55Li2m?cMV@DMi2m?cMV@DMi2m?dMU@_OM01m2m?dMU@_ON0Om2n?eMT@]O01Nm2n?eMT@]O01Nm2n?eMT@^ON10l2n?eMT@^ON10l2n?dMU@DMh2o?]MR@F35Lh2o?cMT@EMh2n?dMU@DMh2n?eMT@CNh2n?fMS@]OO10m2m?eMT@]OO10m2m?eMT@BOi2m?eMT@B0h2m?eMS@B2h2k?eM`@Z2`?fMb@X2^?hMb@X2^?hMc@W2]?jMb@V2]?kMc@U2]?kMc@U2]?lMb@T2_?kMa@V2^?iMc@W2]?iMd@U2]?jMd@V2\\?jMd@V2\\?kMb@W2]?iMc@W2]?iMV@]O5l2e?nMY@S2g?oMV@R2j?oMT@R2l?nMT@R2m?cMS@FOf2n?UMS@M1512Nf2m?[MR@N22Oe2m?eMS@FOf2n?dMS@FOf2n?eMR@f2n?f00oLR@P2n?PNS@P2l?eMU@COg2m?fMT@B0h2l?fMU@^O2l2i?fMT@A1j2j?eMU@B0i2k?fMT@A1i2k?fMT@B0h2l?fMT@B0h2l?fMT@B0h2l?fMT@B0h2m?eMS@B1i2l?eMT@^O3m2i?dMU@_O3l2h?eMU@_O2m2i?dMT@C0i2l?eMS@B1i2m?dMR@D0i2m?cMS@D0i2m?cMS@D0i2m?cMS@D0i2m?cMS@D0i2n?bMS@@ON2o2l?cMS@@4m2i?cMS@@4m2h?dMS@A3l2j?cMS@C1j2l?cMS@D0i2m?cMS@EOh2n?cMS@h2l?XMT@h2l?XMT@EOi2m?bMT@@OO2n2k?bMU@A5l2f?cMU@E1h2j?cMU@HNe2m?dMU@FNf2m?dMU@FNf2m?dMU@EOg2l?dMU@EOg2l?dMT@F0f2l?dMT@F0f2l?dMT@@001k2k?eMT@@2NOm2k?fMS@_O2O0l2k?lMT@XO1l2k?RNT@n1l?RNS@o1m?QNS@o1m?QNS@o1m?QNS@P2l?PNU@o1l?dMS@F2f2k?dMS@F2f2k?oMU@Q2k?PNT@P2l?PNT@P2l?PNS@Q2m?oMS@Q2m?oMS@Q2m?oMS@Q2m?oMT@P2l?iMU@[OOl2m?gMV@\\OMm2m?gMV@\\OMm2m?gMU@]ONl2m?gMU@]ONl2m?hMU@[ONm2n?gMT@[OOn2m?eMV@]OMn2n?QMQ@?5BNk2[f0"}}, "object_label": "bench", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:yellow", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "state:empty", "texture:smooth/sleek"], "control_dims": "color, texture, transparency, material", "answer": "The image features a wooden bench with a black mat placed on it. The bench is located in a room with a wooden floor and a brown counter. The bench is situated near a doorway, and there is a chair positioned close to it. The room appears to be a dining area or a kitchen, as there is a dining table in the background."}, {"question_id": 874, "height": 333, "width": 500, "image": "000000360097.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "cleanliness, color, material, state, texture, transparency", "region_anno": {"bbox": [0.0, 0.0, 465.6, 158.0], "segmentation": {"size": [333, 500], "counts": "[R11Yn02iQO0S:0a:0]\\ONQ8b0WGDGLS92lF02M;3EMT:OTO0kF1e01X81PG1O05LL302^9KY;1TE0SFb04^O2OP90mF;o9FO1SF1L1i9OXF:co0ChYO>eFCO070L0S9OPG0M1Vd00l[O0N1;0k8OiF4NO3N42jm0;TROA90g8g0lFZOO042OMm81TGOP:062gE20010`0OZ8OTG31MON24a0MSm08^ROHh98WFHN0an01^QO32N0NN119T9EmF2j0OUm05RROLM43Li9NUF0a;0iN0WN1`G3O18K`02XW16QhNK2ON2P:MRF0W:O01WO0TG0iX11afN2:Nd8NhG0[O1Y90hF0W:2mFMj73PGMS11Tm0Oh[O1YF0082H^m01gRONX93`FNNO50hm00Y\\O2fENTo01U[O0hd04QQOLj9O^F031k91U9Nd\\O019fn0GZ[O0oE`0OD1L63n8OjF0k00_9O^FOh81D0WG0H0jX16UgNM31hX1LbgNOE2Tn0NQ\\O7bFJVO0`0Oo71aG1^13T7MkGO`05^75oGEH2g03a77mGFK0:N21m7OgG1NO;0X90_F1;2S98`F26E<0_ONX8;gG40A03b0N_O1X8OhG051;Nd80WG2\\97[F1?FL1l78iGIL3\\n07hQOINM5Om88lFH32NM100031R90jF061;ND0m81W10009ORF0@1V90ZGOd83lFN<Oi80iF1Q:0oE0X11Y71^GO:NJ1OO10O0_8:\\GM0M4>f8@ZGO0180E33Ljb00S]O3O20K5071DO2O<2d7R1oGlN1<;Ic70QH0O90E90GNb02_70THMO015LLY95gFL2013ML:O?0V7=QHG100O01NO12?M_74THK00e01a9OeN0UGOO5NM4O60I2a0Mb7X1kGnN1N7MH0R84oGN1M>1C5LL005NL100R84nHLoN011OO2O40K100Q85PHKj04TOLj86VGL3N20O1MOO51JX10U65UILJ0b84eGLIOb87`GJ:0WO4=L^7;WHG312M3<FE8OK0a7=]HG4L40L?m77nG^O2K00O144L0O4P8`0PH]O0?0@18:CQ70dH`02FNg00VO485En60kH0O1[10iN0`0On6;bHE00m04SOLn73mGQ21QN0O;LH4Y6MhIOMc2O^MO0;0H8T6d0kIXOOL8O90_O011OO113OV7l0iHWOn0MSO11OO0V7m0eHA2F0N0a0N^O0a05^OM11ON10OY6l0hIZONN3N1O01L;5FK31LQ76nHJ1N05g1KR6<VHN1Fd01HOL1G16NM3V7`2gHYN3VO`6m0^ISOO70M1K3:LI57LHP7d0dIYO01\\O13O5OU7h0bHYO;OI1a0O[O43Mf7m0^HTOKe0OD4EM0O20N03P7h0YIUOJ15O42F02N_76\\HL1N01S2O_5k0iIUOQO0U7e2`H[M`7l0^HUO1400OM1N82GO1041KNf78ZHN001J>2c0Ng6l0\\HTO12MO>O@140e7[1WHgN4MN;2FLOf7k0fHWOE0;NI0O1f71aH0DN21c1O@2\\5i0cIYON1N90D=Nh02nNOX6Y2RKfMgN1W6f0eI[O5NL01d0O^OOO10R84oGK00O2OO2O<0C10O90H031m7j0RHVO100O11J02O00O1Q8j0PHXOON0O=1CO0140m7:RHG1N01L0T91PG0`0N\\O1S9g0lFYO54k0LQ7k0SHYOl0LQ77oG61B41S97hF5d9?`FUOT9k0lFUOT9<jFN3ET9l0kFTOU9n0hFSOW9n0iFROW97hF86BQ96iFJ453KP9m0jFSOW9l0iFTOW91lFO017Nn8;jFG2NN0U9n0hFSOX9m0iFROY91gFN1130K022\\94bFM210OZ9d0dF]O2KW9=gFJ1N1KX92gFN104004X9NgFOO4M0\\9NgFb0Y9^OdFNO=0G_9LaF81L1L^9e0aF\\OON^9k0bFUO^9=bFOc9FbFNM41M^9f0_FZOa9i0001[O`FL20N2`9e0100]O]F022d9J^F024^9b0O1002C]FLb9`00O3\\O[F201f9L\\F100d9d0ZFZO_9n0LYOcF70D00\\94fFL0`0W9=hFROW9<hF22CT90kF53K02NMV9;lFGO2NMONU9W1OMlFmNT9<oFE10L2Y99iFG1NM0[9j0eFVO[9<eF1_9BeF020N4Z9MdF22NLO13\\9j00M3YOaFM004OM2`9<`FDN2b9i0L^OeF0o9ETF0\\9:bFIN0^9i0OBbFGOOa95dFH00\\9:bFIOO]9:aF0`9G`F0300O^9NaF32Nc9c0\\F^O[9j00JcF\\O]95bFM1MOO11_9d0aF]O^9c0aF^O`90aFO3O1O]90cFO91R9c0cF_O[9c0cF^O]9LcF1040K0320[9McF1044LKO32\\9d0bF^O]9b0cF^O^94bFKOO51[94aFLON61Y97bF01J]96aF12I_96_FH2020_98bFG01\\9c0bF]O^9j0_FUO_9j0aFWO^91cF30K02O31L^9OgF071V9OcF071S9OaF5OL5;X9DcFl0^910HcF_O_96eFGO1[9c0cF_O\\9i0000WOgF0L7]95bFE1N^9b0cF^O^9a0bF^O`91_F;0Ca9d0_F]O^9j0000TOaFj0_9ZObFb0]9^OcFb0_9\\OaF33M00^92^FN6Nc9d0ZF^O\\9k0OJcF\\O]9MbF>0G1M^9k00O2A_FE41]94`FLOO4O^9b0aF_OMN^9f0cF\\OOO^97cF20HOOi20\\M0U67gIKO210a2KcM100T6n0XLQOdM100U6c0fIDa2HeM000U69eIM4LLOf20o39[IL3MM21M\\2OW4Z1kJeNcN1N3i0M_5[1TKgNdN7f0Ha5NiI:1GO50=k0_OVO30LO311OO4NO10OW68fIH0i0h0LXO]O202NL61IY6\\1]JhNZO`00[O011OO10004OL40P6j0oIAc0J[O>3\\O80E100O04OQ62nI1O04MO1M3a08^O3OB50b0Od52fI;OD1031N226Mi04nN0O:2j5i0gIB1DO`10mN0F53P6c3nI]LR6a0kI]O1f11YNOa00BS6h0mI^OOo02hNO2ON0M033NW6k0fI^O32MN1NOJ:NF03030^60^I<OD<0I1K32K120NM1Q8O[I0iN0O10Og7Y1UHmN0NOM1d07]OMNO2f6f2VIYN1TOO1P6m3PJoKU6]3oIhLMJ0Oa61_IO1040K100O113O50O1H000O11OO0203074D10b90b72mHR1lEoNM13N1OV8\\3gGdL2O02NNZ6]3fIjLOM^6X3bISM=Ab5]2QJ`N2_OOG6Nh5l1QJ\\N1H0400O10O90IN4Oi5l0QJ>1iN2K12028NGN51h5Z2PJnM0I3003OK53LM42i5o3SJULl5V40GQJoK1Oo5m3QJTL0NT6W4mIjKm5V4SJjKm5T2QJPO0lN537Od5R2PJTO4kNNM43j5X4O00L4GnIWLS6h3lI]LP6c3QJ\\LP6HQJS11DO^O1JN14OO002NO60i5Z1RJ^OMK1_O1O180FM2o5Y4000TOQJnL4ELNo5W4RJiKn5[1SJ[10ZMm5[1QJm01lM3MNNn5<PJa00_O051F0J20M73IO0=Of5g3XJYLE2m5f3QJYL122NN1n5f3QJYL011N11O1n5d1SJ3OYNOO1O1001R6f1lI80VN101Kn5h3PJ]L10OMP6Z3PJiL1L00000O13NMS61PJ4Mn00TO22N305k0AW5Z3nIiL172Il5n3RJnKO2o5l3RJQL61h53QJ\\32dL[6k3cIVL4Kl5V4RJkKn5d3PJeLZ6Q1gIYO1OO^OO50O2M20OOZ60hIONT3MXMP7a2PI`M[6CTKV1aNmN1107h6GjJ4]N?1\\OO22O17g6MVIk0<QOIN03L>OI0Ki6W1XIeN51ON8j0EVOk6R1UITON63G0O3>NAo6;oH60c01\\OV7b2OmLhHQ3X7oLiH042N^2Y7bMhH1M\\2\\7eMdHb2]7^MbH[2e7eM]H1OO1i1d7h0000gM[H;O^O2OOb01\\Od7:^HHNO<N7Oa7=mGN3E017OE69K[7e20gMZHi1f7UN^HG18M;O_O012Nd79ZHI1`1O_Ne7`2100kMYHG0V14eNM3g7_203NI6nMUHE00010:O74^Ol7`0PH]1g7dNYH]1f7cNZH\\12QNb7<]HGO30R12nNNM2Mb7d2]H\\Mc7g21]O[HQN10g70XHO:OIQ1OnN3Od7?WHB0d11^Nf7a2OlMZHQ11cN1Ne7=ZHQ12cN0Me7e0YHf00iN00f7`0ZH`0OPO11OOg71YH18KL2M1O85EKO62b7OYHN077J5OD1O<6G1Na7>XHJ2KN`06CLLe7h1`H[NKMe7<[HAO228O1;DH1d7d0YH^O0h0b0UOV7f0VH>:lNG110h7d0WH@Oi0_8ROgG1>0H1H2OLY81iG0?1G0LNL2W8`0fG_O2O3440H8>DY7e0ZH[O3443J1U8HfH1@3FNZ83dGM3O7102IMY85bG63EM0135LM33MZ81eG3NM9OoW20Rk5"}}, "object_label": "suitcase", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:red", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "state:closed", "texture:smooth/sleek"], "control_dims": "color", "answer": "The image features a large pile of suitcases, including various sizes and colors. Some of the suitcases are placed on a metal railing, while others are scattered around the area. The suitcases are arranged in a way that they are easily accessible and visible to the people in the scene. The presence of multiple suitcases indicates that this could be a busy location, such as an airport or a train station, where people are either arriving or departing with their luggage."}, {"question_id": 875, "height": 426, "width": 640, "image": "000000102805.jpg", "category": "description", "question": "Describe the backpack in the following image in detail.", "dims": "color, material, pattern, transparency", "region_anno": {"bbox": [52.24, 394.38, 70.15, 31.62], "segmentation": {"size": [426, 640], "counts": "_Qf03U=2N2N2N2M3N2M3M3M3L4N21O2N3M2N1O1O1O1O1O1O001O001O001O001O001O1O001O00001O1O000000001O0000001O000000001O001O0000000000001O001O1OO1001O00Z=0eB11Oeje6"}}, "object_label": "backpack", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain"], "control_dims": "material, pattern, transparency", "answer": "The backpack in the image is brown and appears to be worn out. It is placed on the ground, possibly on a sidewalk or a similar surface. The backpack is positioned in the center of the image, with a close-up view of it."}, {"question_id": 876, "height": 333, "width": 500, "image": "000000319100.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, pose, state, texture, transparency", "region_anno": {"bbox": [239.17, 217.58, 56.8, 40.48], "segmentation": {"size": [333, 500], "counts": "fn]24Z:1N101O000O2O0O00O2O3LYk40hTK001O0O2O001N2O001N100O2N101O0O10O1L4O10O10O10O1000O2O1N5JoSR2"}}, "object_label": "remote", "attribute_label": ["color:black", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "pose, texture", "answer": "The remote in the image is a Nintendo Wii controller, which is white in color. It is being held by a person's hand, and the person is sitting down while using the controller. The Wii remote is designed for use with the Nintendo Wii gaming console, allowing players to interact with games through motion-sensing technology."}, {"question_id": 877, "height": 333, "width": 500, "image": "000000319100.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, pose, size, state, texture, transparency", "region_anno": {"bbox": [466.95, 231.23, 32.92, 72.59], "segmentation": {"size": [333, 500], "counts": "PUh48j90XF0`990:G9I6H9I7O1O1N2000O1000000000000O1000O10O10000O1000000O0100kH"}}, "object_label": "tv", "attribute_label": ["color:gray", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "state:off", "texture:smooth/sleek"], "control_dims": "texture, color, pose, transparency, size", "answer": "The image features a small television set sitting on top of a wooden table. The TV is turned off, and it appears to be an older model, possibly a CRT (cathode ray tube) television. The TV is positioned in the center of the table, and the wooden table occupies most of the frame."}, {"question_id": 878, "height": 480, "width": 640, "image": "000000184384.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, pattern, texture, transparency", "region_anno": {"bbox": [0.0, 181.62, 640.0, 291.89], "segmentation": {"size": [480, 640], "counts": "f9Y5g901O001O00001O001O00001O00001O00001O00001O0000001O000000001O000000000000000000O100000000000000O1000000O100000000000000O10000O10000000000O10000O1000000O100000000O100O100O100O100O1O100O100O1O1O10000O1O100O1O100O1OeLaG7^8BRH6n7CbH4]7IiH5V7HUI1k6K\\I2c6LbI2]6KlI0S6ORJNm5O[JMe50aJM]53gJKj2oNlKT1_1Kc2UOkKo0f1J_2@aKe0U2HY2I[K?`2FU2OVK:h2FR22RK8P3Dn1:iJ3]3Ai1d0_JNk3\\Of1k0WJJW4YOb1S1lIGf4TO^1f2eNYM[1f2hNXMX1f2lNXMT1g2oNWMQ1g2SOWMm0h2UOWMk0h2WOWMi0g2i5O1O1N2O1N2O1O1O1O1N3N1O1O001O1O001O2M4M2N3M3XNnBe0OL]=2fBL\\=1fBM\\=B^B:73d=J]B4g=H[B6Y>N4K4Migh48oWWK6K2N100O002N3M1O4L1O3M2N1O000000001O1O00001O001O00001O00001O001O001O001O00001O001O1O001O001O00001O001N101O1O001O001O001O1O001O1O001N10001O1O1O1O0O2O001O1O001O1O1N101O1O1O001O1N2O001O1N2O1O001O1O1O1N101O1O1O1O1O001O1N2O1O1O1O1O1OfNbDSO];h0kDVOT;e0UEXOj:f0ZEYOe:c0aE]O]:?iE_OW:<PFCn99YFFf97^FIl3YOLj0^LMc3[ONd0dL1\\3]OO=kL6T3^O17QM:m2_O41UMa0c2@Y3`0dLB\\3?aLC`3>]LCd3=XLGg3;VLFk3:RLGo3:mKIT48iKIX47fKJZ46dKL]45_KLb46XKMj43TKMn44oJLR55jJMX54dJGd59XJIi57VJInL"}}, "object_label": "dining table", "attribute_label": ["color:brown", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, texture, transparency", "answer": "The dining table in the image is set with a plate of food, which includes a slice of cake and a slice of orange. The cake is accompanied by a sprig of parsley, adding a touch of freshness to the presentation. There are also two cups on the table, one located on the left side and the other on the right side. The table appears to be well-prepared for a meal, with the food items and utensils arranged neatly."}, {"question_id": 879, "height": 480, "width": 640, "image": "000000367386.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "cleanliness, color, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [127.41, 254.51, 21.95, 10.65], "segmentation": {"size": [480, 640], "counts": "Pik11n>4M3M3M0000000000O10000000001O001O001O0KS\\V7"}}, "object_label": "vase", "attribute_label": ["cleanliness:clean/neat", "color:black", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "color, cleanliness", "answer": "The image features a close-up view of a vase, which appears to be made of wood. The vase is brown in color and has a somewhat rough texture. It is placed on a table, and the focus is on the vase itself, highlighting its unique design and craftsmanship."}, {"question_id": 880, "height": 480, "width": 640, "image": "000000367386.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "cleanliness, color, pose, size, transparency", "region_anno": {"bbox": [91.52, 242.73, 29.53, 23.51], "segmentation": {"size": [480, 640], "counts": "k]Z13l>2O1O0O2N1O2M3N3N2M4M1O000O1O01M4N1O100O2O010O010O2N1N3L6KS`c7"}}, "object_label": "potted plant", "attribute_label": ["cleanliness:clean/neat", "color:green", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny"], "control_dims": "cleanliness, size", "answer": "The image features a small potted plant with a few leaves, sitting on a table. The plant is placed in a white pot, which is positioned on a table. The plant appears to be a small tree, and it is surrounded by a few leaves, giving it a lively and green appearance. The overall scene is simple and elegant, with the potted plant being the main focus of the image."}, {"question_id": 881, "height": 480, "width": 640, "image": "000000081738.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, pattern, pose, texture, transparency", "region_anno": {"bbox": [1.25, 206.25, 631.25, 266.25], "segmentation": {"size": [480, 640], "counts": "g<W2h<10001N00100O100O100O1000000N200M3cJ_M[Na2d1dMWN]2i1PNjMP2U2VNeMk1[2]N[Me1e2dNPM^1o2hNkLY1U3nNaLU1_3oN\\LR1d3TOSLo0m3ZOhKh0X4_O`Kb0_4HVK:j4JPK8P5JjJ:V5KaJ9_5K[J7e54kI1U6]4O1000000000000O1000000000000O1000000O10000000000000000O100000000O100000000O100000000000000O10000O10000000000000000006J5K2N2N1O2N3M1O8H5K2N1O2N2N1O2N1O2N3M2N2N1O1O3M2N001O2N4L2N2N2N1O2N2N2N1O1O2N3M2N1O1O2N2N1O003M2N2N1O2N3M2N2N1O1O1O3M3M1O2N3M2N1O001O2N2N2N1O1O2N2N2N2N1O1O1O2N2N1O3M2N1O001O1O2N3M1O2N2N2N2N2N1O1O2N2N3M1O2N2N1O2N1O2N2N1O2N2N3M1O001O001O0000000000000000O10000O10000O10000000000O100O10000O10000O10000O10000O10000O1000000O10000O10000O100000000O100O10000O1000000O100O100000000O100O10000O1000000O10000O1000000O10000O10000O10000O100O10000000000O100O10000O1000000O100O1000000O10000O10000O10000O10000O1000000O10000O10000O1000000O100O100000000O100O10000O10000O10000O10000O10000O1000000O10000O10000O1000000O100O10000O10000O10000O10000O100000000O100O100O1000000O1000000O100O100O1000000O1hNYLWGg3i8YLVGh3Q:00000O10000O10000O10000O10000O10000iNSL[Gm3l90O1O10000O10000O100O1000000O10000O10000O10000O10000O1000000O100O10000O100O10000O1000000O10000O10000O10000O10000O1000000O100O10000O100O0100O01000O10O01O0100000O01hE]KS:b4mE_KS:a4lE`KS:a4mE_KS:`4mEaKS:^4oEaKP:_4mN_KYHa4S900OfEeKP:\\4PFdKP:\\4oEeKP:f40000O1ODRFgKo9X4RFgKQ9IhG`4UOjKR9FhGa4VOjKn9V4RFjKn9V4RFjKn9U4RFlKm9U4SFkKm9T4RFnKm9S4SFmKm9R4TFgK1Lj9]4VFgK1Kh9^4WFiKOJh9_4YFmKf9T4ZFgKOH_9i4aF_K1HU9OjF\\52cJS9e522NN3AgFVK]9f4dFZK]9d4cF]K]9b4cF`K^9^4bFbK_9]4aFYK02_9d4bFYK5L]9h4_F]Kl9`4TF`K1Kf9d4YF`K0Ng9a4\\F^KN2f9_4dF_K^9_4[FaKn9]4RFdKo9[4<O`EfK[:Y4eEgK^:V47N2N2M2O2M3J6M3M3M5K3M4L4K5M4K4L4M3K4N3L4L4M3L3M5K4K4N2M3N2M4K4N2M3M4M2J6M4LbV6"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:white", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose", "answer": "The dining table in the image is a small, round table with a cake placed on it. The cake is decorated with blue and yellow frosting, and it appears to be a birthday cake. A person is cutting the cake using a knife, and there is a bottle nearby, possibly containing a beverage to accompany the cake. The table setting suggests a celebration or a special occasion."}, {"question_id": 882, "height": 427, "width": 640, "image": "000000357459.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "color, maturity, state, texture", "region_anno": {"bbox": [268.06, 98.89, 198.46, 287.81], "segmentation": {"size": [427, 640], "counts": "]P`37P=7ZCKo;k0L3M2O100N200O1N1O200QMaNQJ`1l5iNXIL]N\\1Z8lNSIN`NV1]8oNoHNaNS1`8ROjH1`Nn0g8TOfHc1[7^NcHS1hN^Ng8a0YHV1UOQNg8i0PHY1[8iNSGXOMo1Q9iNPG^OKi1U9iNjFFNa1Y9jNgFn1Y9RNgFn1Y9SNgFk1Z9UNfFk1Z9UNfFk1[9UNcFl1\\9S1O000UHTLV6m3fI^LR6c3jIcLS6^3lIdLR6^3lIdLQ6`3lIbLm5f3oI\\LP6f3gIbLX6`3fIaLY6b3dI_LZ6d3eI[L[6f3dI[LU6m3iITLS6Q4lInKR6V4lIkKQ6Y4mIgKR6[4nIdKR6^4lIcKS6^4lIbKV6]4jIcKV6]4iIdKW6\\4hIdKY6ROfIn41oK[6oNiIP5KRL\\6lNmIP5GSLm6l3RIULn6k3QIULP7k3PITLQ7Q51O2O1O1O100O100O1O1O1O100N2N2N3N100O2N1O2N100O10001N101O0000001N101N2N2O000O1000O2O>A8I3L5K4UJRJS4P6iKSJU4o5hK\\Jo3e5mK_JQ4d5jK`JU4b5gKaJW4b5eK`JZ4d5`K_J_4V701O1ORJ_KT3a4hLgKS3X4TL_KkN>o4R4VLcKdNb0T5i3YLiK^Na0X5e3YLRMd3o2ZLTMd3l2ZLXMd3i2ZLZMd3g2XL^Mf3c2VLcMg3_2QLiMi3\\2RLkMi3X2TLkMk3V2QLoMm3R2QLQNn3n1nKWNP4k1kK[NR4g1mK[Nm3l1oKWNn3e5N2M3N2H7O2N2N2N2M5L2N2M3N2M3N2L4N3M2M3M2N2M3N2N2N1kNjD5X;JTEHo:7S10O100000O100O101O0001O2N1O1O2O001N2O00000000O100O1O2N1O2N1O2L5L3M5I`^W2"}}, "object_label": "dog", "attribute_label": ["color:black", "color:tan", "maturity:adult/old/aged", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture, color", "answer": "The image features a small dog, possibly a terrier, jumping in the air to catch a Frisbee. The dog is in mid-air, with its mouth open, displaying its excitement and determination to catch the Frisbee. The dog's body is positioned towards the right side of the image, and its legs are spread out as it leaps. The Frisbee can be seen in the upper left corner of the image, indicating that the dog is actively engaged in the game."}, {"question_id": 883, "height": 424, "width": 640, "image": "000000061268.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, length, material, state, texture, transparency", "region_anno": {"bbox": [467.46, 136.16, 16.87, 15.89], "segmentation": {"size": [424, 640], "counts": "W`Q62U=2N1O2M3N2N2N2O0010O001N101O1N2M5I]QP2"}}, "object_label": "traffic light", "attribute_label": ["color:black", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "state:dry", "texture:smooth/sleek"], "control_dims": "transparency, material, state, texture", "answer": "The image features a close-up view of a traffic light, which is a black and yellow object. The traffic light is positioned in the center of the image, with its yellow and black colors clearly visible. The traffic light appears to be a part of a larger object, possibly a car or a piece of machinery. The focus of the image is on the traffic light itself, highlighting its distinctive colors and design."}, {"question_id": 884, "height": 427, "width": 640, "image": "000000066231.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, material, pose, state, texture", "region_anno": {"bbox": [176.91, 248.75, 9.99, 21.02], "segmentation": {"size": [427, 640], "counts": "mQZ282Ik<>O0O1M210002N2N1Ogdl5"}}, "object_label": "bottle", "attribute_label": ["color:red", "material:polymers/plastic/rubber/styrofoam/polymer", "pose:vertical/upright/standing", "state:closed", "texture:smooth/sleek"], "control_dims": "color", "answer": "The image features a bottle with a yellowish-orange color, possibly a candle or a vase. The bottle is placed on a table, and its shape and color make it stand out. The bottle appears to be the main focus of the image, with the rest of the scene being relatively dark."}, {"question_id": 885, "height": 454, "width": 640, "image": "000000082846.jpg", "category": "description", "question": "Describe the bus in the following image in detail.", "dims": "cleanliness, color, material, pattern, state, transparency", "region_anno": {"bbox": [83.85, 171.27, 477.51, 271.99], "segmentation": {"size": [454, 640], "counts": "ehV11T>2O0nG4j1LTN6k1KTN7k1ISN9l1IRN8n1HQN9n1GSN8m1IRN8n1HQN9o1GPMK[K\\1c7kNiKHeLd2c7dM]JIROk2`6aMWIDVO60028k0^2f6kMhHf0?b1h6K`Hf0_7Q30000O10000O01000O2O00000O10000O1000000O1000000O10009G6J4K4M1O1O1O1O001O0O101O000000O11O000000000000O01000O1O1O1O1M3O1M3N2O10000001O1O2BdHnI]7Q6cHoI^7P6bHPJ^7o5dHPJ\\7P6gHlIZ7T6hHhIZ7X6:00O1000000000001O000O10000001O00000[HjIZ7V6fHjIZ7V6fHjIZ7V6fHjIZ7W6:0]HjIV7V6iHlIV7S6iHoIW7Q6eHjI03[7S6eHjI30X7W6dHiId7W6fHiIQ7W6oHjIo6W6>2O10O101O0O01FiIeHW6[7hIgHW6Y7hIhHX6X7iIgHW6Y7kIdHV6\\7lIaHU6_7jIcHU6]7kIcHU6]7kIcHU6]7lIbHU6]7kIbHV6^7jIcHU6]7jIdHV6\\7kIcHU6]7lIaHU6_7kIaHU6_7kIaHU6_7kIbHT6^7lIaHU6_7kIaHU6_7jIbHV6_7iIaHW6`7gIaHY6g7O00000000000000O2O000000000000001O0000000000000000001O000000000000001O00000O10000O2O0N2O13M6J2N3M3M100O1O000000O1N22N001O010O1O00000001O00000000000O100O1O2L3O1001O00100O1OO1001O0000010O00000000000001O00000O10001O0O1O100N2O1O1N2O100000001O0O1000000000001O000000000O1O1N2O1N2N2M4N11O1O1O001O0000100O1O000001O01O00000001N1000000O1N200O101N1O11O5K5K3M1O1O001O000001O000001O0001O000000001O01O1O2N1O0010O00000O10010O000O11O000000O100000000O11O1O0001O0001O0000000010O000O2O000000O11O0O1O1O1O2M2O1N2N2O2AmH_I]7`6<H;E1O20O00000001O0001O01O000000000O10000001O0000NhGVJX8i5300O2O00000000001O00000000000000001O00000eKaGo2`8PM`GP3`8oLdGn2\\8QMfGiNM0Ol3_8g1000000000000001]LfGX1Z8TN_GeN\\1b2V7jMQJK`M8Nl0a8oNSL3m3JWL5i3I[L5f3I\\L6d3I^L6b3J_L5b3J^L6c3I_L4c3K[kS1"}}, "object_label": "bus", "attribute_label": ["cleanliness:clean/neat", "color:red", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:lettered", "state:covered"], "control_dims": "pattern, material, color, transparency, cleanliness", "answer": "The image features a red trolley bus driving down a street, with a large white roof covering the top of the bus. The bus is quite long and has a distinctive appearance, making it stand out on the road."}, {"question_id": 886, "height": 640, "width": 481, "image": "000000070229.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "cleanliness, color, length, material, state, texture, transparency", "region_anno": {"bbox": [287.84, 365.81, 60.3, 67.32], "segmentation": {"size": [640, 481], "counts": "_od53mc03M4L2N2]\\OD4i0Zb0Aj]Og0oa0WOS^OS1ca0kN_^OU1aa0kN_^OU1aa0jN`^OU1aa0kN^^Om0ka0SOU^Ol0la0SOU^Om0ja0UOU^Ok0ka0UOU^Ok0ka0UOU^Ok0la0SOU^Om0ka0SOU^Om0ka0SOU^Ol0ma0SOS^Om0na0QOS^Oo0_b000000000000000000000000000000001O0000001O1O1O1O1O001O1O1O1O1O1O1N2O2M3M3M4H[gb2"}}, "object_label": "bench", "attribute_label": ["cleanliness:clean/neat", "color:green", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "state:empty", "texture:rough"], "control_dims": "cleanliness", "answer": "The image features a green wooden bench situated in a park or outdoor area. The bench is positioned on a concrete surface, and it appears to be empty. The bench is located near a sidewalk, and there is a person standing in the background, possibly walking by or enjoying the surroundings."}, {"question_id": 887, "height": 428, "width": 640, "image": "000000108026.jpg", "category": "description", "question": "Describe the mouse in the following image in detail.", "dims": "cleanliness, color, material, size, texture, transparency", "region_anno": {"bbox": [85.91, 123.18, 155.26, 44.31], "segmentation": {"size": [428, 640], "counts": "ibQ19Q=3N00N03M4N1O0O102M4L2O1N101N3M2N2O1N3O4K10000000O2N1N2O101O002N1N2O1O1O00010WOiC<W<AlC?J]OW<2SD>FAV<OVD`0DAV<OVD`0^<O1O0000000000VCBf<>YCCg<=YCCg<=ZCBf<>ZCBf<>40000000O1VCBf<b0O10MZC@e<d0OH]CIc<7]CIb<8^CGc<9]CGb<:^CEb<<^CDb<<]CDc<=]CCb<=_CBa<?`C@`<`0`C@^<b0bC^O^<b0bC]O_<c0aC]O^<d0bC]O]<c0cC]O]<d0aC^O^<b0bC^O^<j0MOeCSO[<g0fC[O0NZ<g0fC[O0OY<o0O101O3M0O10O1C<010OO200N110O1O010O100O10000O101O00000O1000001O000O10000000O10000000000O100000000O100000000001O00000000001O00001O0000001O0O1000002EQC5^QW5"}}, "object_label": "mouse", "attribute_label": ["cleanliness:clean/neat", "color:black", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "cleanliness, size, transparency", "answer": "The image features a close-up view of a person's hand holding a computer mouse. The mouse is positioned in the center of the scene, with the person's fingers wrapped around it. The hand is placed on a mouse pad, which is located on a desk. The person's hand is visible in the foreground, while the mouse and the desk are in the background."}, {"question_id": 888, "height": 480, "width": 640, "image": "000000073326.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, pattern, pose, texture", "region_anno": {"bbox": [494.89, 357.01, 33.47, 53.55], "segmentation": {"size": [480, 640], "counts": "UlX75^>?L3M3N1N3N1O2M3N1M4M2N3O010O0001O000M4N1O2K4N3N1O2O0O2YOlA>a>H\\Re1"}}, "object_label": "bottle", "attribute_label": ["color:black", "pattern:plain", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, color, pattern", "answer": "The image features a bottle placed inside a cabinet or cupboard. The bottle is positioned in the middle of the cabinet, and it appears to be a small, round, and clear glass bottle. The cabinet itself is white, and the bottle is the main focus of the scene."}, {"question_id": 889, "height": 480, "width": 640, "image": "000000074209.jpg", "category": "description", "question": "Describe the sink in the following image in detail.", "dims": "cleanliness, color, length, material, state, transparency", "region_anno": {"bbox": [242.43, 256.0, 170.93, 34.7], "segmentation": {"size": [480, 640], "counts": "bod32m>2O1N2O1N100O2O0O110O2N000O101O1O1O00001O001N100000000000001O00000O11O00000O10000000000O100000O100O1000O100000000000O10000O1000000O0100000000O10000O100000O10O2O0O7A_A2i>Kg\\11[cN6J8I5K0O10000000000000000O1O10O1000O100O10O1000O1000O10001O0000001O0O10001O00001O001N10001O00001O000O2O0000001N101O0O100O2NUf4LPZK0001O00aeY3"}}, "object_label": "sink", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "state:empty"], "control_dims": "length, cleanliness, color, state", "answer": "The image features a large, stainless steel sink with a silver finish. It is placed in a kitchen setting, and the sink appears to be empty. The sink is positioned on a countertop, and there is a drain visible in the middle of the sink. The sink's design and finish give it a modern and sleek appearance, making it an attractive addition to the kitchen."}, {"question_id": 890, "height": 480, "width": 640, "image": "000000074209.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, color, material", "region_anno": {"bbox": [506.55, 226.24, 63.2, 23.8], "segmentation": {"size": [480, 640], "counts": "Wa[74l>1N10000O1O002O1N101N2O1N2O001O1O10O00010O10O10O010O1O000001O0000000000000L^OjAb0V>_OhAb0X>3004L4L001O0000O0100O011N10001N1O2O1N2N3N`kS1"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver"], "control_dims": "material", "answer": "The bowl in the image is filled with a variety of fruits, including apples, oranges, and possibly other types of fruit. The fruits are arranged in a visually appealing manner, with some fruits placed on top of each other. The bowl is placed on a dining table, and the fruits are displayed in a way that makes them look fresh and inviting."}, {"question_id": 891, "height": 480, "width": 640, "image": "000000074209.jpg", "category": "description", "question": "Describe the oven in the following image in detail.", "dims": "cleanliness, color, material, transparency", "region_anno": {"bbox": [199.94, 237.25, 80.36, 31.97], "segmentation": {"size": [480, 640], "counts": "hZP3:e>;F00000000000O0100000000O1O1001OO100000O10000000000000O10O100000O100O1O1N20O1000O1000bABZ>>40000001O0O0100000000000000O10O100000001O001OO10O101O000010Jd`X5"}}, "object_label": "oven", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque"], "control_dims": "color, cleanliness, material", "answer": "The image features a stainless steel oven with a glass front, which is placed on a wooden countertop. The oven is large and occupies a significant portion of the countertop. The glass front allows for easy visibility of the interior, making it convenient for monitoring the cooking process. The stainless steel material gives the oven a sleek and modern appearance, blending well with the wooden countertop."}, {"question_id": 892, "height": 640, "width": 464, "image": "000000438304.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "cleanliness, color, material, pose, transparency", "region_anno": {"bbox": [59.48, 179.35, 77.12, 45.95], "segmentation": {"size": [640, 464], "counts": "l]T1<cc05J3N3M2N3M2O2M3N1NSOV]Og0ib0YOY]Of0fb0YO]]Oe0bb0[O`]Oe0`b0[Oa]Od0^b0]Oa]Oc0_b0]O]]OLMh0eb0\\O[]Ok0eb0UO[]Ol0eb0SO\\]Ol0db0TO]]Ok0db0TO\\]Ol0db0VO[]Oi0eb0WOZ]Oj0gb062O001O1N3M3L4N2M3N2L4M4L2O1N101O0000001O4LRX12mgN1N1O00010O00000001OYeh6"}}, "object_label": "tennis racket", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:tan", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "material, transparency, color", "answer": "The tennis racket in the image is a black and white racket with a white handle. It is being held by a person, who is wearing a white shirt. The racket is positioned in the person's hand, with the strings facing upwards."}, {"question_id": 893, "height": 640, "width": 480, "image": "000000074646.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "color, length, material, pattern, pose, state", "region_anno": {"bbox": [353.57, 595.08, 41.3, 44.3], "segmentation": {"size": [640, 480], "counts": "h^n64jc07K2N2M6a\\O^OVc0i0L6K6J4L00000000000000000000000000000001O00000000001O000F:C>G9L4MYie1"}}, "object_label": "cup", "attribute_label": ["color:red", "length:long", "material:asphalt/cement/clay/concrete/stucco", "pattern:lettered", "pose:horizontal/lying", "state:covered"], "control_dims": "pose, material, state, length, color, pattern", "answer": "The image features a red plastic bucket, which is sitting on a dirt ground. The bucket is filled with water, and it appears to be emptying, as the water is spilling out of it. The bucket is positioned in the center of the scene, and the dirt ground surrounding it gives the impression of a desert-like environment."}, {"question_id": 894, "height": 375, "width": 500, "image": "000000416256.jpg", "category": "description", "question": "Describe the keyboard in the following image in detail.", "dims": "color, length, material, pattern, pose, transparency", "region_anno": {"bbox": [121.64, 210.81, 193.65, 102.52], "segmentation": {"size": [375, 500], "counts": "Qn\\12b;4L4L4M2N2O2M2O1N2N3N1N2N2O2M2O1N2O1M4N1N2O2N1N2N2N2N3N1O1O2N1O10001O001O00000000001O00001O00O1000O01I_FUNe9o1O8G1010O0001OO100N2G90_FRNY9X2N1OWNgFU1X9kNhFV1X9e0OmNlFDS98TGFk8:VGEj88iFRO:f0o85hFTO:g0P9XOfFe01[O:h0n8YOgFe01XO;j0m8YOfFf0a01h83ZGLg8WOgFc00Ab0d0h8XOeFe0i03b8O^GNe82[GMe84\\GJe87oFWOKa0IBW95hF78BHO8?HGY90hF9f0OYOIZ9NhF9e0OYOLY9LiFLM61J00c0h0g8[OiF4j0`0]8\\OhF6k0=^8\\OgF7l0<]8]OkF0k0d0Y8\\OSHd0n7[OQHf0o7ZOQHf0o7ZOQHg0n7YORHg0o7XOeFOY1i0R8XOeFOY1i0R8XOeFOZ1h0U8XOkGi0T8WOlGi0T8WOlGi0T8XOkGh0U8WOlGj0a9O00bNWOnGi0R8WOnGi0R8WOnGj0`9O00`NXORHg0m7[ORHf0m7YOTHg0l7YOTHg0l7ZOSHf0m7ZOfFNY1i0Q8\\OmGg0R8VOgFNW1l0T8SOfF1R1P1[8PO]GX1`8hNeF0o00QOR1Z9nNfF0o00QOR1Z9mNgF1c0O]O01Z1[9gNWG3\\OW1]9fN^GY1b8gN^GY1b8gN[G]1d8cN[G^1e8bN[G^1e8bN[G^1b8eN_G[1a8dN^G]1c8bN]G^1b8cN\\G_1d8aNYGb1g8^NVGf1i8[NTGg1m8XNPGk1P9WNkFl1U9VNgFl1Y9:0O00000010O000000010O000000001O01O1O1O100O00001O01O0O10O000O3N1O1N2L5M2K5O1L5M2L4N2H8L4M4K4L4K6I7K[lS2"}}, "object_label": "keyboard", "attribute_label": ["color:gray", "color:white", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying"], "control_dims": "pose, pattern, color", "answer": "The image features a computer keyboard with a cat lying on top of it. The cat is positioned in the middle of the keyboard, covering a significant portion of it. The keyboard is placed on a carpeted floor, and the cat appears to be resting comfortably on the keyboard."}, {"question_id": 895, "height": 612, "width": 612, "image": "000000419882.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, pose, transparency", "region_anno": {"bbox": [12.09, 212.4, 300.71, 116.0], "segmentation": {"size": [612, 612], "counts": "T_73eb0?L1@AZ^Oa0ea0_OZ^Ob0fa0^OZ^Ob0fa0^OZ^Oa0ga0^OZ^Ob0fa0^OY^Oc0ga0]OY^Oc0ga0]OY^Ob0ha0^OX^Ob0fa0@Z^O`0ea0AZ^O`0fa0@Z^O?ia0_OW^Oa0Vb0O01B\\O\\^Od0da0\\O\\^Od0da0\\O\\^Od0ca0^O\\^Oa0ea0_OZ^Ob0fa0^OZ^Ob0fa0^OZ^Oa0ga0^OZ^Ob0fa0^OY^Ob0ha0^OW^Oc0ia0]OW^Ob0ja0^OV^Ob0ja0^OV^Ob0ja0^OU^Oc0ka0]OU^Oc0ka0]OU^Ob0Wb00E^OT^Ob0la0^OS^Oc0ma0^OR^Ob0oa0@n]O?Ub0_Ok]Oa0[b01O1O02OO1E[OW^Od0ja0^OS^Ob0na0]OS^Oc0ma0]OS^Oc0la0^OT^Ob0ka0BR^O>na0CP^O>Pb0AQ^O?oa0AQ^O>oa0BR^O>na0BQ^O>Pb0BP^O>Pb0BP^O>Pb0BP^O>oa0CQ^O<oa0En]O>R1[Ok?7S_O=R1]Ok?6T_O<Q1^Ok?5U_O<Q1_Oj?4V_O=o0@k?0X_Oa0i0Dn?JZ_Ob0h0Co?KY_Ob0g0DP`0KX_O`0h0EP`0MW_O>j0Co?0V_O>7\\O86[`00V_O>7\\O77\\`0OV_O>j0BQ`00U_O=j0DP`0OV_O>j0CP`0OV_O=9]O37_`0OU_O=i0ER`0NU_O<8^O57_`0OT_O=6_O65_`00S_O>7_O62``02S_O>5_O81``02S_O=7^O73_`02S_O<8_O53a`01S_O<7@63_`02T_O:8@64^`02T_O99@38``0OT_O:h0GU`0OS_O:g0HU`0OT_O89A16c`02R_O6:C2MD3o`06R_O6:D04d`02R_O6;A07d`01R_O7i0HT`03R_O57C65a`03R_O56D65b`01S_O65D64c`02S_O45E56c`02Q_O47D55c`0f0W_OVO63d`0g0U_OWO72d`09n^OM7G82d`09o^OM5H82d`0h0T_OVO73d`0h0V_OTO0OJ6Pa0g0b_OTO]O4Ra0g0T_OUO12H3Sa0f0S_OVO1;l`0<U_OZO00H2Sa0`0m^O\\O922LG5Qa0a0n^OZO9405j`0<Z_O_OI8m`09Z_O_OG9o`09Y_O3g`0MY_O3g`0MX_O4h`0LY_O2h`0NW_O3i`0MV_O3j`0\\Om^O98;l`0\\Ol^O98;l`0\\Ol^O98;l`0NS_O2m`0OS_O0n`0OS_O1m`0OS_O0n`00R_O0n`00Q_O1n`0OS_O0n`00Q_O1o`0OQ_O1o`0OQ_O0Pa00o^O1Qa0\\Og^O=77Sa0[Oh^O=58Sa0[Oh^O<68Sa0\\Of^O=77Sa0[Og^O>57Ua0[Of^O>57Ua0ZOg^O>57Ua0[Of^O>57Ta0\\Og^O<67Ta0]Od^O>67Ua0\\Oe^O=66Va0]Od^O=66Va0]Od^O=65Xa0]Ob^O=67[a0Je^O6Wa0ZOe^O`046Va0[Of^O>57Ua0[Of^O>57Ua0[Of^O>56Va0]Od^O<7HG6_a0Fc^O<76Va0^Oc^O<76Va0_Oa^O<85Xa00h^O0Va02i^ONXa0_Oa^O>81Xa0_Oc^O>63Wa0_Ob^O?72Wa0_Ob^O?71Wa0Ba^O=81Wa0Ab^O=72Xa0Aa^O=72Xa04f^OMZa03f^ONYa03f^OM[a03d^ON\\a02d^OM]a02i^OIWa07j^OHVa07k^OHVa08j^OHVa08j^OHUa09k^OFVa09k^OFUa0;k^OEVa0:j^OEVa0;k^OEUa0;l^OCTa0>l^OAUa0>l^OBTa0>l^OBTa0=m^OBSa0?m^O@Ta0`0l^O@Ta0?m^OASa0?m^O@Ta0`0l^O@Ta0?m^O@Ta0NY^O?c0CXa0<h^ODXa0;i^ODWa0=i^OBWa0?i^OAWa0>i0O0O00JDe]O=[b0Dd]O<\\b0Ce]O=[b0Ce]O<\\b0Eb]O<^b04d]O@Vb00g]O;4EUb0Oi]O;2FZb09g]OG41ia06Q^OK50Xb0Oi]O1Wb0Oh]O2Xb0Nh]O1Yb0Og]O0Zb00f]OO[b01<OY]OORh12ajNNT]O4Pc0NKOV]O2jb05M3O0Z]OEcb0;]]OEcb0>0000000C\\]O9eb03O1O010000O01000O100000O10000O01O^]OC_b0<5O10O100[]ODab0<`]OD`b0<`]OD`b0<310O10000O010O1000O01000000O10O10000000N1O201O002M4MMOS]O1WV10i\\O7I1O00IW]O2jb040O0010O01O002O0000M2O20HX]O3ib0MX]O2hb0NX]O1ib0O64L01O1Naf]5"}}, "object_label": "train", "attribute_label": ["color:red", "color:yellow", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying"], "control_dims": "pose, transparency, color", "answer": "The image features a train yard with a long row of train cars parked next to each other. The train cars are arranged in a neat and orderly manner, creating a visually appealing scene. The train yard appears to be well-maintained and organized, with the train cars lined up in a way that showcases their design and structure. The overall atmosphere of the image is one of efficiency and order, highlighting the importance of the train yard in the transportation industry."}, {"question_id": 896, "height": 427, "width": 640, "image": "000000210855.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [357.51, 233.52, 13.47, 36.74], "segmentation": {"size": [427, 640], "counts": "Wne4b0_<;K4M3000001O08H9F\\h`3"}}, "object_label": "bottle", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:lettered", "pose:vertical/upright/standing", "state:empty", "texture:smooth/sleek"], "control_dims": "state, pattern, pose, transparency, texture, material", "answer": "The image features a bottle with a red cap, sitting on a wooden table. The bottle is tall and slender, with a white label on it. The label appears to be a sticker, possibly indicating the contents of the bottle or providing information about the product. The bottle is placed on the table, and the red cap is visible on top of it."}, {"question_id": 897, "height": 640, "width": 427, "image": "000000231527.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [161.44, 290.45, 122.52, 171.53], "segmentation": {"size": [640, 427], "counts": "mPU3d0hb0g0^NgNU_O]2e`0b0M4I6I7K5L4L4L4J5M4M3N2M3O0N3O1N1O101N2O0O101O0O101N10001O0O100O2O0000001N100000001O0O1000000000001O0000000000000000001O00O1000000000000000001O00000O10001O000O10001O0O10001N10000O101O0O101N101N100O2O0O2N101N2N1O2N2N2N1O2N3L2N4J5J8^Mf_Oa0Wa0VOo^OVOI92IO6oa04c^OGokj2"}}, "object_label": "cup", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:open", "texture:smooth/sleek"], "control_dims": "pose, material, state, pattern, texture, transparency", "answer": "The image features a small glass jar filled with a yellow substance, likely a jam or a sauce. The jar is placed on a table, and it appears to be the main focus of the scene. The table is white, and the jar is positioned in the center of the table."}, {"question_id": 898, "height": 359, "width": 640, "image": "000000268378.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [83.05, 233.0, 45.41, 109.8], "segmentation": {"size": [359, 640], "counts": "iem06P;4L4M2M5L2M4M3M3M3M2O103ONO021N22L4LO1M5L1O107I4L5L3N1O3NOO0211K3L3M2M3M3L5H8K6J4M4K5HYVc5"}}, "object_label": "chair", "attribute_label": ["material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a wooden chair with a wooden backrest and a metal armrest. The chair is positioned in a room, and a person is standing next to it. The chair appears to be a dining chair, and it is placed near a wall."}, {"question_id": 899, "height": 438, "width": 640, "image": "000000080949.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, color, material, pattern, pose, size, texture", "region_anno": {"bbox": [549.59, 0.0, 87.18, 171.86], "segmentation": {"size": [438, 640], "counts": "o`]7:R9GVK<b8H_C9X<g0^LoN]JS1a5PO[Jj0TMRO[85_Ji0VMSO[85]Ji0YMQOZ87lIY1jM_NZ88jI[1lM^NY88iI[1mM^NZ88hIZ1nM_NY87iI[1lM_N[89eHDUO9C\\18^N[85\\GIV1f2SO]MZ84]GJQ1i2YOXMY8=WH`2@SMY8:YHd2^ORMY89eG1Ld27QMX8T1`Gk17SMX8R1aGd1MlMa8b0_GY10bM4b0]8X3_GXL2`0_8X3_GXL2`0_8X3_GXL2KNa0a8\\3_GYL62KK`8`3_GbL1062c8e3WGYL62c8e3WGYL62c8a3WGWL1553c8[3XG]L6029`8X3RHhLVOFd8[3[GgL0N=h0CXOe8m1[G^O0fN10:k0Z8Z2ZGlL8NK0On0NSOf8P3nGRNV8d1ZGYMa0V1AkN[8f2THnNl7R1SHoNm7Q1nGUOQ8k0eG_O[8YO`GT2`8lMaGj1h8VNYGg1i8YNXG^1MZM<Kn7]1iGV1M`M218Oo7Y1kGn0OfMO32ONL19U8U1mGm0NoM2JMMO9W8T1nGl0NnM2LL:V8Q1jG\\15XMK;V8Q4nGcKN:U8S4mGbKO;T8R4nGcKM;V8R4oGcKI;X8R4nGeKH:0DW8^2WHPOIXOo7f1[HPOG[Om7e1YHSOJYOl7d1THXO0UOl7e1mGZO8QOk7_3XHaLg7\\3\\HdLd7X3`HhL`7h0mGe0j0dNX7k2oHkLQOCP8\\1nG6_1jNeNBo7T3_IXMj6b2\\I_Mc6^2`IbM`6Y2eIgM[6U2iIlMV6e1kGmMU2?o5a1^J^Nb5_1aJaN_5\\1dJfN`5^OfG^1k2iNRM5d8l0\\JoNRMJO6d8k0_JWOlL2h8b0_JHd52`JMe5LnJCU5:lJE_9N43O0oJ"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:red", "material:glass", "pattern:lettered", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, size, texture, material, cleanliness, pattern, color", "answer": "The image features a bottle of beer, which is placed on a wooden table. The bottle is tall and has a brown color, giving it a distinct appearance. It is positioned next to a cup, which is also placed on the table. The scene appears to be set in a room, with the bottle and cup being the main objects of focus."}, {"question_id": 900, "height": 436, "width": 640, "image": "000000192904.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "color, length, material, texture, transparency", "region_anno": {"bbox": [375.04, 137.91, 30.5, 26.48], "segmentation": {"size": [436, 640], "counts": "SXP52a=1O1O1BL[C4f<LXC5S=O1001O010O00O2O000000O2O0000000001O0O0100001OemS3"}}, "object_label": "spoon", "attribute_label": ["color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:reflective", "texture:smooth/sleek"], "control_dims": "texture, material, color", "answer": "The image features a spoon with a long handle, which is placed on a table. The spoon is made of metal and has a silver color. It appears to be a large spoon, possibly designed for serving or eating large portions of food. The spoon is positioned in the center of the image, with the handle extending towards the top of the frame."}, {"question_id": 901, "height": 436, "width": 640, "image": "000000192904.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "cleanliness, pose, state, transparency", "region_anno": {"bbox": [2.83, 0.41, 637.17, 430.35], "segmentation": {"size": [436, 640], "counts": "2l1b6lN_Ia33cM^6V3bIkL]6U3cIkLb5XNiJMFP5OlLo4TN]K4NMFo40mLf4\\NeKMIIK11Q50lLe4^N^KDL40O3NM01Q50mLd4WNZK=0B2NM02o41mLk3QNWL381Gf0OYOM02o41nLP4TNZLNHi0MYONO3n40PMn3PNPL1:0K1J92I0NO12m40PM6oM\\32]LO91J1M26KO2K21m40RM4mM\\34^LM93J01L<4BO0n40RMOmM10^3:hLLI0;LI4KM2n40SMd3YNZL:<ZOFON70L1o41RM^2lM_N\\1YOfNK?Na41RM^2lMZN3UOS10oN410;Na41SMY3@eLbN2;O`41TMOjMT3P2mLbNO`41UMMiMY3Z1hLhN64M;O`40XMW3hMgL22<MH[1KiNo4OXMW3hMgL132002MW1OiNP5M[MU3kMlLN001NX1OhNo4N\\MT3jMmLN000OP1MSO1No4N]MR3jMnLO0N1Oo0ORO0Oo4O\\MQ3lMlLb01VOj07UOM3l40\\Mi2dMWM\\11hNN02<Na41\\Mg2eMWM[11SO01Oa42\\Mf2JYM_31hLf2aMXMa00>O\\O3ONKOl43^MP3kMoLE25N14KM09OG1N051Lo41`Mo2_MPM25N02K44K<OE11OJQ51aMQ3aMRMN01N31M0020N13MJQ51aMP3bMRMOO00110ON21N2OT50ZMo2aMRM00ON41OON2i5OfLg2iMZMIOMMn63dK0\\M]22`M;1S72UKO[M^22`Mn73fJ0ZMV20jM1On71iJY2XMlM;IL0e1O]33_MY2XMlM0J61KN020N2O42:NG0O3R50`MX2WMlM1L0N0`01A42NM32NNMO13V50aM`2WM`M4>MB310L23NN13S5OaM_2YM`M14N02M201MO282k4ObMV2UMlM?ME3a1Ne30aMU21iM_22aMf1TM_N1IY82bJf1TM_N^8K_J1TM]1OfN_8L_J0SMl11SNR81kJORMn1OVN3K41N11O;0D01O_52[M>QMo0OgN2K41N4MM5L15L00Mg0Om32[N:QMJNo0OoN4M21N3NN4L15K02MNOc00R42[N0QM112Nn00QO2N10O3NN>0A23KN1c0OR42\\N8QMKNn00PO6LN1O4NO>NEOO0M0^52dM7PMKNP1OoN`0LF1P72nK3lLJ320Q1OQOd0Le63kK0ZMn0CSOQ8OSKOYMn0DTOP8O[KNbL40V15eNe00E1h52UM:cLR11eN2O13LO2N300Mi53_M:cLR10hN1M22M1000N3Ni50aM9dLS1OgN2N10O2N21L3Nh51bM7eLS1NhN2O00O1O14L00f51cM3aLK4\\1OgN2O00O2N14M0Mg53cM1hLX1LfN4NK0O144NO5Mk52\\M1gLd0J^O016J54LOMN0OM1Q61^M0gLd0I_O01e0LD0:O_51_MOgLl0IZOd0JD1:0^50aMNbL0K[15fNM4OO7ONN31i50cMN\\La12UOM[O1?1AO23MO1`51SNc1[LVO0FOA32NL13?L^43iN`1ZLWO1N0\\O30:M_42iN1XLY12TONF2c00ZO319Na40jN_1YLoNNF2:NE3N12;Jb43iN2VLT12A2FNC30OOb51UN1VL?0D2M02N1004LL09NM0M1c51UN0WL=OG1M02M<6_OK3c0MA0b52VNOVL>OH0L0g07[Ob0Lk41]NQ2SLZNLJ1J2O`52\\N<oKV11\\N0k00XO3N`51]N;PL[10SO0YO2M3OU52gN:oKZ12]O0nN4NT53hN0mK32X1NiN2i0NRO315NQ52kN7nKS1OjN1i05SO]50`N3nKh0NC3C1l01TO_5OaN1oK<LJ154D0m0OVO_5MbN1RLf0JE3D0m00WO_5LdNOQLg0IG1E1k0OZO`5IPOg2aK`M_5IhNn2iK\\M]5FjNn2hK]M^5ElN1dK40j2_5QMnN0eK2On2]5PMQONhKU3W5mL\\OZ2XKXN[5^O]OZ2XKXN[5^O]O2VKQ21aN[5\\OXO2^KLOP3Z5RM\\OX3d0hL]OX3b0hL^OV2YKgNX5SOCU3=kLE;RKY2X5\\MH8QK]2V5[MK4PKY11GQ5lNO1QK[10HP5lN9]1dJGU5lN6OdJ[11JU5lN6OdJe2V5\\M6h2JXM6h2JXM6i2IWM8h2HXM:1cJ^2R5aM=ObJi00g0n4cN`0LcJi00h0k4eNj0c0XJj0Q5`Nh0e0WJl0i4^NYK0g5^2oNcMZKOh5^2lNcM]KOc5M[Ja0N]1e4XN^KNc5M\\Ja2m4bMg0M]Ja2k4bMh0N[Ja2m4aMi02YJ51g1l4RNj02ZJ31i1c4PN`K1b50\\J8Mh1n4PNk0M[Ja2i4bMR1^2nNbMS17PJk1l4nMT1_2kM`MZL0>1]5_2TN`M_L1Y5MZJ_2m3cMYLOH2h5MZJ`2l3aM[L0G2i50TJ^2Z4`MfK33Oi50TJ_2Y4`MfK24Oj5OSJa2X4_MgK24OP6_2UN`MgK24On5a2WN]MiK211o5a2XM[MbM0WO212n5a2QM^MoLNn01TO2m5c2oL\\MUMMl01SO3l5d2oL\\MVMNb0O^O1M3m5e2oLYMRNOUOON4k5g2RNYMSLL05k5f2kLTM\\N6mNK15j5h2RNWMYL2d5h2hLRMeN2oN5b5j2ZJ]Mh1D]ONQO7`5b3nKYLO5R4e3iKYLeNKW17Z4f3iKTLbNN42V16Z4h3eKULlN3S11[4h3fKTLlN1T14Y4i3fKoKPO0FO12h0O]O8]5j3gKmKhN30MOO13a0N^O435^5k3nKoKbNM43b0O\\O8]5l3nKlKdNN33b0N]O9[5m3nKmKdNL5On0;Z4n3`KhK[O2EOe19k3n3_KiKXO5JJd1:j3P4iKQL<0j3P4\\KeK_O=Z1Oi3Q4iKPL?Og3S4hKoKa0Nf3U4hK`KnN94GY1:l3W4iK_KnN94GX1;l3W4jK^KnN94FY1<j3Y4jKiKc0Nb3Z4WKYK02C?d1Ka3\\4TK\\K4=CAb0NE11O42D6T5b4SKXK4OG`0O_Ob00<3QO5S5c4TKVK50Fa0d1AZN5S5c4cKmKb0XOlN004L4R5d4_KUK@a0ODb0KO1_O141L4Q5f4_KSKA`00F1K9O57CMM3Q5g4^KRKB?1F2Jl02PO132M3o4i4`KPKC>1ET1MmN0M403l4k4aKoJD5N02NU1KQO6H2c4U5kKeJD0N1132JN26Oe0O\\O6H2^4JbK\\5>dJDOO20OO0610Nf0O\\O`0U4S5RL^JC1N11N01510Ne01ZO`0T3D[Mf5O[JLK2O03B>V3EWMh52YJ^OK7MJ2`0N04C>U3GgLJ1T68jII0O7ON30OKi07YO:U3V6PMZIG1050O2O0Ke00YO75:T3V6PMZIG0150O2O0Nb0M]O64<S3V6QMXIG212200000Q1?R2W6SMVIH10233MM33<KNb0h2W6RMWII1N0;6LNONNMN00O4c0Q3^OiLf65YIM10592LHJ343MMNO2N4c0Q3^OiLf6?YIB3:4KJLi07Jn2]OiLg6a0_IAJ082H07L5:7l2X6\\MXIBMN0O671I944Q3X6QMSIL2N05OMON85>J;V3l5PMUIL0OO60O70MM6Nf0U3l5PMVIJO2O6ON6M27NGk0T3m5QMXI`0O^O092C01`0T3W6QMXI`0O]O299F6R3Z6oLRId01YO0284GJ?25R3Z6nLRIc0N\\O8080610R3[6oLoHa0P1\\OF11S3[6dMVIXO20h01ES3[6nLnHb06^OX1NZOT3[6mLnH30N134NR2Q3k4mLoH2OO2220;MU1T3]5SMoHJ231NOOMO8O]1W3[5QMQIJ230N044I^1W3[5QMPIL13OJ751J`021P3WOQMQ7:oHE146Li0NRO4g0n2WOQM1Mm6a0TIDS1MlN002h0n2WOQM0Nn6e0ZJ\\OjN0N2j0V3T6\\MYJ[OmN4i0R3SOjLn6d0cJ]O]OT3TOjLl6d0eJ\\O\\OV3SOjLl6c0WI^O7OL00020e0U3TOkLk6a0XIB5MM0O11Oi0o2POSM3Nj6`0WIF4KN00000j0n2X6^MQID3O41BOO2n0n2X6[MSJEhN1N100o0m2Z6ZMQJHhN0N100o0m2Z6XMYJJ]N6Q1f2]6WMgHOV15Ge2\\6WMgHOU15Ie2[6WMhHMU16If2Z6XMUJ1Bg2Y6XMhHKT17Kf2Y6XMgHLU15Lf2Z6XMeHMV13Lh2Y6WMfHNU12Mi2Y6VMeHOU12Mh2Z6WMeHNS120i2X6WMeHOQ113h2Y6WMcHOR122h2Y6WMmI2Jg2Y6WMmI0Li2k7VMVHj2Z9O1O^NZMXHe2h7\\MXHd2f7]M[H`2cN\\Mh72YI1=`2cN]Mg71ZI1=e2Z6ZM[IO<g2Y6ZMPKb2TM_M]10m7a2fF_MZ14o7]2hF^MY15X6JSJb2]N^MZ15mNKn60^Ja2^N_M\\12iN0n6N_J`2_N`M\\10hN3e8]2UGbMh11S7]2UGbMh11S7]2jHaM_N3l6LfJ^2XNdMd11`N2n6LeJ]2YNeMc10bN2^8LbG]2KeMc11aN2^8LbG[2MfM0M]16fNNML`82cGZ2OeMOOX1;iNFl8[2TGeMN0Y1:iNEm8[2TGfMM0X1:kNE22`8X2]GhMOOV1:UOKD4T8P2nGgM00T1<lND3c0n7f1UHgMn0>jNC3c0P8e1UHgMm0?jNC2e0f5XOaLZ2oMhMo0b0kN5d5XOcLY2oMhMo0b0kN5c5YOdLW2ZOWN^NA3g0n7a1oGgM^12bN6`0<`7d1QHhM\\13cN4d0:\\7f1cIkM]N5e0:o4_OdLV2\\OkM]N7d09c1_OP10POU2WOkMcN4M4g09a1@P1OQOT2cNmMDd07Ma1_OoM0Q5Q2fKPNWOO2d0O[O52F`0V2@oM0Q5o1jKXNTO=>ZO@b0T2@oM0R5m1kKZNnN`0b0WOAb0Q2APN0S5k1lKVOH]OX1CQNMT5l1mKVOJnNQO9R2J^3i1eKVO3SOf01b3e1gKVO2TOd00W1KUOj1POVO2UO9M^N2R3MTOh1ROWO1VO77b1FROe1VOXONXO56e1GPOb1YOYOJQOhN8Z19l1CnNa1[OZOHoNlN<T11iNHV34jL20F50T1e17[OGoNmN>m01ROER3o0iMPOVOb1^1\\OL\\OA2VODQ3P1fMQOXO`1`1ADkNkN:i06[O@90E0[2R1XNVO[O\\1c1AcNkNl0:A73@[O5b0Kl0R1SOWO^OZ1c1@2oNlN=\\OAi01YO5c0Ml0P1mN[OET1d1A3lNXN1009<d0ERO6c00j0P1iN[OKo0g1A5oNRN17<i0Bi1R2YM^Oi1ZOWNWO2Nk1g0WN[O^3Q2^L]Oj1ROTN@?Nn00TOf0D]O`3o1]L]Ol1mNl0<YM[Ob3o1]LVNNl0o1WOf0E_Mi0OXOd3P2[LWNNk0Q2VOSOHlN?S18l2X1SL\\OQ2jNROg0EUOYO4ML1Oc03]ONS3m1nL]OR2fNSOl0CTO<8o1d1mL]OS2gNROl0CSO=8o1e1lL\\OU2gNQOl0BTO>7n1f1lL[OW2gNPOl0AUO=7P2f1kLZOe3BRMYO<5T2d1iL\\Of3XOZLFg0M^OMd08`2c1hL[OV5jNiJ4S12W2f1fLYOW5lNiJ3T11V2g1fLXOW5oNgJ2S12[2d1dLXOV5^OiJA`0;P3\\1bLYOW5CQK]OF;a3\\1aLXOZ5BTKGT3^1^LXO\\5ZOcJIa05S3`1]LXO`5UOaJM=7V3_1\\LVOa6ZOVM_1YLkNMGd60WM]1YLkNLHS6I[JNe3f1QLkNLFT6M_Na1bKkNKFV6KSJ0IOS4e1PLRO]6@cM]1PLnNK@d64bM]1PLnNP;R1PEnNQ;Q1oDoNQ;Q1oDoNR;P1oDoN^6AlM_1fKoNY6AeI0\\4`1fKoNX6CeIN]4`1gKnNS;Q1mDPOS;o0mDQOT;n0mDQOS;o0mDROS;m0mDSOS;m0mDTOS;k0nDTOR;l0nDTOS;k0nDTOR;l0nDTOS;k0mDVOR;j0oDUOR;j0nDWOQ;i0oDWOR;h0oDXOP;h0PEXOQ;g0oDYOQ;g0oDZOQ;e0oD[OQ;e0PEZOQ;e0oD\\OQ;c0oD]OR;b0nD^OR;b0oD]OQ;c0PE]OP;b0PE_OP;`0PE@Q;?oDAQ;?PEAo:?QEAP;>QEBo:=QECo:=QECP;<QECo:=QECo:=RECn:<REDo:;REDn:<REDo:;QEEP;:QEFn::SEEn::REFn::REFo:9REFo:9QEHn:8SEGn:8SEHl:8TEHm:7SEIm:7SEIn:6REKm:5SELn4C4`0oJLm4D4`0oJMl4C6?oJMk4D6?oJNb4EeJMl5?nJNa4He09jJ0_4If07kJ0_4Ig06jJ2^4Hi05jJ3\\4Gk06iJ3]4Fk06hJ4]4El07hJ3\\4Em08gJ3\\4Do08eJ5_3BeK2>Oi58eJ5^3DeK0>2i54gJ6[3EgKO>3h53iJ5Z3FgKO>3i52hJ6[3DiKO<5g52jJ6Y3ClKO;6e52kJ6Y3D`L4[52mJ6W3E`L4\\50nJ6V3FaL4Z50oJ6V3FbL4YOJh55XK7T3FeL4SOMk52ZK6S3GfL;l4H[K6S3HeL:m4H[K6S3GgL:k4I\\K6P3GnL7e4L]K6P3FVM1\\44^K6n2EXM2[44`K4m2EYM3Y45aK4l2C\\M3T49eK0k2D]M2R4;fKO_4EZJO\\5>kKNo2EZMOk3?mKLn2FZMOj3`0nKJo2Gf2`0\\JHn9:RFDo9=RFBP3J_2e0aJ@P3L^2e0bJ_OQ3K[2h0eJ\\Oh9f0YFYOg9g0YFYOe9i0[FVOe9k0[FUOd9l0\\FTOc9m0^FQOa9Q1^13N2O1N2O1N2O1N2O1fI`N?a1h52gI]N?e1g51N2O1iIXN`0j1_OWNnMNcL=m1_1Y7WNlF0k1j1e91N2N2N2O1gDkMQ;W2oDiMo:Y2_JhM0Z20fMN\\23cML^2d51WJaM<`2^J`Mo42`0`2aJ^Mo43>`2cJ^Mn42=b2eJ\\Mm43TKLQ5g2nJZMl41XKNm4h2oJYMk43XKLl4j2QKVMl44:h2jJTMl43:j2jJSMY:o251N2N2fElLT:T3lEmLR:T3nElLR:T3nEkLR:V36000O100nJiLGW37mLFT3]50jEhLo9Y3QFgLf10h02eMOo4Y3nJfLY43S1W3POkLVLLR4Y3HjLR1V3nNgLkK0k4Z3UOfLPL1FOU5Z3UOfLPL0HOR5\\3BfLd0Z3]OdLc0]3iJcLQ40c1]3\\JcL`30kL0I1OOl4^3XObL[1_3eNaL[1_3eNaL[1_3[NbLVLO_5_3QNaL`L20N_5_3[NaLWL0]5`3]40O1SF`Lf9`3ZF`Le9a3[F_Le9a3[F_LP4O_1b3aJ^Lf9b3ZF^Lg30Q2c3XJ]Lg30P2d3YJ\\Ld9d3\\F\\Ld9d3\\F]Lc9c3]F]Ld9b3\\F^Ld9b3\\F^Le9a3[F^Lf9b3ZF^Lf9b3ZF^Le9c3[F]Ld9d3\\F\\Ld9d360VF\\Ld9d3\\F]Lb9d3^F\\Lb9d3^F\\Lb9d3^F[Lc9e3]F[Ld9d3\\F\\Ld9d3\\F\\Ld9d3\\F\\Ld9d3\\F\\Ld9d3\\F]Ld9b3\\F^Ld9b3\\F^Le9a3[F_Le9a3[F^Lg9a360001OO100SF_Lg9a3YF`Le0OV8a3UG`Ld00W8`3UG`Lg9_3YF`Lh9`35100O1N2N2XFZL\\9l3dFULo8W4QGiKh8^4XGaK_8i415K5E;J6@`0M3J6oHcIh6`6XI`Ig6a651O1O1M3O1M3M3M3TOl0N2O1N200N2O1N2N2O1O1N2O1O100001O001O00oJcGl4\\8TKdGl4\\87O^OeGlKZ8T4fGlKZ8h4O2N001O1O1O1O001O0000001O00001O00001O001O000000`JSHZ5l7fJTHZ5l7fJTHZ5l7fJTH[5k7eJUH[5k7eJUH\\5j7dJVH\\5j7dJVH]5i7cJWH]5i7cJWH^5h7bJXH_5g7aJYHa5e7_J[Hc5c7]J]Hb5d770O1UJ"}}, "object_label": "bed", "attribute_label": ["cleanliness:clean/neat", "transparency:opaque", "pose:horizontal/lying", "state:covered"], "control_dims": "pose, state, cleanliness", "answer": "The bed in the image is a large, white bed with a red blanket. It is covered with a white sheet and a red blanket, giving it a cozy and inviting appearance."}, {"question_id": 902, "height": 396, "width": 640, "image": "000000084241.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "color, material, size, transparency", "region_anno": {"bbox": [305.63, 171.1, 48.06, 29.37], "segmentation": {"size": [396, 640], "counts": "Z`f37S<5L2O0O2O3M3L2O1O001O000000O1M3000O201N1O001O00000000000000000001N100O1O2O0O1N2L5M2O1O2N2N_V_3"}}, "object_label": "bowl", "attribute_label": ["color:white", "material:ceramic/brick/porcelain", "transparency:opaque", "size:small/little/tiny"], "control_dims": "size", "answer": "The image features a white bowl, which appears to be made of ceramic or glass, being held in a person's hand. The bowl is placed in the center of the scene, and the person's hand is positioned around it, giving a sense of the bowl's size and shape. The bowl is likely being used for serving food or as a decorative item."}, {"question_id": 903, "height": 403, "width": 640, "image": "000000085911.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, material, size, state, transparency", "region_anno": {"bbox": [193.51, 168.72, 247.2, 110.8], "segmentation": {"size": [403, 640], "counts": "TW\\23\\<5G8I6I8D<A`0C=F:NM4G9N2O10000001O0O10001O1hEnMm9S2PFPNo9[2O0000O1000O10000000001O0O100000O1O0100000O10000000000000O10O10000000O10O100000O10000000O100000O01N2O100O010001O00002M2O001O0000O0100000000O10000O100000000O1000O100000O100000000O10O10000000O100000000O1000000O010000000O10001O0O1000O1O10000000O100O10000O10000O1O10000001O001O1O1O2N1O1O1O1O2N001O1O2N1O1O1O1O1O1O2N1O002N1O1O1O1O1O2N1O1N2O2N1O001O1O1O1O1O2N1O1O1O1O1O1O1O1O2N1O1O1O1O1O1O1O1N2O1O1O1O1O1O2N1O1O1O1O1N2O1O2N1O100N102N002N1OhVa2"}}, "object_label": "kite", "attribute_label": ["color:red", "color:white", "material:paper/cardboard", "transparency:opaque", "size:big/large/giant/huge", "state:wet"], "control_dims": "material, color, size, state", "answer": "The kite in the image is a large, white, and red object that has been washed up on the shore of a lake. It appears to be a broken kite, possibly damaged by the water or the wind. The kite is lying on the ground, partially submerged in the water, and is surrounded by a body of water."}, {"question_id": 904, "height": 431, "width": 640, "image": "000000186345.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "color, length, pattern, pose, transparency", "region_anno": {"bbox": [32.15, 61.97, 57.03, 89.37], "segmentation": {"size": [431, 640], "counts": "_b=2Z=7K1L4O1O1cCDf;<TDNi;2TD2l;KTD8l;GRD<n;CQD?n;b0O0]OoNiDQ1S;UOkDj0S;[OgDi0U;j0O_OREdNk:\\1YEbNf:^1\\EaNc:_1^EaN^:b1cE^N\\:b1\\EWN07d:a1\\EYN06d:a1[E[NO4g:`1[E[NO5g:_1YE]NO5g:^1[EkNf:U1ZEkNf:T1[EkNe:U1]EiNb:8XE56Bc:8YE46Ab:<YE19]Ob:a0VE1`;OaDO`;0cDM^;3cDJ^;8cDD^;=eD^O];b0eDZO^;d0h000O1O3N8G2O000O1O1000O01O1N1OdjW7"}}, "object_label": "kite", "attribute_label": ["color:orange", "color:yellow", "length:long", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing"], "control_dims": "transparency, color", "answer": "The image features a large, colorful kite shaped like a yellow fish. The fish kite is flying high in the sky, with its fins spread out, giving it a unique and eye-catching appearance. The kite's design is reminiscent of a whale or a dolphin, making it an interesting and playful sight in the sky."}, {"question_id": 905, "height": 500, "width": 375, "image": "000000087244.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, length, pattern, state, transparency", "region_anno": {"bbox": [227.72, 63.43, 34.98, 23.57], "segmentation": {"size": [500, 375], "counts": "Yl_3?R?4O000000000000001O000000000000000000000000000000000O1000O1O1N3FkSg1"}}, "object_label": "bench", "attribute_label": ["color:black", "length:long", "transparency:opaque", "pattern:striped/lined/pinstriped", "state:empty"], "control_dims": "transparency, pattern", "answer": "The image features a black bench with a metal frame, located in a dark room. The bench is positioned in the center of the room, and it appears to be the main focus of the scene. The bench is surrounded by a few other objects, including a book and a cup. The book is placed on the bench, while the cup is located near the right side of the bench. The overall atmosphere of the scene is somewhat mysterious and intriguing."}, {"question_id": 906, "height": 640, "width": 480, "image": "000000088432.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, length, material, pose, state, transparency", "region_anno": {"bbox": [169.5, 78.47, 25.75, 46.99], "segmentation": {"size": [640, 480], "counts": "a[Z3:Wc0`0M3M2O10000H8K6N1N2K50001O08H001O0mN`]Of0ab0YOa]Oe0_b0\\Ob]Ob0^b0^Oc]Oa0^b0]Oc]O:N^Obb08a]OKN2kb0OY]OOO0Vc05f\\OLYc04g\\ONVc02j\\ONWc01j\\ONYc0MUm^5"}}, "object_label": "traffic light", "attribute_label": ["color:yellow", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "state:on"], "control_dims": "length, color, pose, state", "answer": "The traffic light in the image is a unique and interesting design, featuring a yellow pole with a large number of yellow traffic lights attached to it. The traffic lights are arranged in a circular pattern, with each light facing different directions. The traffic light is located on a street corner, and it appears to be a multi-directional traffic signal, ensuring that drivers can see the signals from multiple angles."}, {"question_id": 907, "height": 640, "width": 480, "image": "000000088432.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "color, length, material, pattern, size, state, transparency", "region_anno": {"bbox": [6.86, 266.39, 296.14, 134.1], "segmentation": {"size": [640, 480], "counts": "QS43mc0000SO8^]OMWb0S1BmNj]OY1Qb0=O1M4M2APNm^OR2Qa0oMo^OQ2n`0RNR_On1n`0SNl^OR2Ta0=O100000O1000000000O100000000000000001O000bMl^OLOJ1m1Ua0jNk^OU1Ua0kNl^OAMY1_b0YOa]OI^[h0_OddWONUc04j\\O=Ub0_Ol]O24Y1ha0e0O1O1O101O@V^OkNia0U1W^OkNia0U1W^OjNja0f101O1O0000000000O1M32N1O1O3M2N1OiN^^OQO;`0Sa0=[_OoNWO=]a0e0`_OmNTO8]a0l0b^OmNl07b`0Q1b^OgN<e0Qa0Z2A1O0000003M0O1000N2O1O1O1M0=A7L4N2N2N1O001O1O0O2O000010O00000000000000000000001O000O10O10O1O1O1O100O1O1O1O1M3J6K5K5N20000000000001O00000000001O0000000000O100001O0001O000000000001O3M1O001O00001O000000010OO1O1000000O100O1N3N1O1O1O1O2O00001O1N2O001O1O1O1O1O1O1O1O1O1O1O1O2N1O1O1O1O2N7QNn]Ob1Uc0[NQ]O5\\V66m\\Jc0d\\OVO13Sb0j1F1N1O1O1O1O00000001O01O1O0000000001N100000000O2O0O2N1O1O1O1O1O2K4VOk0@cf]3"}}, "object_label": "truck", "attribute_label": ["color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "size:big/large/giant/huge", "state:off"], "control_dims": "material", "answer": "The image features a large truck driving down a street, passing by a bus stop sign. The truck is positioned in the middle of the scene, occupying a significant portion of the image. The bus stop sign is located on the left side of the truck, and there is a traffic light visible in the background, further down the street."}, {"question_id": 908, "height": 480, "width": 640, "image": "000000091654.jpg", "category": "description", "question": "Describe the spoon in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, texture, transparency", "region_anno": {"bbox": [1.08, 0.0, 211.41, 235.15], "segmentation": {"size": [480, 640], "counts": "0R2n<001O10000O100O010000000O01001O00O01000000O10O01000000000O010000O10000O10O1000O10000O10000O10O10O10000O10000O10000O10000O10000O2O000O102M1000001N100O2O001N101O1N101N10002M2O00001N3N1O1N2O001N2O1N2O1O3M1N3N1O1N2O1O1N2O1O1N100O2OO0010O0001O1N2O00001O001O001O1O001O001O001O1O001N101O1N2O001O0O2O1O001N2O1O1O000O2O1O1O0O2O001O1O1N101N2O1N101O0O2N2N2N1O2N1O2N1O2K^CjMc<U2]CkMc<R2`CnMa<P2\\CSNe<j1]CWNd<g1\\CYNf<d1XC_Nj<_1WCaNj<j11N2O0O2\\OQCUOP=j0oBWOR=e0oB\\OS=c0lB^OU=U12WOiBGX=8gBH[=6fBH]=i05M3VO[B6f=a03J5M3N4L3L4M7HZ]Y6"}}, "object_label": "spoon", "attribute_label": ["cleanliness:clean/neat", "color:orange", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, length, transparency, cleanliness", "answer": "The spoon in the image is an orange plastic spoon, which is placed inside a bowl filled with soup. The soup appears to be a noodle dish, as there are noodles visible in the bowl. The spoon is positioned in the middle of the bowl, ready to be used for eating the soup."}, {"question_id": 909, "height": 640, "width": 640, "image": "000000088848.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, material, pattern, size, state, transparency", "region_anno": {"bbox": [323.29, 391.48, 264.37, 167.31], "segmentation": {"size": [640, 640], "counts": "Wb[623501S18nNBN0`?^1_@C;nNH0O23V1o>\\1UA^MG0220V1i>b1^A[MGO0U1k>a1`AYMF0OU1l>c1bASME30U1i>e1iATM_Ol0NXOk>h2aASMG1Nm0NXOk>h2aASMG1Nn0NVOl>h2aASMF3Ok0NWOl>h2aASME41i0MXOl>h2aATMD41h0NXOl>h2aATMD41h0NYOk>f2cAUMB52P1i>g1bASME6Og0OYOk>g2kAUM[Ok00WOk>i2kATMZOl00WOj>j2kATM\\Oj0OXOj>j2kAUM[Oi00XOj>j2lASM[Ok0OXOk>i2kATM\\Oj0OXOj>j2kATM[Ok00WOj>j2kATM[Ok0OXOk>i2kATMZOT1k>h1lARMZOn0NXOl>g2SBoMSOXOi>j2UBmMROYOi>j2UBmMQOZOj>i2UBmMPO[Ok>h2UBTNm=k1TBcMoNOm>_1WAkNn0FnNK1Gm>0RA20d12SOo07l=oNUA2N`11^Oo02m=nNUAi2P1WNk=n1UBPNl=Q2SBkMQ>U2oAnMn=Z1QA_NQ17n=S2QBmMo=U2ZAPM7OBg0n>c0RA:4_N7NGd0m>[Oo@W1280aN17`0`0]>YOQAV1181bNO:>>`>XOPAW1280QO=7b>n2aAlL`>T3`AlL`>Dn@Y33bL9`0f>Do@Z31cL:`0e>CQA`38nLi>]ORAe33PMR?Q3f@^L1a0Y?P3g@WMY?h2i@WMW?e2f@bL3i0V?f2i@_L8c0P?n2TARMh>^Ok@_3>SMf>_Ol@j0Of1>RNl>8f@f1>hMBNZ?b0i@g10bM35MOW?c0i@h1NdM320NV?c0i@j1NdM23NNX?a0i@k1NdM0`0Y?Q3RA[LF3W?b3VAYLD5V?b3]A\\Ld>^3i@]Le05b>]3cAcL^>\\3bAdL^>\\3i@_Le04b>]3h@`Lf03b>^3g@`L?OD3V?d3TA[LD2X?`0h@X2>UMC3X?>h@^O0e2e0^Md>?g@^O0d2f0_Md>?e@_O0d2f0]Mf>`0d@Z2d0WMi>>d@AMe21YMa02Q?;e@^2:VMT?:b@`2;UMT?:b@[2I[M:0H0d?:`@Z2:]M\\?8\\@Z28]Mb?3Y@]2_`0`Mb_O`2]`0aMe_O]2[`0cMf_O\\2[`0cMW_O09\\2f`0eMZ_OZ2e`0hMZ_OX2e`0jM\\_OU2_`0fMU_O6<b1EfNj`0BU_O71I6h1IfNl`0AV_O>2l1m`0UNQ_Oj1n`0XNR_Og1n`0XNT_Og1o`0kMS_O00S2Ya0lMh^O1J51Z1ba0_Nc^O2J0O03^1ka0gNR^OL1f0OMPa0[Ol_OU1WO]Oo`0]Oj_O1ZO;JG1539_b0@b]OO120=Zc0OO10000H80_Oi\\O8Xc0Cm\\O>Zc001Fa\\O0Qa0Mj2O[\\O1fc0O1O[e51WT^3"}}, "object_label": "boat", "attribute_label": ["color:green", "color:white", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:dotted/speckled/spotted", "size:big/large/giant/huge", "state:full/whole"], "control_dims": "size, pattern, color, material, state", "answer": "The boat in the image is a large green and white paddle boat, which is likely a tourist attraction or a riverboat. It is carrying several passengers, including a group of four people who are posing for a picture on the boat."}, {"question_id": 910, "height": 480, "width": 640, "image": "000000180383.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, material, maturity, pattern, pose, state, texture", "region_anno": {"bbox": [25.83, 51.34, 597.12, 368.49], "segmentation": {"size": [480, 640], "counts": "bT?7h>2N2I6O2N1O2N2N2N2O1N2N2N2N2N1O1O100O1O1N2O1N2O]OcBE\\=P1O100OCdBXO[=i0hBPOMMY=W1gBQOX=\\1\\NZNmEg1o9aNkEX1fNbNOOa;9fEX1oN^N[;;cEY1QO]N\\;=_EW1UO\\N];<]EZ1TO[N_;<[E[1UOYNa;=WE[1XOYN`;=WEZ1XOZNa;=UEa1l:^NSEc1m:^NQEc1P;]NnDc1S;^NlDb1T;_NjDb1V;^NhDd1Y;\\NeDe1[;[NeDe1\\;[NbDf1^;[N`Df1a;YN^Dh1b;YN\\Dh1e;YNYDg1g;i000001O0001O0001O00001O01O000001O00001O0000001O00001000O2O0O2O0O10000O3N0O2O1O0O3N1O100O002N1N2O1N1O3M2O1N2N1O3N0O4M1N3M3M3N2M2N101N2N101N2N1O2O1N1O2N1O2N1O2O0O1O1O2N1O100O1\\J`Jf1a5WNaJi1`5UN_J\\LN_5c5SN`J_LL^5e5RNdJl1]5SN`J`LL\\5e5RNdJn1]5oMeJQ2\\5lMfJT2Z5lMgJT2Y5jMhJV2Y5gMiJY2W5eMkJ[2V5cMlJ]2S5bMmJ_2S5_MoJa2R5]MoJc2Q5\\MQKc2o4\\MSKc2n4ZMTKf2l4YMTKaMROn4j5`MUKbMQOo4i5]MXKdMPOn4i5ZM[KdMkN0OR5k5VMhKj2X4TMdKiMcNT5j5oLlKP3W4iLnKV3W4cLkK]3\\4ZLgKe3\\4ULgKk3]4oKeKQ4a4]KXIC_2P5P7oJkFQ5b901O000000]OPKVGP5j8PKVGP5]900O10000O1000DSK^F02m4`9SKeFm4g900O01O1G9N2L4N2O1O1O100O1L4D<[Od0F;J5M4L4L4L4I7J7J5H8E_GTJd8k59O100O2N100O100O1000000O101O0[KlFRO4LQ14WONEj1T9kNnFYOd28_MP1Q9\\O`I@XM67m0R9UOhHHPN0;`0Kb0W9lNVHO`Nf0OZO10J208=g0l:POhDo0OPOb0OA0`0n0X:SOWEO16Nk0OPOQ1OXOm0o8UOXHObNO1Z1MgN\\1l0l7VOmFNj02TO3NX1[1_Ol7VOlF22K3`0GH0W1[1^Oo7V1fFUN1N24NHZ1k0P8k0eF`N1JO07NN7NLNMP10SOm0X9BdFI001O0O2O3L:3EOU1j0i7SOUG5J02M2O11;N84[OOU1k0h7TOSG5LMh0N^OO00c03[OOU1k0h7DkGBVO101NK6O48GMU1i0k7DhGFVO?5\\OLM59KLU1j0l7DoF]O:]1GhNOL0;1IT1j0l7VOoFS21`N0]OT1j0e7QOZGa2KXN2\\OS1k0e7QOZG]3LeL0NU1o0e7QOZGn2LTM050J1OT1o0e7QOZGf2N]MN90F0NT1P1f7POZGf20ZM18LJU1n0d7POZGf2O[M35W1k0\\7oN[Gm24WMU1m0\\7oNZGn26UMT1n0\\7POZGm25UMT1o0]7oNZGm25UMT1o0]7oNYGn26TMT1o0]7oNYGn2NRM33X1P1\\7nN[G`2OgMO2[1j0[7mN\\G`2OgMO2[1j0[7mN]G_2NhMO2[1j0R2jNj13lJ_2NUN[1?Z7mN\\G`2ObMO;\\1f0Z7mN\\G_21aMN<[1h0Z7lN\\G_21bMM:]1i0Y7lN\\G_20SNZ1c0Z7kN\\G_20UNX1a0\\7kN[G\\3X1jM\\7jN\\G\\3W1kM]7hN^G\\3U1lM]7hN^G\\3U1mM\\7gN_G\\3T1nM^7eN^G]3T1nM^7eN^G]3T1nM^7eN^G]3T1nM]7gN^G[3T1PN]7dN`G[2NaNU1`0]7dN_GZ22aNR1a0]7dN_GZ22aNR1a0]7dN`GY21bNR1a0]7cNbGY2OcNR1a0d7l0ZGdNR1`0b7k0^GfNo0`0c7i0^GhNo0?b7j0]GiNQ1>a7i0]GjNR1=b7h0[GlNR1=d7b0XGoM1S1S1<d7b0YGnM0U1R1<d7d0[GPOQ1<e7b0ZGSOQ1;d7a0]GTOo0<`7b0bGROn0<_7b0cGSOn0;`7b0aGSOo0;`7b0aGSOo0<`7`0aGTOn0=b7:\\GRN4X1m0=_7ZNcGT1O]ONA2N1Z1n0<d7^O^G@3h0j0:c7ZN^GR14B0h0k0:b7B_G^O4m0d03g7<dGDd00h7<cGFd0Og7<eGEd0Of7=eGEe0Nf7=dGFf0Mf7]NcGe152KVNc0h1i7[NeG=2a02i0KWN7O1h1S8]NgG82e0Om0?Ii7]NgG82DLm03P1`0Kf7^NhG62i2a0cNe7kNhG[O3U3MkLb0j1f7WNgGa06d2`0eNb7]NhG37j2?fNb7\\NjG3OI0S3d0eNc7\\NjG3OT3b0]Nd7]NjGe36SL2l1m7\\NkGe36TL1k1n7\\NkGe36TL1k1n7\\NlGc3a0QNc7\\NkG12R3c0aN`7VNjG3043R3c0aN`7VNjG>7f2?gN`7UNjG3037P3?dN`7VNkG2O46Q3`0cN`7]NjG02R3:eLLm1n7UNjG30c3;ZLKl1P8[NjGZ32]L:2Jl1P8[NjG[3?^LGm1o7ZNkG[3>_LIk1n7[NkGZ3`0_LFm1o7SNkG`00A0j2e0SMBo1n7SNlG>1A0j2m0TOV7SNlG?0_O3k2j0TOW7SNmG1N87`2<VMEn1m7SNkG30;2[2b0WMBn1n7RNlG30;0]2d0UMBn1n7RNlG30;0B1f2c0[MAm1o7YNlG70]2d0VMAm1o7YNlGW3b0dLCl1o7YNlGV3d0cLBn1n7RNlGj00VO1;1INK2d1c0[NBP2m7RNlGi02UO12M5`0^1>;V7RNlGi0=ZO4_1=<V7YNlG;V1P1\\O^NEn1m7YNlG;:DKIK16b1<_NDm1n72PH@7^NK30m1n73oG_OM_N80M30l1o7YNlG`12K7\\NM4Ol1o7YNlGa10Ka0_NDm1n7XNmGc10Fb0bNCl1o7RNlGQ21]Oc0bNBn1n7RNlGQ22\\Ob0cNBn1n7RNlG30g12Ca0dNCm1n7YNlGc13C?dNDm1n7YNlGc13C?dNDm1n77PHVO?gNBl1o77PHVO`0fNAm1o78oGUO`0gNBl1o7YNlGd13ZONmNa00Cl1o7YNlGd14_O`0gNAm1o7RNlGQ26XO?gN@n1o7QNnGQ24oNJWOe0K_Om1P8RNmG2Ol12[Ob0iN@l1P8RNnG1Nm12[Oa0jNAk1P8<mGoNb0jNAk1P8<nGnNOfN?5Dk1P8<nGnNNgNa03Cl1P8<oGPO=iNDk1Q8;nGPO>jNCj1R8<mGnNb0iN@m1P8RNlGf00U2m0ROX7SNlGd04_1JXN1Gm0k1X7TNlGc0Nd10SN1Gm0k1X7TNlG[30fLl0j1Y7g1jG_Lm0j1Y7nNiGl11\\Mm0i1Z7oNhGl11[Mn0j1Y7h1iG_Lm0i1[7g1hG`Lm0h1[7j1gG^Ln0h1[7WNgG50Q30jLo0h1[7XNfG51T3n0_N[7XNfG51T3n0^N\\7bNeGR3n0\\N]7P2dHPN\\7YNeGc3o0TN\\7YNeGc3f0[LBh1S8ZNeGc3P1RN\\7R2eHmM[7\\NeGb3P1RN[7\\NeG]31aLP1f1Z7\\NeG40g2OUM2O0OP1f1Z7\\NfG3Oh2OUM2N10o0f1Z7\\NfG3Oh2OUM2N10o0f1Z7\\NfGR30mLO11NP1f1Z7[NgGS3ORM0JP1f1Z7[NfGU3OPMU1_1W7\\NfG^3R1VNX7\\NgG0MZ3T1XNY7^NfG]3R1UNX7^NgG2Lg1O[O1mNU1a1Y7]NgG30OLOO11OO114OL0010N02OO115N10K0OV1e1b7\\N^GO00LOO114OL001OO16OK6N10OV1`1l7\\NTGO1NN5K22JO16NOg0P1o0n7\\NRG0LN020>0AO1?d0g0n0_7_NdG4G00?0\\O00;OE`00AX1^1_7cN^GNK6000?0\\O1O91G>0AX1]1`7cN[HOnN001Q1;;R1]:bNfE4^NS1g:lNTFNk03[NS1c8jNaHORO7IW1b1dNaNT1`8mNWHO[OV2MkMS1OnNR1b8PO_Gc4M^Lc8U5000O010O01O01000O010O10002N1O1O1O1O1O2N1O1O2N1O100O001O`JmGT4S8kKmGV4R8\\101O1O10O0001O010O1O1O1O5L3XHjH^7`7L3M0001N1O1O1L4M4M2M3N2J6L4O1O1O1O10001O000O10000000000000hJ\\I]M1V4b6[NaI\\MOX4`6YNeI^MLX4_6ZNfI_MGY4d6WNgIU2Y6lMfIT2Z6fM\\I^M9l4[6dM`I^MNN3P5_6cM`I^M8n4X6dMSJY2m5dM^I_Md0m4V6ZMXIjMa0l4Z6VMVIoM`0k4Y6UMXIoM?m4Z6PMZIRN<o4Z6mL[IUNIO41L0Mn4o6jL_IWNM0JR5j6cLoI\\NWOQ5j6`L]J]3c5XLRIjNd1l4_5nKlJR4Q8000O1XORKZG0_Oo4W9QKkF09S5l8mJYGT5Y901O3M0000[OPKZGP5f8PKYGQ5X93ASKfFS5W9<L4N2O2N1M3N3ROm0\\Oe0I73L2O101jJiHdM0`4Y7iMhHfMOb4Z7ZMfHWN1MOc4[7TMiH[NMM0e4[7mLmH`NHOOd4h1[KXN6Q5T1]KhNBn4b1iKi1SOUNU1SOQO]On4]1QLb3HiKYOXOo4Z1XLf1cNlN?SOGQOP5W1]Le1\\Nd06`L10f4U1oLT5ZNhIO0h4P1YM\\1kMU14`LN1k4m0ZMY1kMY1O]LO303n4i0]MT1iMb1M\\LN124m4j0^MP1hMf10]L0Ok4Q1[Mh0jMn1O\\LU5o0PMc0oMS2L[LV5T1iL<WNU2J[LV5\\1bLKfN^2BZLY5`1ZL]NZNO1S1a0g2A[LY5i1[LUNYN>0Cc0g3\\O_L0IW5T2SMiM\\N\\4b4`NkJbM:FG9`0n3e4^OhJ^LO:f0^3ZOTL^5d3cJ`LO:h0\\3n4]O^JhL03O9j0R3T5E_JmLF1OOS1S3o4KXJTMFON0_1g2o4`MkIg1ISNM111OMf1NXN]2`8_NdGXON01O2MU3j0_5M\\G\\ON12MU=d0kB^ON12MY=`0gBCN00N`=;aBGO00Oc=1ZBN6OU>2fAMf>2f?Nk>1Xc9"}}, "object_label": "cow", "attribute_label": ["color:brown", "material:polymers/plastic/rubber/styrofoam/polymer", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, material, pose, pattern, maturity", "answer": "The image features a large cow statue with a television mounted on its back. The cow statue is brown and white, and it appears to be a decorative piece. The television is positioned on the cow's back, displaying a news broadcast. The cow statue is placed in a room, and the television is turned on, providing a unique and interesting visual experience."}, {"question_id": 911, "height": 640, "width": 480, "image": "000000094871.jpg", "category": "description", "question": "Describe the sheep in the following image in detail.", "dims": "color, pattern, state, texture", "region_anno": {"bbox": [97.8, 411.42, 378.24, 218.61], "segmentation": {"size": [640, 480], "counts": "kTW27_c0c0@b0A9H7J4L4L5K4M4K3N3L4M2M2N3N2M3N4J6`_OfL1Ni?T4J3NC]@\\Lc?e3^@VLOMb?n3_@ULON`?n3a@YL^?o3b@kK\\?V4e@iKY?Y4g@gKX?Y462O2N2N4M2L3N2O1N2N4M1N4L2N3M1O1O100O1O100O1O1O1O1O10000O1O100O1O1O1O100O1O100O10000O1O100O100O100O1O100O100O1O100O100O1000000O1000000O100O10000O10000000000O10000000000000000000000000000000000O1000000000000000000O10000000000000000000000000000000000O1000000000000O10000000000000000O10000000000O100000000O10000000000000000000000000000000000000000000000O1000000001O0000000000000000000000000000000000O10000000000O1000000O10000O1O1O10000O100000000O01O100O100O1O10O10O100O1O100O1000000O100O1O1O101O0O100O1000000O101N1O1N3N1N3O001O0N3O1O001N101O1O001N1N3N1O1O2O0O2N2O000O2N2M2O2L3O2O1N101O1N2N1O2N2L3O2M3N2L4L3O3M1O2N2N2M3N2M4M2M3N3M2N2M3M3J6M3L4M4J5J7I7J6J7E:EZ]OSOn[6"}}, "object_label": "sheep", "attribute_label": ["color:brown", "pattern:plain", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, color, pattern", "answer": "The image features a sheep with a thick, shaggy coat of hair. It is standing on a sidewalk, possibly in a city or urban setting. The sheep appears to be a woolly sheep, which is a breed known for its dense, curly wool. The sheep is positioned in the middle of the scene, and there are several people around it, with one person standing close to the sheep and others further away. The presence of people and the urban environment suggest that this might be an unusual sight in the area."}, {"question_id": 912, "height": 480, "width": 640, "image": "000000097679.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, material, pattern, transparency", "region_anno": {"bbox": [103.45, 159.23, 417.8, 216.48], "segmentation": {"size": [480, 640], "counts": "`a`19e>7J3M2UOHkB;o<LgB<W=h0N2O001JWNRCk1l<501N101O1N101N101O00001N101O00001O00001O1O1O1O0O2O6J4L1N3N3L2N3N2M2O1N2N2O1N101N1O2N101N1O1O1O1O100O100O1O1O1O10000O001O01O10O010O01N11O0100O010O0O2KTETLn:n302O0O1O2oNoKQGQ4n8RLPGn3P9TLnFm3Q9ULmFk3R9WLlFj3T9VLmFi3S9YLkFg3U9ZLjFg3U9ZLjFf3V9[LhFf3X9ZLhFf3X9[LgFe3Y9\\LfFd3Z9\\LfFd3Z9\\LeFe3[9\\LdFd3\\9\\LdFd3]9[LcFe3\\9\\LdFd3\\9\\LdFd3\\9\\LcFe3]9[LcFe3]9[LdFd3\\9\\LdFd3\\9\\LdFe3[9[LeFe3\\9ZLdFf3\\9ZLdFf3\\9ZLdFf3[9[LdFg3[9ZLdFf3\\9ZLdFf3\\9ZLdFf3\\9ZLdFf3\\9[LbFf3^9^L^Fb3b9o0O00^K^Ff3b9XLbFf3^9ZLbFf3^9YLcFh3]9VLdFj3\\9VLdFj3]9ULcFk3]9ULcFk3\\9VLdFj3\\9VLdFj3\\9VLdFj3\\9VLdFj3\\9VLdFk3[9ULeFk3[9VLdFj3\\9VLdFj3\\9VLdFj3\\9ULeFk3[9gK_F56U4[9eK`F55V4[9eK`F55V4[9eK`F56U4Z9gK^F57V4Z9RLfFn3Z9RLdFP4\\9oKfFP4Z9PLgFo3Y9QLgFo3X9SLhFl3X9TLhFm3W9RLjFn3V9RLjFn3V9RLjFn3U9TLjFl3V9TLjFm3U9SLlFl3T9SLmFm3S9SLmFm3S9RLnFn3Q9SLoFm3Q9SLoFm3R9SLnFm3P9VLnFj3R9WLmFi3S9YLkFg3U9YLjFh3V9XLiFi3W9XLhFh3X9P10001O0001O000\\KeFc3[9ZLiFf3V9XLlFh3S9YLnFf3R9YLoFg3R9XLnFh3S9WLmFi3S9WLmFi3S9WLmFj3Q9WLnFj3R9VLoFi3Q9VLPGj3P9VLPGj3P9WLnFj3R9VLnFk3Q9ULPGj3P9VLPGj3P9VLRGh3n8XLSGg3m8ZLRGf3n8YLSGg3m8YLmFYOM_4U9XLnF[OK]4W9XLnF\\OJ\\4X9XLnFn3R9QLoFo3Q9QLoFo3R9QLmFP4R9PLmFQ4S9oKmFQ4S9oKmFQ4T9nKlFR4T9mKnFR4R9nKnFR4R9nKnFR4S9mKmFT4S9kKmFU4S9kKmFU4U9gKmFY4T9aKPG`4R9\\KPGd4f900001O`KQFo3P:kKkEO7T4n9mKkEO7T4n9SLPFn3Q:a0O00`KmES4T:lKlET4T:<000001O10O0010O0001O0001OO2O0000001O0010O2O1N3N0O2O0O2O0O101O0O1O10O01O1000O010O10O0001O100O001O10O01O00001O1O100O001O001O1O1O001O1O001N101O1N2O0O2O1O1N101N2N1O2N2N2N2N1O2N1O2N1N2O1M4M22O1O0O010O0001O001O0O101O00001O00001O0000001O001O0O10001O00001O001O00001N101O001O001N1000001N10000O2O00001N10000O2O1N2O000O2O1N101O001N2N1O2O1N3N0O2O2M3N2M3M3M4L3M2N3M2N1N3L3K7L5L`0^OXaf1"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain"], "control_dims": "cleanliness, color, pattern", "answer": "The image features a silver car parked on a dirt road or gravel surface. The car has a surfboard strapped to its roof, indicating that the owner might be heading to or returning from a surfing session. There are two people in the car, one sitting in the driver's seat and the other in the passenger seat. The car is parked next to another car, which is also visible in the scene."}, {"question_id": 913, "height": 386, "width": 500, "image": "000000507667.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, length, material, pattern, state, transparency", "region_anno": {"bbox": [120.41, 26.22, 30.38, 7.28], "segmentation": {"size": [386, 500], "counts": "VT\\11P<4L2O00O10O100000000001O00000O100001N1000000000000001O00000000001NPaS4"}}, "object_label": "bench", "attribute_label": ["color:brown", "length:long", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pattern:plain", "state:empty"], "control_dims": "length, pattern", "answer": "The image features a long bench situated in a grassy area, possibly a park or a field. The bench is positioned in the middle of the scene, with a large expanse of grass surrounding it. The bench appears to be empty, providing a comfortable spot for people to sit and enjoy the outdoors. The grassy area extends to the edges of the image, creating a serene and peaceful atmosphere."}, {"question_id": 914, "height": 476, "width": 640, "image": "000000258793.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [592.07, 233.19, 24.03, 13.66], "segmentation": {"size": [476, 640], "counts": "bnb86d>4M2O000O100O010000O10O100000010O000001O1O1O1O_\\;"}}, "object_label": "car", "attribute_label": ["length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "size, pose, state, texture, material, length, transparency", "answer": "The image features a silver car driving down a street at night. The car is positioned in the middle of the scene, and its headlights are on, illuminating the road ahead. The car appears to be a taxi, as it is driving down the street with its lights on."}, {"question_id": 915, "height": 427, "width": 640, "image": "000000110638.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pose, size, texture", "region_anno": {"bbox": [228.31, 130.01, 210.15, 213.02], "segmentation": {"size": [427, 640], "counts": "jdP32V=5M1N2O1hLH\\I9j91SMEhH=]7B^H?d7IoG;P8MfG5[8O^G3c8<hFIh7XOfHl0]O0i7^OiH<fNYO>P1Q8AiH_OjN54N2P1U88_HdN^O4FJOZ1Z8`0mH[NiNZ1W8f0lH_On6o0WH^MF3:`1e7T1YHaM0\\1e7^1ZHmLNi1g7[1`HgN^7^1ZHgLNl1f7f1YHZNf7f3N2L4O1O001O1N200O1O011N1O10O01O100O1O1000000O1O1OiNnHWLR7Q51O000O101hNnHULR7k3oHTLQ7m3nHSLQ7g3QI[KLn0R7f3TI[KKn0Q7f3\\IXLe6f3_IXLa6f3jIQLV6k3XJcKQ6[4`1O2M3O0N2M4O1N2N1M4N2N2O0M4N]HcL[5\\3^IlLSOH>8o6S3_IPNb6n1\\IUNe6i1ZIYNg6d1XI_Ni6`1VIaNk6]1UIeNl6Y1TIgNn6W1PIkNQ7T1kHPOX7WOVHmN0\\1a0a0Y7l0eHVO[7ZOXH1;f0Z7[O\\HO7i0[7YO`H_2_7TM\\HZO5a3a7TMZH_3f7S1001dKYHR3g7mLZHR3g7mLYHT3h7jLYHV3g7jLXHV3i7iLXHW3h7iLXHY2O`Mi7a3`H[L`7b3iHXLW7f3oHTLT7j3PIPLS7o3U1O100N3O0O1O1O1O2N100O100O1O100001O3[GVLc7n3WHULh7n3PHWLP8k3mGVLS8l3iGWLV8_40000000001O001O00000000YNeG^N[8b1eG^N\\8X3OYNiG\\NW8d1jG[NV8e1lGYNT8g1mGXNS8h1nGWNS8g1PHWNP8i1QHUNP8j1SHTNm7k1VHSNj7m1WHQNj7n1YHPNg7n1\\HRNc7n1^HPNd7o1^HnMc7R2_HkMb7U2bHTMXOO\\8l2e102N100O1001O1OO11O001OO0102N1O1O6J4oFgLg7_3]GWMb8i31O2N1O1O2N1O2N1O1O2N1O2N1O1O2O1N2N2lMeF3^9_OaGMe8nNeHg0V:I=C`mc2"}}, "object_label": "elephant", "attribute_label": ["cleanliness:clean/neat", "color:brown", "maturity:young/baby", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness, texture", "answer": "The image features a large elephant standing next to a smaller elephant, possibly a baby elephant. The baby elephant is standing close to the adult elephant, possibly seeking protection or comfort. The adult elephant appears to be a mother, providing care and guidance to the younger elephant. The scene takes place in a dirt area, which is a typical habitat for elephants."}, {"question_id": 916, "height": 480, "width": 640, "image": "000000289741.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "material, pose, size, transparency", "region_anno": {"bbox": [61.49, 453.8, 8.84, 23.32], "segmentation": {"size": [480, 640], "counts": "Xbl0;b>8K5J11O6J3M3N1N3L4MWXZ8"}}, "object_label": "handbag", "attribute_label": ["material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny"], "control_dims": "material, transparency, size", "answer": "The handbag in the image is blue and has a bird design on it. It is placed on a table, and the bird design is visible on the front of the handbag."}, {"question_id": 917, "height": 612, "width": 612, "image": "000000138954.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 0.0, 612.0, 612.0], "segmentation": {"size": [612, 612], "counts": "261b10`N10OO2M4M12N1KN214O1O:0F10Oj10[N1E01000000O10O100O2O41KO10N3Oc00]O0[7j2cHYMON2131KO15OL5O2N:0F10OW10nN0F20N0105O00MOO15Oi00RO100O100O06m0LWON:20N\\4a4TKfK5KL5O1082AO105O`93]F10N12N02M2OL<eT1DSSO0lM4^JNj11UN2N1O2Oj02k0a6UNSO0`JO;OV12]N2000:M05DO1OO21M119=ELNF051a001OYO0Q10oN1M21OOO3Oh01VOO26NL0O\\10jNO01_93iF^1BeNON4LM0150Oo4KY53TFOoa01Q^ONQb01o]ONRb02a0O000000000000000000ec0O\\\\O000_O1m]OOSb01m]OOSb01m]OOSb01`00iV1OXiN0gES1KmNjG0n7k1MVNTHOh7[2KfM]HOa7j2JVMa0T3ZOlLc0Y3[OgL`0d3Z75I;_HlKB[4KeK^I0d6b4J_KaIOa6j4JWKb0m4]OSK?V5\\OjJb0Z5\\OfJa0`5\\O`Jb0e5\\OZJa0l5[OUJb0P6\\OQJa0S6]OmI`0Y6]OgIa0^6\\ObIa0c6]O]Ia0g6]OYIa0k6]OUIa0o6^OPI`0T7^OlH`0X7]OiHa0[7]OeHa0_7]OaHa0c7]O]Ha0g7]OYHa0k7]OUHa0o7]OQHb0Q8]OoGa0U8]OkGb0X8\\OhGa0]8]OcGb0_8]OaGa0b8^O^G`0f8^OZGa0i8]OWGa0l8^OTGa0o8]OQGb0Q9]OoFa0T9^OlF`0X9^OhFa0\\9\\OdFc0]9]OcFa0a9]O_Fa0d9^O\\Fa0f9^OZFa0i9]OWFa0l9^OTFa0o9^OPFa0R:^OnEa0T:^OlE`0W:^OjEa0X:^OhE`0[:_OeE`0^:^ObEa0a:]O_Eb0c:]O]Eb0e:^OZEa0h:^OXEa0j:^OVEa0l:^OTE`0o:^OREa0P;^OPEa0R;^OnDa0U;]OkDc0V;\\OjDc0W;^OhD`0\\;^OdDa0];_OcD`0`;^O`Da0b;]O_Db0b;^O^Da0e;]O\\Da0f;^OZDa0h;^OWDc0i;]OWDb0k;]OUDb0m;]OSDa0P<^OPDa0S<]OmCb0T<^OlCa0V<^OkC`0W<_OiCa0X<^OhCa0Z<^OeCc0\\<\\OdCc0^<\\ObCc0`<]O_Ca0c<_O]C`0e<_O[Ca0f<]O[Cb0g<]OZCa0g<_OYC`0j<^OVCb0j<^OVCa0l<^OTCa0n<^ORCb0o<]OQCb0P=_OnBa0T=]OnBa0T=^OlBa0U=_OkBa0V=^OjBa0X=^OhBa0Y=_OgBa0Z=^OfBa0\\=^OdBa0^=^ObBa0`=^O`Bb0`=^O`Bb0a=]O_Bb0b=^O^Ba0d=^O\\Bb0e=]O[Bb0f=^OZBjMMb2k=CXBa0i=_OWBa0j=^OUBb0m=]OTBa0m=_OSBa0n=^ORBa0P>^OPBa0R>^OnAPNM]2U>CnAPNM]2V>BmAQNM\\2W>DkAa0V>]OkAb0V>^OjAa0X>^OhAb0X>^OhAa0Z>^OfAa0[>_OeAa0\\>^OdAUNMX2`>BcAVNMW2a>CbAb0^>^ObAa0`>^O`Ab0a>]O_Ab0b>^O^AXNMT2g>C\\AYNMT2g>C\\Aa0f>^OZAb0g>]OYA[NMS2j>BYA[NMR2k>CXAb0i>]OWAb0j>^OVAb0k>]OUAb0l>^OTAb0l>^OTAa0n>^ORA^NMo1Q?CRA^NMn1S?CPA_NNm1R?DPA_NMn1S?Co@b0S?]Om@c0S?]Om@b0U?]Ol@b0U?]Ok@bNMk1Y?Cj@bNMk1Y?Cj@bNMj1[?Cg@dNNi1[?Cg@dNOh1Z?Dg@b0[?]Oe@c0[?]Oe@c0\\?\\Od@c0]?]Od@b0\\?^Od@b0]?]Oc@b0^?^Ob@fNMg1a?Cb@fNMg1b?Ba@gNMf1c?C`@b0`?^O_@b0b?^O^@b0c?]O^@b0b?^O^@a0d?^O\\@b0d?^O\\@iNMd1g?C\\@iNMc1h?D[@iNNb1h?DZ@jNMc1i?CY@b0h?^OX@b0i?]OW@c0i?]OX@kNMa1m?CV@lNMa1m?CV@lNN`1l?DV@lNN_1m?EU@lNN_1m?EU@lNN_1n?DT@mNM`1o?CS@c0n?\\OR@d0n?\\OS@nNM`1P`0BS@nNM_1Q`0CR@nNM_1Q`0CR@nNM20V1R`0IP@POO]1Q`0CP@POO\\1R`0Do_OPON]1S`0Co_Oc0R`0\\On_Od0R`0\\On_Oc0S`0]On_Ob0R`0^On_Ob0R`0^On_OWOMo0U`0Jm_OQON\\1V`0Bl_ORON[1W`0Ck_ORON[1W`0Ck_Oc0U`0]Ok_Oc0U`0]Ok_Ob0W`0]Oj_Ob0V`0^Oj_OROM[1Y`0Cj_Ob0V`0^Oj_OROM[1Y`0Ci_OSONZ1Y`0Ci_OSOOY1Y`0Ch_OTONZ1Z`0Bh_Oc0Y`0]Og_Oc0Y`0]Og_Oc0Y`0]Og_Oc0Y`0]Oh_Oa0Y`0_Og_Oa0Y`0_Of_OTONX1\\`0Df_OTONX1]`0Ce_OUONX1]`0Dd_Ob0\\`0^Od_Ob0\\`0]Oe_Oc0[`0]Oe_Oc0[`0]Oe_Ob0]`0]Od_Ob0\\`0^Oc_OVONW1_`0Cc_OVONW1_`0Cc_OVONW1_`0Cc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Ob0^`0_Oa_OUOOV1``0Ea_Oa0_`0_Oa_Oa0_`0_Oa_Oa0_`0_Oa_Oa0_`0_Oa_Oa0_`0^Ob_Ob0^`0^Ob_Ob0^`0^Ob_OVONV1``0Ea_OUOOV1``0Ea_OUO0U1_`0Fa_OUOOV1``0Ea_Oa0_`0_Oa_Oa0_`0_Oa_Oa0_`0^Ob_Ob0^`0^Oc_Oa0]`0_Oc_OUOMW1``0Db_OVONV1``0Ea_OUOOV1``0Ea_OUOOV1``0Ea_Oa0_`0_Oa_Oa0_`0^Ob_Ob0^`0^Ob_Ob0^`0^Ob_Ob0^`0^Oc_Oa0]`0_Oc_OUOMW1``0Db_OVONV1``0Db_OVONW1_`0Cc_OVONW1_`0Cc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Oc_Oc0]`0]Od_Ob0\\`0^Od_O\\OMj0^`0Ke_OTOM20o0^`0Kd_OUON10o0^`0Kd_OUONW1^`0Dd_Oc0[`0]Oe_Oc0Z`0^Of_Ob0Z`0^Of_Ob0Z`0^Of_Ob0Z`0^Og_Oa0Y`0_Og_OZOMk0\\`0Kf_OTON10P1\\`0Le_OSOOY1[`0Df_Ob0Z`0^Of_Ob0Y`0_Og_Ob0X`0^Oh_Ob0X`0]Oi_Oc0W`0]Oj_Ob0V`0^Oj_Ob0V`0^Oi_Oc0V`0^Oj_Ob0V`0_Oi_Oa0W`0_Oi_Oa0W`0_Oi_Ob0V`0^Oj_Ob0V`0^Oj_Ob0V`0]Ok_Oc0T`0^Om_Oa0S`0_Om_Ob0R`0^On_Ob0R`0_Ol_Ob0S`0_Om_Oa0S`0_Om_Ob0R`0^On_Ob0Q`0^OP@b0P`0^OP@b0P`0^OQ@a0o?_OQ@b0n?^OR@b0n?_OQ@a0n?@R@a0m?_OR@b0n?^OR@b0m?_OS@a0m?_OS@a0m?^OU@a0k?_OU@b0j?^OV@b0i?_OW@a0i?@V@a0h?@X@`0h?@X@`0h?@X@a0f?@Y@a0g?^O[@a0e?_O[@b0d?^O\\@b0c?_O]@a0c?@\\@a0c?_O]@a0b?@^@`0b?@]@a0c?_O]@b0a?_O_@b0`?^Oa@a0_?^Ob@b0]?@b@a0]?_Oc@a0\\?@c@a0]?_Oc@b0\\?^Od@b0\\?^Od@b0[?_Oe@b0Z?^Of@b0Y?_Oh@`0X?@h@a0W?_Oi@iNN[1X?Mj@hNN[1X?Mj@a0T?@l@`0T?@l@a0R?@m@b0R?^On@b0Q?_OPA`0P?@PA`0P?@PAeNN_1P?MRAdNN`1o>LSAdNN`1n>MTAa0k>_OUAa0j>@VAa0i>_OWAa0h>@XAa0g>_OYAa0f>@ZA`0f>@[A_NMe1f>M\\A_NNd1f>M\\A_NNe1d>M^Aa0a>_O_Aa0`>@`Aa0_>_OaAa0^>@bAa0]>_OdA[NMi1g:mMnHP2_LYNLk1\\>MgAYNMj1\\>MgAYNMk1Z>MiA?W>AiA`0U>AjAa0U>_OkAa0T>@lAa0R>@nA`0R>@PB?n=BRBSNLP2Q>NRBSNMP2P>MSB`0k=AUB?k=ATBa0j=@VBa0h=@XB`0g=AYB`0f=@[B`0c=A^B>b=B]BnMMV2d=M_BmMMW2c=L`B`0_=A`Ba0^=@bBa0\\=@dB`0[=AeB`0Z=@fBa0X=@iB?W=AiBhMM\\2X=MkBgMM]2V=MmBfMM^2T=MnBa0P=@PCa0o<_OQCb0m<_OSCa0l<@TCa0j<@VCa0h<_OZCaMLc2i<NZC_MMd2h<M[C_MMe2f<M]C`0a<A^C`0a<A_Ca0^<@bCa0\\<@dCa0Z<@fC`0Z<@hC?V<AkCXMKm2X<MkCWMMl2W<NlCVMMn2T<MoC`0o;AQD?n;BQDa0l;@TDa0j;@VDa0h;_OZD`0e;A\\DoLKU3h;L]DoLKV3e;N^DmLMV3c;N`D?^;BbD?\\;BcD`0[;AeDa0X;@hDa0V;_OkDb0S;_OnD`0Q;APE?n:BQEeLL_3Q;NRE`0k:AUE`0i:AWE`0f:BYEa0d:@\\Ea0b:@^Ea0`:_ObEa0\\:@eE`0X:BhE?V:BjE?T:CjE`0S:AmE`0Q:AoEa0m9ASF`0k9ATFa0i9@YF`0e9A^F=`9D`F>]9CaFmKKX4b9MbF`0Z9BfF?X9BgFa0T9BlF?R9BnF`0n8BQGa0l8_OYG>e8C[G>b8D^G=_8F^G>^8DaG?\\8BdG`0X8BgGa0U8AkG`0S8AmGa0n7ASHa0j7@YH>e7C\\H?`7B^HoJKW5d7M_Ha0\\7BcHa0Y7AgHa0V7@jHc0o6AQI`0m6ASIb0g6@ZIb0c6_OaI?[6CdI`0X6BfIb0U6BiIb0Q6AoIb0l5@TJb0g5AYJb0`5AaJb0[5_OeJd0T5@PK>k4EUK>f4DXKaIKf6g4K\\KaIMg6^4OdKc0T4@lKc0n3@RLe0c3A]Lc0[3@fLe0P3@PM]HMT8g2F`M?X2DhMg0c1C[NPHKZ8\\1OgNU1M_O2j90000000O101OO2O0000000000O100S]OMib071K400000000000O100S]OMib03`]OMWb03i]OMWb03=00000]]ONSb03m]ONPb04P^OMZ=N`B1O11ON1MM1T1OmN`0O00A10O11277Kk5MWK0iN1N2O10O2N100ON>NG00On0NR5;QJ4K10B1N06O10U11fNi>9m3=X]OZO7OKO0150KO104010O10O010O10Q>0nA02Z4HiK5M;2_OO2050O010J0141MMO26N01L4O10KN1240JO25OMON26OM3MM015O10O1M<3C10O1O1LNO70R10J4oN1O01O1N12O0ON4b4JbK1:NG10O01i10`N0n0OO1jNOm01SOO01O1O10O1O01O1O02O0O1O10N2O11N00O3W4LiK3N21N2N10O010\\20TOO]O19OkN0O002N02N10O1N20O2N:001E01O92k30iK2O10O2N1O011N]20TO0\\O0V11lM1d0N]O10OW10jN0b01a31iK2O10O2M;0S81`HOj10^10kK1O3NM3N;0i70nG0m325OlK1O3NM3N;0j10_10WN0VN0o32mK"}}, "object_label": "dining table", "attribute_label": ["color:black", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:full/whole", "texture:rough"], "control_dims": "texture, pose, transparency, state, color, size", "answer": "The dining table in the image is white and features a plate of food with a variety of fruits and vegetables. The plate is filled with sliced apples, cucumbers, and peppers, creating a colorful and healthy meal. The arrangement of the food items on the plate is visually appealing, making it an attractive and appetizing display."}, {"question_id": 918, "height": 357, "width": 500, "image": "000000134112.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "color, pattern, pose, size, state, texture", "region_anno": {"bbox": [193.28, 65.51, 294.26, 206.27], "segmentation": {"size": [357, 500], "counts": "S`U27k:4M3M3O1N2M4M101N2O001N2N2N2N1O1O2N1O1N3N2O0O2N101O0O1O2O001N2O1O1O100O1O001000O010O2O00O001O1O1N2O1N2O1O2M2O1N2O1N2O1O1O0O2O1O001O1O1O1O1O1O1O2OOO2O001O010O001O001O001O0001O010O01O0010O0001O00001O1O01O01O0000001O0003N3bMkG]O1043N_1o7WOoG]OOM2OO[1l72SHcN2Z1c7cN_HX3]7mLaHU3[7<M3N3L3N3M2O1M4N1N3N1O2O0O1O1O2O001O00001O001O000010O01O0001O01O0001O00001N101N101N2O0O2N1O2N101N2O0010O01N2O1O100O1O1N2O1O1O1O101N3M2N10O001O0SI[LZ6g3a01O2N4kHXLe6U40O01O000001O00001N10001O01hIkK^5P5OO01O010O001O01O0000001O1O1O0000000O010O000O20O01O001O1O001N200N2O001O1DcIoK^6l3lInKT6R4`001N101N10O11N1kNnHWNR7h1oHWNR7h1oHXNR7f1PIYNP7f1QIYNP7g1PIXNR7f1oHZNQ7e1PIZNQ7e1QIYNP7f1QIZNP7d1QIZNQ7d1QI[NP7e1QIYNP7f1QIZNo6e1RIYNQ7e1RIXNo6g1RIXNo6h1RIVNP7g1SIWNn6h1UITNm6i1XISNk6k1X1M4M2N3N1N3M3M3M3N2M4M4J9^OhS5"}}, "object_label": "dog", "attribute_label": ["color:black", "color:white", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "state, pattern, size, texture, pose, color", "answer": "The image features a small white dog lying on a bed next to a laptop computer. The dog appears to be relaxed and comfortable, possibly enjoying the warmth of the bed. The laptop is placed on the bed, with the dog positioned close to it, creating a cozy and inviting scene."}, {"question_id": 919, "height": 451, "width": 640, "image": "000000113403.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, material, pattern, texture", "region_anno": {"bbox": [47.63, 98.31, 243.24, 215.87], "segmentation": {"size": [451, 640], "counts": "jdj02Q>00001O001O01O010OYk4NiTK1O000cd23][MN0O00]V2OciM20NX>1gA1O2O0O2N2L4K5UOAiCf0P<FhC>W<g001O001O01O100O01O00001NdNfC>0IZ<c0gC\\OY<GgCc00GX<EiCX1X<cNnC\\1\\<0N2N3M2O1010OQOnNmDR1Q;QOnDo0k:YOTEh0h:]OVEd0e:CWE>e:HYE9k9[NcFME[3a9SMcFV3Z9e0_FkK^9W4bFjK[9f2dFmNZ9U1fFkNY9V1gFkNW9V1kFiNS9Y1lFgNT9Z1kFgNS9U300O101O0NZNTGZNi8a1`G]N^8d1dG[NZ8g1gGXNX8i1iGVNV8k1jGVNU8i1mGVNR8k1nGUNQ8l1oGSNQ8n1PHnMR8S2nGiMV8W2jGnLQ9R3RGiLP9W3oFiLR9W3mFhLU9X3lFgLS9Z3mFdLU9\\3i0O01YFbLi8^3n01O0O100gG`Lo5`3QJ`Lo5_3[2001O000gEhLg9Y3VFjLi9i3fGlKc6U4e110O00000000_GTLk6l3gHPLVO9R8f3iHeLV7Z3kHgLT7Y3lHiLS7V3lHnLR7Q3oHoLP7Q3PIUMj6k2VIVMi6j2XIVMh6i2XIWMh6i2XIXMh6f2XI\\Mg6d2YI\\Mh6d2VI^Mj6a2UI`Ml6_2TIaMm6^2PIfMP7Y2oHhMQ7X2oHiMP7W1WHUNg0f0Q7V2nHkMS7T2lHnMS7R2lHoMT7R2jHPNU7P2kHPNU7P2kHQNT7P2jHQNV7=[HUO??U7n1kHSNT7m1lHSNT7m1kHTNU7l1jHVNU7j1kHVNU7j1iHYNV7g1iHZNX7e1gH\\NY7d1fH]NZ7c1fH^NY7b1gH]NZ7c1hH[NX7e1hH[NX7e1iHZNW7f1iHZNW7f1hH[NX7e1gH[NZ7f1eHZN[7f1dHZN^7e1aH\\N_7d1bHZN_7f1aHYN`7h1`HWNa7h1`HYLG\\1U8[2VHVLHX1W8c2QHTLHS1]8j2oGjLD[Oc8j3mGbL`8^3aG[Lf8c3n0O10OO2O0O10001O000O3N001N2N2N4L3N2M4M1N2O1N2N3M5K3L4L6K5QORD^OS<=TD]OR<MdC0`=GX^j4"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:white", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "pattern:plain", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness", "answer": "The image features a white teddy bear lying on a bed, positioned between two other stuffed animals. The white teddy bear is wearing a white shirt and has a bow around its neck. The other stuffed animals are brown and white, and they are also lying on the bed. The scene creates a cozy and comforting atmosphere, as the teddy bear and its companions appear to be enjoying a relaxing moment together."}, {"question_id": 920, "height": 451, "width": 640, "image": "000000113403.jpg", "category": "description", "question": "Describe the bed in the following image in detail.", "dims": "length, pose, state, transparency", "region_anno": {"bbox": [0.0, 0.0, 638.43, 441.63], "segmentation": {"size": [451, 640], "counts": "T121h0[8XOgGb12eN3JJj0W1UOhNh0Z8YOgGb12fN3HKj0W10R7WOfGb12eN3ILi0X1OhNVOU8X2mGlMMg0Y1OhNVOU8X2mGjNU1@hND1KU80kGQ21PO>mN7b0\\ODML\\8e1dGbN2j0>mN7c0ZOHZ8]1eGaN2j0>mN6R1`5QOmI1O9P1_1nN]N1k0W1Nn4QOnI`0Q1j22iMb3kNmKO5=<CjNZ3V1mMa3jNmK15;`0m2MmMa3jNmK169`0o2MoM]3hNPL178?P3NnM\\3iNQL077?R3NdMd3SOhKO97=e1dN@[1Ae1TOkN0M2XNM]1l1dN_OZ1Be1TOkNON3Fi1bN_OZ1ClNRO_21P12iMi1bN_OZ1Be1SOlN0nN121e0h1aNAY1YOl3]OVK0K7>Il0i1`NAY1POeNLj0K_3OSL1DN69KI313N[1e1dNEV1XOk3^OUK3J1JM1O4040Y1i1_NB[1WOWO_OC2n3MXL3J0NO2M40Y1X3I[MXO]OF0k30XL5INZ2U3kNRMhNKT5KVK1D02O01OO;0b1X3ZOnLhNJ35b5K\\J11O01OO60J1n1W3WOSMlNKQ1J_31eKO91_1W3WOSMlNL5I`03i3NZL0U1W3WOSMmNJP1M]30eK091a1T3WOTMi4FPJ25091g1n2oMnLm0;@E?1U3OnK6O0<OCKQ2\\1nM65^Nl0:b0Fi26gKO;0CKQ2\\1nM65^Nl06POKe013Nd35fK0;0g1W1lM5X1cNP5OjI2;0g1k2d5RMZH3:1CKQ2Q3@nLd41oI482DJQ2Q3@PMb4OQJ482DJQ2Q3@QMYOO^ONc40XK691DJQ2Q3_OSMEKe31YK591i1j2[OTMX4K^J3L3<Nh1m2ZOUMX1J42VM400OK93m1k2ZOWMV1K6OVM6O0OK84n1j2ZOVMDN8Of13PM0OK47R2h2ZOSM`40RJ3NK74P2j2`5SM\\H3ML92HNR2m2d5TM^H0LO?0c1n2c5SM]H2b0M_1m2m0SMh13TNi2j4UM\\H3<Mi1k20UMR31hJ2NL1133R2i21UMR30iJ2MM2034NKn1l27UMS31gJ3OK1134S2e20VMU31fJ43K06Q2d2b5VM[H42L06R2c2a5WM[H4ML1042JOY2g2`5XM\\H3LM:2EOY2h2=WM\\M0P53\\K4k1a2<[M[M0f01^3NZL5l1`2b0\\MiM1^3OZL5m1_2\\OZM\\O2e38ZKE88R2_2ZOZM]O2TOMX4<bKD99_1GgNg2\\2\\Ml19eKMo1\\2_O]MRO2l37dKO`0F?7fNS2j1fMRO3m31UKO>5o11dMP2l7jMTHO1N93FNP20YN8FP2m7jMUHN0O`00^12RN116MQ2l7iMVHNl22UM6MQ2S2fMfN0S43hKMi13eM7No1m7jMgHM_O0T24kMb2`2ZMg22[K5`1MoMb2^2\\Mg20\\K5V1K[N02c2[2[Mh21ZK6^1LUNa2Z3\\Mk01XLO_O2n11WNa2g7\\MkH2f1`2_5^MkH2i1^2W6bMjI]2U6dMkI\\2U6cMlI\\2V6cMjI]2Q6dMbGNY2]2T6fM]GM10`2[2R6hM]GM10`2[2R6hMWJX2i5gMYJX2i8O1QNYDb1g;^NYDb1h;]NXDc1e8VNYJ7QMd1]8TNhG3i2U2VMgMi7;VHJk2T2VMgMi76THL23k2T2VMgMi76THK43i25SMd13SNk74RHM60i27QMe1U8VNlGM51k25oLg1V8UNkGN60k25nLh1V8TNlGO[34cLi1n3SN62nKN[34cLi1V8TNlGO[34cLi1W8SNjG1]32bLj1W8SNjG2Q2NVO2iNk1Z8TNTK0bLl1[8SNbI1_O0dNl1n;TNQDl1k8SNVJ1nLm1V8TNmGN:0e21nLm1T8UNPHM]31_Lm1S8VNeKl1\\4QNRHO^3n1]OSNX2O\\Nm1_LSNg22O1_OMXN2KNV2m1bMSNg22O1_OMWN2b2OoLg13XNg22O11OoMO_1g1kMXNh21N31MoM1^1f1k0XNG4n0NaNe1j0YNC0\\M4f1M61lNO<OQOc1l2]NG4oNL52jN4d0]1b4bNkMMoL5XOMU1_1j4aNjMMlL`0a0Q1i4aNiM0hLc0g0k0i4aNgM2hLe0g0g0j4aNhM4eL`0C@T1[1l4aNiM3cLa0F@R1Z1h8gNVFg01WOP1\\1g8aNVFU14mNo0]1n1aN2O>1`LT13nNo0]1n1`N]O1TN0P3O^LU15oNm0\\1o1`N]O1RN2S3S1bLnNl0]1U5_NbMR1]LROl0]1e4bN`JO\\2NfM0e0S1WOPOn0^1d4bN`JN]2OeM0f0R1<oNgN]1e5dNWMN[M0f0R1<nNhN^1c5dNcNP1mKnNn00oN8Nk0S:M[G>f8^OlEUO]1^1g8\\OmEVOf0OF0H_1o9]OlEUO]1^1h8^OYGb0g8@mEYO8H;^1a9:jEYN:2Il0NRO21U:j1iEUN33OMN100051I01b:l1\\ETN4301M20K5O^:m1cEUNN1M2OM5M^:l1eEXNLNNO4Og:^1REjN0I:32Lm:\\1hDfNO11N94\\;a1\\DZN85LLW;e1PEaNGKY;d1eDZN78KIZ;`1bDaN1O88JG\\;a1aDaN1O88\\;W1[DbN1O89[;V1aDaN49[;V1]D`N206:[;Q1\\DgN2N106;[;n0]DiN1N10000=`;l0^DiN1N<=T;Q1gDcNM<];V1]DcN48^;]1aDeN_;Z1aDfN_;Z1aDgNk2G`MMDK^7j1cHiNh2FbMNDI_7j1cHjNb2L[MC1M18b7a1_HmN[2c0W5?^HPOV2g0Y59aHQOS2h0\\57aHROR2d0kMcNb7g1aHROP2d0d5:\\HROl1e0l5KUHQO3`0f0VO7a1j65YHUOe0UO5d1m61YHYOc0RO6e1n6OZHWOLUOe014`1Y7ZOnG^O1H0046LJ06OI30`022b1E^NZ7h0]H_O1GO132MM67II32>02b1D]NJ0d7h0]H@0GO04373DJ41<22`1DaNKL1O`7j0`H@OH8325II;12S1_OUO53\\7o0`HbN4566HH<11n03Cn6i0_HdN4456II>MOh0AXOh0c0j6l0aHhN16NF?LNm08Hk6j0cHhNN83A61EO=n01QOCj0`7d0eHjNL8>F@J?l003R7=fHnNJ5a0FT1M^Nm0_73]HnN117:KHMNj00m0W1l5E\\HVOa08DFNO?0_1Y1c5D\\HVO6M3>IDd0NC3>M@20_1^7[O[H[O1J8>HCd0OAOK3e0;^OT1a7D[HlN8=JBd00C133DS2g7mNYHmN8=JA605240@f11^N0O1Le7W1`HWOJA517120Bd12]N101Ma7X1aHWO3B321OD0M^16aN1000_7W1bHWO2C51OODc14\\N011O_7W1bHXO3@43ONDg1O^N2L30a7V1aH[Od0]OC0Bj1O\\N2MOM22e7U1_H]O6\\Oa00SOS20RN2Ne7T1^H^OW1_1cNTN1Mg7S1]H]OX1[OcN\\21iMg7W1XHZOa1\\1aNPN4Oc6OVJT2=lMfN7Oa1;YN\\60XJR2AmMK1M1I40`1<[NZ6OXJS2OnMZO2H40^1?\\NW6OYJT2MnM\\O:HZ1>\\NZ7S2`IVNiN\\11ZN41d7T2gHjM1;^OMO00m01nN52c7P2hHlMI0L:K_1OYN53d7P2TIkMYO8Ki11VNg7n1TIlMXOl1KaN1Ih7n1TIkMYO1J51X15mNKJd6J]JW2XOkMHN81L1K4100e0N[O76JJd6J]JX2WOjMH00O=;BP1;mNHLb6K]JY2VOiMJOO0=h1O^NGMf7V2ZHiMe09WOn0>mNEOf7U2]HeMN0?2]O51Q1`0PO@Og7T2^HfMM0N0=1B511Od0c0\\O^O1f7R2^HfMN0N0=1B51o0b0_OS7g1_HdMN1N0=9Dk0b0@R7g1dHdMI0;2B43n0`0DQ7e1iHdM11C41n0a0EQ7e1^HbM4280D30o0a0EQ7e1^HbM4280E2NQ1b0DR7d1eHeM41D0NS1d0DP7c1fHeM40D12P1`0GP7c1gHdM31C054J304g0=m6d1bHbML1<1CO65J123e00ZO2c7Q2`HeMMN<2C05=OJc01XO4Q7BaI^2BdM>0_O06;OLb01XO3Q7DaI]2CcM=1^O2486L>`0[6XO`I^2EcM6i00ZO:c0Q6[OSJ\\2\\OcM6i00ZODLb0d0W6_ORJ[2YOdM8g02YO9b0R6_ORJ[2XOeM9f02WO;d0Q6^OQJ\\2WOeM;f0n0J`5_OPJ]2JYNg0K_5_OPJ^2IbMZOb0^1Na5_OoI^2HYNh0J`5@PJ]2HYNh0J`5@PJ^2GXNi0J`5@QJ^2EYNi0Fd5CnI^2SOaM=h0n0Ef5ClIe2_OTNn0Dg5ClIa2RO_M=i0n0Di6T2lG_M=h0o0Dj6T2jG`M=g0o0^OdNOV8]2iG_M>f0P1^OdNNY7MbId2ATNo0^OcNM[8`2THUNn0Bo6Y2SHSNBZOZ1;Q7Y2RHRNCZOZ16fNL[8c2PHQNFZOY16fNK\\8d2oGQNFZOY1:S6F_Ie2_OQNFZOY1:R6G`Id2_OQNS1Dn5G`Id2_OQNR1AS6J]Id2]OQNS1]ObNOb7N\\If2]OoMS1BR6J_Ie2\\OoMS1BR6J_If2[OnMS1BT6I_Ig2ZOoMR1^OdNMg70SIf2_OoMHZOW14jNLd73TId2^OoMI[OV13kNLd72UIe2]OoMI[OV14b6MRIe2]OoMS1^O_7b2^GPNS1^O_7c2^GnMS1_O`7d2[GnMS1_Ob7c2[GoMQ1_Od7b2[GoMQ1_Od7b2[GoMQ1_Oe7a2ZGQNP1YOkN1i70TIe2XOQNP1ZOjN0j7OUIf2WORNo0]Oe6JVIg2VORNn0ZOlNNn8e2WGSNP1YOmNNm8e2VGTNl0WOQO2W80^Hb2^OUNP1ZOS7O_Hb2^OUNP1ZOS7O_Hb2^OUNP1ZOS7O`Ha2]OWNP1WOU70^Hb2]OWN]9WOVGb2]OWNP1VOQO0m71eHb2]OWNP1VOQO0l70hHc2[OVNQ1WOS74_H^2]O`MK5100JU1OS77\\H[2@_MM1N0221Ml0OVO0S89]HX2@aMK514n0EUO1T88]HX2AiMK1m0FUO1U87]HX2AeMJL1:]9NWGW2AdM0:T9L\\GV2_OcM3<o8L_GU2_OcM3<o8L`GT2^OdM3=n8KaGT2@bM1>o8LaGS2KQN_O@Q9=eGQ2KRN_O@Q9=eGQ2ITNA^OQ9=eGQ2_ObM0c0P9JbGP2^OfMLN2;MDQ9=fGo1^OhMJN88GGR9=gGn1^OhMJN9;g81hGn1^OiMIM;:f82iGn1\\OmMNJ07l85jGm1\\OmM80b87jGk1\\OmM:L@Mo8a0lGh1\\OlM;L@Nl8d0mGe1[OnM=J_OOl8e0lGd1\\OnMa0JW8d0lGc1]OoM?LV8c0nGc1\\OmMa07j7;XHY1WOUN60a07h7=ZHW1WOUN60<JB<[8>ZHW1WOUN60<LA:Z8?\\H^1]OmM>JA4LN]8j0[HT1WOVN7Ng0Me7l0WHQ1YOUN51Y9l0ZGm0XOVN52W9l0\\Gm0WOUN53`0Jn7R1VHl0WOUN54V9k0^GoNUOj12YN43V9l0_GmNVOk11YN43S9o0fGd0SOZN43S9o0eGf0SOXN53S9o0eGm0XOTNR9P1fGe0ROYN71R9P1fGd0RO[N61Q9R1fGb0SO[N61Q9R1fGb0SO[N62o8R1hGa0SO[N53o8R1iGh0XOVNo8S1gGh0ZOUNn8T1hGg0ZOVNl8T1jGf0[OUNk8U1jGf0[OUNk8V1iGe0\\OUNk8W1jGb0[OWNk8W1kGa0ZOXNk8W1kGa0ZOXNj8Y1kG?[OXNg0HS7a1kH?[OXNg0JQ7_1mH?[OXNe0LS7]1mH?[OWNe0KV7_1jH?\\OVNd0KW7`1iH?\\OVNc0LX7_1iH?\\OVNc0KX7a1iH>\\OVNc0KXOOk7b1nH>\\OVNa0L[ONi7d1oH;\\OVNb0MYOOj7c1oH;\\OTNd0NYOOh7d1oH;\\OSNl8b1gG<]ORNl8b1gG<]ORN;Ok7d1\\H;^ORN;0j7d1]H9^OSNl8d1fG9^OSNl8e1eG8_OSNl8f1dGOZO]N6Na0N`7h1_H0YO\\N7N`0Oa7g1_H0YO\\N7Nl8f1dG1XO[N8NJNi01W7g1fH7@SNJO?OB1N1P8f1gH7@SNJNd06\\7b1fH1XO[N8N;O@6o7a1PHXNb0h1]O\\N8MIO>0B8o7a1gHOYO\\N8MIOb06_7c1dH0ZO[N8MIOa06a7d1bHN\\O\\N7MH1?6d7b1bHO[O[N8NG0?6FHi7k1gHN\\O[N8NG0>7g7c1_HM]O[N7OHN=:g7b1_HN]OYN8156i0Eg5n1eIM^OYN8147j0Dg5n1eIM^OYN8227k7b1\\HL_OYN8316l7b1ZHMBXN73L3LLU8j1lGPN7o1IUN74J2OH1NS8P2kGRN6m1LUN6g0Q8U1gGQN6o1LTN5h0Q8U1iGoM4Q2MSN5h0Q8Y1lGMMRN60N9KEX8T2jGMOQN6O17IHW8[4iGgK6O2;o7o3iGgK6O2;o7P4hGfK7O2;o7o3iGgK7M3;U1DW5\\4[IhKd00ZO2`1KV5[4\\IhK6M2;W1EU5[4\\IhK5N3:W1EU5[4\\IgK6009Z1ET5[4\\IhK5>J@c1O^NO_6]4aIgK4?K_Od13k4X4aIhK5>K^Oe13k4Y4_IiK6a00YOX13T5Z4^IiK61M0NJf10l4\\4]IhK8M13HL\\8\\4cGhK:K13FN`12V5Z4YIhKg0OYOMa13T5Z4[IgK8K48T1MU5Y4[IgK8K48T1LV5a4oIeKk0GX5d4lIgK\\OFV8d4]HkKf0_Oa5e4jImKd0^Ob5e4kIgKh0D]5e4kI[K[O4c1L`N1`6e4UJ\\KQ1Oj4e4RJ`KS1Kk4e4QJaKT1Jk4e4QJaKo0I_N3`6c4RJaKo01n4^4SJaKLIa0:^5\\4UJaKLIa0;]5[4VJaKP13i4]4WJ_KQ15g4\\4XJ_KQ15g4\\4XJ_KQ15g4\\4XJ_KR16d4[4ZJ_KR16d4V4fIaKd03Q19c4X4\\J_KQ19c4X4\\J_K0J:`0Z5W4\\J_KOK;`0X5W4^J^KOL;>X5X4_J]KOK:d0U5T4bJ]Ko0b0iN[OR5f4WK\\Kn0d0`NXO13Z5e4VK]Ko0e0dN[OV5c4WK]Ko0e0dN[OV5c4WK]Ko0U1i3^3XK]Ko0V1h3]3XK^KP1W1f3[3ZK^KP1W1f3[3ZK^KP1W1e3\\3[K\\KP1Y1e3[3[KYKS1]1a3Z3_LWKnNa1a4Y3^KWKS1`1_3Y3^KWKS1a1^3X3_KWKS1c1\\3V3aKVKS1f1[3T3bKVKS1g1Z3S3cKWKR1g1Y3S3eKVKR1h1X3Q3gKVKR1j1V3P3hKVKR1k1U3o2aMTM]2l2bMVM]2k2PMWKdNQ2Z4h2QMYKcNR2Z4f2nKTK>6XOT2Y4b2QLTK>9SONLo1_4f2TLTK>o2]3m1ULTK?a0POh1\\4c2VMUK^Nl2[4o1VMWK_Nj2Y4P2WMXK_Ni2Y4o1WM\\Ng2d1XMbK`N[22VMQ4m4]M^NbNeLP4n4dLRK1\\3_3b1`LRK1\\3_3b1_LTK1Z3`3b1`LSKO\\3a3a1`LRK0]3`3a1UMcNj2]1oLfKlN_2T4k1QMdKlNb2R4j1RMRKlN?0f2Q4i1RMeKmNa2R4j1PMfKnN_2S4k1nLgKoN^2S4k1jLkKSOY2T4l1hLlKTOX2T4l1gLnKTOU2V4m1eL[KVOG21NZ3U4c1eLYKBS3i3d1eLVKFU3e3e1eLVKGT3d3f1eLUKHU3c3f1gLSKGV3a3h1cLQK3V3Z3i1hLRKHU3`3i1gLTKIR3`3j1hLRKI0ZOQ3U4m1dMTN[2l1eMUNY2l1gMTNY2l1fMVNY2j1gMVNY2j1gMWNX2i1hMWNW2j1iMVNW2j1iMWNV2i1jMWNV2i1iMYNV2g1jM[NT2jMULc2g1DS2dMcL`2Y1MS2bMgL`2V1OR2\\MoLc21bL3`3m2WMVMd2@eLJ0b0b3m2TMZMc2]OhLIOb0d3m2RM\\Mb2\\OiLIOb0f3k2nL`Md2ZOiLIOa0g3S3^LaMS3ROhLJ0>j3h4]OPKiLJ0>c0[Ob2\\52QKiLJ0=m3g4ZORKiLJ0=n3f4YO]KiLMo3e4XO^KiLMP4d4WO_KiLNQ4b4UO`KjLNS4a4ROYLo0f3QOZLQ1d3oNZKkLb0Y4Q4lN]KkLb0\\4o3hN_KmLa0\\4o3gN_KnLb0]4m3eNbKlLb0a4j3cNfL`1`N`Ka4[2_KTNa1Z4m2`McKVNb0]O@0d07ZO0OT4]4SNcKUN<^OG1OOd04@K21No3U4SOQLoLE11Nc06_OK23JP4Y4nNSLPMD10O216MIV5S4mMXLUMD32X5n3`M\\LcMFn4m3_M]LcMGo1O6k38^LeMEQ5j3[MaLb3]3^LcLe3Z3cK\\LXN:U6Y3\\LgLe3X3[LhLe3V3]LjLWMEG2m5\\3UMmLWMEG2o5Z3SMoLh3Q3XLoLi3P3WLPMj3o2VLQMl3l2ULTMW1HPNS3MjL]N;[3IeNQ3ClL]N:Y3KhNl2DoL[N:^6d2UL\\Mm3_2VLaMk3]2VLcMk3\\2ULdMm3Y2TLgMm3X2SLhMQ4P2SLPNn3n1SLRNm3n1SLRNYOFb1W2UOSNo3i1TLWNn3d0YHRO2h0h3Bo3a0TM_Ol2a0TM_Ok2b0UM^Oo2>QMBo2>QMBP3=PMCQ3<oLDR3;nLEX36gLJ[35dH@R3;^42dGEa0OA1ONi3;b4MeGNe0LW39`4LeGNd0MW39a43YHDV39e4JaGKd01E0S3;e1DXN4`MNZO0J0_3:U5IUH2XOJc3;Q5HPH9Q3OP5IRL7[KG[85bGIb4c0m3ETL3`KG]83UL6aKD\\83TL9U4GjK9W4FiK:W4FiK:W4FiK:X4EhK;P1DaM1_1;>HnJ7T3G`1=;3UN@`1>:2WN_O_1?;@UK:R3F^1d0SM\\OY12RM9T3E^1e0QM\\OZ1b07]O^1n0hLSOb1c0o4;^IROc1c0o42RHB1NQ1Km1c0o4f0RHmNh0JW2c0o4d1UHiMl20SM0O:X3EZ1Y2_KhMm20WM:S3FY1Y2^KhMo2NZM2J0V3OY1e0^KP1n6[NdMe0^KP1n2\\NTMO09W3GY1e0^KQ1k2PO>ZOY1e0^KQ1k2PO>ZOY1d0bKo0g2SO>ZOY1`0^K@6b1e2TO>ZOY1d0cKn0f2TO>ZOY1e0aK@NN3m0g2F>ZOY1n0bKRO3j0IXOk2d0>ZOY1o0aKQO7OJ6L22Ki2d0>ZOY1W1XLjN[O0f2e0>ZOY1Y1^KlN`0KF1d2f0?YOY1c1aK_N2O20b2f0`0YOY1e1^K`N3M4Nb2g0`0YOY1m1`KVNQ3d06YOY1U2aNbN6YOY1W2`KnMe2b0b0YOY1c2SNTNd0YOY1d2SNkM\\MDX3MY1e2RNjM]MDX3MY1e2RNjM]MDX3MY1e2QNRNf0YOY1f2lMUNk0VOX1f2lMTNl0VOX1f2lMTNl0VOX1h2jMRNn0UOY1j2hMQNo0UOY1o2cMlMT1VOX1o2cMkMU1VOX1P3bMjMV1UOY1;_KY2o1XNY1TOY1:aKY2m1YNY1TOY19mKP2_1dN[1TOX18QLn1Z1hN\\1ROY18VLj1T1kN^1SOX18WLi1R1mN_1ROX18XLi1o0nNa1QOX18bL_1e0XOa1QOX19bLHnNa0O9g14b1QOX19bLGQO_1c1@b1QOX19SMm02Jc1oNY1:SMl01Kc1oNY10"}}, "object_label": "bed", "attribute_label": ["length:long", "transparency:opaque", "pose:horizontal/lying", "state:covered"], "control_dims": "pose, state, transparency, length", "answer": "The bed in the image is covered with a white and brown blanket, and it has a pillow on it. There are three stuffed animals on the bed, with two of them sitting close together and the third one positioned further away. The stuffed animals are of various sizes and colors, adding a playful and cozy atmosphere to the scene."}, {"question_id": 921, "height": 426, "width": 640, "image": "000000320490.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "color, length, pose, texture, transparency", "region_anno": {"bbox": [565.32, 220.3, 11.5, 37.19], "segmentation": {"size": [426, 640], "counts": "Uf[7c0]<@fCf0U<:O0O3N0011N8G6J4EZCIR\\j0"}}, "object_label": "bottle", "attribute_label": ["color:blue", "length:long", "transparency:transparent/translucent", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "texture, pose, transparency, length, color", "answer": "The image features a bottle with a blue label, which is placed on a table. The bottle is positioned in the center of the scene, and it appears to be the main focus of the image. The blue label on the bottle adds a touch of color to the otherwise dark and moody scene."}, {"question_id": 922, "height": 364, "width": 488, "image": "000000172935.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, pattern, pose, transparency", "region_anno": {"bbox": [19.74, 252.6, 92.4, 30.26], "segmentation": {"size": [364, 488], "counts": "nf71;2a:OYE8m:1N10000000001O000000000000001O00000000000000000O1O1O2O0001O0000001O01O00000001O001O100O00001O000001O000000001O01O000000010O0O100001O00O101O0000000000001O1O1N1O3K`WX4"}}, "object_label": "boat", "attribute_label": ["color:black", "color:gray", "transparency:opaque", "pattern:plain", "pose:horizontal/lying"], "control_dims": "pattern, transparency, color, pose", "answer": "The image features a small boat floating on a body of water, possibly a lake or a river. The boat is positioned in the middle of the scene, and it appears to be a small fishing boat. The water appears to be calm, providing a serene environment for the boat to glide through."}, {"question_id": 923, "height": 480, "width": 640, "image": "000000322610.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, material, pattern, pose, size, state, transparency", "region_anno": {"bbox": [49.39, 147.51, 23.5, 34.11], "segmentation": {"size": [480, 640], "counts": "eSg05j>4M7]AIS>b00N6J2O00O01O0010O00O2O000O2N1N3N100O1N2OicY8"}}, "object_label": "handbag", "attribute_label": ["color:black", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:open"], "control_dims": "pattern, pose, material, size, color, transparency", "answer": "The handbag in the image is a black backpack with a strap. It is worn by a person, likely a man, who is standing in a room. The backpack is positioned on the person's back, and the strap is across their chest. The backpack appears to be a functional and practical choice for carrying belongings, as it is designed to be worn comfortably and securely."}, {"question_id": 924, "height": 480, "width": 640, "image": "000000123480.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "cleanliness, color, length, material, size, transparency", "region_anno": {"bbox": [212.22, 313.99, 28.81, 27.92], "segmentation": {"size": [480, 640], "counts": "meS34k>3M2O1O1O1O1O10O010O1O010O2N101O00000000O01001O00O001M2O2NcWj5"}}, "object_label": "toothbrush", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:white", "length:short", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "size:small/little/tiny"], "control_dims": "length, color, material, size, transparency", "answer": "The image features a close-up view of a pink and white toothbrush. The toothbrush is white with a pink handle, and it appears to be a new, unused item. The toothbrush is positioned in the foreground, occupying a significant portion of the image."}, {"question_id": 925, "height": 427, "width": 640, "image": "000000347664.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "maturity, pose, state, texture", "region_anno": {"bbox": [449.69, 198.46, 20.28, 12.43], "segmentation": {"size": [427, 640], "counts": "Tkk53T=4M30O10000O1O10000100O1O0000LQCLn<46N10aSW2"}}, "object_label": "cow", "attribute_label": ["maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a black cow walking across a sandy beach. The cow is the main focus of the scene, and it appears to be the only animal in the image. The cow is walking in a straight line, covering a significant portion of the beach. The sandy beach provides a unique and picturesque setting for the cow's walk."}, {"question_id": 926, "height": 480, "width": 640, "image": "000000124636.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, material, maturity, pose, state", "region_anno": {"bbox": [25.81, 47.48, 528.51, 375.75], "segmentation": {"size": [480, 640], "counts": "UR`0c0T>?^O`0F8K4L4L3O2M3N3K5M?@9H6J4L4L3M2M5L3M3M3M3M3M2O1N2O1N3L3M3L5L3M3N3N2L4N1N3M3N4K5L>B4L3L3N4L2N2N2M3N4K6`IUIa4T7eJdIT5W8M00N1011O3NL30000002NN3N1nLeJ_L[5`3hJnJNO[5R5lJiJN1V5W5PKeICg0:;S5Y5ZKVJI4@]O^5Z6YKSJN2\\O@]5[6ZKRJZO_Oc0g0j4h5ZKPJYOBk0=b4R6]KjIWOGm0<]4S6RL_ID;Y4W6]McIc2]6P31O001O010O00001O00001O01O0001O0hHcIm5_6mIeIS6]6cIkI]6\\71O02SIPHf6l7ZISHk6k77N1ORIWHg6h7ZI[HKNd6e7b0SOhHQJY7n5iHPJX7o5nH^IJN_7d6f001N100000001O0O10001O000O101O0000001O[KfId0Z6ZOiIe0W6YOnId0Q6jNfIWM>l3l5hNnIWM9P4i5fNPKX1P5eNTKZ1l4cNXK\\1h4`N\\K`1c4_N`Ka1_4fLiIZO`0d0[1\\3\\4`LkJKo0e3X4VLgMi3h61O01O0000000001O0000001O00001oMlKTIT4`6fLRIZ3m6XMaHi2[7]MaHe2^7^M^Hd2a7`M]H_2`7iM[HX2c7kM[HU2b7PN\\HP2c7UNXHm1e7h2N2N2M2VOk0J6L4I7L4N200O01000000O1000000O101O0000001N100000001O00000O2O00000000001O0010O01O001O001O001O001O1O100O1O1O00100O1O1O1O1O2N2O0O6J5K6J5^I]HUO0S6S9F0O1O2N1`JnFQ5`904L1O1O1O1O100O00000010cMQKgJo4T5bK`J^4^5iK]JW4a5PLZJQ4a5XLZJh3U5RK\\I07\\1T1b3X5RMdJo2Z5UMcJl2[5XMbJh2^5\\M^Je2`5]M_Jc2a5^M^Jc2a5^M^Jb2b5_M]Jb2a5aM]J_2c5bM\\J`2a5eM[J\\2d5eM[J[2d5hMYJY2g5hMXJY2h5gMWJY2i5kMRJW2m5jMRJV2n5mMmIV2S6\\3N100O2O0O101N2O00000O2O00001O00000000000O2O000O100O2N1O1O1N3N1N2O1O1O2N1N2O1O2N1O1M3O2N1N2N3N1O1O101N1O101N1O2O0O100O100O1O1O2O0O1000000O100O10000O100O10000O1000000O100O10000XMnDb1Q;W100000000000000O100O1N101M3M300O10ON3O1O1N200O010O10000O1000000000000001O001O1O1N2O1O1O100O2N1O1O100O1O00100O1O100O001O10O0100O1O001O10000O001O100O001O100O10O01O2N1O1O101N1O3M2N3M9G5L1N2M2O2N1O21NO101N1O1O1O1O1O1O1O2M2O2N1O1O2O1N1O1O1O1N2GiBfNY=Y1gBfN[=Y1dBhN]=]11N2O1N2M3M2N3N2O0O1O2N2O1O1N3J6EbAMc>0jg]1"}}, "object_label": "cow", "attribute_label": ["color:brown", "material:leather", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry"], "control_dims": "maturity, color, pose", "answer": "The image features a cow standing next to a calf, both of them in a dirt area. The cow is positioned on the left side of the image, while the calf is on the right side. The cow appears to be looking down at the calf, possibly showing affection or concern. The scene suggests a close bond between the two animals."}, {"question_id": 927, "height": 480, "width": 640, "image": "000000124636.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, material, maturity, pose, state, texture", "region_anno": {"bbox": [524.04, 65.0, 48.9, 103.37], "segmentation": {"size": [480, 640], "counts": "afe77h>4K5oAGT=;eBLY=6dBL\\=4cBL`0Ho;1]CI0O83d0<X=;NWOlAe0U>ZOlAb0\\>04L00OO1N30^AKb=5mB3`;EnDh0_OCb;5UDj02ROh;i1WDWNh;i1ZDUNg;k1ZDSNf;m1^DhMD4o;T2d0D]C]Nb<f1`CVNa<k1aCPNb<P270O11O2MUDVNc:i1[EYNf:e1WE_Nj:`1QEdNQ;[1]DWOd;Q22N2M3N2J7H8G;^OPCeNX=V1<N2M3J7CTB_OR><>GV\\n0"}}, "object_label": "cow", "attribute_label": ["color:black", "material:leather", "maturity:adult/old/aged", "pose:vertical/upright/standing", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, material", "answer": "The image features a black cow standing in a fenced area, possibly a pen or a cage. The cow is positioned near the center of the scene, with its head and body visible. The fence is made of wire, and the cow appears to be looking through it, possibly observing its surroundings or seeking attention. The cow's presence in the fenced area suggests that it might be a part of a farm or a livestock facility."}, {"question_id": 928, "height": 314, "width": 640, "image": "000000125072.jpg", "category": "description", "question": "Describe the cow in the following image in detail.", "dims": "color, material, maturity, pose, texture", "region_anno": {"bbox": [88.92, 196.24, 22.81, 15.51], "segmentation": {"size": [314, 640], "counts": "`_k01h95L6JO1N2001O000001N100O100L4O1O10000000^ZR5"}}, "object_label": "cow", "attribute_label": ["color:black", "material:leather", "maturity:adult/old/aged", "pose:vertical/upright/standing", "texture:soft/fluffy/furry/hairy"], "control_dims": "color, texture, pose, material", "answer": "The image features a cow standing in a grassy field, with its head down and looking at the ground. The cow appears to be grazing or searching for food in the grassy area. The cow is positioned in the middle of the field, and its body is facing the camera. The scene captures a peaceful moment of the cow in its natural environment."}, {"question_id": 929, "height": 480, "width": 640, "image": "000000131379.jpg", "category": "description", "question": "Describe the cake in the following image in detail.", "dims": "color, size, texture", "region_anno": {"bbox": [0.0, 0.0, 640.0, 479.8], "segmentation": {"size": [480, 640], "counts": "3U48X6NhI2X6MlINW61\\4000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000XFMc43]KMc43]KMc43]KMc43]KMc43]KMc43]KMc43U500000000000000000000000000000000000000000000000jIN]M3d2L\\M4d2LkG1m43X3MjG0n43X3M[M3d0LZK1R43d0LZK1S42c0MZK1S42d2N\\M2h81lJL\\K4j0LbL0o33gNNaKOi12m31iNOPN0W31jNOoMORMO2000W53F0nMNSMO12O0X51HOnMN[M2GOY52HNmM0[MOI0V54IMmMO\\M0H0W53HN_N0`L0Y52HNkMO`M1@O01]52HNkMO`M0E1X52HNXN1dLN41X52HNUN0eL02O41X52HNUN0eL10050X51JMdM2`MOE65K3Nj434NeM0WM13OK56L2Nj434NeM0WM13OK10N721Nj434NfMOWM12OM181S51IMnM0QM0;6i4MMMnM0eM5`4NT3M_H2]41T3M`H1\\42T3MRH0Y53W3MiL3V3NjL2W3MiL3W3MiL3R9000YHMa03_OMcJ1T42Y1MlI3AOZ51Q3OoL1U3MiL3V3OiL1W3NTGOa53[3NTGOa53[3NjL2V3OUGO]52_3NTG2[50a3NSG3\\5Oa3MSG5\\5Ng31YLOk3MUL3_4MmJ3U4MlG0VO0e43Y4NkGOWO0d44Z4LlG0n34[4L_L3h3OoK1Q4NUGOX43c4NUGOX43d4MoK3Q4MoK3_9000dJMRG0V43h4MRG1U43h4NQGOW43h4OPGNX42i4NQG0V42h4ORGOV42i4MSG0T43i4MkK3U4MdF0R53P5M_J3`5N`J2a5M_J3k4MdF0<0U43k4MdF1;OV43k4MfF080W43k4NeF08OX43R5O[K1e40ZK0h4NXK2k9000PKM`F0V43W52`FLY42W53_FMX40X50dF0S41V50iFOQ41V5MlF0P43T5LiF0E1^43T5LiF1DO`44`5NdJ2X52hJNU:000000000000000000000000000000000000000000000001OO10000001O000000000000O1001O0000O1000000000000001O00000001O0O01001O01O0O100000O100000000000010O0000000000O1000O10000001O00O100001O000000O1000000001O0000000000O1000000001O00O2O0001O0000O010001O000000O1\\HN:2^ONSI4_7M]O9c0G]O0TI3_7M\\O0VI3^7M]OOUI4^7M_OMSI2N1^71B1QI1Y7NE1SIL]73@0f00ZO1SIL]73_O8SIEY73C><BD>SIAT71H0UI8OHT7OG2VI>R7@Gk07UOHl08TOHc0YI@n6MI4XI45Hj60Ig0XIZOn6OJn05SOKn04ROLn04ROLh0XIXOl6OKk0XIVOm6OKR14nNKo0YIPOl61Jo0\\IPOi61Kn0]IROf61Nm0[IROg61Om0XISOi60OT11kNLM\\IY1g6jNMM\\IS1OROg6NMO\\Io02TOe6NMO\\Im04VOc6NMo0aITOa6MNn0eIRO]60Nm0fITO[6OOP1`ImNM4c600\\10dNLLbI`1b6dN3Y1MgN4W1MiN3W1MiNcNMVLY1W5jN`N1XLU1X5jN`N0YLV1W5jN`NOVKOf0W1d5kN`NOSK1j0U1c5kNaNNSK0k0V1a5lNaNNSKOn0U1^5nN`NN_LT1Q5nN^N0VKLP1W1lNiNY63eN0VKNP1U1]5mNiN0iKT1^5lNhN1jKS1^5lNhN0kKT1]5lNXNM_K4l0MhNR1e6POWNN_K3R1o0W5QOXNN]K0W18_N>:YOm53fNN\\K1X17_N43G7Lm53fNM\\K1Z18]N>:YOn52eNM\\K3Z17]N=<YOl53POM]LT1gNmNk52gNMYK1]1S1iNPOg5OjNMYK1]1S1iNQOf5NjNNZKO]1V1hNoNg5NcNN\\K24N^1U1]NkN74j5OdN5`KG]14]NQ18kNI2Q62WNNPL2HNj12UNP14lN22l52WN0nK0JOh11YN=2IOL0Lo52WNOoK0g1NRNO27N02NNL`00BOj54]NMnK22NX10fN5I10O2J91F1O1j51_NLmK51M[10cN5J94@=2_O4i5NVNMYL0M61L]1ObNg0OYO5OK5MMg50UN0[LNJOO71KN0^10dN11g01ZO1O00O0c50VNO\\LNM6NJM2\\1OhNO1g01[O;NC3a51UNNiL2EMS11VO?F@c02j41VNLkL3DNQ11PONKa0Q1A^42eNMlK20ML1Y1OmN0J14?S1B[42RNMkL3CN2OJ1[1NmN0J14>f0C^O1Y51SNLlL1_OO3045]1L\\N05<i0E[O0Y52gNLXL5a0LPOO62HN5<k0FZO0W52hNLhK11O55k0MZO0L9i0HXOOY51gNNfK21051o0MXO0K:l0JTONY51iNLgK:5HP10mNN>;e0LROIY54^ONYLN_O1\\O1T17c4KUOOXLMQ1:PNFW54kNLYL3n20bLONN41Y53XNLaL100LOO44O\\3NfL2KN[53XNM`L010K93Ih31ULM\\53XNM`L010K1N36Nh3OULO[53XNLgL0F000N54Oj3MUL1X52iNLnK001M37Oo31T10oNMiK66KS4Oo02oNOhK48Lj30SLOR52QOOhK48Lk3O]12ZNMbL:KIl3N]12hN8oKHn3MZ13_N0QLN2:6Hn3NQLOo43iN3SL56Hn3NPL0o43kNMPL1296Hn3NX13bNLRL10;NF22T4MX13gNLnKg0T4ZOV13PO`0J]OoK0n43ZO>J@mK0o41ZO?K_OlK2n40ZO?N^OkK2l42\\O>J@oKOk43\\O>J@PLNj44\\O>IAQLMj44[O?J@QLNi43XO3hK6V4GoKOj41UO7kK3W4FoK0i40VOg03XOlKOL0o42VOLQLc0R4@lKNN0m43_O>J@mKOM0m43_O>8@XL0n22b0>1@eK0i00o224MQL01f0]4[OfK0h0Oo23OLXL1M12f0\\4[OgK0b0M[O2i33ILdL0I01g0\\4ZOhK1a0M[O2i33FOgLLJ10f0^4ZOfK2`0N]O0NOg356MSL00e0i4[OmKN[O2ONg36GJmL2Dk0i5UORN5BJjL0JQ1g5QOSN4MIZL2Nk0Q5SOeK2U35MIZL2O0O11>P5@eK1U35LJ[L1N10d0R5YOdK2U35LKZL5O90DS5LbK3V34LKYL6071Ei5NYJNd38OJZLg01[Oi5NRN6\\OHTM2Ef00\\OW5LUK1DOl39ZOGUM2Dm0g5ROZN8D`0\\L]Og5KdJ1U374?]L]O]5KiJ143S366>[L]Oc4KXL0\\O26NU3:3d0o0ROWL1ZO2l38Cb0Q1SOVL1YO1o39A0]LG61_4MVL0VO3R48QOEXM:FF53_50^N8POE[M7KM^5N\\N9oNF]M5H0`4MRLN[3:oNE\\M7ENh4MlK0[39CL]LNk4MiK0\\39CL]LMl4OgK0\\38DL\\LLP5OdK1\\38nNEbM7@LQ5MeK2Z3:mNDcM6@Lo50QN:kNDgM2BOS5O[K3^39kNDhM0A1T50YK2_39kNDa32TJ1`39]5GRG0a3:^5DQG2a3;]5CQG4a3:^5APG8`37g5AcF3GM02i3>POAm35hIM`0Mi1`02@S42VI00OL3j3<POAk3ObI<IG03h3:ROAk3ObIa0IEh3:T6CUF20MO1k3>Q6AVF100m3>S6CoE08MY3`0a6BnE27MY3`0\\5@UH0oN64L`2LSNb0[9@oE83GZ3`0e6AoE74HV3`0XO_Oh42eH94EX3a0VO@i4e0TLKSO_Oj4g0RLKb6HoE2^37b6DUFLJ2_3>d6AZF2EKV3c0]7IaH7`7JRFB_O1h1d0k8CPFH]O1i1d0j8AZFLk0c0l8@PFK\\O2h1d0m8_OmEK^O2h1d0MZOS75iGK_O2h1d0o8_OiEKA000^1f0Z9]O[FM;f0\\9\\OoDNn2g0S8^OUELn007f0S1YOS65bGOo016c0U1XOU64cGNn034c0V1XOV63bGN<OO6f0b0o9ZOPEO1Od06WOKP1g0T:[OoDN2Od06WOK70=g0a:ZOnDO2Od06WOK62=e0j:YOhD0d05WOK71<g0e:[OnDM>0\\O1OO>15g0g:[OlDM;0D1KO>2DM;i0o:ZOjDM:2E1JMg01Gh0o:ZO]EO\\O1c0N\\O01h0X;ZO[EO^OO0Oc01ZOi0[;YOYEOH0:o0e:QOfDN12119M<P1d:QOdD1O42N0L50L0?m0k:TOdD3M24OOK61b0l0d:UOcD0N65K:0<j0c:\\ObDO6J56`0d0h:CcDC38b0b0i:[O]DM4NM=NCg0l0m:XO^DM30J=2Ce0k0P;UO^DO11L0;O;m0h1QOe61QG110>OEO2P1S2POP72gF0>05n0V;SOVDN`01ON^OQ1m;SOUDLb02M0^OP1o;WOdDI00\\OR1\\2lNW77QGK0W1_;lN`DM2V1^;mNaDL2V1^;mNoCM70b0U1Y;kNmC28Ne0R1[;oNQDOd0R1Y;QOSDLe0S1X;nNSD2e0P1X;nNRD3f0P1W;lNZET1f:lNZEU1e0kN[9U1eFkN[9U1eFkN[9V1dFkN[9V1dFkN[9U1dFkN]9V1bFjN^9V1bFjN^9V1cFiN]9W1cFhN^9Y1aFgN_9Z1`FfN`9Z1`FfNa9Y1_FgNa9Z1^FgNa9Z1^FfNb9Z1^FeNb9\\1Q21]DdN`9\\1_FeNa9\\1^FdNb9]1]FcNc9^1]FaNc9_1o11O00001O001O00000010O0001O001O00001O1O1]DXNl9i1SFWNm9j1RFVNn9j1d11O001O00001O00001O001O0000001N100001O00O100000100O001O0000001O0O101O0000001O001O000000001O001O1O00gM"}}, "object_label": "cake", "attribute_label": ["color:red", "color:tan", "size:big/large/giant/huge", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The image features a close-up view of a cake with a crumbly texture, likely a pound cake. The cake appears to be partially eaten, with a few pieces missing. The cake is placed on a table, and its crumbly texture is evident in the close-up view. The cake is likely a dessert, and the missing pieces suggest that it has been enjoyed by someone."}, {"question_id": 930, "height": 480, "width": 640, "image": "000000132375.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "material, pattern, pose, state, texture", "region_anno": {"bbox": [330.03, 212.03, 134.39, 240.12], "segmentation": {"size": [480, 640], "counts": "f^k49c>8I6K7I<E=\\B^NQ=c1oBcNi<_1WCjN_<R2I7I7I;D<E7H5L2M3MgM_EQN0R2_:3aEN[:]2ZNbKhHl1cNVN1R2c8mMgHb4V7`KfHe4Y7TK`G50Lo0P5^7PKcG40Ll0T5a7kJdG75K8X5n7eJgG4i0X5g8ZM]FMb93_FN`90dFN[92gFZNO>Y9X1gFfMMINl1\\9g0gF\\ML3=i1o8h0PG[MNP2R9e0RGFn8:QGHP96PGKo86hF2Z9LcF8]9XOeF\\NMY2_9UOlF^NEG1b2^9k21O2O0]K_F^O0JOn3c9hL`F_O3i3\\9hLaF_ONn3a9cLaF_ONo3`9bLbF_OMP4b9`LbFj01V1^9ZM^Fa04m02W1\\9[M^FW26?[9ZM_FX24?]9YM_FX23`0^9CcF=\\9mMbFl02X1]9jMbFm01Y1]9jMbFm02X1\\9CcF=]9HdF2\\9cM^F<0T15m0U9_MjFb2OOS9dMnF:LW4U9aKlFT5n8hJQG`10\\2j8YLWGk0OXO2b3b8TL\\Gd11bN0f3`8oMdGYNKh3c8nMaG[2a8cM_G]2d8WM[GgNNn0Oo1k8eNUGa2l8i13M3bKnFh2S9VMnF4OQ1U9MkFe0X9kNjFWN0m2W9lNgFYN0l2\\9`MdFH1\\11a0\\9YNbFB1N1e12a0Z9kNbFe00c0^9KcFm0]9[20O0gKbFR3^9nLbF:2S1\\9dNbF87o0U9kNfF62Q1U9\\NgFXO220o3U9hLkFTO25Nn3V9jLhFVO131m3U9[MkFe2U9\\MiFd2X9kLhFUO1Z4V9aLjFTO3Y4T9bLjFTO5V4S9fLgFSO8c2H`M3Q1W91iFg1MZN[9Z4lNdJgH[5X7fJfH\\5U7_JoG63L?`5_7hJoHR5Q7oJPIP5l6SKVIk4j6QK^Il4b6RKbIk4_6oJiIn4Y6oJkIo4U8M3M2N2N3M2N2M2O2N3N1M2N3N2N3M2G9]Oc0H8D=_Oa0F;C;J9^Oiga2"}}, "object_label": "vase", "attribute_label": ["material:glass", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, texture, pattern, material, state", "answer": "The image features a vase filled with water and a single pink flower. The vase is placed on a table, and the flower is positioned in the center of the vase. The vase appears to be made of glass, and the water inside it helps to keep the flower fresh and hydrated. The simplicity of the arrangement creates a visually appealing and elegant display."}, {"question_id": 931, "height": 427, "width": 640, "image": "000000132544.jpg", "category": "description", "question": "Describe the baseball glove in the following image in detail.", "dims": "color, length, pattern, size, state, texture, transparency", "region_anno": {"bbox": [368.71, 219.68, 49.07, 47.0], "segmentation": {"size": [427, 640], "counts": "Saj41Y=3[O4fCOV<f0M2M3O1N2N1O1O100O2O000O10001O0000000O10001O000O100000000001O0O2O0O2N1N3N1N3N2N2O2L4M3N8GjZl2"}}, "object_label": "baseball glove", "attribute_label": ["color:brown", "length:short", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "state:open", "texture:smooth/sleek"], "control_dims": "length, state, texture", "answer": "The image features a baseball glove with a black leather exterior. The glove is placed on a surface, possibly a table or a chair, and appears to be dirty. The glove is positioned in the center of the image, with a person's hand visible on the left side of the frame."}, {"question_id": 932, "height": 425, "width": 640, "image": "000000133819.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "color, length, pattern, pose, size, transparency", "region_anno": {"bbox": [106.1, 247.17, 12.31, 19.28], "segmentation": {"size": [425, 640], "counts": "Xj[14U=9F6K2N1O0000000000O1D^C1n<N4J_og6"}}, "object_label": "handbag", "attribute_label": ["color:black", "length:short", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny"], "control_dims": "pose, length, size, transparency", "answer": "The handbag in the image is black and appears to be a shoulder bag. It is worn by a person who is standing in front of a building. The handbag is positioned on the person's shoulder, and it is likely that the person is carrying it as they go about their day."}, {"question_id": 933, "height": 427, "width": 640, "image": "000000136355.jpg", "category": "description", "question": "Describe the vase in the following image in detail.", "dims": "length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [212.54, 241.87, 35.58, 60.59], "segmentation": {"size": [427, 640], "counts": "jQi24W=b0^O>B4SDjN];W1`DmN^;U1_DmN`;U1]DmNc;]10000000001N1000000000O1000O100O10O10000O010DaDkN_;<jDEMMZ;<V1O2M4M3LkiR5"}}, "object_label": "vase", "attribute_label": ["length:long", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "material, state, pose", "answer": "The image features a large, green vase filled with green leaves, possibly ferns or other plants. The vase is placed on a wooden table, and it appears to be a decorative piece that adds a touch of nature to the room. The leaves inside the vase are arranged in a way that they fill the entire vase, creating a visually appealing display."}, {"question_id": 934, "height": 333, "width": 500, "image": "000000137246.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "color, length, pattern, pose, state, transparency", "region_anno": {"bbox": [123.91, 167.39, 42.59, 19.05], "segmentation": {"size": [333, 500], "counts": "h_X19T:1N2O1N2O000O1000000O10001O05J2O000000000001O0000000000001O00000001O001N101O00001NU^\\3"}}, "object_label": "bench", "attribute_label": ["color:blue", "length:long", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "state:empty"], "control_dims": "color, pose, length", "answer": "The image features a blue bench with a person sitting on it. The person is wearing a hat and appears to be looking down. The bench is located in a public area, possibly a park or a street, and is situated near a body of water. The scene is captured in a blue-toned photo, giving it a unique and artistic appearance."}, {"question_id": 935, "height": 333, "width": 500, "image": "000000137246.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, pattern, pose, size, transparency", "region_anno": {"bbox": [147.13, 140.61, 18.89, 18.56], "segmentation": {"size": [333, 500], "counts": "Vn_13Z:1N10001O00001O00001O7H101O01N1JSFIP:6404JiT\\3"}}, "object_label": "dining table", "attribute_label": ["color:blue", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny"], "control_dims": "transparency, pattern, color", "answer": "The dining table in the image is blue and has a wooden top. It is positioned in a corner of the room, and the table appears to be empty."}, {"question_id": 936, "height": 415, "width": 640, "image": "000000137950.jpg", "category": "description", "question": "Describe the airplane in the following image in detail.", "dims": "color, length, material, pattern, pose, size, texture", "region_anno": {"bbox": [4.64, 32.18, 531.05, 141.12], "segmentation": {"size": [415, 640], "counts": "lf11m<2O1N100O1O2O00000O1000001O000000001O000000001O00000010O00000001O000000010O000000001O000KChC=W<DiC<V<FjC9V<GjC:U<FkC:U<FkC:U<FkC:T<GlC9T<GlC:S<FnC9R<GnC9R<GnC9S<FmC:S<GlC9T<GlC:S<FmC:S<FmC:S<FmC:S<FmC:S<FmC:S<FmC;R<EoC:Q<EPD;P<EPD;P<FoC:Q<FoC;P<EPD;P<EPD;P<EQD:o;FQD:o;FQD;n;DSD<m;DSD<m;DSD<m;DSD=l;CTD=l;DTD;l;ETD;l;ETD;l;ETD;l;DUD=j;CVD=j;CVD=i;DWD<i;DWD=h;CYD<g;DYD<g;DYD<g;DYD<g;DYD<g;DYD=f;CZD=f;CZD=f;C[D<e;D[D<e;D[D<e;D[D=d;C\\D=d;C\\D=d;C\\D=e;B[D>e;B[D?d;A]D>c;C\\D=c;D]D<]:9cE\\O0;Y:Q1dEPOY:T1eElNZ:V1eEjNZ:X1eEhNZ:Z1eEfN[:[1eEdNZ:]1fEdNY:\\1gEdNY:\\1gEdNY:\\1gEdNY:d0kE[OL2X:c0lE[OL2X:d0kE[OL1Y:e0iE0W:\\1000000O2iE[MS:h21O101N2N2N3N1N3M2N4L3M2O2M2N4L2N1O3N1N1O0001O000000001O000O10001O00000000001O00000000001N10000000001O000000001O000O10001O00000000001O0O1000001O000O1O1O1O2O0001O1O1O0O1O1O1O1O1O1O1000000000O10000000000000002N1O1O000000000O100000O1O1O10aEUNj9k1RF]Nj9c1UFaNh9_1VFdNi9\\1VFgNh9Z1VFhNh9Y1XFgNh9X1XFjNg9V1YFjNg93QF77Hg91RFY1n9gNRFY1n9gNRFY1n9gNRFY1n9l00O10O01N2M3I7O100O1O1O1O1O1O1N2N200O1N20O02N1O1000O100000O100000010O01O1O0O2O001O00KYESNf:m1ZESNf:l1\\ETNc:l1_ESNa:l1_EUN`:k1aETN_:l1aEUN^:k1bEUN^:j1dEVN[:k1eETN[:n1cERN]:Q2`EPN_:X20100O2N1O10]OeEaNZ:_1gEaNX:X2L1N1O2O0O00POoEROR:k0SFROn9m0TFQOm9m0TFSOm9l0SFTOm9l0SFTOS:f0nEXOT:f0mEZOS:f0nEXOS:h0mEWOT:i0mEUOU:i0nEROU:n0mEmNV:S1k00000O10O1000001O000000001_DeN];_1O01O001O001O1O1O4K3N1K4O101O0001O001O000O100000000000000000O011O00000O101N1O2N2N2O0N2N2M210O10000000000O10O100000000000O1000000O10O1000O10000O10000000O10O1000000O1000O1000O10000000O0100000000O100000O10O1000000000O010000000000O10O01000000O1000O1000O100000000O0100000O10O1000O10000O01000000000O1000O1000O1000000O0100000O10000O10001O0O100Ogl\\1"}}, "object_label": "airplane", "attribute_label": ["color:gray", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "texture, pattern, material, color", "answer": "The image features a large propeller airplane flying in the sky. The airplane has a distinctive vintage appearance, suggesting that it might be an older model. It is flying through a cloudy sky, which adds to the overall atmosphere of the scene. The airplane is positioned in the middle of the image, with its wings visible as it soars through the air."}, {"question_id": 937, "height": 640, "width": 478, "image": "000000376322.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "cleanliness, material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [154.57, 253.18, 33.25, 74.76], "segmentation": {"size": [640, 478], "counts": "W`P3d07Bfb0a1T]O^NRb0i1O0O100000000000000JTNX^Ok1oa000ZOP^O\\OPb0d0Q^OZOPb0g0n]OYOSb0g0m]OWOUb0m0l]OmNUb05P^O7^b0Eg]O:Qc0N1O2M3N1M3M4Lkfh5"}}, "object_label": "bottle", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "material, pattern, pose, cleanliness, texture, transparency", "answer": "The bottle in the image is a wine bottle, which is placed on a table. It is filled with wine, and the wine appears to be red in color. The bottle is positioned between two other glasses, with one glass located to the left and the other to the right. The arrangement of the wine bottle and the glasses creates an appealing and inviting display."}, {"question_id": 938, "height": 640, "width": 478, "image": "000000376322.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, length, material, pattern, pose, state, texture, transparency", "region_anno": {"bbox": [194.98, 364.69, 48.29, 100.48], "segmentation": {"size": [640, 478], "counts": "cWj31mc05M1N7J5K8H6I4M6Ia0@>Y^OhMj`0h2O000O2OO11O000001O000001O000000Oo^OWMm`0i2S_OWMm`0i2S_OWMm`0i2S_OVMn`0j24000000O2N10000ZO\\_OPNd`0X1^1G:G8H9L4L4L`Tc4"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "state:full/whole", "texture:smooth/sleek"], "control_dims": "pose, state, cleanliness, material, pattern, texture, transparency", "answer": "The image features a glass of beer, which is filled to the brim and placed on a table. The beer is served in a tall glass, and it appears to be a dark beer. The glass is positioned on a dining table, and there is a knife placed next to it. The scene suggests a relaxed and enjoyable atmosphere, with the beer being the center of attention."}, {"question_id": 939, "height": 640, "width": 428, "image": "000000140439.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, length, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.52, 255.34, 38.92, 60.96], "segmentation": {"size": [640, 428], "counts": "Z8:5NTc01m\\OORc02n\\ONQc03o\\ONPc02Q]OMnb04R]OMmb03S]ONkb02W]ONhb02X]OOgb01Z]OOdb02\\]O0bb00_]O0`b00a]O0]b01d]OOZb01g]O0Xb00i]O0Vb00k]O1Rb00P^OOna02S^ONla01W^OOga01]^OMaa03e^OHZa08i^OFUa0:m^OFRa0:P_OEo`0;R_OEm`0:U_OFj`0:^100O100O100O1001O10L^\\OHcc04b\\ONX_c7"}}, "object_label": "potted plant", "attribute_label": ["color:green", "length:short", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:piece/cut", "texture:rough"], "control_dims": "transparency, length, state, texture, pattern, size, pose", "answer": "The potted plant in the image is a small, green plant with a few leaves. It is placed on a table, possibly in a kitchen or dining area. The plant is positioned near the edge of the table, and it appears to be a decorative element in the room."}, {"question_id": 940, "height": 427, "width": 640, "image": "000000300341.jpg", "category": "description", "question": "Describe the remote in the following image in detail.", "dims": "color, length, pose, size, state, texture, transparency", "region_anno": {"bbox": [458.04, 12.15, 23.33, 28.52], "segmentation": {"size": [427, 640], "counts": "non5;n<5M1N2O001N2O2N1O1O001O1O1O0000O2N2N1O2N2N4L2N;DS^Q2"}}, "object_label": "remote", "attribute_label": ["color:white", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "state:on", "texture:smooth/sleek"], "control_dims": "color, size", "answer": "The image features a close-up view of a white remote control, which appears to be a Wii remote. The remote is held in a person's hand, and it is positioned in front of a cell phone. The remote control is designed for use with a gaming console, specifically the Nintendo Wii, and is used to control various games and functions."}, {"question_id": 941, "height": 500, "width": 375, "image": "000000142585.jpg", "category": "description", "question": "Describe the motorcycle in the following image in detail.", "dims": "length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [126.97, 348.31, 30.33, 94.39], "segmentation": {"size": [500, 375], "counts": "ljo14[?5f@H?7g=;jAB7?f=0SBS1V=mNjBY1P=ZNSC3Mg1l<TNXC6Lg1k<TNWC6Ng1j<bNVC^1i<QNYC;Nd1j<f000001O2M2O1M3I6J6[OeBcN14]=S1i0K5H9VOXA11<S?O3LRbZ3"}}, "object_label": "motorcycle", "attribute_label": ["length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:full/whole", "texture:smooth/sleek"], "control_dims": "size, state, pose, material", "answer": "The image features a motorcycle with a yellow sidecar attached to it. The motorcycle is parked on the side of the road, and the sidecar is filled with luggage. The motorcycle has a red light on, indicating that it is currently in use or preparing to move. The luggage in the sidecar suggests that the motorcycle is being used for transportation or travel purposes."}, {"question_id": 942, "height": 480, "width": 640, "image": "000000463842.jpg", "category": "description", "question": "Describe the bottle in the following image in detail.", "dims": "length, material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [162.86, 245.49, 24.31, 79.7], "segmentation": {"size": [480, 640], "counts": "Va^2<a>9I7I;F9^O=HTNRCT2h<20jMXCk11UN91W<O`Ci1<_Nn;HfCh1c0ZNg;NfCh1e0YNg;R1dC^OV=>PCSOK6W=f0TCYOo<f0jBVOJ6b=>aBI`=DURe6"}}, "object_label": "bottle", "attribute_label": ["length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:closed", "texture:smooth/sleek"], "control_dims": "pattern, material, texture, size, pose, state, transparency, length", "answer": "The image features a bottle with a pink liquid inside, which appears to be a plastic bottle. The bottle is placed on a table, and it is surrounded by a few other bottles. The bottle is positioned in the middle of the scene, with one bottle to its left and another to its right. The bottle's contents are visible, and it seems to be a part of a collection or display."}, {"question_id": 943, "height": 427, "width": 640, "image": "000000151820.jpg", "category": "description", "question": "Describe the wine glass in the following image in detail.", "dims": "material, pattern, pose, size, state, texture, transparency", "region_anno": {"bbox": [227.15, 243.89, 16.28, 32.35], "segmentation": {"size": [427, 640], "counts": "RZo29R=2\\CFS<<kCDV<=gCEX<=fCCZ<h0O001O01O2N2C`CJc<3_CLa<3`CMP=NRYU5"}}, "object_label": "wine glass", "attribute_label": ["material:glass", "transparency:transparent/translucent", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:empty", "texture:smooth/sleek"], "control_dims": "material, state, size, texture, transparency", "answer": "The image features a wine glass sitting on a table, filled with water. The glass is tall and slender, with a narrow base and a stem. The water inside the glass appears to be clear, allowing the viewer to see the glass's structure. The glass is placed on a table, which is the main focus of the image."}, {"question_id": 944, "height": 437, "width": 640, "image": "000000147205.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, pattern, state, texture, transparency", "region_anno": {"bbox": [0.98, 1.09, 639.02, 431.13], "segmentation": {"size": [437, 640], "counts": "j25k4N\\Lm3kNWLP3Ni1OVKMR1P4oNVLo23f1MZLl3QOSLo25d1M[Ll3SORLm24g1MXLW4Q2lKg1LXLT4TOgKo27g1MULV4UOfKo27f1MVLW4UOeKo27f1MVLX4W2kKc1MULZ4W2iKd1MTL\\4YO`Ki21SM2g41SL^4XO_Kk20SM2f41TL_4YO]Kj26i1NSL`4ZO\\Kj20TM3e41RLb4ZOZKn23f10RLd4\\2\\Kc1NQLh4[2ZKc1ORLh4Y2ZKe1NQLj4Z2VK`2k4aMTK_2m4`MSK_2n4aMRK_2o4R31O1O1WOmJoHT5Q7lJoHT5h71O1O100O100O1O100O1O100iJeJS2\\5mMdJS2\\5mMdJR2]5nMcJR2]5nMcJQ2^5oMbJP2_5PNaJo1`5QN`Jo1`5QNaJn1_5RNaJm1`5SNaJk1`5WN^Ji1b5WN^Ji1b5WN_Jg1b5YN^Jg1b5XN`Jf1a5ZN`Jd1a5[N`Je1`5[NaJd1_5[NcJc1^5]NbJb1_5^NbJa1^5`NbJ^1_5bNbJ]1^5cNcJ[1^5eNcJY1^5gNbJY1^5gNcJX1]5gNfJV1[5jNfJU1Z5kNgJS1Z5mNgJR1Y5oNfJQ1Z5oNgJo0Z5QOfJo0Z5POeJQ1\\5oNcJR1]5nNcJQ1^5oNbJQ1^5oNbJQ1^5oNbJP1i1SLW1m2PMo0h1XLV1i2RM\\M@T3V2jLW1g2RM[MBS3S2oLW1b2UM\\MAR3S2QMW1`2VM]MAP3R2UMV1^2WMTM_O23V3Q2XMU1\\2XMSMA13W3n1ZMV1[2XMSMOU3b1`MU1X2ZMSM0T3a1bMT1X2oLTMNO?Q3`1eMT1W2mLWMNMc0m2^1jMS1U2oLUMOMc0n2[1lMT1U2PMPMl0n2P1mMT1T2WNMe0QNS1Q2[MTMH14h2e1UNR1n1]MWMC74]2j1WNXNQO]2m2VNWMUOM7e2j1ZNSN_OU2^2bNTMYON6e2f1WO7S1cNVMWOL9c2f1^O1m0TNRMN0M027LJ<a2f1BOk0SNSM1OLO2`06Q2i1DNj0UNRM1NL12;:U2c1HMg0eNQMA6`0X2^1LJe0cNPMC21=9o1f1OIb0[NQM1n02`1g11K?dNWNCZ1m12K=fNPN@TO4\\2k14K<kNTM^O?NA4OKY2m1:M;jNRM_Oa0N@8V2d1=M;dNQMD1Ng0:^1b1?N;VNSM7NJ0Og0;\\1`1d0N7jNQM_Og0:\\1^1g0N5QOaMZO_O;S2[1i0O3kNSM_Oa00]O<S2Z1k0O0iNPN@TO=P2[1m0ON_NUM1P1KnN7Q2`1n0NNkNPN^OUO2N8P2_1o0NMWOfMROA0N:o1_1o0NOTOeMUOC;i1^1Q1M0\\NQM7m0GYO=d1\\1V1M4cNaMJ\\ON6<b1\\1W1MOhNRMDN0<7J6c1Z1X1MOiNPMH;j0^1g0Y1NMjNRMA018Q1_1f0Z1MLjNeMb0V1f0Z1NJ]NWM4`0b0\\O^Oh1b1[1MJkNfMa0U1g0[1MI[NTMa01C70Jd0:WOn0h1j1NKjNRMH5NLd08XOo0e1l1OKhNRMC112S16kNn0h1l1NKhNRMC21N71a07VOn0h1n1NJiNPMC1>593YOn0e1P2OImNQMK8:L^OR1`1P21HlNSMCN09b0LZOK0W1c1Q22EkN[M_ON23f0IYOY1c1n12DjN]M_OM22l0S1f0n13BPOWM]O2N4k0T1f0n14A[OVMQO6k0LSOQ1b1V25A[OVMoN6l0KWOo0]1Z26@ROTM]O2J7h0GHn0Q1]27AQOTM]O>`0DAN4h0LYOH6n0T3l0AYObMTOD50=c0^ON?h2T1@ZOcMSOE4N`0c0ZO5<c2Y1_OZO_MWOI0N`0c0XO9;`2\\1]O`NXM<2\\ON:1N0`0g1_Od1a1\\O_NZM2LM3j01UOL9k1Hc1b1\\O^N\\M>J>2TON8l1Fb1e1\\O\\N]Mf1J[NO7o1E_1g1[O]N_M<Ia01RON8Q2A_1k1YO]N_M70c0KTOO8a5]1VM]N_M53MFG11N1122009`5]1VM]N^M72o0GQOc5\\1VM^N]M62a1[5KVM^N]M63`1Z5LVM^N]M1KFc05^O3Nk0c5h0VM^N\\M1d0I[O3N1Nb0c5R1VMoNoMZO\\O3L10`0d5S1UMoNoMZO[O>N5c5T1UMoNnM^O\\OL0N99\\5a1QMjNXMZOb0>@Cc09R5b1QMiNlMJ8Hn4e1nLjNjMI_6]1gKjNiMIa6]1eKkNiMGd6^1cKjNjMEe6b1aKhNkMEe6c1`KiNkM[O@OX7m1\\KmN\\5S1dJlN]5T1cJjN_5V1aJjNbM_O[7h1SKjN`M@\\7f1TKkN]MB^7c1UKjN_MB]7c1TKhNcMEX77^Hi0g2YOfMEU74oHEEe0`20dMBY70]I<f18\\M\\Oc7MdI9]1i0P5kNgI;Y1;[MDY9N\\I>[MDZ9M[In0e6RO[In0f6QOZIn0g6ROYI<_M^OM3\\92WI4[ML6KM1]93UI?_M_ONO^93UIa0[MA0K`93UIP1k6POUIP1k6POVIo0j6QOVIo0k6POUIP1k6POUIo0l6QORI`0_MG`9HoHc0bMD_9IoHc0cMC^9JoHc0cMC^9JnHe0cM[OLNe92lHf0aM[OOKe94jHh0`MYOj9OfHn0[7ROeHO`Mf0o9[O`Hi0b7WO^Hh0d7WO\\Hi0dMTOk93aHi0dMTOk93`Hj0eMSOk93`Hj0e7VO[Hk0d7UO\\Hk0d7UO]Hj0c7VO^Hi0b7WO^Hi0b7WO^Hi0dMTOh93eHi0aMUOj92eHNaMk0j9WOkHh0U7XOkHf0W7ZOiH:]MEn91eHNZM66Jk92eHNYM77Ik92eHNYM77Ij93fHMYM68Ji93fHMYM4:Lg93iH1`MKh94hH0d71]HNc72_HLa74o2100000000O1000000O10000000000O1000000O1000000O1N2K5O100O1O1O1O1O1O1O100O1O10000O10000000000000000001O00000000001O001O00aDVOS:j0lEXOS:h0nEVOS:j0[1100000000bDVOQ:j0oEUOR:k0\\100000000000000000O100[DTOa:l0^EUOb:k0^EVOa:j0_EVO`:k0`EUO`:k0`EUO9Nk8m0lFUO9Nk8m0lFUOBO03^9j0QGRO_O6OOMOQ9j0SH]OmNMMMQ9j0THAjNI0No8i0WHAiNH0On8j0YH@gNI1Nm8j0ZHAfNJ1Ll8k0]H6dNQOm8j0^Hi0_7XO`Hi0_7XO]Hl0b7UO]Hl0c7TO^Hk0`7WO`Hh0a7XO_Hi0_7XObHg0iNmM_8]1gHg0[7\\OeHc0[7^OdH@kNM3SOP8e1RIZOlNO1QOR8f1QIZOmNNX8i0jHZOnNMU8l0mHWOnNMNROQ8k1SIVOoNMLROR8k1VISOlN4n7i0XIQOjN6o7h0XIQOiN7S8c0VIUOgN8T8=ZI\\O`N8V87fGhNe1j0]N7\\83cGlNd1g1[N_N_8m0bGnN2M\\1i1aN_N_8m0cGlN10\\1Q2Q7SOhGlNW1Q2Q7TOgGkNW1R2R7QOiGmNU1R2R7POcGnN10Y1S2S7nNeGnN00P12nNQ2`8lNRI[1n6cNTI]1l6cNTI\\1m6cNlGUOd0Y2`7aNnGUOb0Z2`7`NTIa1l6_NUI`1k6_NVIa1j6^NVIc1j6\\NVIe1j6[NUIf1k6VN\\G^Oj1\\2k6UN\\G^Of009^2e7TN\\G^Of009^2e7SNVH_O3\\1ROFe8_OUH@4S1\\OWOF8e8NUH@4S1]OLY8@VHB4R1TOmN4o0^8@VHB3S1TOmN3P1`8^OVHB2U1TOlN2P1a8]OYHA0[1VOGa8]OYHAOc2h7lMXHB0c2g7kMYHB0c2g7kMYHBOV2WOTN`83ZHDOl1WOUN37]84ZHDOT2XOUN_82[HEOc2e7iM\\HDN]1VOE`8ZO\\HDNo0[OUOK`00E`82]HELo0_OROJb0NF`82]HELl0CSOFS1]8ZO]HFKd02<f7ZO\\HGGf0:8c7ZO]HH@k0c01_7]O]HH_Ol0f0N^7]O^HI]Ol0l0JY7A^HI]Ol0o0GV7D^HI]Oj0T1VOfN4Z83`HI\\Oi0e1WO_66aHJZOi0h1VO\\67cHJZOg0i1WOZ68bHK[Oc0m1YOV69bHK[O>HZOX23S69cHLVO`0Z2ZOm5:cHLUO9LDb2Kj5;dHMTO6h2C`59dHNTO4k2E\\58fHOSO3Z;MdE0m:OTE1k:0UE0j:0WE0g:2YEOe:0]E0b:0_EOa:2_ENa:1_E0`:1`EO_:2aEN]:3dEM\\:2eENZ:3fEMZ:2fEOY:1hEOW:1jEOT:3lEMT:3lEMS:3mENS:1nEOP:3PFMn94RFMn93RFMn92SFNl92UFNj93VFMf96[FJa9:_FF[9?fFAT9d0lF]OU9a0lF_OT9`0mF@S9`0lFAU9=lFCT9<mFDS9;nFES9:mFFS99nFGR98oFHR96oFJQ95oFLR92oFNQ91PGOP91oF0Q9OPG1Q9MPG3P9MoF4Q9JQG6o8IRG7n8HSG8m8GSG:m8FSG:m8ETG;l8DUG<k8CVG=j8BWG>i8BWG>i8AWG`0i8@WG`0j8^OWGb0n:000O1000000O1000000O10000O1000000O100000000O100O10000O1000000O10000000000O100000000O100000000O10000O10000000000O1000000O100000000O100O10000VHmNQ3T1nLnNQ3R1nLoNR3Q1kLSOT3m0mLROR3o0oLQOP3o0QMPOo2P1QMQOn2o0RMQOm2P1SMPOm2P1SMPOm2P1SMPOm2P1RMROm2n0SMROl2o0TMQOl2o0TMROj2o0WMQOh2o0XMROg2n0YMSOe24jHJ0Na44e23jHLONb4H]K8W76kHMNNg4H]KNS7>lH:c4[O^KNR7=lH;b4\\OaKMn6=nH;e4YO_KOn6=nHHO:h4_O_K3j6<QIG09o4DP2;RIG0:e4A_K4h6;SIGO;f4@`K4g6;SIFO<Q5Cl1<TI9Q5[Oi1<XI8o4]Oh1<XI7P5]Oh1Y1WNfNoJNf6]1\\NbNk1^1V5ZOnCIQ<7PDZON9R<>nCIe4]Oe2`1[M_Nf2a1f41[H^NV3c1jL^NU3b1kL_NiKNT7m0hHFZ4Hl2c0jHEY4Jl2a0kHEY4Jl2`0kHXOO8Z41j2?oHFW4Kj2?oHFV4Lj2a0mHDY4JYMDl3d1jN_NiK2a1Lk3c1kN]NnK1\\10i3c1mN[NoK3Z10h3c1oNYNPL4Y11f3c1QOXNQL4W13e3f0oJGT4\\OQL5V14c3e0RKFT4[ORL6V14a3d0RKIa4_OlL5`3b0SKKT4YOSL58J;;Q4c0TKKT4ZOSL39J;=o3^1ZOXNSL1:M:=m3o0WKoNU4GRL2<K9?k3^1^OVNRL2<K9`0j3]1^OWNSL1[1<R3]1@UNTL1\\1=R1_OTOT1UNDU4[OTL1\\1=Q1@dM4o0o0hNRO09U4FPLO?L9c0f1_OcM7o0U1kNQOV4HjKOd0J:b0e1@bM:n0d1R3aN^L@;b0d1_OcM<k0c1T3aN^L@<b0b1_OeM?e0`1Z3`N_L@<a0`1@gMa0b0^1[3aN`L^O=b0`1@eMd0?[1`3aNcM0_N^OQ21nMh0;Y1d3_NdM2[N_OT2OmMk0:V1f3YNlKDl1c0VNBT2MmMn08S1j3WNlM:PNBT2MmMo05S1n3PNjKN1Mn1n05XOmMn05Q1Q4PNiKN1Mn1o04XOmMn03`0NjNT4HkKKT2l0N[2nMVMU4IkKIU2m0Kn2T2]LUNd0CR3Y2ZLlKGU2n0DR3Z2ZLmKFV2m0BT3Y2[LoKDV2n0AR3[2^LUNa0^OQ3^2WLlKNY2j0\\OQ3^2XLmKNX2i0\\OQ3`2XLlKOW2i0\\OP3`2XLoKJNOY2n0ZOQ3`2XLoKI[2n0UOQ3]2PLSL81H\\2o0ROP3_2RLPL92G\\2o0QOP3a2]LRLD\\2P1lNS3f2YLQLE]2P1jNR3h2ZLQLF\\2Q1iMnNc0Q4V3\\LQLE\\2_1WNa2]3[LPLF[2X6d1SJQLE\\2V6d1UJQLD[2W6c1VJSLB[2V6a1ZJUL^Oa1NTOY6W3[JTL]O\\2X6^1^JhN`5Y1bJeN^5oM"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:pink", "color:yellow", "transparency:opaque", "pattern:dotted/speckled/spotted", "state:covered", "texture:soft/fluffy/furry/hairy"], "control_dims": "transparency, cleanliness", "answer": "The dining table in the image is set with a delicious meal, featuring a large piece of meat, likely pork, accompanied by a variety of vegetables. The meat is placed on a white plate, and the vegetables are scattered around the plate. There are several carrots and mushrooms on the table, adding to the visual appeal of the meal. The table setting also includes a knife, which is placed near the plate, ready for use. The overall presentation of the meal is inviting and appetizing."}, {"question_id": 945, "height": 425, "width": 640, "image": "000000148508.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "color, length, material, pattern, state, texture, transparency", "region_anno": {"bbox": [377.3, 199.77, 30.48, 25.63], "segmentation": {"size": [425, 640], "counts": "gRm4`0g<3N1O10001O0000000000000000O10000000O1000010O1001O0O4K3N;D[RP3"}}, "object_label": "car", "attribute_label": ["color:black", "length:short", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "state:piece/cut", "texture:smooth/sleek"], "control_dims": "pattern, length, color, state, texture, material", "answer": "The image features a black car driving down a street, with its brake lights on. The car is positioned in the middle of the street, and its rear lights are clearly visible. The car appears to be a small SUV, and it is moving in the direction of the camera."}, {"question_id": 946, "height": 427, "width": 640, "image": "000000148730.jpg", "category": "description", "question": "Describe the boat in the following image in detail.", "dims": "color, length, material, pattern, pose, size, state, transparency", "region_anno": {"bbox": [214.46, 101.1, 277.64, 191.48], "segmentation": {"size": [427, 640], "counts": "Qli27R=8J3M6I2bC[OT<U1I;F4L2_D[NW;c1kD\\NV;c1kD\\NU;d1lD[NT;e1lD[NU;d1kD\\NU;d1kD\\NU;d1kD\\NU;d1kD\\NU;e1iD\\NW;d1hD]NX;k1000O11O01GgD]NZ;b1800001`DZNY;e1hD[NX;e1hD[NY;d1gD\\NY;d1fD]NZ;c1fD^NY;b1hD\\NY;d1700000001O0O10cN_NPGa1]:1O000O1O2OO10O10000000O2N2O11O00N1G[DlNe;T1\\DkNd;T1]DlNc;U1^DhNd;W180O100O3N3M10O0O10000O10000000000O1O1000000000_OfNQEY1a;OcLmNcJS1]5nNcJR1[5PObJHnLW1`8RO`GG`20PNU1R8XOlIEPNk0^8^ObIGQNj0_8]O`IIPNk0b8ZO]ILQNj0e8XOYINRNj0f8XOWINTNS1IlNV83kI0UNQ1InNX80iI0WNR1InNW81gIOXNS1JmN\\8LcI3WNT1KjNg:2]EU11jNT82aH0DOEV12iNU82]IO\\NV11jNX8OZI1^NV10jN\\:0eEU1OkN\\:0fET1NlN]8NQI2dNT1NkN^80oH1eNT1NkN_80lH2fNT1OjN\\:2dEU10iNf8N_H4jNX11dNg85XH0oNX1Z9gNgG1oNX1Z9gNgG1oNX12cNi83VH2oNX1\\9gNcG0QOZ1]9gN`GNTO[1^9fN]GOUO[1_9eN\\G0UO[1l:eNTE[1d9dNSG0YO]1d9hNnFJ_O^1c9iNmFJ@\\1c9jNmFK_O[1f9hNkFL@\\1g9fNiFN_O]1j9cNXG]1[:1@`NSEa1j:aNTEa1l:_NoDf1Q;ZNoDf1P;[NRENK_1S;bNZE]1f:cNZE\\1f:eNZE[1f:dN[ES1DkNR;3ZEP1EoNP;1[EP1EPOo:0\\Eo0FQOn:0\\Eo0HoNl:2\\Eo0NPO_:1cEo0InNH3k:1dEn0InNH3l:OdEP1LQO`:NeEQ1KRO_:MfEQ1DnNN4b:M\\EOa0R1ISOZ:MZEOc0Q1ITOY:0nEl0CPOK4e:OmEl0C[Ob:IiEm0D[Od:GhEn0D[Od:GhEo0B\\Of:ChER1CZOf:CfES1EYOZ;g0gDXOZ;g0eDZO\\;e0dDoNJ9b;h0dD[O\\;e0cD\\O];d0bD]O^;d0aD\\O_;f0_DZOa;X10000000]O`D[Oa;f0]DZOc;W100001O0O1000001O1O1N1AWD\\Oi;S1O1N2I6M4L4N2O001000000O1000000000000WOlM[Fj1ZO]NT;m1000000O11O0000O1UOmM^FR2c9lM`FR2_9mMdFS2Z:G90000O10O100000O101O2NI\\NhDc1X;]NiDb1W;^NXES1h:mNYER1g:nNXES1h:nNWER1i:nNWER1i:mNXES1h:nNWER1i:nNWEQ1j:oNVEQ1k:mNVES1j:mNVER1k:nNUEQ1l:POSEP1m:QOREo0o:POQEP1o:oNSEP1m:QOREo0n:QOREo0R:POTF1Km0S:RORFOLo0R:SOhFm0S:ROSEn0m:SOREm0X:TOeE02l0[:QOdE31l0o:TOQEl0P;SOoDn0f;10O10002N1O1O0O2O1M4K;CRbo1"}}, "object_label": "boat", "attribute_label": ["color:black", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:big/large/giant/huge", "state:piece/cut"], "control_dims": "material, pattern", "answer": "The image features a large boat docked at a pier, surrounded by several smaller boats. The main boat is a large black boat, which is docked next to a smaller boat. There are also two smaller boats visible in the scene, one located near the main boat and the other further away. The scene appears to be a harbor or marina, with the boats docked in a line."}, {"question_id": 947, "height": 375, "width": 500, "image": "000000159791.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "color, material, maturity, state, texture", "region_anno": {"bbox": [283.29, 63.83, 25.68, 19.72], "segmentation": {"size": [375, 500], "counts": "TRX33d;2N2N2O0gDHR;8kDJV;<0O1N3M3M1000O01O001O1O101O00001O00gWV2"}}, "object_label": "bird", "attribute_label": ["color:gray", "material:paper/cardboard", "maturity:adult/old/aged", "state:dry", "texture:smooth/sleek"], "control_dims": "color, maturity, state, material, texture", "answer": "The bird in the image is a blue bird with a black head. It is perched on a white surface, possibly a wall or a piece of paper. The bird appears to be looking at the camera, capturing a close-up view of its face."}, {"question_id": 948, "height": 480, "width": 640, "image": "000000281179.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "material, pose, size, texture, transparency", "region_anno": {"bbox": [620.25, 136.24, 19.75, 37.17], "segmentation": {"size": [480, 640], "counts": "ZWS9g0Y>1O4L6J1OFTB@l=>ZB]Og=b0ZB^Of=b0[B]Oe=c0[B]Oe=c0[B]Oe=d0XB_Og=m0000N2K5L4M3MiK"}}, "object_label": "bench", "attribute_label": ["material:wood/wooden/bamboo/hardwood", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "pose, material", "answer": "The image features a bench with a wooden back and a metal frame. The bench is located in a dark room, possibly a basement, and is situated near a staircase. The staircase is made of metal and has a few steps. The bench appears to be empty and is positioned in the middle of the room, providing a place for people to sit and rest."}, {"question_id": 949, "height": 408, "width": 640, "image": "000000166563.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, material, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [79.69, 43.03, 443.06, 330.44], "segmentation": {"size": [408, 640], "counts": "oSQ12f<200O2G6N3N2O2N2M3N3M1N2N3O1O1O01O01O100O010N11O001O10O100O10O1O000O101O1O0O100O2O0O100O101O0O1O011N100O0010001OO10O10001N00100O011N0100O0100O01000O010O10O10O011N010O0001000O01O01000O00010O001000O01O10O1O01O010O001O100O001O010O00001O001O1O00001O001O0O2O001O0O3NN2O01ZDVO^;j0aDVO`;j0`DVO^;l0bDSO^;n0bDPO_;Q14O10]DPO^;P1bDPO];P1dDPO[;Q1eDoNZ;R160O01O001000O100kDnNc:S1\\EPOa:P1UEmN53f:P1TEnN61f:R1TEmNX;U141O1dDhNW;Y1iDhNV;X1jDhNT;Z1lDfNT;Z1lDfN:O[:\\1[EeNS;[1mDeNR;\\141O1O100O1OOPE`N71U:a1cE_N80T:b1eE]N70T:d1RF\\Nn9c1SF]Nk9d1d000100O00OUE\\Ne:d1[E^Nc:c1^E\\Nb:e1]E[Nb:f18N1O20O01OhE]NYO0n9d1gFfNV9Z1iFVOh8i0XGWOh8j0XGSOk8n0RGVOk8k0SG^Of8b0ZG@c8a0]G_Oc8c0ZG^Of8c0YG^Oe8c0YG_Og8b0XG_Og8a0XG@h8`0WGBg8X20001N101N100O100O2N2O3QIPLo4R4dJeLQ5[3fJgLnNZO[6Q4]JlL[OROX6S4TJjKAV13mNX6\\6J10L300N3@gI`JY6`5hI_JY6a5gI^JY6d5eI[J]6n52M201O1OlKPJb1n5e2EZIcJg6\\5[IbJg6^5XIbJh6^5WIcJi6]5VIcJl6c52N101N2N2O0O2O1O0O3N001O00000iJeHR5Z7mJiHQ5W7PKhHQ5V7901O2N2N1O2NVMQILn63SIOk60VI2h60UI4h6V3H2N<DlKnIcM1M0n3l5bNSJeM0k3m5gNSJY1m5lNSJo0m5QOSJo0m5QOSJo0m5QOSJm0o5SOQJl0P6n20QLPJV1P6jNPJV1P6i21O000lKoIa1R6]NoIc1Q6\\NnIf1R6YNoIg1Q6WNQJi1P6TNSJl1l5RNVJn1j5QNXJn1h5QNYJo1g5oM[JQ2e5mM^JR2c5lM^JU2a5jMaJU2_5jMcJV2]5iMeJU2[5iMiJ\\1UOaMS6Q1kJP1Z6nNiIl0\\6SOfIh0_6TOeIh0^6TOgIh0\\6WOgIe0[6ZOgId0[6YOhIe0Y6YOjIe0X6UOPJe0T6VOQJh0YO_NX5f0bKi0SNaNg00d5b0gKl0nMaNh01d5>kKm0oNdNW5<mKm0iNgN`59kKl0fNlN_56nKm0bNnNa52PLl0aNSOa5MQLo0TNQORO4m9h0VFTO>7ZONT:`0XF^O49^OJV:<[FAOMC9NLY:1`FLFNC62NW;LUEh0DZO`;g0^DZOa;g0^D[O`;o0M3J6L6RObNPFK4e1a9\\N\\F39L@e1j9]N_F15NBe1j9[NTGOSOe1a:[NlEb1T:^NmEb1c:1I]NWEe1]:^NbEm1\\:9O2OO101OoNkM_GT2`8mMSGLKX2Q9kMUGLKX2P9lMUGLKY2R:1GfMQF\\2c9eM^F2NZ2c9eM_F0N\\2e8bMRH2[O0O\\2]9hMcFM0Z2S8dMnH5PO0MW2T8eMnH4ROOMX2S8dMoH4SOOKY2R8cMRI4ROOK[2Y9eMnFOG_2[9aMoFh2R8YMiHj2T7VMmHj2R7XMlHj2S7QMgG1W14hNc2n7YM^HOm02jNi2g7WMaHNV1m2V6UMWJn2f5QMkIOoNS3U7oLRJO_NT3]7oLbHLN7:KM0MNM21\\3U7fLjH;4D10NOK03P4b6RL[I>0E7LNNK23o3b6nLcIRO11Jo3OnK_6;bI55A22If3M^L2J_68eIM9LK1If3M_L0N]62jIN7MK0KX4Z6fKPJ4NONOJX4l6hK\\I000HX4m6gK[I0O4HV4Z6dKUJ1H036FU4Z6eK`J1^O7HS4h7mKYHR4g7oKYH^3M_L1Ni73YHn2NPMOMOO1>V7@ZI9A\\20aMOOa0L_O>U7A]I9_O[22`M1N=a0X7_2ZHSMNOa0=X7DYHb2OhM?2W6ATJ1XOZ3OgL0?f6@RJ1YOZ3KjL0=k6_OnI1]OU4k6hKeIOGV4h6kK\\I4LP4i6lKVI9Ln3P7jKRI9LR3JeL:4S7LcHc05h2MdL93T7e0cHQ3O`La74cHBLY4g7hKZHN5^4Q80O1O1O1N1N300001O1N3N1O[HbKQ7]4oHcKR7\\4jHdKB1f7Y4lHfKV7W4lHhKT7W4h0O2OkGkKF5h7m3bHnKD7l7j3aHWL`7h3`HXLa7g3_HYLb7f3]H[Lg7a3UHcLP8<gGR27cMT8DhH\\2ROQNl9`1UF_NP:CkE05\\15lN`:e0VERO?8T<J1Oad`1"}}, "object_label": "elephant", "attribute_label": ["color:gray", "material:asphalt/cement/clay/concrete/stucco", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry", "texture:rough"], "control_dims": "state, texture", "answer": "The image features a large elephant statue standing on its hind legs, positioned in front of a sign. The elephant statue appears to be wearing a suit, giving it a unique and eye-catching appearance. The statue is located in a parking lot, and the overall scene is black and white, adding a vintage feel to the image."}, {"question_id": 950, "height": 612, "width": 612, "image": "000000341828.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, state, texture, transparency", "region_anno": {"bbox": [338.7, 259.06, 101.64, 142.99], "segmentation": {"size": [612, 612], "counts": "^b[6;eb05L5J5L3N3L4J5L4M3N3M2M3N2O1O1N200O1O1O002OO01O1O0O2O1O1O1O1O1N2O1O1O1N3N1N101O1O1O001O11N01O001O100O1O1O001O1O1N2O00O11O0O2O0O2N2N10WMX@W2h?c0NQMX@V22mMd?]2`@bM_?[2e@[MI4`?`2k@[MF4^?_2UAaMj>]2ZAbMd>]2`AaM`>\\2U1O1M3N2N3L3N2M3M4L4M3M3L3M4L4M3M4L4M2O2N2K6BdTW3"}}, "object_label": "cell phone", "attribute_label": ["color:black", "transparency:opaque", "state:on", "texture:smooth/sleek"], "control_dims": "texture, state, transparency", "answer": "The image features a man lying down with a cell phone placed on his chest. The cell phone is a flip phone, which is a type of mobile phone that has a hinged design, allowing it to fold in half when closed. The flip phone is open, revealing its screen and keypad. The man appears to be resting or sleeping, with the cell phone serving as a source of communication or entertainment."}, {"question_id": 951, "height": 640, "width": 474, "image": "000000191013.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "material, pattern, pose, size, texture, transparency", "region_anno": {"bbox": [450.52, 567.14, 23.48, 36.09], "segmentation": {"size": [640, 474], "counts": "YRk8=ac04M2N2N100O2O0O10001N100O01000O2O0O0010000S^O"}}, "object_label": "car", "attribute_label": ["material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "pose:horizontal/lying", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "pose, pattern, material", "answer": "The image features a white car parked in a parking lot. The car is positioned in the middle of the scene, and it appears to be a compact vehicle. The car is parked next to a large white building, which could be a warehouse or a similar structure."}, {"question_id": 952, "height": 480, "width": 640, "image": "000000329080.jpg", "category": "description", "question": "Describe the suitcase in the following image in detail.", "dims": "color, pose, state, transparency", "region_anno": {"bbox": [0.19, 303.84, 20.45, 43.99], "segmentation": {"size": [480, 640], "counts": "`9\\1d=02M2O1N2O1N2N2O1O1N2O1O001N2N2O1M3BhAN[WS9"}}, "object_label": "suitcase", "attribute_label": ["color:black", "transparency:opaque", "pose:horizontal/lying", "state:open"], "control_dims": "state, transparency, color", "answer": "The image features a black suitcase with a handle, placed on a table. The suitcase appears to be empty, with no visible contents inside."}, {"question_id": 953, "height": 427, "width": 640, "image": "000000200961.jpg", "category": "description", "question": "Describe the truck in the following image in detail.", "dims": "material, pattern, state, texture, transparency", "region_anno": {"bbox": [456.05, 147.15, 54.82, 29.52], "segmentation": {"size": [427, 640], "counts": "]To5<m<3O1O001O2N1O000O0K50100O100000000O100000000000000000000001O0O01001O0000001O0000100O1O001O1O2N1O1O001O0O2HWWe1"}}, "object_label": "truck", "attribute_label": ["material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pattern:plain", "state:off", "texture:smooth/sleek"], "control_dims": "pattern, transparency, material", "answer": "The image features a red pickup truck parked in a grassy area. The truck is positioned in the middle of the scene, with its front end facing the viewer. The truck appears to be parked in a field, and there is a person standing nearby, possibly observing the truck or the surrounding area."}, {"question_id": 954, "height": 480, "width": 640, "image": "000000254814.jpg", "category": "description", "question": "Describe the bicycle in the following image in detail.", "dims": "length, material, pose, texture, transparency", "region_anno": {"bbox": [69.93, 269.19, 49.43, 27.05], "segmentation": {"size": [480, 640], "counts": "lcP15i>3I8M2O1O1N101O00000000000O10O2N1@eA:]>EcA:c>N2O00000J[A1e>M^A1c>042O101O0O101O1N3L3O1O1O10O00O100O100O11N2O2M2M3M\\nc7"}}, "object_label": "bicycle", "attribute_label": ["length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "transparency", "answer": "The image features a bicycle with a pink seat and a pink pedal, parked on a sidewalk. The bicycle is positioned in the middle of the scene, and it appears to be a child's bike. There are several people in the background, with one person standing close to the bicycle and others further away. The presence of multiple people suggests that the area might be a busy or popular location."}, {"question_id": 955, "height": 480, "width": 640, "image": "000000254814.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [212.46, 200.36, 14.26, 36.59], "segmentation": {"size": [480, 640], "counts": "[bS39e>l0VO00O1O1O100O1I7N2O1O1O1JfAFZ>6;KjmP6"}}, "object_label": "traffic light", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:red", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "texture, state, length", "answer": "The traffic light in the image is a large, multi-colored light mounted on a pole. It has a red light illuminated, indicating that vehicles must stop. The traffic light is located near a building, and there are several people standing nearby, possibly waiting to cross the street or observing the traffic."}, {"question_id": 956, "height": 401, "width": 640, "image": "000000210032.jpg", "category": "description", "question": "Describe the knife in the following image in detail.", "dims": "color, length, material, pose, texture", "region_anno": {"bbox": [4.51, 163.1, 125.25, 118.05], "segmentation": {"size": [401, 640], "counts": "e`27U<6I7N2O1O0010000O100O10O11N01001N01000O1000001O0O100000O010O10O102N1O00O001O0000100O100O1O100O1O001OfDXOk:h0`0O100O1O2N2OiD^O_:a0k0N1EoC2Z<O00O100O10000000000O2O001O000O100O0100O01O1O11O0O100O100010OO100O1OHIWD7R<O1000000O1000000000DK[D5d;L\\D6b;I^D8JHn;9oCKo;=O1N10O003MN11O4L1O100O1O2L3ORRW6"}}, "object_label": "knife", "attribute_label": ["color:gray", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "pose:horizontal/lying", "texture:smooth/sleek"], "control_dims": "pose, color, texture", "answer": "The knife in the image is a large, wooden-handled knife with a silver blade. It is placed on a plate, which is sitting on a dining table."}, {"question_id": 957, "height": 500, "width": 335, "image": "000000293071.jpg", "category": "description", "question": "Describe the car in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.2, 153.33, 90.5, 66.02], "segmentation": {"size": [500, 335], "counts": "m4a1S>1N1O10000O102N3M2N1O1O000000000000000001O00O01N2O1N2N2O10000000000001O00O110O00000000001O000000000000010O0000001O00001O1O001O001003M1O00O011\\OPB@Q>;WB@k=<ZBAh=:_BE`=7eBG[=8fBG\\=7fBHZ=8gBGY=8S1N100O1O2O00001O002Mc^g3"}}, "object_label": "car", "attribute_label": ["cleanliness:clean/neat", "color:red", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:off", "texture:smooth/sleek"], "control_dims": "length, texture", "answer": "The image features a red car parked on the side of a street, next to a silver car. The red car is a compact sedan, and it is parked in front of a building. The silver car is parked behind the red car, and both cars are positioned close to each other."}, {"question_id": 958, "height": 640, "width": 523, "image": "000000339442.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, texture, transparency", "region_anno": {"bbox": [21.61, 362.39, 485.4, 142.96], "segmentation": {"size": [640, 523], "counts": "eod0e11]N3j029b?T3M2O1000fN^@WNa?T3000000001O001O0000001O0000001O00001O001O001O0000001O00001O000O101O00010O0000001O000O11O01O0000001O0000001O00000000001O00000000001O000000001O0000000000001O000000000000001O000000000000000000000000000000000000001O000000000000000000001O000000000000000000000000000000000000000000001O0000000000001O00001O001O00001O0000000000001O000000001O0000MaLe_O_3_`0O000000O1O1O1O10000000000000000O100001O0000000000O1000000000000O11O00O100000000000000000000000000000000O100001O001OO10000N200001O0000000000O1O10000000000O11O00OjLZ@T2f?gMd@T2\\?iMh@V2X?iMj@V2V?iMm@U2S?iMPAV2P?hMSAW2\\`0O2N001O1O001O1O1O1O001O001O001O001O000000001O0000000000000000000000O10000000000O1000O1000O11OO100O1O1000000000000O10000O1O1O1000000O100O1000000001O00001O00O10000000000LkM\\^OV2ca0kM]^OU2ga0000M3O101O000O001O1001O001O10O00O0100O100001O001O1O1O2N1O1O1O1O4L010O1O00001N101O0010O0001O001O0O10000001O0000000000O10000000O2N10000O10O010000O2N1O1000000O00100O101O0001OKPN[^Oo1la0O0O101O1O0010O01O1O0O3N001O1OVOeNo^O[1Pa0hNn^OX1Sa0bNa^OL=a1oa0Mk]e0"}}, "object_label": "dining table", "attribute_label": ["color:green", "color:red", "transparency:opaque", "texture:smooth/sleek"], "control_dims": "color, texture, transparency", "answer": "The dining table in the image is covered with a red and white checkered tablecloth. On the table, there are several black grapes scattered around, with some of them placed closer to the center and others near the edges. The table appears to be set for a meal, and the grapes are likely to be part of the food being served."}, {"question_id": 959, "height": 375, "width": 500, "image": "000000275749.jpg", "category": "description", "question": "Describe the laptop in the following image in detail.", "dims": "color, pose, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 342.13, 74.16, 28.66], "segmentation": {"size": [375, 500], "counts": "R;b0U;00000O01000000000000O01000000000O010O10oD@j:a06000PE_Oj:`0WE@i:`0WE@h:8SEO5Ih:8SEN6Jg:`0YE@g:`0YE@f:a0ZE_Of:a0ZE_Of:`0[E@e:`0[E@e:`0[E@e:`0[E@e:?\\EAc:`0]E@c:`0]E@c:`0]E@c:`0]E@b:b0]E^Oc:d0[E\\Oe:a0VE@100Oi:`0WEBOO1Oi:`0WEBOO1Oh:a0XE@000Oh:b0WE_O5Od:b0WE_O5Od:`0YEA3Od:`0YEA3Od:`0YEA3Oc:a0ZE@3Oc:a0YEB3Md:a0ZEA2Nd:`0\\E@M10Of:b0[E_O3Ob:h0]EXOc:k0ZEUOf:n000OE[EGd:9[EHe:d01DZED0Jf:6ZE30M0Je:l0[ETOe:o001O02M3N6K4K6J5K5J^aj4"}}, "object_label": "laptop", "attribute_label": ["color:gray", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, size, color, state, pose", "answer": "The image features a laptop computer with a white screen, sitting on a desk. The laptop is turned on, and its screen is displaying a blue background. The laptop is positioned in the center of the image, with the screen taking up a significant portion of the frame. The desk appears to be a simple, flat surface, providing a suitable environment for the laptop to be used."}, {"question_id": 960, "height": 640, "width": 427, "image": "000000350002.jpg", "category": "description", "question": "Describe the hair drier in the following image in detail.", "dims": "cleanliness, color, pose, texture, transparency", "region_anno": {"bbox": [0.0, 101.67, 163.96, 181.22], "segmentation": {"size": [640, 427], "counts": "kP2j0Pc0;G7J8H8H:G5J7J3N3K4N4K3M3N3L3N3M3M3M3M3M3M3M3M3M3M3M2O2M3N2M3M3N2M2O1N3N1N2O1O1O1N2O1O2N1N101O0000000O2O00001O00001O00001O00000010O000000001O00000000001O0000001O00001O001N10001O001O001O001O0O2O001O001O1N101O1O1O1N2O1O0O2O1O001N2O1O1N2O1O1N2O1N3N1O2M2O2M2O1N2O1N2O1N2N2O2M2O3L4L3M3M4L3N3K4M4L4L4L4L3M4K4M4K5L3L5K6J8F<D^iT5"}}, "object_label": "hair drier", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "color:black", "color:white", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "pose, texture", "answer": "The image features a hair drier with a unique design, resembling a metal hat or a metal helmet. It is placed on a table, and the hair drier appears to be a large, industrial-sized model. The hair drier is positioned in the center of the scene, drawing attention to its distinctive appearance."}, {"question_id": 961, "height": 640, "width": 480, "image": "000000218439.jpg", "category": "description", "question": "Describe the tv in the following image in detail.", "dims": "color, size, state, texture, transparency", "region_anno": {"bbox": [0.0, 310.65, 54.65, 117.93], "segmentation": {"size": [640, 480], "counts": "l9`3``00000000000000001O00000O101O0000001O0000000000000000000000000O10000000001O000000000O101M3C=Eb0ZOZ1aNn\\OIZd]8"}}, "object_label": "tv", "attribute_label": ["color:gray", "transparency:opaque", "size:small/little/tiny", "state:off", "texture:smooth/sleek"], "control_dims": "size", "answer": "The image features a small television set sitting on top of a wooden table. The TV is turned off, and it appears to be an older model. The television is positioned in the center of the table, and there is a picture frame hanging on the wall above it."}, {"question_id": 962, "height": 463, "width": 640, "image": "000000225946.jpg", "category": "description", "question": "Describe the train in the following image in detail.", "dims": "color, length, material, size, state, texture, transparency", "region_anno": {"bbox": [182.98, 159.5, 326.56, 114.33], "segmentation": {"size": [463, 640], "counts": "m]c29P>`0B50O10M3N1L4^Oc0I6000000O1F:N2O1O1O1N2O1O1L4I7N2N2O1O1O2O0O1O2N1O100O1000000O100O10000000000000000000000001N02O00000O10000O1000O10000001O01O00001O0O2O001O0000001O001O001O0000001O001N1000001O00000000001N10001O000O2O00001O0O101O001O00001O0000001O00000001O01O00001N101O1O1O1O001O001O00001O0000001O00001O0O1000001O00010N101O00000000100O0000001O001O001O001N10001O0000000O101N10001N10001O01O2OO001O1O0O101O00001O0O2O1O000000000000010O001N10001O00001O0000001N101O00001O001O001O2N2N001O1O00001O001N101O0O100001O0001O001N10000010O01O0000000O101O00001O0O10001O001O0000001O000000001O1O0000001O0O2O00001O0000001O0000000O2O001O1O000000001O0O2O0O1O2N2NQXm1"}}, "object_label": "train", "attribute_label": ["color:green", "color:white", "length:long", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "transparency:opaque", "size:big/large/giant/huge", "state:on", "texture:smooth/sleek"], "control_dims": "state, material, color", "answer": "The image features a long train traveling down the tracks, with a green engine pulling several cars behind it. The train is moving along the tracks, and there are trees in the background, adding to the scenery. The train appears to be a freight train, as it is carrying a variety of cargo cars. The train is quite long, with multiple cars visible in the image, showcasing the diverse cargo it is transporting."}, {"question_id": 963, "height": 480, "width": 640, "image": "000000236592.jpg", "category": "description", "question": "Describe the dog in the following image in detail.", "dims": "cleanliness, color, maturity, state, texture", "region_anno": {"bbox": [1.94, 167.46, 241.45, 305.46], "segmentation": {"size": [480, 640], "counts": "Y5f9Z501O00001O0000001O1O000000000000000000000000000000000000001O001O000O2O0O1O1O1O2N1N2O101N2N2O1O001N2N102N1O2N2N1O001O1O1N101O1O1O1N2O1O1O1N2O001N2O2N1O2N1N2O001O1N2O001O2N01000O1O0O2N20000O1O1O1O2N1O2M2O2N103Kf0[O2N1O1O0O2O1N10001O0O2O0O2O0O2N101O0O101N1O101N100O101O0O100N2O2N100O1O1O10000O100O2O0O100O2N1000001N1000000O101N1000000O2O00000O101N10000O1O2N100O1O10000O101O0O100O1O2N1O100O1O2O0O1O1O2O0O1O1N3N1O1O2N1O1O1O2N1O1N3N1O1N2O2N1O1N3N1O2M2O1O2M2N3M2L5L3M4WOXCUOl<i0VCSOm<l0WClNn<T1`0N2N1O2N2N2M3M3N3K6J7B^kh5"}}, "object_label": "dog", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "maturity:adult/old/aged", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "cleanliness", "answer": "The image features a brown and white dog with a mix of black and white fur, standing in front of a white door. The dog appears to be looking at something, possibly a mirror or a person, as it stares intently. The dog's head is turned to the side, and its eyes are focused on the object of its attention. The scene captures the dog's curiosity and interest in its surroundings."}, {"question_id": 964, "height": 480, "width": 640, "image": "000000242946.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "material, size, texture, transparency", "region_anno": {"bbox": [0.0, 435.19, 32.36, 44.81], "segmentation": {"size": [480, 640], "counts": "d=<3`0b=@^B`0b=@]Ba0c=@\\B`0d=>000000001O0VO[B9e=G\\B8d=H\\B2OCf=;ZB12Cd=o0ZBSOe=>[B1f=NZB2g=c01O1O001O1O1O1O1N2N3M5J4K5M4Jfal8"}}, "object_label": "bowl", "attribute_label": ["material:glass", "transparency:transparent/translucent", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "transparency, size, texture", "answer": "The bowl in the image is filled with a red substance, which appears to be a sauce or a soup. The bowl is placed on a table, and it is positioned in the center of the scene."}, {"question_id": 965, "height": 480, "width": 640, "image": "000000242946.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "color, pattern, size, texture, transparency", "region_anno": {"bbox": [0.0, 148.05, 640.0, 325.48], "segmentation": {"size": [480, 640], "counts": "c63602N12Ld0n1X2n5UMTH10O2ONd0l1Z2o5UMRH2O04MOc0j1[2Q6TMRH2000O2a05ZOY1S3]6[MSHH0O2a05ZOY1S3]6[MUHFOO2a0i1Q2TNeMn73VHFNO1a0i1Q2WNeMj76SHO359^On0c2jNeMh7i0WHA8Ag0e2TO_Mg77SHO25:^Ok0MQO^2OmMe76XHCN00a0:]OX1Y2dNPNe74`HEEa0:\\OZ1X2dNQNa78YHBM11`09]O[1W2eNPN_7:VHN14:^OZ1V2hNnM]7<WHMO6:^O\\1T2lNiMY7b0YHANOOd09]O^1Q2i6^NdG_ON0Oe08]O^1Q2i6nNaGE7\\O`1o1i6PO`GE7]O_1m1l6PO]GG8\\O0KU1g1cN`NS9J^Gh0G]OOJW1b1jN`Na9g0_F]OOJW1b1kN_N`9i0^F\\O0JX1a1[8aNWFN2k02\\OOJ]1`1X8bN^Fh0N^ONG_1_1Y8cN[Fj0O^Ob1U1T8cN[Fj0O@a1R1T8fN[Fh00A`1Q1U8iNXFe03E\\1m0Y8gNZFh01A_1o0V8fN[Fk00_O`1P1U8eN\\Fl0O\\Oc1S1NeNY65RHh03ZOe1T1LgNkNLo50ZJ8WOg04YOf1U1KmNdNHU6N\\J2[Om0OUOj1X1H[OR66\\HWOk1V1H]OR65[HWOl1U1I^OQ67YHVOm1T1J_OP67YHVOR1MDV1R1_Oo57dIVOZOS1T1_Oo58dIUOYOP1Y1Bj57fI[OTOk0\\1Bk54hI]OTOl0Z1Ck5LnIEmN:YO1Q23l5LlJ`0[OCi5CVKi0SOBh5DVKi0TOAQ9?oFAQ9>QGAo8>SG@n82dD0a2Kl84eDOa2Lj85eDOa2Kl85bD0c2Kk84cD1b2Kk84dDKf21f84dDJg21f85cDIh22e84dDIh22e85bGI_86V3O1000000O2O000O100OTNOkD0Q;6mDKR;5oDKQ;5n1L3O1O01gcd00Y\\[O0O100O101O0O00101XAJd>90M2O2MoS1NVlN1N2N2O001O101M2QJFVM;g81YLDfH?Y7AfH4dL2e:JgHb0T5^O]I0_1c0V7_OiH6bLOd:MiHNjL4]:2eHIPM5Y:2hHIoL7W:0jHIgL116]:0lHIeL225]:OSIJbL6[:0RIKeL3Y:3QIJeL4Z:2_EI_32gL3Z:3`EH_31iL3W:4cEG_30gL5V:5aIK_65dEF_30gL5V:5dEF^32gL3V:6eEE]32hL4V:5eEE]31iL5T:6fED]30jL6R:7gED\\30fLON6Y:8eED^3OfLON6X:9fEC^3NgL0L7Y:8gEAf39a68iE_Of39a68iE_Oc31\\L8W:9iE@b3;e65jE^Oe3:`69kE]Of39^6;dIF\\6:lE\\OS33YM7g9;mE]OP32VMML9P:<oE\\On2OZM0I9n9>RFYOY31fL9m9?cIYO_L8m9`0dIXO^L9m9`0eIEZ6<iIAS6c0mI]Oj5m0UJSOj5n0VJROj5o0UJQOk5o0UJQOj5P1UJQOk5P1TJPOl5P1SJQOm5o0SJQOm5o0RJROn5n0QJSOn5n0RJROn5o0PJROP6n0PJROP6n0PJROo5o0QJQOo5o0PJROP6o0fF]NU3e0T6o0fF]NV3d0T6o0gF\\NU3e0T6o0mISOS6m0mISOS6o0kIQOU6_OQGm0i2EV6[OXGl0b2IV6XO_Gk0[2MT70kH1W7MhH4Z7KeH5\\7KbH6a7G^H:c7E]H;d7D[H=f7CQHB`Mk0`:BPHC_Ml0b:AnGAaMo0Z6QOhM>aNc0g3QOgM<aNc0h3QOhM<_Nc0T8\\OkGe0W8ZOgGg0b7PO_F8h1EiMT1Q:oN]F9h1DjMT1Q:oN]F9h1DiMU1R:nN^F9>D9V1k8mN`F7_1FRNW1P:kN`F87F71QOV1Q:lNQFM5:`0H>V1l8kNnE088>H?V1m8jNoEO89i1o0P8gNcF9[1R1Q6fNhIOmN8Z1S1Q6gN[JMgM:k1S1S6iNXJJkM:b1F[N]1P8mN^J1\\OS1V6oN\\JOQOFeN`0I8U8C]JNoNHeN5LON04NL1U86^J1mNDhN\\1n7nN_J2VOo0\\6mN`J4UOHTNi00TOY86_J5VOCXN201M9W8K`J4hNGA9X7KaJ4dNJPOMG1M9X8K_J7_NJlNJ02O1M9Z8H`J8\\NKnNJO101L:^8E]J=UNCPO25M00Oc0[8]O]J>QNDUO03N01JO1b0_8^O]Jd0jM@[OO3MNo0^8PO\\JS1[MTOHN4S1];LfDPONN2M:c0P;b0hDnNm0NnN2e;R1SFkNo9S1XDnNd12R:o0ZDQO>2=Oj:n0[DQO4MW13gNM];P1_DVO5KZ1OeN1];n0_DXO5K`1Ol9m0^D[O6IY1OdN1_;k0_D\\O4JZ1OaN3b;f0bDWOMO7O]13n9g0jFXOn32hIOg4f0dMYOn31fI2h4c0XKXOh83VG4j4`0YKYOm86jK`0ZKZOl86jK`0]4_OdKa0[4@dKa0[4_OfKa0[4]OeHLS1b0RM@X;NfGa0_8_ObG>`8B_G?a8A_G?a8A_G:f8Gd1O[D1d;0\\D0d;0\\D0iNO^<0Ya11U^OOPf<0f\\B1O1O001O01NP1OXR51XkJOoC7o;KoC4S<LlC4U<KlC3U<LlC4`=O100O100O1000O1ck31[TL2^NMRD6n;L_Cg0^<]O]Cf0b<l01O000O1O12N01O00000001OO1O100000000000000001N101O1O0000O1000001YNWCU1^=L6J1O2O0O2M3N002OO02N1O1O002N00eLAVH>j7BWH=i7DVH<j7CXH<W;OmLG`G7b8I]G7c8K[G5e8K\\G4h8IXG6XMJW;0bG5VMMW;NdG4TM0LMW;OiG4TM6Q;FlG3SM7V>HjA9U>GkA:T>FlA:U>EkA<T>DlA`0P>@oAb0Q>]OnAd0R>\\OmAf0R>51OO1PLUOjIk0nMVOX60iKj0nMXOX6OjKi0mMXOY6NkKj0lMYOW6MoKj0jMXOV6OPLi0kMXOT6OQLh0lMZOQ6NULf0lM\\On5NVLc0RN[OT53WI0c3`0]5BnFOf3=]5EmFMf3<_5GmFKd3=_5JnFGc3>_5MRKOP54nJKR56nJIS57mJITNHX4>fMGTNKW4<fMFVNNT4<gMDV5;i4O0O2N2N1000001NPd`0NR\\_O1010OJN_A0a>17000\\f8OeYG0Pn00PRO0Y[21fdM1O1UAOf>OZA3i>2n]4KUbK000HOaA11O]>2bAN_>181XAN`>2_AO\\;2bENi01YNO\\;2bENi01YNOZ;4eEKh02h95`EIK0M1ZO0U;9hEGG4MNANQ;;jEEF5ZOO20MO6MQ;;gFHVNN3NN011o:=jFEVNNc00]:>mEAI0\\O0a01^:>kEBIO10YO1S;=jECIOL0\\O021S;=jECIO81V:<gFCTO0V:5lFMQNN;1CO]=8_BM4:b=3\\BNd=2]BL0Ca=4^BN31M01Mb=2`BN11M20Mc=1`BN10O3I1h=LjB0F8`=HUC7k<IVC6h<MjBOI5X=0cBMO;0D^=4bBNN<2B`=2aBOO;0Da=0bB0N3NM20l=OUB2N00OX>NkA2J2[>LgA007Z>IkA7m<HRD0RO8l<HQD2oN5LKg=OaBOL5N11M`=2aBN02M22LV>OkA21N]>1cAO^>0bAO`>8dJIcJOYM0lN8V9LdJK_M9k7NTL0k32PLIQK0o87hJJWMOSO0m87iJKVMNTO0m87jJIWMNSO2l87jJHaM1e77kJH_M0R7OcG2;7a3IPM0UON12W89QHMc3JnL2UO4Y82RHOb3H[M2j63mGMOO2N98d3I]M0g66nGLOO2N89m4GnJ1m7g0VHAe4GYK3NOm7g0VH@k3IcL0@2ONn7f0UHAm3HiL3WONn7e0VHBl3HeLOYO33No7e0THDk4IRKOn7c0VHE`3IZM2QONo7a0WHF\\3NaLI`05ZOOQ8a0WHD]3NbLH`00YO:Q8<WHD]3J[LNT17m6=WHE\\3N^M2n6;YHE[31WMKWOLn7c0YHEZ33WMIXOLn7c0YHFZ31YMGWONo7d0VHF[3G^LOOOW10l6d0UHHZ3E`L0NOW10jN"}}, "object_label": "dining table", "attribute_label": ["color:white", "transparency:opaque", "pattern:plain", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "transparency, color, texture", "answer": "The dining table in the image is filled with a variety of food items, including several plates of vegetables, meat, and noodles. There are also several bowls containing different types of food. The table is set with various utensils such as forks, knives, and spoons, as well as cups and bottles. The table is surrounded by chairs, and there are people sitting around it, enjoying the meal together. The scene appears to be a lively gathering where people are sharing a meal and engaging in conversation."}, {"question_id": 966, "height": 427, "width": 640, "image": "000000361103.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "color, pose, size, transparency", "region_anno": {"bbox": [472.73, 168.82, 23.32, 98.27], "segmentation": {"size": [427, 640], "counts": "nYV64T<6dD1Q;5mDOh:9UEC@Oe:o0jESO@0b:o0mESOAMa:Q1lETOEI]:W1cEYO7YOU:[2=1N2bEaMP:_2PFaMo9`2lEaMKOY:`2lEbMJNZ:`2iEeMZ:[2dEgM\\:X2eEgM\\:a23M7dN_EjNM26Oa:2Wnk1"}}, "object_label": "potted plant", "attribute_label": ["color:brown", "color:green", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge"], "control_dims": "pose", "answer": "The potted plant in the image is a small, green tree with a few red flowers on it. It is placed in a large pot, which is positioned on the sidewalk. The tree is surrounded by several people, some of whom are sitting on a bench nearby. The scene appears to be a lively outdoor setting with people enjoying their time in the area."}, {"question_id": 967, "height": 423, "width": 640, "image": "000000423229.jpg", "category": "description", "question": "Describe the traffic light in the following image in detail.", "dims": "color, length, material, pose, size, state, transparency", "region_anno": {"bbox": [241.77, 59.82, 16.9, 28.67], "segmentation": {"size": [423, 640], "counts": "WdS31S=6J5K4N1N3J401O10O100O1O1O1O1N3M4K^Zm4"}}, "object_label": "traffic light", "attribute_label": ["color:green", "color:red", "length:short", "material:glass", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "state:off"], "control_dims": "color, length, material, transparency, state", "answer": "The traffic light in the image is a unique and colorful design, featuring a red heart shape with green and red colors. The heart shape is made up of two red circles, one on top of the other, with a green circle in the middle. The heart is positioned on a white background, making it stand out even more. The traffic light is likely a decorative piece or a creative design meant to catch the attention of passersby."}, {"question_id": 968, "height": 427, "width": 640, "image": "000000301421.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "cleanliness, color, length, pose, size, texture, transparency", "region_anno": {"bbox": [347.57, 224.08, 34.78, 57.97], "segmentation": {"size": [427, 640], "counts": "Yia49n<5H7I7L5I6K5K6M201O00001O000010O01O01O00000O2M2L4K6I6K6H7K7IXV\\3"}}, "object_label": "cell phone", "attribute_label": ["cleanliness:clean/neat", "color:black", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "pose, color, cleanliness, size, texture, length, transparency", "answer": "The image features a black cell phone sitting on a white stand or docking station. The cell phone is placed on the stand, which is designed to hold and charge the device. The stand is positioned on a table, and the cell phone is the main focus of the scene."}, {"question_id": 969, "height": 500, "width": 375, "image": "000000269932.jpg", "category": "description", "question": "Describe the horse in the following image in detail.", "dims": "cleanliness, color, material, pose, size, state", "region_anno": {"bbox": [209.93, 53.73, 165.07, 176.13], "segmentation": {"size": [500, 375], "counts": "dTX38T?9M2M5L5L4L2N4TBQOl<R1cBgN7`0P=o0lBVOQ=l0lBWOR=f1O101N1O1O100O10O0N3L3O2N2N2O010N2M3M3N2M3N1O2N2O1N2O1O1O1O2N100000000001O00001O000O1000001O01OO101O0O100000000O10000O100O00100O1O2[CaNS;R3M2O1N1O2O0O10TOeD^M\\;]2lD`MS;]2S1L4J6M4N1001O2N1O:F?A;\\CYMf;\\3N2N5K1OWOhDdLMa0Z;e2\\ERMc:g2hEVMW:e2PFZMo9c2XFYMh9b2h1M200N2L4O2N101N100N3]OcBlN_=Q1hBgN]=W1`0O2N1O2N1O2O0O2N1O2O001O1O001O1O010O010000O01000O2N101N2N1O100O1O2N1O17I1O1O1O1O1NoM"}}, "object_label": "horse", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:white", "material:polymers/plastic/rubber/styrofoam/polymer", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry"], "control_dims": "color", "answer": "The image features a large, brown horse statue, possibly made of metal, standing on a red pedestal. The horse statue is positioned in front of a building, possibly a brick building. The horse statue is the main focus of the scene, and it appears to be a prominent and eye-catching feature in the area."}, {"question_id": 970, "height": 375, "width": 500, "image": "000000270474.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "cleanliness, color, length, pose, texture, transparency", "region_anno": {"bbox": [287.81, 126.76, 193.85, 111.74], "segmentation": {"size": [375, 500], "counts": "_]Z35a;6J2O00FkD2T;OlD1S;0lD0U;1hD1W;0iDOX;NlD1T;OlD0T;OjDN03V;NoD1R;OlD3S;NjD5U;LkD3V;7O10N5L2N3NM2eDKV;3lDMT;1nDOR;0`g0OkXO3hDMg:4>0O4bDHW;9hDGW;=O100O010O1O01O01O10O10O00010O1O010O010O010O0010O0100O0010O010O01O010O10O010O01O0100O01O01O01O10O010O0100O01O01O0100O01O10O000100O010O00100O01O010O0100O010O0010O010O010O010O010O1O010O010O010O010O010O0100O001O10O01O010O010O010O010O010O00010O010O010O010O10O0100O01O0100O010O0010O01O0100O100O101N101N2N2O2N1N3M2O3LQV7"}}, "object_label": "baseball bat", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:orange", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "texture:smooth/sleek"], "control_dims": "cleanliness, length", "answer": "The baseball bat in the image is a large, wooden bat with a blue handle. It is being held by a young girl, who is wearing a pink dress. The girl is standing outside, possibly in a backyard, and appears to be playing or preparing to play baseball."}, {"question_id": 971, "height": 394, "width": 640, "image": "000000340175.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "length, material, pose, size, texture, transparency", "region_anno": {"bbox": [427.65, 176.6, 183.3, 68.08], "segmentation": {"size": [394, 640], "counts": "_kT5>l;<C8I5K2N0010O000001O01O001O001O010O000001N1000001O0000001O00001O00000O101O0O1O2O0O101O000O101O0000010O000O1N2O2N10001O0000001O0001O01O000000001O00000001O01O00001O0000001O01O000001O0000010O_NgEQ1Y:`00000000_NgEQ1Y:`01O0000001O000001O000000000001O0000000000001O000000000000001O0000000O10001O0O10001M2O1O1O10001N100000001N1000000000001O00001O4L001O000000000O1N2M4K4M3I7L4N3L3Mbg;"}}, "object_label": "couch", "attribute_label": ["length:long", "material:leather", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:soft/fluffy/furry/hairy"], "control_dims": "material, texture, length, transparency, pose", "answer": "The image features a large, red leather couch in a living room. The couch is positioned in the center of the room, and it appears to be the main focal point of the space."}, {"question_id": 972, "height": 320, "width": 640, "image": "000000417285.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, length, material, pose, size, texture, transparency", "region_anno": {"bbox": [245.21, 41.17, 128.0, 176.18], "segmentation": {"size": [320, 640], "counts": "fb]2`0`92N5NOI[OPGf0n8ZORGh0R9100N3N0_O]O_Gj0^8?K6K7J9F6J5L6J5K3M5K3M3N2M3M3N2M4L4oIZLb5W4J4L3N1N@jJZLT5Z4O1N2O1N2O1O0O101O001N2O1O000O2O00001O00001N100000000000000000000000000000O100000001O0O100000001N10000O2O0O100O1O2O0O1O10001N1[OQKXLQ5e3UKVLl4i3SKYLm4e3UKZLm4e3QK\\LP5d3nJ\\LU5a3kJ_LW5_3jJ_LZ5]3iJbLY5[3lJ]LZ5`3d0N3M3N2M2N3M3L4L5K5J5K5H9F:E;F;ZOYfc2"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "length:short", "material:glass", "transparency:transparent/translucent", "pose:vertical/upright/standing", "size:small/little/tiny", "texture:smooth/sleek"], "control_dims": "material, length, size, transparency, cleanliness, texture", "answer": "The image features a cup filled with a dark liquid, likely coffee, sitting on a saucer. The cup is placed on a dining table, and there is a spoon resting on the saucer next to the cup. The cup appears to be a small glass cup, and the saucer is white. The scene suggests a cozy and relaxing atmosphere, possibly during breakfast or a casual meal."}, {"question_id": 973, "height": 436, "width": 640, "image": "000000288685.jpg", "category": "description", "question": "Describe the bench in the following image in detail.", "dims": "length, pose, size, texture, transparency", "region_anno": {"bbox": [323.89, 245.4, 209.5, 45.3], "segmentation": {"size": [436, 640], "counts": "TRX42b=3M2N004L00M3001gBK3Nf<8UCM2MOOO1`<6`C90C^<g0cCYO3KT<l0iCYO3LS<k0jCYO2MS<k0kCXO2MT<j0jCZO1LU<j0jCZO2KT<6kC:OE2KT<5lC;NE2KT<5lCd0OXOU<4lCd00WOT<S1mCmNS<g0iCB4GS<g0jCA3HS<f0kCB2GU<g0hCB3HU<e0hCC3HX<b0eCF3HX<b0eCF3HX<b0fCE2IX<b0eCG2GY<o0gCQOY<o0fCROZ<n0gCQOY<o0gCQOY<o0gCQOX<P1hCPOU<S1kCmNU<S1kCmNT<1lCl00SOT<T1lCkNU<V1401N10001O1N1000cCPOV<Q1601]O_C1a<O_C1a<a000O]O`C4`<L`C4`<L`C4a<K`C4_<`01N2O100O11O1O3M00LaCTO^<m0aCSO_<P110000MaCQOb<o010O000001N1O`CTO[<k0eCUO[<j0fCVOZ<j0eCWO[<h0fCXOZ<g0gCYOY<g0gCZOY<e0hCYOY<h0_CYOg<j0O1JUOcCk0]<UOcCk0_<TO`Ci0b<XO^Ch0a<600001N01000O10001O0O20O0O11O001O0000010O001O002O0O01O0001N1N3IRCEo<;RCDo<:RCFP=8PCHQ=8mBJR=<0O101O01O000001O00000000000O101O0000_OFiC:V<GiC:V<FjC:V<FjC:V<EkC;U<ElC9U<GdCOL:`<GkC9U<GjC:V<FjC:V<FkC9U<GkC9U<FlC:g<01O\\OGmC9S<GmC9S<GmC9S<GnC8R<HnC8R<HnC8R<HnC8R<HnC8R<HnC8g<001O0000000[OGoC9Q<HoC6R<JnC6R<KmC5S<IoC7]<IWC7i<IWC7i<JVC6j<JVC6^<IoC7Q<IoC9o;GPD<^OE\\<OVD;o;EQD:\\<GVC;d<DZC11=c<C\\C01=c<C\\C01=d<B[C11=]<BdC0N022K8a<FdC0N02>\\<BdC05=X<DnC<R<EmC;i<N1OO2N01N10010O0O2O0M3O2N101N]gZ1"}}, "object_label": "bench", "attribute_label": ["length:long", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge", "texture:rough"], "control_dims": "pose, texture, length, size, transparency", "answer": "The bench in the image is green and located near a fence. It is situated in a park-like setting, possibly at a zoo, where a sheep is running towards it. The bench is positioned in the foreground, and the sheep is running towards it, creating an interesting scene."}, {"question_id": 974, "height": 427, "width": 640, "image": "000000334309.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, length, pose, state, texture, transparency", "region_anno": {"bbox": [256.02, 250.28, 119.05, 86.58], "segmentation": {"size": [427, 640], "counts": "mcZ31X=i0XO4M5K2M3M2N1O2M2M3M2100000O01000O100O010O0N3N2O10O01000O10O10O10O10O1O1000O10000O1000O1000O1000O10O0100000O010O1000O10O10O10O10O10O1000O100O10O1000O10O10O10O10O1000O10O100000O0100O0100000O0100000O010O1000O10O100O1000000O101N2O1N2M3N5Cde^3"}}, "object_label": "cell phone", "attribute_label": ["color:gray", "color:white", "length:long", "transparency:opaque", "pose:vertical/upright/standing", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, length, pose, color", "answer": "The image features a person holding a silver Apple iPhone in their hand. The person is taking a picture of a sandwich, capturing the delicious meal in a close-up shot. The iPhone is positioned in the center of the scene, with the person's hand holding it securely. The focus of the image is on the person and the cell phone, highlighting the act of capturing the moment."}, {"question_id": 975, "height": 500, "width": 375, "image": "000000299553.jpg", "category": "description", "question": "Describe the kite in the following image in detail.", "dims": "length, pose, size, transparency", "region_anno": {"bbox": [185.73, 173.95, 34.11, 59.51], "segmentation": {"size": [500, 375], "counts": "Z`j23]?6N1N3M2N101O001O1O1O000010O00001OSABd>>]ACb>;_AG_>9cAG\\>7gAIY>4jAMT>1PBNP>OTB0i>0000000O11OOO200O0Oe^[2"}}, "object_label": "kite", "attribute_label": ["length:long", "transparency:opaque", "pose:vertical/upright/standing", "size:big/large/giant/huge"], "control_dims": "length, size", "answer": "The kite in the image is a large, black and red one, flying high in the sky. It appears to be a parachute-style kite, with a distinctive design that makes it stand out against the blue sky. The kite is soaring through the air, capturing the attention of anyone who sees it."}, {"question_id": 976, "height": 640, "width": 589, "image": "000000307658.jpg", "category": "description", "question": "Describe the bear in the following image in detail.", "dims": "color, maturity, size, state, texture", "region_anno": {"bbox": [2.88, 54.41, 527.82, 576.72], "segmentation": {"size": [640, 589], "counts": "df123m4]>g0G3O0O2DVJ\\BP6a=9O1N2K6M2M3O1O100D<N2O100O1O1O1O1N2O1N2O1O1O1N2M3O1N2O1O1L4M3O100N2N2N2N2O1O100O1N2L4O1O1O1N2N2O1O1N2O1N2O1J6N2M3N2M3N2O1O1O1M3O1N200O1O1O1N2N2bJPFj0R:TORFh0P:VOUF>T:^OQF<T:@RFCCdLb:g3oE@h:>[E]Oi:a0ZEZOj:e0XEVOl:i0VESOm:m0UEPOl:o0VEoNk:P1WEnNj:Q1XEmNi:R1YElNh:S1ZEkNg:S1\\EkNe:S1^EkNc:R1aElN`:S1cEjN^:V1eEfN\\:Y1fEeN[:X1hEgNY:W1iEhNX:W1jEgNW:X1jEgNW:Y1jEeNW:[1iEdNX:\\1hEcNY:]1hEaNY:_1hE`NX:`1iE^NX:a1jE]NW:c1iE]NW:b1kE\\NV:e1iEZNX:f1jEWNW:i1jEUNW:k1iESNY:m1hEPNZ:P2fElM^:T2cEhM`:X2`EfMb:Y2`EdMb:\\2`E_Mc:`2`E\\Mb:d2aEWMa:i2[3001O0000000000001OO1001O00001O00001O0000000000000001O0000000O02O01O001O0000000O10O0101O000O010001N01000000000000O1O2N10O10O1O1000000O1O1O100O10000O2O0000001O0000O1000O2O000O1O1000000000000000000O10000O10000000000O10000000000O100000000000000000000O11O0000O100000000001O0000O10000000000O10000000000001O0000000000000000O10000O10000000000O1000000O10000O10000O1000000000000001O00O1000000O1000000000000O100O100000000000000000000001O0000001OO1001O0000000000000000O100000000O11O001O00001O0000001O00001O001O001O000000001OO1000000000000O10000001O0000000000O1O1O1O100O100O1O1O1O1O1O100O1N21O1OO1O1O100000000001O3MO1O100001O0000000000O1O100O10000O1000PAZNf;e1ZD]Ne;c1\\D\\Nd;d1\\3000000001YA[NQ;e1nD^NP;c1oD^No:c1RE]Nl:d1TE]Nk:c1UE]Nl:b1PEWNfL8Y>`1REXNeL;V>]1UEXNeL?S>X1WE[NdL`0R>V1ZEROa:o0^ESOa:m0^EUOa:k0^EWOa:j0]EXOb:h0]EZOb:g0]EZOc:f0[E\\Oe:c0[E^Od:c0ZE_Oe:a0ZEBc:?\\EBd:?ZECd:>[EDd:<ZEFf::XEIg:8WEJi:5TEOk:1SE2m:NQE4n:LPE7n:KPE7o:JlD;R;FlD=S;DiD?W;BfDa0Z;_ObDd0_;]O]Df0b;]ORDl0n;XOiCm0W<YO^Cm0a<UOYCP1d<SOUCT1j<mNPCY1o<m2O2N3RCoHh<V7ZKjH^LX7_3lH_LU7V3XIeLR7T2\\H]Jf0[3R7P2aHnIF3S1n3l6h1aJdMb5^1ZHRKg2[3Q5^1bK`Na4\\1cKbNa4X1bKfNc4U1`KhNd4S1_KkNc4RO\\GKU4o0g4kN_GJX4Q1b4jN_GIX4Y1[4ZNjF]OMMQ1g0W4_1Y4XNXHFl3o1Q4RNWNk1R:N2M4L4L8H5K7I4L5TOR]O;\\c0M4N1NYPS1"}}, "object_label": "bear", "attribute_label": ["color:brown", "maturity:adult/old/aged", "size:big/large/giant/huge", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "maturity", "answer": "The image features a large brown bear with a thick, shaggy coat. The bear is standing in a zoo enclosure, looking directly at the camera. The bear's fur appears to be dirty, giving it a more natural and wild appearance. The bear's size and presence make it an impressive sight, capturing the viewer's attention."}, {"question_id": 977, "height": 640, "width": 480, "image": "000000311394.jpg", "category": "description", "question": "Describe the toothbrush in the following image in detail.", "dims": "cleanliness, color, length, material, pose, size, transparency", "region_anno": {"bbox": [155.33, 208.1, 53.21, 291.95], "segmentation": {"size": [640, 480], "counts": "WVS3Q1Pa0UO]@\\1T?SO^@V1l:]N]H]3X7RM_HR3^7UMYHQ3d7UMUHn2j7WMnGm2R8VMfGo2Z8TM_GQ3_8SMWGT3h8oLSGf2RNgKl:e1kFh2YNdKk:g1_FP3fNXKl:m1SFQ3jNPK[;[8eDfGY;Z8hDfGX;Z8hDfGX;Z8hDeGY;\\8fDdGZ;\\8fDdGY;]8gDcGY;]8gDcGZ;\\8fDeGY;[8gDeGY;\\8eDeG[;[8fDdGZ;\\85100O01O00dDdGU;i1RFZ3iNmJV;d1hFm2PNaKX;_1UGg2`MkK];Z1^Gh2c8UMdGg2]8VMiGe2Z8UMnGf2T8SM\\H4\\LQ1];bNRJT1d<I4L7I7I8H7IZiZ5"}}, "object_label": "toothbrush", "attribute_label": ["cleanliness:clean/neat", "color:blue", "color:white", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pose:vertical/upright/standing", "size:small/little/tiny"], "control_dims": "material, cleanliness, size, pose, length, color, transparency", "answer": "The toothbrush in the image is a children's toothbrush, featuring a character on the handle. It is being held by a young child, who is brushing their teeth with the toothbrush. The toothbrush is designed to make the process of brushing teeth more enjoyable and engaging for children."}, {"question_id": 978, "height": 398, "width": 640, "image": "000000311928.jpg", "category": "description", "question": "Describe the baseball bat in the following image in detail.", "dims": "color, length, transparency", "region_anno": {"bbox": [249.53, 271.89, 307.67, 64.4], "segmentation": {"size": [398, 640], "counts": "V^Q34P<;N10000000000010O00000000010O00000001O0001O000000010O00000001O0001O0000000001O0000001O01O0001O00001O0000010O0000001O000000001O01O000001O01O0001O000010O0000000001O00001O0000010O0000001O000000001O01O0001O000000010O00001O001O00010O001O0000000000001O000001O00000001O000000001O01O0001O000000001O0001O0001O00000000010O001O00000000001O000000001O0001O01O00001O000001O01O000000010O000001O0000001O00001O00010O000000001O01O0000000001O01O000001O00001O0001O01O0000000001O01O00000000010O000000000010O0000000001O000001O01O00000001O01O0000000000010O0000000010O00000001O0000001O01O0001O00000000001O00000O2O0O2O0O2N1O2O1N3KgSQ1"}}, "object_label": "baseball bat", "attribute_label": ["color:gray", "color:yellow", "length:long", "transparency:opaque"], "control_dims": "length, transparency, color", "answer": "The baseball bat in the image is made of a combination of wood and paper. It is a homemade bat, possibly created by a child, and is being swung by a person. The bat is quite long, extending from the left side of the image to the right side, and it appears to be a makeshift version of a traditional baseball bat."}, {"question_id": 979, "height": 427, "width": 640, "image": "000000312421.jpg", "category": "description", "question": "Describe the dining table in the following image in detail.", "dims": "cleanliness, color, material, size, state, texture, transparency", "region_anno": {"bbox": [439.4, 295.4, 90.4, 78.66], "segmentation": {"size": [427, 640], "counts": "lVh5?l<1O0000000000000001O0000000010O00000001O0000000000O1000000O10000O10000O1O2O002M5L7H4M7I9G1O001OoN_D8`;HgD2Y;MlDOS;2REIn:6XEDi:<^E]Ob:b0T100O100O001O100O100O00100O010O1O100O010O0100O1000O010O0M^C0JFR<9ZDGD000Q<8fDKW;OoC2Q=NoB1j1M[93lDNf14]9MUd]1"}}, "object_label": "dining table", "attribute_label": ["cleanliness:clean/neat", "color:brown", "material:wood/wooden/bamboo/hardwood", "transparency:opaque", "size:small/little/tiny", "state:covered", "texture:rough"], "control_dims": "cleanliness, color, transparency", "answer": "The dining table in the image is made of wood and has a bench on one side. It is placed outdoors, possibly in a park or a similar setting."}, {"question_id": 980, "height": 612, "width": 612, "image": "000000315492.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "color, size, texture, transparency", "region_anno": {"bbox": [481.42, 488.56, 107.26, 108.1], "segmentation": {"size": [612, 612], "counts": "gnR94lb06I8M2M3j]OE^a0=^^ONYa0R1L4L2O1O1N3N1O1N2O1O10O10KhM\\_OX2d`0iM[_OW2e`05O1O0O1o_OaM]?a2`@aM_?`2^@bMb?^2^@cM`?_2_@aMa?_2_@aMa?`2]@`Md?a2[@_Me?a2[@_Me?b2Y@_Mg?a2Y@_Mf?d2U@_Mj?n200O1000O1000O1000000000O1I700000001O4K101O01O0n_OVMj?l2S@UMm?m2Q@TMn?l2R@TMP`0o22Gn_O]MR`0a2o_O_MQ`0`2P@aMP`0^2o_OcMf?Ic@m2]?SMc@m2]?TMb@k2^?VMb@j2^?VMc@i2^?VMb@k2]?UM_@0Jk2g?UM_@0Li2e?WM_@OMj2d?XM^@NNj2d?XM^@NNj2d?ZMa@g2_?ZM_@g2a?_MY@a2g?WM]@MMl2g?VMa@NGi2g?YMe@g2[?YM]@N1i2b?YM]@O0g2e?YM[@0MOOh2i?ZMZ@4Lb2j?ZMZ@n2g?QMY@o2g?QMY@1Lj2k?TMc@g2R`0ZMa_O]2[`0bMj_O^2U`0cMg_O0N70l1\\`0mMf_O:Ni1]`0lMg_O_2Y`0dMd_O[2S`0eMn_Od2Q`081TMo_Ob2Qb0lMR^O@]h="}}, "object_label": "teddy bear", "attribute_label": ["color:blue", "color:gray", "transparency:opaque", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "texture", "answer": "The teddy bear in the image is brown and has a tattoo on its back. It is sitting on a table, possibly in a kitchen setting. The tattoo on the teddy bear's back is quite intricate and adds a unique touch to the toy."}, {"question_id": 981, "height": 480, "width": 640, "image": "000000322895.jpg", "category": "description", "question": "Describe the couch in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, size, transparency", "region_anno": {"bbox": [380.9, 306.58, 259.1, 168.26], "segmentation": {"size": [480, 640], "counts": "`Pb523h1NXNg;_3[O=M4M2O2M2O1N2O1O1O1O001O1O1O1O1O1O1N2N2O1O0O2O1O2N1O001O101N1O001O1O1O0010O001O2mJVFl4j9TKUFm4l9WKTFd4m9[KSFe4n96000TKSFe4m9[KTFd4n9YKSFg4T:O1O1O0000J[KRFd4m9^KRFb4m9_KTF`4l9`KUF_4l9`KTF`4m9^KTFb4l9^KUFa4U:0MaKfE^4S:`KRF2K^4S:aKRFb4n9^KRFb4n9^KRFOM_4Q:bKWF]4i9bKYF]4U:01O001O001O1O001O0000001O1O00001O001O1O001O00001O1O001O1O0000001O001O001O00001O001O00001O001O_O\\LfEd3Q:]LdE2;`3Q:]LeE2;a3P:\\LiEO9d3n9\\L]Fc3c9]L]Fc3c9]LeEOd0d3g9^LdEOe0b3g9cLZF\\3f9dLZF\\3f9dLZF\\3f9dL[F[3e9dL\\F\\3e9bL]F]3d9bL\\F^3d9bL]F]3c9cL]F]3d9cL[F]3e9dL[F[3e9eL[F[3e9eL\\FZ3d9gL[FY3e9gL[FY3f9eL\\FZ3d9fL\\FZ3d9gL[FY3d9hL]FW3c9iL^FV3b9jL^FV3b9jL^FV3b9jL^FV3b9jL]FW3c9iL\\FX3d9gLbEMf0\\3i9gLaEMe0l2YOYM6L\\:2SFN^O\\3^:fLSFO^O]21\\N]:YORF0_O[3_:eLQFc3o9]LaEM8OIg3^:aLhEIJf3^:bLfEHNe3\\:`LPF`3P:^LRFN@^3_:bLRFO@_3]:dLRFN_O_3_:dLQFa3n9`LQFa3o9^LbEK=3B_3_:cLbEM7OI2O_3_:cLaEN8MJ3N_3_:iLlE\\3T:^LSFa3l9`LUF_3k9`LWF_3i9bLVF^3j9dLTF\\3l9fLRFZ3n9hLfEH0`3Y:jLfEG0_3Z:TMeEm2[:SMeEm2[:SMeEm2[:RMfEn2Z:iLcEJ2]3[:SMdEn2\\:k0O10000O10000000TLfER3Z:oLeEQ3[:oLeEQ3Z:k0000000000000O1000000O1000000O100000000000000000000001OO1000000000000001O00000000O10000O100000000O100O1O10000O1000000O100O1000O1000PF"}}, "object_label": "couch", "attribute_label": ["cleanliness:clean/neat", "color:gray", "length:long", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge"], "control_dims": "cleanliness, material, color, pattern, length", "answer": "The couch in the image is a large, tan-colored sofa with a beige cover. It is placed in a living room, sitting on a carpeted floor. The couch is positioned in front of a coffee table, which is located on the left side of the room."}, {"question_id": 982, "height": 480, "width": 640, "image": "000000322895.jpg", "category": "description", "question": "Describe the chair in the following image in detail.", "dims": "cleanliness, color, pose, transparency", "region_anno": {"bbox": [152.2, 190.83, 23.59, 53.27], "segmentation": {"size": [480, 640], "counts": "XkX2=_>P1lN;L2N1000kNWC3j<_OoBJe0>_<CRD6]=O00A?]Oc0M300O10WOnBDS=2S1M4Lhhi6"}}, "object_label": "chair", "attribute_label": ["cleanliness:clean/neat", "color:black", "transparency:opaque", "pose:vertical/upright/standing"], "control_dims": "color, cleanliness, pose, transparency", "answer": "The chair in the image is a black chair with a person sitting on it. The person is wearing black clothing, which matches the color of the chair. The chair is positioned in a room, and the person appears to be sitting in the corner of the room."}, {"question_id": 983, "height": 640, "width": 480, "image": "000000326128.jpg", "category": "description", "question": "Describe the snowboard in the following image in detail.", "dims": "color, length, pose, size, transparency", "region_anno": {"bbox": [106.3, 548.86, 349.25, 52.5], "segmentation": {"size": [640, 480], "counts": "e]S21jc0<G4L3N3M3M3N1N2O1N2O001N1000001O0O1000000000000000000000000000001O00000000000000000000000001O001O0000000O1ROX]Od0hb0\\OY]Oc0gb0^OZ]O`0fb0AZ]O>fb0BY]O`0fb0AY]O?gb0AX]O`0hb0<000TOW]Oa0jb0^OV]Oc0ib0\\OX]Od0hb0\\OX]Od0hb0\\OX]Od0hb0\\OX]Od0hb0\\OX]Od0hb0:0000000000001O1O2N000000001OO1O1001O0000O100N2N21O01O0O010001O000000001N110O2OOIU]OYOlb0d0W]O[Ojb0NR]Oc04_OPc0>o\\OCRc0=l\\ODUc0:l\\OFUc08l\\OIUc06k\\OIVc06k\\OHVc08j\\OH`c0N`\\O2gc0000000000001O002N0000O1O10001O0000000001O1N100001O0O1O1O100O011O0FKi\\O5Wc0Kj\\O4Vc0Lj\\O4Uc0Mk\\O3Uc0Mk\\O3Uc0Mk\\O3Uc0Mj\\O4ac00DLl\\O4Sc0Nl\\O2Sc02i\\OOWc00k\\OOUc00l\\O0Uc0Nm\\O1ac000000001O1O0000000000000000000001O000001O000000000O1000001O0000000000000000C1c\\O0N0gc0OY\\O2jc00O11O00O1M3BLo\\O5Qc0Ln\\O4Rc0Ln\\O5Pc0Lh\\OO26Tc02j\\OG14Sc07l\\OE14Sc0;m\\OESc0;m\\OERc08R]OHlb09U]OGjb09W]OHhb08X]OGib09W]OGib09W]OGib06P]OE76hb05Q]OE67ib07X]OHhb08X]OGib06Y]OEG3Pc07Y]OFJOob0;W]OFnb0:<001O1O000001Eb\\O2^c0L^aP10n^oN1O00000000000Pd00P\\O0000001O0000001N10000O010O1000000DKl\\O6_b01b]OMM2]b0h0a]OWO^b0l0`]OTO_b0n0`]OQOab0W10O1000001N100O101N1O1O2N1O2N2M3N2N2L6K[R?"}}, "object_label": "snowboard", "attribute_label": ["color:black", "length:long", "transparency:opaque", "pose:horizontal/lying", "size:big/large/giant/huge"], "control_dims": "size, transparency, color", "answer": "The image features a snowboard lying on the snow, with its underside visible. The snowboard is black and red in color, and it appears to be a snowboarding gear."}, {"question_id": 984, "height": 426, "width": 640, "image": "000000330790.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, maturity, pattern, pose, size, state", "region_anno": {"bbox": [181.89, 67.01, 272.83, 354.2], "segmentation": {"size": [426, 640], "counts": "][]2e0^<8J5I7I7I700ZOeN\\E\\1c3YNP3`0\\IW1]:lNdET1X:oNiEQ1T:QOmEo0P:TOoEm0m9VOTFj0h9ZOXFf0e9]O[Fc0a9A^F`0_9CaF=\\9EeF;W9IhF8V9HkF9T9GmF9^8_N`GX129o7oNnGg03;h7UOUH`03;_7^O^H63=S7IkHI2>m6OQIB2`0i62UI^O1a0f65XIZO3a0]6=`IQO3c0U6d0hIdMLg06R1R6g0lI^MNh05S1n5j0oIZMOh05T1^5QNcJh2JZM4e02DCU1h5cN_JKMi24ZM3e01EGT1b5gNaJJMg26YM3d01GFT1b5fNbJJMh25YM3c01HGT1l5bNWJf22YM3b01JHR1j5dNXJe22YM3a02KGR1j5iNRJa29WM2a02MHP1i5g1[JkL2`02NJo0g5kNQJb2:VM2`01OKn0k4dNmJNf07]OL01MX2:eM1`03NLn0f4lNfKH3W20WNE1Lm0Y4ZOPM`1UOXNE2Ml0V4BTMR1VO[NC6Mk0S4GWMk0VO\\NC7Ml0n3LaLiNNj13^NC7Mk0l31YLeNB5OIe0i15_ND:Lk0g37[LmN:V14`ND<Lj0e3<QLXN2:NK4L:d1=_NC>Lk0c3Q1SLgM4L:e1<]NE?Kk0a3S1WLbM21:b1=\\NDa0Lk0Z3n1hLYNQ1oNmNj0Y3o1RMoMg0XOnNk0X3o1WMkMa0\\OPOj0V3Q2ZMhM?]OROj0S3S2]MeM>^OQOk0R3U2_MaM=_OSOk0o2[2^MZM?ATOj0n2`2\\MTMa0BUOk0i2m2YMfLg0CWOj0h2Q3mL]K7U1m0BXOk0d2\\3PMYLS1AXOk0c2g4SN`JZOi0b2h4SN_J[Oj0a2i4SN]J\\Oj0`2j4SN]J]Oh0_2m4SN[J^Oi0^2m4TNZJ]Oj0^2m4TNZJ^Oj0\\2n4UNWJ@j0[2P5UNVJ_Ok0[2P5VNTJ@l0Y2Q5WNSJ_Om0Z2P5WNSJ^OFHd0b2e5WNPJ@EHg0`2e5XNnIACIk0^2d5YNmI_ODKIKk0b2k5YNlI@DLFNm0\\2n5ZNjI@E6b0P2P6YNiIAD7c0n1Q6ZNgICCEJOO8l0W2Q6[NeIFADN6k0T2R6\\NdI1_O_O0Ff0^2X6\\NaI2ACf0n1Y6]N_Ig08l0Y6]N]Ii0:i0Z6^N[Ik06j0`6[NWIR15c0d6\\NSIU17?g6]NoHU19`0i6a0RICo6<nHGS79mHGS79mHFT7X300`NSJcKm5]4TJ_Kn5`4UJ_Kk5`4VJ`Ki5`4YJ_Kg5`4ZJbKc5_4]JbKb5^4^JdK`5\\4aJdK^5\\4bJdK^5\\4bJeK]5]4aJcK_5`4_J_Ka5U60000O1K50]H]J_7h5O0O010O1N2NkMgH]NW7d1kHYNW7e1kH[NV7c1kH]NW7_1kHbNV7Z1lHeNX7V1jHjNZ7Q1gHoN\\7n0dHRO^7k0cHQOBTNn7h2aHTOc7i0_HWOb7f0`HZOb7c0_H]Od7>^HBm71UH0o7ISH7Q8CQH=R8_OoGa0U8YOmGh0S8VOnGj0V8QOkGQ1V8kNkGV1V8fNlGZ1W8bNjG^1Y8^NhGc1[8YNeGg1g8nMXGR2i8mMWGT2o90nNlMnFT2T:0000001O00O10000000000O11O0000001O00001O001O001O00001O1O001O1O001O1O001O0O1L5J5M4M2N3oLYM\\Kh2b4QNeJQ2Z5VN_Jl1`5]NVJe1i5`NoId1P6^NlIe1S6_NeIf1Y6\\NcIh1[6ZN_Ik1`6b2M2M3M3L4J8G7M3O1K4O3N1O2O0O_HbJX7\\5hHdJd7P5\\HPKg7m4?K100[KbG27i3b8VL^Gg3g8WLZG1GS1a03o8iNiF1Hm0b;ROfD0Gm0e;UO]DNN1O513Q<EQD3N0O523S<NnCMO;k;HYD;W3]OdLO_87hG<U3CR51jG:U3ER51gG7JC]35S50fG8KB\\36T50dG8KD\\34W5OaG9LD\\34X5O^G9ODZ35Z5M]G90EZ34Z5M\\G:0EZ34[5L\\G5MJ31X34]5L[G45LP3NhL6i8KZG56Jk2=f5DYG47Kj25lL0Q9OZGLi21PM3m80bJN\\LN32P91bJ2d5N\\J1_9L_hc2"}}, "object_label": "elephant", "attribute_label": ["cleanliness:clean/neat", "color:gray", "maturity:young/baby", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry"], "control_dims": "size, state", "answer": "The image features a large elephant with its trunk full of leaves, standing in a forest. The elephant appears to be enjoying its meal, as it is holding the leaves in its trunk. The scene is set in a natural environment, with the elephant surrounded by trees and foliage."}, {"question_id": 985, "height": 426, "width": 640, "image": "000000330790.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "color, pattern, pose, size, state", "region_anno": {"bbox": [0.0, 156.04, 223.05, 265.17], "segmentation": {"size": [426, 640], "counts": "c5f7d5000000000O1000000000000000aI_JkN:k5T7L2N1O5J4M2M6_O>A`0\\Of0@`0\\Od0UOn0[OPl<QO_iBNjN1N0U:d0mEZOj12UN5b93]Fg00QOe11\\N5W9=iF>d1PO]N3R9d0nF1OVO10a12`N1P9h0oF10UOa14^NLT9k0mFOOVOb1:a7d0mFGO[O100O7O:0L?f8`0oF54lN:1Dl0j82UG61kN;3CQ1e8L\\G<;jNBP1e8J^G=:3W8@`G=0dNO`1`8A`Gc00M_8A`Gb01N^8A_Gc02L^8A_GnN1W13lNO_1]8@`GnN3R15POL`1Z8EeGJ6QOKa1Y8BhGJ7ROHb1f0lNU6i0TIEd0h0JTOZ6b0VIAg0d2f5kN\\JX1_5fNdJeMTOe3U6cNjJhMQOg3R6iMmITOV1V3j4fMQJnNZ1a3_4aMXJjN]1f3Z4aMXJhN_1i3W4jMiKY2T4fMfKd2X4ZMeKS3S4hLgJ]NR1R5T4cLfKg3Y4YL\\KT4b4kK\\KZ4a4fK^K\\4b4bK`K_4_4_KaKc4^4\\KbKf4^4XKaKk4_4SKaKo4_4PKaKQ5_4nJ_KU5a4iJ_KY5a4eJ_K]5`4]JSKRO=c6`4YJfKh5Z4UJhKl5X4QJjKP6V4lIlKV6T4gIlK\\6T4bIlK`6T4\\IoKe6Q4YIPLh6P4WIXLb6h3]IZLb6f3]I[Lc6f3ZIUKNP1h6k3YIUK0P1g6l3XIUKOP1i6Y510000O10000O100O10000001O001O1O1N100N3K4B?M2001O2005SLfH^1g7RN\\Hm1n7gMTHY2R8`MnGd2W8SMiGQ3[8gLfGZ3[8cLeG_3a8XL`Gi3Q9O2O0O8HmLdL`IKh2[3f3_MULY2j3SNSLA`MW1\\6CoKoNgM^1Z6MjK_NmMd1Y6<_KjMZNj1V6b0jK^OV4c0jK\\OV4d0jK\\OV4d0mIcM[1i1h4e0kInMR1]1o4i0PJoMk0X1h4V1]JgMf0S1l4W1^JlM<Q1U5T1_JPN6m0[5S1_JSN2k0_5R1`JUNMj0b5R1aJVNJi0e5Q1aJWNIg0g5R1`Jb0`5^O`Jb0`5_O_Ja0`5@`J`0_5AaJ8f5H[J0l5OUJJR66nICY6=hI\\O^6e0aIVOd6j0\\I_N[7a1eH]N\\7d1dHVNb7j1_HPNe7Q2[HlMh7T2XHgMm7Y2SHdMo7]2QH`MR8`2nG\\MU8e2kGXMX8h2hGTM]8l2bGPMb8P3_GlLe8S3\\GfLk8Y3UGdLP9Z3j0Ee0[O6D;E=\\Oa0F<CXeb5"}}, "object_label": "elephant", "attribute_label": ["color:gray", "pattern:plain", "pose:vertical/upright/standing", "size:big/large/giant/huge", "state:dry"], "control_dims": "color, pose, state, size", "answer": "The image features a large elephant standing in a forest, surrounded by trees and bushes. The elephant is wearing a harness, which is likely used for carrying people or goods. The elephant appears to be walking through the forest, possibly in search of food or water. The scene captures the majestic presence of the elephant in its natural habitat."}, {"question_id": 986, "height": 480, "width": 640, "image": "000000331817.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, material, state, texture, transparency", "region_anno": {"bbox": [306.51, 186.38, 166.27, 112.97], "segmentation": {"size": [480, 640], "counts": "[W^41o>0[l19XSN6L4M2N2N2O1N2N101N2O1N2O1N2O2N7H6K2M4LiNnBd0o<]OSCc0k<VOSCG3S1i<]OWCd0g<^OWCd0h<ZOZCg0e<nNYCF213\\1`<mN`CF1_1]<kNbCF0`1]<kNkCV1T<jNlCX1R<gNoC[1n;cNUD_1i;aNVDa1i;_NWDc1g;]NYDc1f;aNVDGDd1U<aNjCJ<2E60P1U<nNZDL@72n0T<oNYDMA62n0T<oNZD9Bk0P<nNPDH7?Il0o;mNQDI7=In0n;kNSDJ6=In0n;jNbDL@41V1l;jNlD0WOV1m;jNmDOWOW1j;jNQEOUOV1j;kNQEOUOW1i;jNREOUOW1i;jNRE0SOW1k;iNSEb1l:_NSEa1l:_NVE`1j:_NWEb1h:^NYEa1g:_NZEa1e:_N\\E`1d:_N]ENlN\\1e;gN_EMmN[1d;hN`E`1`:cN]E^1b:fN[EY1e:fN\\E[1c:dN_E[1a:eNXECYOi1^;dNYECZOh1];`N`DHc01Fg1V;_NZEJBf1S;`N\\EIBf1R;aNoE]1Q:cNPF\\1P:mNgET1X:cN`D0X1\\1Y:dNaDMW1_1X:cNcDKX1`1V:eNQFZ1o9gN\\EJD_1P;fN]EJD_1P;gNQFX1P:hNPFW1Q:jN`DIb00M[1R;lN^DM?N0Y1S;lN_DJ`01NX1T;mNWEIFZ1S;mNWEIFY1T;nN]DIb00MY1T;nN]DI332M:X1U;nN]DJ125N8W1V;oN\\DK017O5V1X;POZDNONn0S1j:ROWD0NMP1Q1k:SOVD6o0f0l:TOUDOOMP1P1l:SOWDJ32j0Q1l:SOWDJ41i0Q1m:UOUDI60h0R1m:UOUDI7Oh0Q1m:VOUDJZ1P1a:VOUDJZ1o0b:WOTDJZ1o0b:WOTDLX1l0f:WORDM6MJOg0P1W;WORDM6MI1g0n0X;WORDK8OG1g0n0X;WORDK8OG1g0n0X;WORDM6Mf0n0S;XOQDN5Lg0n0S;XORDMV1k0h:XORDMV1j0i:YOPDOO1l0g0U;0jD0V;1jDNV;2jDNV;2jDNV;2iDNY;1gDOY;NjD0Z;BRE4X;E^CK]18^;LUCM]14`;ORC0b>0^A4^>LcA36Im=3nA44Jn=2oAM01[>2dAL35U>OPB1o=OQB0P>0QBOo=1RBNn=2gAN7OR>3gA1a>O_AN1N_>4`AN1N_>4`AN01^>>N1O00000001IcAI]><100O2O000O100000001O000O1N3N101O1Ll__2"}}, "object_label": "bowl", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "material:glass", "transparency:transparent/translucent", "state:full/whole", "texture:smooth/sleek"], "control_dims": "texture, state", "answer": "The bowl in the image is filled with a variety of food, including vegetables and possibly some fruit. It is placed on a dining table, surrounded by other bowls and cups. The bowl is positioned in the center of the table, and it appears to be the main focus of the meal."}, {"question_id": 987, "height": 427, "width": 640, "image": "000000335081.jpg", "category": "description", "question": "Describe the bird in the following image in detail.", "dims": "cleanliness, color, material, maturity, pose, state, texture", "region_anno": {"bbox": [332.8, 148.71, 212.28, 145.94], "segmentation": {"size": [427, 640], "counts": "cT]45T=5L3M2N2O3L3M4L2O1O7H3N3M2O0O3M1O2N2N001N2O2N1O001O1O001O1O1O1N101O001O001NZOnDVOQ;k0oDTOQ;l0oDTOQ;k0PEVOn:k0SETOm:l0UESOj:m0UETOj:m0REXOm:h0SEXOl:i0UEbNN?m:o0VE`NOa0j:o0WEaNN0O=k:R1XEaNNO0>i:S1ZE^NO0O>h:T1cEmN\\:S1dEnN[:S1dEmN\\:S1_E^NL>e:T1[E^NM22=e:S1\\E^NM40;g:S1\\E^NM41;d:T1^E\\NN50;d:S1bEaNK<c:S1dE`NH>c:R1gEROY:n0gESOX:m0hESOX:m0eE_NH10>b:R1fEdNH:c:Q1fEWOZ:i0gEWOX:i0gEYOX:g0gEeNI;`:P1jEaNH?]:Q1dE^N7a0U:R1bE_N8?V:R1bE_N8?V:R1bE`N6`0W:P1cE`N0N0b0^:o0cE_NOi0^:i0hEXOW:h0iEXOW:h0iE`NHb0_:n0hEYOX:i0bE[O_:h101O01O1O010O000VO`EiNa:V1`EiN`:W1`EiNa:Y1]EfNc:Z1]EgNb:Q21O001O1O000010O0000M30O1O2N2N2N2N2M2M4L3L4N2O1O1J6N2O100O10OK[LdFg3[95OXLfFa3Z9_LgF_3Y9cLeF^3[99ETLWGk3j8VLUGj3k8WLSGi3n8WLSGh3Q9TLoFl3Q9TLoFk3Q9WLnFi3R9XLmFg3S9ZLmFe3T990O001O1O1O1O1O1\\NcFYN85V9`1gFSN;9o8`1nFPN8<l8c1kGVNW8i1lGRNX8l1SGRNe9n1[FRNe9n1m0N10000O2N100O2O001N1O2O0O2O100O0O2N2O1N2O1N2N102M2M4M4H7L4Lg[_1"}}, "object_label": "bird", "attribute_label": ["cleanliness:clean/neat", "color:brown", "color:yellow", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "maturity:adult/old/aged", "pose:horizontal/lying", "state:dry", "texture:soft/fluffy/furry/hairy"], "control_dims": "material, color, cleanliness, pose", "answer": "The bird in the image is a rubber duck, which is a popular stuffed toy. It is sitting next to a group of other stuffed animals, including a teddy bear and a duck. The rubber duck is positioned in the middle of the scene, surrounded by the other stuffed animals."}, {"question_id": 988, "height": 480, "width": 640, "image": "000000341719.jpg", "category": "description", "question": "Describe the skis in the following image in detail.", "dims": "cleanliness, length, pose, transparency", "region_anno": {"bbox": [294.8, 357.21, 77.76, 27.42], "segmentation": {"size": [480, 640], "counts": "jWY44l>1O00010O1O00010O00000O10O10O100000O010000O001000O01O01NO13O00000000001O1O0000001O00O100O10O01O001O01O1OM040000O01O100LNZA2e>50003L11O1H]A1h>10O10O1O1O10O01O010000O2N102LiZl3"}}, "object_label": "skis", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "length:long", "transparency:opaque", "pose:horizontal/lying"], "control_dims": "cleanliness, length, pose, transparency", "answer": "The skis in the image are red and white, and they are attached to the person's feet. The person is standing on the snow-covered ground, possibly in a park or a beach, with the skis on their feet."}, {"question_id": 989, "height": 426, "width": 640, "image": "000000346968.jpg", "category": "description", "question": "Describe the cell phone in the following image in detail.", "dims": "color, pattern, state, texture, transparency", "region_anno": {"bbox": [368.4, 222.01, 22.8, 35.08], "segmentation": {"size": [426, 640], "counts": "_bj4=j<5L3L3M3K6N1000O1O1O1O1N2N1O2M2O002L4N2M6JZaV3"}}, "object_label": "cell phone", "attribute_label": ["color:blue", "color:gray", "transparency:opaque", "pattern:plain", "state:on", "texture:smooth/sleek"], "control_dims": "transparency, color, pattern, state", "answer": "The image features a close-up view of a cell phone held in a person's hand. The phone is silver in color and has a blue light on the side, indicating that it is turned on. The person's hand is visible in the foreground, with the cell phone occupying a significant portion of the frame. The focus of the image is on the cell phone and the person's hand, emphasizing the device and its use."}, {"question_id": 990, "height": 640, "width": 427, "image": "000000372260.jpg", "category": "description", "question": "Describe the potted plant in the following image in detail.", "dims": "cleanliness, color, pattern, pose, size, transparency", "region_anno": {"bbox": [255.56, 431.68, 66.98, 65.67], "segmentation": {"size": [640, 427], "counts": "_ZR53lc02M3L3D=M3O1O2M2N2O1N2I601N5L4k]O\\Nea0g1V^O_Nga0c1V^O^Nia0m10000O0100000000O1000000000001O00000O3O0O001O1N101O1N2O1O1N2O2M101O1O0L5M3N2N2O1N4K6K6D<I^UQ2"}}, "object_label": "potted plant", "attribute_label": ["cleanliness:clean/neat", "color:red", "transparency:opaque", "pattern:floral", "pose:vertical/upright/standing", "size:small/little/tiny"], "control_dims": "cleanliness, pose, size, color, transparency, pattern", "answer": "The image features a potted plant with a mix of red and yellow flowers, sitting on a sidewalk. The plant is placed in a flower pot, which is positioned on a concrete surface. The combination of red and yellow flowers creates a vibrant and eye-catching display. The plant is surrounded by a variety of flowers, adding to the overall beauty of the scene."}, {"question_id": 991, "height": 640, "width": 568, "image": "000000406417.jpg", "category": "description", "question": "Describe the tie in the following image in detail.", "dims": "cleanliness, color, length, material, size, state, texture, transparency", "region_anno": {"bbox": [61.91, 331.69, 28.72, 26.18], "segmentation": {"size": [640, 568], "counts": "i^V13lc05L2M101O001O1OO1O001O010O000O10N201N2000O101O1O1N3N1N3M]]Z9"}}, "object_label": "tie", "attribute_label": ["cleanliness:clean/neat", "color:blue", "length:short", "material:textile/cloth/fabric/denim/cotton/jean/silk/plush", "transparency:opaque", "size:small/little/tiny", "state:folded/bend", "texture:smooth/sleek"], "control_dims": "color, texture", "answer": "The tie in the image is a blue bow tie with a red stripe. It is worn by a man and is positioned under his chin. The bow tie is a prominent feature of the man's outfit, adding a touch of elegance and style to his overall appearance."}, {"question_id": 992, "height": 425, "width": 640, "image": "000000440184.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "color, length, material, pattern, transparency", "region_anno": {"bbox": [494.75, 209.06, 48.86, 29.82], "segmentation": {"size": [425, 640], "counts": "[e]64Q=7L2N2N1O2N1O101N100O0100000000O100O1O1O1O1O1O1N3N1O1N3N001O10O010O01O0010O10O1000gW10YhN02MgQX1"}}, "object_label": "tennis racket", "attribute_label": ["color:red", "color:white", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain"], "control_dims": "length", "answer": "The tennis racket in the image is red and white, with a black handle. It is being held by a woman who is playing tennis on a court."}, {"question_id": 993, "height": 425, "width": 640, "image": "000000440184.jpg", "category": "description", "question": "Describe the tennis racket in the following image in detail.", "dims": "cleanliness, color, length, material, pattern, pose, transparency", "region_anno": {"bbox": [258.43, 218.77, 56.8, 21.41], "segmentation": {"size": [425, 640], "counts": "]T\\32W=00O10ia42T^K101O00001N100O2O001O001O1O001O01O01O000010O01O010O010O01O00100O001O1O1O1N2O2MTeV4"}}, "object_label": "tennis racket", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:opaque", "pattern:plain", "pose:horizontal/lying"], "control_dims": "cleanliness, pattern, material, transparency, length", "answer": "The tennis racket in the image is black and white, with a blue background. It is a tennis racket with a black handle and a white frame. The racket is being used by a person who is playing tennis on a court."}, {"question_id": 994, "height": 356, "width": 640, "image": "000000442456.jpg", "category": "description", "question": "Describe the handbag in the following image in detail.", "dims": "cleanliness, material, state, transparency", "region_anno": {"bbox": [606.02, 32.66, 15.4, 26.34], "segmentation": {"size": [356, 640], "counts": "Vgb64m:6K7J1O2N1O0000N3N2L4K6M2L`m6"}}, "object_label": "handbag", "attribute_label": ["cleanliness:unclean/dirt/dirty/muddy", "material:polymers/plastic/rubber/styrofoam/polymer", "transparency:transparent/translucent", "state:closed"], "control_dims": "material, state", "answer": "The handbag in the image is white and has a logo on it. It is being carried by a person, who is wearing a yellow shirt. The person is standing in front of a black background, which makes the handbag and the person's yellow shirt stand out."}, {"question_id": 995, "height": 359, "width": 640, "image": "000000449190.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "length, material, pattern, texture, transparency", "region_anno": {"bbox": [342.94, 39.43, 138.94, 130.91], "segmentation": {"size": [359, 640], "counts": "Tog3;h:8I5L4L3N3M3M3L3N4L3N4K5KhNfFi0U9WORGD4?g8LYGDOc0c8J`GDJn0Z8]OoGCHQ1V8]OSHBIP1R8]OWHBHR1o7[O[HBFV1k7WObHAFX1e7VOYIj0e6UO\\Im0b6SO_In0^6SObIn0]6ROdIn0Z6SOgIl0X6UOhIl0W6UOiIk0V6UOkIk0S6VOmIk0R6VOmIk0Q6VOZI]OH]1m6WOZI\\OIh0]OJ`72QJ3_NL^72SJh0m5YORJh0m5XOSJh0m5YOSJg0k5ZOUJf0k5ZOVJe0j5\\OUJe0j5[OVJL`N1Z73WJIbN4U74YJHbN4U74YJGeN4Q75YIUO`0a0VO5Q74YIXO??VO6R72ZIZO=>WO6R72ZIZO>=VO7Q72]IZO;>VO7Q70bJMYN3U7OdJg0\\5XOeJh0[5XOeJi0Z5WOfJi0Z5VOgJj0Y5UOhJ0VN3R7MiJOWN2P7OiJOXN1o60iJ0WN0P7OjJ4TNLR70jJ5SNKS70jJ5SNKS7OkJ6RNKS7OkJl0U5TOlJk0T5UOlJk0T5UOlJk0U5TOkJl0U5TOkJl0U5TOkJk0V5UOjJk0V5UOjJk0V5UOjJj0W5VOiJj0W5VOiJj0X5UOhJj0Y5WOfJi0Z5WOfJi0Z5WOfJh0[5XOdJi0]5VOcJj0]5VOcJj0]5VOcJi0^5XOaJh0_5XOaJg0`5YO`Jg0a5YO^Jf0c5[O\\Je0d5\\O[Jc0g5\\OXJd0i5]OVJb0k5_OTJ?o5@QJ`0o5@QJ?P6BnI>S6DkI;W6DiI;X6EhI:Y6FfI:\\6EdI8_6HaI6b6I]I6f6IZI5h6KXI2l6NRI1P7OPI0R7OmH1T7OlHNW72hHJ^75bHJ`76^HJc76]HIe76[HIg76XHIj77PHBnN8T95hGKRONY96^G;b8EYG?i8@QGe0Q9ZOjFk0X9UObFn0_9;3O001N2N1O2M4M2M4M3L4L4K8I7ITeg1"}}, "object_label": "bowl", "attribute_label": ["length:long", "material:ceramic/brick/porcelain", "transparency:transparent/translucent", "pattern:plain", "texture:smooth/sleek"], "control_dims": "pattern, texture, transparency, length", "answer": "The image features a small bowl filled with a variety of vegetables, including carrots, pickles, and peppers. The bowl is placed on a dining table, and it appears to be a healthy and colorful meal."}, {"question_id": 996, "height": 428, "width": 640, "image": "000000522638.jpg", "category": "description", "question": "Describe the teddy bear in the following image in detail.", "dims": "cleanliness, color, pattern, size, texture, transparency", "region_anno": {"bbox": [0.0, 0.09, 383.0, 423.22], "segmentation": {"size": [428, 640], "counts": "332o<35O2O00000000O100001O00O1001O00000000000000000000000000000000000000000000000000000000000000O100001O000000O11O0000000000000000000000000000O10000001O000000O100001O00000000000000000000O11O0001O0000000O100001O0O100000O1000000001O000000000000O10000001O00O10000000000`I0D0l60TI0SJNh5241TJMh526ORJOh52N1nIMf62[O0PJ0=0b5001QJO=0c5ON1SJ1<Ob50O0SJ1=Na51OOSJ46KJ0n52N0SJ2e6NXOOSJ3f6N^O0d00SOMY13gNMUJ1n62RONn02kNMXJ2m61kNMWJ3n60jNNWJ4n6NkNOUJ4151E11U62COUJ342OJ01T61DOUJ17NJ02O22R61DNVJ2R70lNOU11jNNX12Q600000fH0X10hN0TJ24L`62YOOW11iNNX12hNNX12hNNX12hNNX12Q60000000000000lINnN20MnJ1S52OMmJ1U52n0MSO3S70000000000000000000000000000000000000O1FM[C3e<MZC4o<00000O11O001O000000BLdC4[<OcC1]<NdC2k<0O1000000MKoB5\\<LjC0LOO1O4R<0oCONM17O2S<m00YOoCF0KO4R<MmC1001N100044n;LlC2001N11OO54m;1nC2ON7Ol;0oC;5El;0PDMM60J63m;1oCLO50K52l;3oC?0_Ok;LWDW1h;lNVDT1k;kNUD5Of0n;ROUD2NO0<O2R<DoCN0m0k;ROXDX1h;iNVDX1i;6OgNVDM0P1i;YOWDg0i;>0dNWD140N>g;AZDL41Nb0d;^OXDN214006I3i;H]DO100b0b;A[DN12O`0f;_OZD;O6f;@[DNM54=d;_OWDM31O1N02OOc0h;_O\\DN21Nb0e;_OZD01O12M6P<IRDO12N5P<GTD0O2O7a<H`C1I3g<L`C8`<I^C8b<JYC9g<D[C=e<C[C=f<B_C9a<G_C9a<GcC5j<0001O0000000000BLdC4\\<McC3]<LdC4Y;L\\E0[O4j<0\\NMoE3Q:MnE4R:LoE3P:NPF2o90bELZO4T;1bDL`0OE331V;2`DM7M03M25OV;3aDKa00E141U;3bDJ`00F1JN74W;3aDLa0MF60NW;<PE@H80LX;b0jDZON9OKX;d0jDXOO:NJY;d0iDYOM0M94JY;h0eDVO0NO;2IY;i0eDWO37NJY;i0fDXO150JY;i0fDVOOL2;0JY;i0fDUO0N0:1JY;j0eDTO67LKZ;P1hDUONKZ;P1hDUONKZ;Q1fDUO0JY;S1fDSO1JY;S1fDSO1JY;R1hDTONJY;S1iDSONJY;S1iDSONJY;S1iDSONJY;S1iDSONJZ;R1hDTONJZ;b1fD^NY;b1hD^NX;b1hD^NX;c1gD]NX;^1jD^NN4X;]1lD^NL5X;^1kD]NM5X;_1jD\\NN5X;g0gDJ3ZON5X;^1jD^NN4W;9hDg02TOU;j1NcNkDB0k0T;l0lDVNS;>mDc01kN04R;>mDc01kN04Q;?nDb00lN13P;l1PETNo:n1PERNn:W2O1O1N2O1NgNZEZOO2f:e0\\EWOO4d:f0\\EWO03c:g0]EWOO2a:k0_ESO02_:W2fJ\\MKe23_MIc25aMI_26dMG]27gMoNC_Lg2a4iMlNE^Ld1IlNl4NkNB`Ld1IlNj43gN@eLb1JkNh48fNf1bLRNe4<bNf1lLmM`4a0aNkNlL]23^MNb0a4j0`NjNnL^3_4mM^NhNSM[3^4PN[Na2d1aM[Nd1^MUMV4Y1VNg1dMPMU4[1UNg1eMnLU4]1TNg1eMmLU4_1QNmMiMi3OkLS4f1QNgMlM`4R4lMnMZ2o1kMoMU2o1nMoMS2n1RNPNn1o1VNkMm1S2WNjM]1_NkKd3m2kMX1aNkKa3Q3lMhLcNX4OoK`3U3lMdLdNY40nK^3[3jMX1T2lNiMU1S2QOkMo0o1RKoLU4P1h0m1BoM?o1GlM:R2JjM8S2LkM6o11nM0n18hMNR2j5K6E<H9I7ZOPD_O_<0ej[3"}}, "object_label": "teddy bear", "attribute_label": ["cleanliness:clean/neat", "color:brown", "transparency:opaque", "pattern:plain", "size:small/little/tiny", "texture:soft/fluffy/furry/hairy"], "control_dims": "color", "answer": "The image features two teddy bears sitting next to each other. One teddy bear is brown and white, while the other is white and brown. They are both sitting on a surface, possibly a table or a bed. The brown and white teddy bear has a black eye, adding a unique touch to its appearance. The bears appear to be positioned close to each other, creating a sense of companionship or togetherness."}, {"question_id": 997, "height": 640, "width": 480, "image": "000000488673.jpg", "category": "description", "question": "Describe the bowl in the following image in detail.", "dims": "cleanliness, material, pattern, size, texture, transparency", "region_anno": {"bbox": [140.73, 302.48, 54.64, 35.95], "segmentation": {"size": [640, 480], "counts": "\\Ri22fc0<J2M4L3N2N2O1O00O2O0O2O100O1O000N20010O100O1000O10O1000001O00000001N0101O000010O01O1O1O9FRl1LUja5"}}, "object_label": "bowl", "attribute_label": ["cleanliness:clean/neat", "material:glass", "transparency:transparent/translucent", "pattern:plain", "size:big/large/giant/huge", "texture:smooth/sleek"], "control_dims": "texture", "answer": "The bowl in the image is made of glass and is placed on a table. It appears to be empty and has a reflective surface, possibly due to its glass material. The bowl is positioned in the center of the table, and it is surrounded by a chair on one side and a person on the other side. The person is sitting in the chair, which is located close to the bowl."}, {"question_id": 998, "height": 640, "width": 480, "image": "000000488673.jpg", "category": "description", "question": "Describe the cup in the following image in detail.", "dims": "cleanliness, length, material, state, texture, transparency", "region_anno": {"bbox": [167.82, 257.3, 11.82, 29.68], "segmentation": {"size": [640, 480], "counts": "RlY3f01_OSc0g00000000000001N7ZOWlk5"}}, "object_label": "cup", "attribute_label": ["cleanliness:clean/neat", "length:long", "material:glass", "transparency:transparent/translucent", "state:empty", "texture:smooth/sleek"], "control_dims": "state, material, cleanliness", "answer": "The image features a tall, thin glass cup with a clear, see-through appearance. The cup is positioned vertically, and its shape is elongated, giving it a unique and elegant appearance. The glass cup is placed on a surface, possibly a table or countertop, and it appears to be empty."}, {"question_id": 999, "height": 480, "width": 640, "image": "000000556498.jpg", "category": "description", "question": "Describe the stop sign in the following image in detail.", "dims": "cleanliness, color, length, pattern, texture, transparency", "region_anno": {"bbox": [241.71, 317.71, 144.58, 74.29], "segmentation": {"size": [480, 640], "counts": "\\fb36f>;G4M2N3M3N1N1O2O1N2O0O2O1O1O001O001O000001O010O0000010O00000010O0000010O000010O000010O000001O01O01O000001O01O00010O0001O01O01O000001O01O0001O0001O01O00010O000010O0000010O0000010O000001O01O01O0001O01O0001O01O01O0001O0001O01O0001O01O01O00010O00000010O0000010O0000001O000000001O001O1O1Ne0\\O[he3"}}, "object_label": "stop sign", "attribute_label": ["cleanliness:clean/neat", "color:black", "color:white", "length:long", "transparency:opaque", "pattern:lettered", "texture:smooth/sleek"], "control_dims": "pattern, color", "answer": "The stop sign in the image is located on a street corner, with a street sign above it. The stop sign is positioned on the side of the street, and it is placed near a building. The street sign above the stop sign reads \"Duke of Gloucester.\""}, {"question_id": 1000, "height": 640, "width": 480, "image": "000000565989.jpg", "category": "description", "question": "Describe the elephant in the following image in detail.", "dims": "cleanliness, color, material, maturity, pattern, pose, size, state, texture", "region_anno": {"bbox": [13.27, 368.35, 72.21, 90.74], "segmentation": {"size": [640, 480], "counts": "_e62kc07J3N2O1M3N1N2O1N2N2O10O010N2O1O1O010000O10000O100O10000O100o\\OZOib07T]O20Mhb0P1L4L1O001O0KbNh]O^1Ub08WOXNY_Oi1f`0hNi^OY1Xa0gNf^OZ1[a0e0N3M2O100001O3M3M6J2O1N1O1O001O1O002M1000000iNS^O;la0EY^O6ha0J[^O2fa0N]^OLfa04]^OEha0:\\^O^Oha0b0k001M6Ff_f7"}}, "object_label": "elephant", "attribute_label": ["cleanliness:clean/neat", "color:gray", "material:metal/metallic/aluminum/brass/copper-zinc/iron/stainless steel/steel/silver", "maturity:adult/old/aged", "pattern:plain", "pose:vertical/upright/standing", "size:small/little/tiny", "state:dry", "texture:smooth/sleek"], "control_dims": "state", "answer": "The image features a large, golden elephant statue, which is positioned on a platform or a ledge. The elephant statue is the main focus of the scene, and it appears to be a decorative piece, possibly placed in a public space or a building. The statue's size and intricate design make it an impressive and eye-catching piece of art."}]